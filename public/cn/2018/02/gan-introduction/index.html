<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

        <title>生成对抗网络简介 (GAN Introduction) - Zeqiang Fang | 方泽强</title>

    <meta name="referrer" content="no-referrer">
    
    <meta property="og:title" content="生成对抗网络简介 (GAN Introduction) - Zeqiang Fang | 方泽强">
    <meta name="description" property="og:description" content="Generative Adversarial Networks (GAN) 生成对抗网络 (Generative Adversarial Network, GAN) 是由 Goodfellow 1 于 2014 年提出的一种对抗网络。这个网络框架包含两个部分，一个生成模型 (generative model) 和一个判别模型 (discriminative model)。其中，">
    <meta property="og:type" content="article">
    <meta property="og:site_name" content="Zeqiang Fang | 方泽强">
    <meta property="og:url" content="https://leovan.me/cn/2018/02/gan-introduction/">

    
    
    
    
    <meta name="author" property="article:author" content="范叶亮">
    
    
    
    <meta name="date" property="article:published_time" content="2018-02-03" scheme="YYYY-MM-DD">
    
    
    <meta name="date" property="article:modified_time" content="2018-02-03" scheme="YYYY-MM-DD">
    

    
    <meta name="keywords" property="article:tag" content ="GAN,DCGAN,生成对抗网络">
    
    
    <meta name="theme-color" content="#0d0d0d">
    
    <link rel="icon" type="image/png" sizes="16x16" href="/images/web/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/web/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="48x48" href="/images/web/favicon-48x48.png">
    <link rel="icon" type="image/png" sizes="62x62" href="/images/web/favicon-62x62.png">
    <link rel="icon" type="image/png" sizes="192x192" href="/images/web/favicon-192x192.png">
    <link rel="apple-touch-icon" size="192x192" href="/images/web/icon-192x192.png">
    <link rel="manifest" href="/manifest.json">
        
    

    

    <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://leovan.me/cn"
        },
        "name": "生成对抗网络简介 (GAN Introduction)",
        "headline": "生成对抗网络简介 (GAN Introduction)",
        "description" : "Generative Adversarial Networks (GAN) 生成对抗网络 (Generative Adversarial Network, GAN) 是由 Goodfellow 1 于 2014 年提出的一种对抗网络。这个网络框架包含两个部分，一个生成模型 (generative model) 和一个判别模型 (discriminative model)。其中，",
        "genre": [
            "机器学习", "深度学习"
        ],
        "datePublished": "2018-02-03",
        "dateModified": "2018-02-03",
        "wordCount": "3962",
        "keywords": [
            "GAN", "DCGAN", "生成对抗网络"
        ],
        "image": [
            "https://leovan.me/images/cn/2018-02-03-gan-introduction/zhoubotong.png", "https://leovan.me/images/cn/2018-02-03-gan-introduction/different-generator-jsd.png", "https://leovan.me/images/cn/2018-02-03-gan-introduction/mode-collapse-demo.png", "https://leovan.me/images/cn/2018-02-03-gan-introduction/mnist-gan-keras-train-history.png"
        ],
        "author": {
            "@type": "Person",
            "name": "范叶亮"
        },
        "publisher": {
            "@type": "Organization",
            "name": "范叶亮",
            "logo": {
                "@type": "ImageObject",
                "url": "https://leovan.me/images/web/publisher-logo.png"
            }
        },
        "url": "https://leovan.me/cn/2018/02/gan-introduction/"
    }
    </script>
    

    <script src='//cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js'></script>
<script src='//cdnjs.cloudflare.com/ajax/libs/js-cookie/2.2.1/js.cookie.min.js'></script>

<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/MaterialDesign-Webfont/6.5.95/css/materialdesignicons.min.css">





<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism.min.css">

<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism-.min.css">





<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<link rel="stylesheet" type="text/css" href="/css/fonts.css" />
<link rel="stylesheet" type="text/css" href="/css/style.css">
<link rel="stylesheet" type="text/css" href="/css/light.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" id="dark-mode-style" disabled="disabled">
<link rel="stylesheet" type="text/css" href="/css/icons.css">
<link rel="stylesheet" type="text/css" href="/css/print.css">

  </head>

  
  <body class="cn">
    <header class="masthead">
      

<div class="logo"></div>
<p class="slogan">优雅永不过时</p>
      <nav class="menu">
  <ul>
  
  
  
    
  
  
    <li><a href="/">首页</a></li>
  
    <li><a href="/cn/">博客</a></li>
  
    <li><a href="/categories/">分类</a></li>
  
    <li class="menu-separator"><span>&nbsp;</span></li>
  
    <li><a href="/cn/about/">关于</a></li>
  
    <li><a href="/cn/resume/">简历</a></li>
  
  


<li class="menu-separator"><span>&nbsp;</span></li>

<li><a href="/cn/index.xml" target="_blank" type="application/rss+xml" title="RSS feed">订阅</a></li>

<li><a href="https://github.com/fang-zeqiang/fang-zeqiang.github.io/blob/master/LICENSE" target="_blank" title="Attribution-NonCommercial-ShareAlike 4.0 International">版权</a></li>


  <li class="light-dark-mode no-border-bottom"><a id="light-dark-mode-action"><span id="light-dark-mode-icon" class="mdi mdi-weather-night"></span></a></li>
  </ul>
</nav>

      <script src="/js/toggle-theme.js"></script>
    </header>

    <article class="main">
      <header class="title">
      
<h1>生成对抗网络简介 (GAN Introduction)</h1>







<h3>范叶亮 / 
2018-02-03</h3>



<h3 class="post-meta">


<strong>分类: </strong>
<a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>, <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度学习</a>




/




<strong>标签: </strong>
<span>GAN</span>, <span>DCGAN</span>, <span>生成对抗网络</span>




/


<strong>字数: </strong>
3962
</h3>



<hr>


      </header>






<h1 id="generative-adversarial-networks-gan">Generative Adversarial Networks (GAN)</h1>

<p><strong>生成对抗网络</strong> (<strong>Generative Adversarial Network, GAN</strong>) 是由 Goodfellow <sup class="footnote-ref" id="fnref:goodfellow2014generative"><a href="#fn:goodfellow2014generative">1</a></sup> 于 2014 年提出的一种对抗网络。这个网络框架包含两个部分，一个生成模型 (generative model) 和一个判别模型 (discriminative model)。其中，生成模型可以理解为一个伪造者，试图通过构造假的数据骗过判别模型的甄别；判别模型可以理解为一个警察，尽可能甄别数据是来自于真实样本还是伪造者构造的假数据。两个模型都通过不断的学习提高自己的能力，即生成模型希望生成更真的假数据骗过判别模型，而判别模型希望能学习如何更准确的识别生成模型的假数据。</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/zhoubotong.png" alt="" /></p>

<h2 id="网络框架">网络框架</h2>

<p>GAN 由两部分构成，一个<strong>生成器</strong> (<strong>Generator</strong>) 和一个<strong>判别器</strong> (<strong>Discriminator</strong>)。对于生成器，我们需要学习关于数据 <code>$\boldsymbol{x}$</code> 的一个分布 <code>$p_g$</code>，首先定义一个输入数据的先验分布 <code>$p_{\boldsymbol{z}} \left(\boldsymbol{z}\right)$</code>，其次定义一个映射 <code>$G \left(\boldsymbol{z}; \theta_g\right): \boldsymbol{z} \to \boldsymbol{x}$</code>。对于判别器，我们则需要定义一个映射 <code>$D \left(\boldsymbol{x}; \theta_d\right)$</code> 用于表示数据 <code>$\boldsymbol{x}$</code> 是来自于真实数据，还是来自于 <code>$p_g$</code>。GAN 的网络框架如下图所示 <sup class="footnote-ref" id="fnref:goodfellow2016nips"><a href="#fn:goodfellow2016nips">2</a></sup>：</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/gan-framework.svg" alt="" /></p>

<h2 id="模型训练">模型训练</h2>

<p>Goodfellow 在文献中给出了一个重要的公式用于求解最优的生成器</p>

<p><code>$$
\min_{G} \max_{D} V\left(D, G\right) = \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log D\left(\boldsymbol{x}\right)\right]} + \mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}\left(\boldsymbol{z}\right)}{\left[\log \left(1 - D\left(G\left(\boldsymbol{z}\right)\right)\right)\right]}
$$</code></p>

<p>上式中，在给定的 <code>$G$</code> 的情况下，<code>$\max_{D} V\left(G, D\right)$</code>衡量的是 <code>$p_{data}$</code> 和 <code>$p_g$</code> 之间的“区别”，因此我们最终的优化目标就是找到最优的 <code>$G^*$</code> 使得 <code>$p_{data}$</code> 和 <code>$p_g$</code> 之间的“区别”最小。</p>

<p>首先，在给定 <code>$G$</code> 的时候，我们可以通过最大化 <code>$V \left(G, D\right)$</code> 得到最优 <code>$D^*$</code></p>

<p><code>$$
\begin{equation}
\begin{split}
V \left(G, D\right) &amp;= \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log D\left(\boldsymbol{x}\right)\right]} + \mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}\left(\boldsymbol{z}\right)}{\left[\log \left(1 - D\left(G\left(\boldsymbol{z}\right)\right)\right)\right]} \\
&amp;= \int_{\boldsymbol{x}}{p_{data}\left(\boldsymbol{x}\right) \log D\left(\boldsymbol{x}\right) dx} + \int_{\boldsymbol{z}}{p_{\boldsymbol{z}} \left(\boldsymbol{z}\right) \log \left(1 - D\left(g\left(\boldsymbol{z}\right)\right)\right) dz} \\
&amp;= \int_{\boldsymbol{x}}{p_{data}\left(\boldsymbol{x}\right) \log D\left(\boldsymbol{x}\right) + p_g\left(\boldsymbol{x}\right) \log \left(1 - D\left(\boldsymbol{x}\right)\right) dx}
\end{split}
\end{equation}
$$</code></p>

<p>对于给定的任意 <code>$a, b \in \mathbb{R}^2 \setminus \{0, 0\}$</code>，<code>$a \log\left(x\right) + b \log\left(1 - x\right)$</code>在 <code>$x = \dfrac{a}{a+b}$</code> 处取得最大值，<code>$D$</code> 的最优值为</p>

<p><code>$$
D_{G}^{*} = \dfrac{p_{data} \left(\boldsymbol{x}\right)}{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}
$$</code></p>

<p>因此，<code>$\max_{D} V \left(G, D\right)$</code> 可重写为</p>

<p><code>$$
\begin{equation}
\begin{split}
&amp;C\left(G\right) \\
=&amp; \max_{D} V \left(G, D\right) = V \left(G, D^*\right) \\
=&amp; \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log D_{G}^{*}\left(\boldsymbol{x}\right)\right]} + \mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}\left(\boldsymbol{z}\right)}{\left[\log \left(1 - D_{G}^{*}\left(G\left(\boldsymbol{z}\right)\right)\right)\right]} \\
=&amp; \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log D_{G}^{*}\left(\boldsymbol{x}\right)\right]} + \mathbb{E}_{\boldsymbol{x} \sim p_g\left(\boldsymbol{x}\right)}{\left[\log \left(1 - D_{G}^{*}\left(\boldsymbol{x}\right)\right)\right]} \\
=&amp; \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log \dfrac{p_{data} \left(\boldsymbol{x}\right)}{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)} \right]} + \mathbb{E}_{\boldsymbol{x} \sim p_g\left(\boldsymbol{x}\right)}{\left[\log  \dfrac{p_g \left(\boldsymbol{x}\right)}{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}\right]} \\
=&amp; \int_{x}{p_{data} \left(\boldsymbol{x}\right) \log \dfrac{\dfrac{1}{2} p_{data} \left(\boldsymbol{x}\right)}{\dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}} dx} + \int_{x}{p_g \left(\boldsymbol{x}\right) \log  \dfrac{\dfrac{1}{2} p_g \left(\boldsymbol{x}\right)}{\dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}} dx} \\
=&amp; \int_{x}{p_{data} \left(\boldsymbol{x}\right) \log \dfrac{p_{data} \left(\boldsymbol{x}\right)}{\dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}} dx} + \int_{x}{p_g \left(\boldsymbol{x}\right) \log  \dfrac{p_g \left(\boldsymbol{x}\right)}{\dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}} dx} + 2 \log \dfrac{1}{2} \\
=&amp; KL \left(p_{data} \left(\boldsymbol{x}\right) \Vert \dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}\right) + KL \left(p_g \left(\boldsymbol{x}\right) \Vert \dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}\right) - 2 \log 2 \\
=&amp; 2 JS \left(p_{data} \left(\boldsymbol{x}\right) \Vert p_g \left(\boldsymbol{x}\right) \right) - 2 \log 2
\end{split}
\end{equation}
$$</code></p>

<p>其中 <code>$KL$</code> 表示 KL 散度 <sup class="footnote-ref" id="fnref:kl-divergence"><a href="#fn:kl-divergence">3</a></sup>，<code>$JS$</code> 表示 JS 散度 <sup class="footnote-ref" id="fnref:jsd-divergence"><a href="#fn:jsd-divergence">4</a></sup>，因此在全局最优情况下 <code>$p_g = p_{data}$</code>。</p>

<p>整个 GAN 的训练过程如下所示：</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{Minibatch SGD for GAN 算法}
\begin{algorithmic}
\REQUIRE $iter, k, m$
\ENSURE $\theta_d, \theta_g$
\FOR{$i = 1, 2, ..., iter$}
    \FOR{$j = 1, 2, ..., k$}
        \STATE Sample minibatch of $m$ noise samples $\{z^{\left(1\right)}, ..., z^{\left(m\right)}\}$ from $p_g \left(\boldsymbol{z}\right)$
        \STATE Sample minibatch of $m$ examples $\{x^{\left(1\right)}, ..., x^{\left(m\right)}\}$ from $p_{data} \left(\boldsymbol{z}\right)$
        \STATE $\theta_d \gets \theta_d \textcolor{red}{+} \nabla_{\theta_d} \dfrac{1}{m} \sum_{i=1}^{m}{\left[\log D \left(x^{\left(i\right)}\right) + \log \left(1 - D \left(G \left(z^{\left(i\right)}\right)\right)\right)\right]}$
    \ENDFOR
    \STATE Sample minibatch of $m$ noise samples $\{z^{\left(1\right)}, ..., z^{\left(m\right)}\}$ from $p_g \left(\boldsymbol{z}\right)$
    \STATE $\theta_g \gets \theta_g \textcolor{red}{-} \nabla_{\theta_g} \dfrac{1}{m} \sum_{i=1}^{m}{\log \left(1 - D \left(G \left(z^{\left(i\right)}\right)\right)\right)}$
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>在实际的训练过程中，我们通常不会直接训练 <code>$G$</code> <strong>最小化</strong> <code>$\log \left(1 - D \left(G \left(\boldsymbol{z}\right)\right)\right)$</code>，因为其在学习过程中的早起处于饱和状态，因此我们通常会通过<strong>最大化</strong> <code>$\log \left(D \left(G \left(z\right)\right)\right)$</code>。</p>

<h2 id="存在的问题">存在的问题</h2>

<p>针对 GAN，包括 Goodfellow 自己在内也提出了其中包含的很多问题 <sup class="footnote-ref" id="fnref:goodfellow2016nips"><a href="#fn:goodfellow2016nips">2</a></sup>，因此后人也提出了大量的改进，衍生出了大量的 GAN 变种。本章节仅对原始的 GAN 中存在的问题进行简略介绍，相关的改进请参见后续的具体改进算法。</p>

<h3 id="js-散度问题">JS 散度问题</h3>

<p>我们在训练判别器的时候，其目标是最大化 JS 散度，但 JS 散度真的能够很好的帮助我们训练判别器吗？ Wasserstein GAN 一文 <sup class="footnote-ref" id="fnref:arjovsky2017wasserstein"><a href="#fn:arjovsky2017wasserstein">5</a></sup>给出了不同生成器情况下 JS 散度的变化情况。</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/different-generator-jsd.png" alt="" /></p>

<p>上图中，左边为一个基于 MLP 的生成器，右边为一个 DCGAN <sup class="footnote-ref" id="fnref:radford2015unsupervised"><a href="#fn:radford2015unsupervised">6</a></sup> 生成器，两者均有一个 DCGAN 的判别器。根据上文我们可以知道判别器的目标是最大化</p>

<p><code>$$
\begin{equation}
\begin{split}
L \left(D, \theta_g\right) &amp;= \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log D_{G}^{*}\left(\boldsymbol{x}\right)\right]} + \mathbb{E}_{\boldsymbol{x} \sim p_g\left(\boldsymbol{x}\right)}{\left[\log \left(1 - D_{G}^{*}\left(\boldsymbol{x}\right)\right)\right]} \\
&amp;= 2 JS \left(p_{data} \left(\boldsymbol{x}\right) \Vert p_g \left(\boldsymbol{x}\right) \right) - 2 \log 2
\end{split}
\end{equation}
$$</code></p>

<p>上图中 Y 轴绘制的为 <code>$\dfrac{1}{2} L \left(D, \theta_g\right) + \log 2$</code>，因为 <code>$-2 \log 2 \leq L \left(D, \theta_g\right) \leq 0$</code>，因此我们可得 <code>$0 \leq \dfrac{1}{2} L \left(D, \theta_g\right) + \log 2 \leq \log 2$</code>。从图中我们可以看出，针对两种不同的情况，其值均很快的逼近最大值 <code>$\log 2 \approx 0.69$</code>，当接近最大值的时候，判别器将具有接近于零的损失，此时我们可以发现，尽管 JS 散度很快趋于饱和，但 DCGAN 生成器的效果却仍在不断的变好，因此，使用 JS 散度作为判别其的目标就显得不是很合适。</p>

<h3 id="多样性问题-mode-collapse">多样性问题 Mode Collapse</h3>

<p>Mode Collapse 问题是指生成器更多的是生成了大量相同模式的数据，导致的结果就是生成的数据缺乏多样性，如下图所示 <sup class="footnote-ref" id="fnref:mlds-gan-basic-idea"><a href="#fn:mlds-gan-basic-idea">7</a></sup>:</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/mode-collapse-demo.png" alt="" /></p>

<p>不难看出，其中红色方框圈出来的图像十分相似，这样的问题我们就称之为 Mode Collapse。Goolfellow 曾经从不同的 KL 散度的角度解释引起 Mode Collapse 的问题，但最后发现其并非由散度的不同所导致。对于 KL 散度，其并非是对称的，即 <code>$D_{KL} \left(p_{data} \Vert p_{model}\right)$</code> 与 <code>$D_{KL} \left(p_{model} \Vert p_{data}\right)$</code> 是不同的。在最大化似然估计的时候使用的是前者，而在最小化 JS 散度的时候使用的更类似于后者。如下图所示</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/difference-of-kl-distributation.svg" alt="" /></p>

<p>假设我们的模型 <code>$q$</code> 并没有足够能能力去拟合真实数据分布 <code>$p$</code>，假设真实数据由两个二维的高斯分布构成，而模型需要使用一个一维的高斯分布去拟合。在左图中，模型更倾向于覆盖两个高斯分布，也就是说其更倾向与在有真实数据的地方得到更大的概率。在右图中，模型更倾向于覆盖其中一个高斯分布，也就是说其更倾向于在没有真实数据的地方取得更小的概率。这样，如果我们用 JS 散度训练模型的时候就容易出现模式缺失的问题，但尽管我们利用前者去优化模型，但结果中仍然出现了 Mode Collapse 的问题，这也就说明并非 JS 散度问题导致的 Mode Collapse。</p>

<p>针对 Mode Collapse 的问题，出现了大量不同角度的优化</p>

<ul>
<li>基于正则化的优化 <sup class="footnote-ref" id="fnref:che2016mode"><a href="#fn:che2016mode">8</a></sup></li>
<li>基于 Minibatch 的优化 <sup class="footnote-ref" id="fnref:salimans2016improved"><a href="#fn:salimans2016improved">9</a></sup></li>
<li>基于 Unrolled Optimization 的优化 <sup class="footnote-ref" id="fnref:metz2016unrolled"><a href="#fn:metz2016unrolled">10</a></sup></li>
<li>基于集成算法的优化 <sup class="footnote-ref" id="fnref:tolstikhin2017adagan"><a href="#fn:tolstikhin2017adagan">11</a></sup></li>
</ul>

<h2 id="mnist-示例">MNIST 示例</h2>

<p>我们利用 MNIST 数据集测试原始的 GAN 模型的效果，代码主要参考了 <a href="https://github.com/eriklindernoren/Keras-GAN" rel="noreferrer" target="_blank"><code>Keras-GAN</code></a>，最终实现代码详见 <a href="https://github.com/leovan/leovan.me/tree/master/scripts/cn/2018-02-03-gan-introduction/image_gan_keras.py" rel="noreferrer" target="_blank"><code>image_gan_keras.py</code></a>，我们简单对其核心部分进行说明。</p>

<ul>
<li><p>生成器</p>

<pre><code class="language-python">def build_generator(self):
  model = Sequential()
  
  model.add(Dense(int(self._hidden_dim / 4),
                      input_shape=self._noise_shape))
  model.add(LeakyReLU(alpha=0.2))
  model.add(BatchNormalization(momentum=0.8))
  model.add(Dense(int(self._hidden_dim / 2)))
  model.add(LeakyReLU(alpha=0.2))
  model.add(BatchNormalization(momentum=0.8))
  model.add(Dense(self._hidden_dim))
  model.add(LeakyReLU(alpha=0.2))
  model.add(BatchNormalization(momentum=0.8))
  model.add(Dense(np.prod(self._input_shape), activation='tanh'))
  model.add(Reshape(self._input_shape))
  
  print('Generator Summary: ')
  model.summary()
  
  noise = Input(shape=self._noise_shape)
  image = model(noise)
      
  return Model(noise, image)
</code></pre></li>
</ul>

<p>在生成器中，我们使用了一个包含3个隐含层的全链接网络，其中 <code>self._hidden_dim</code> 是我们定义的隐含节点最多一层的节点数；<code>self._noise_shape</code> 为用于生成器的噪音数据的形状；<code>self._input_shape</code> 为输入数据形状，即图片数据的形状，中间层次采用的激活函数为 <code>LeakyReLU</code>，最后一层采用的激活函数为 <code>tanh</code>。</p>

<ul>
<li><p>判别器</p>

<pre><code class="language-python">def build_discriminator(self):
  model = Sequential()
  
  model.add(Flatten(input_shape=self._input_shape))
  model.add(Dense(int(self._hidden_dim / 2)))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(int(self._hidden_dim / 4)))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(1, activation='sigmoid'))
  
  print('Discriminator Summary: ')
  model.summary()
  
  image = Input(shape=self._input_shape)
  label = model(image)
      
  return Model(image, label)
</code></pre></li>
</ul>

<p>在判别器中，我们使用了一个包含2个隐含层的全链接网络，中间层次采用的激活函数为 <code>LeakyReLU</code>，最后一层采用的激活函数为 <code>sigmoid</code>。</p>

<ul>
<li><p>对抗网络</p>

<pre><code class="language-python">class ImageBasicGAN():
  def __init__(self, width, height, channels,
               a_optimizer=Adam(1e-4, beta_1=0.5),
               g_optimizer=Adam(1e-4, beta_1=0.5),
               d_optimizer=Adam(1e-4, beta_1=0.5),
               noise_dim=100, hidden_dim=1024):
      '''
  
      Args:
          width: 图像宽度
          height: 图像高度
          channels: 图像颜色通道数
          a_optimizer: 对抗网络优化器
          g_optimizer: 生成器优化器
          d_optimizer: 判别器优化器
          noise_dim: 噪音数据维度
          hidden_dim: 隐含层最大维度
      '''
          
      # 省略一大坨代码
  
      # 构建和编译判别器
      self._discriminator = self.build_discriminator()
      self._discriminator.compile(loss='binary_crossentropy',
                                  optimizer=d_optimizer,
                                  metrics=['accuracy'])
  
      # 构建和编译生成器
      self._generator = self.build_generator()
      self._generator.compile(loss='binary_crossentropy',
                              optimizer=g_optimizer)
  
      # 生成器利用噪声数据作为输入
      noise = Input(shape=self._noise_shape)
      generated_image = self._generator(noise)
  
      # 当训练整个对抗网络时，仅训练生成器
      self._discriminator.trainable = False
  
      # 判别器将生成的图像作为输入
      label = self._discriminator(generated_image)
  
      # 构建和编译整个对抗网络
      self._adversarial = Model(noise, label)
      self._adversarial.compile(loss='binary_crossentropy',
                                optimizer=a_optimizer)
</code></pre></li>
</ul>

<p>在构造整个对抗网络的时候，需要注意我们训练完判别器后，通过训练整个对抗网络进而训练生成器的时候是固定住训练好的判别器的，因此在训练整个对抗网络的时候我们应该将判别器置为无需训练的状态。</p>

<ul>
<li><p>训练过程</p>

<pre><code class="language-python">def train(self, x_train, output_dir, iters,
        batch_size=32, k=1, save_interval=200):
  ''' 训练模型
  
  Args:
      x_train: 训练数据
      output_dir: 相关输出路径
      iters: 迭代次数
      batch_size: 批大小
      k: K
      save_interval: 结果保存间隔
  '''
      
  # 省略一大坨代码
  
  for iter in range(iters):
      # 训练判别器
      for _ in range(k):
          train_indices = np.random.randint(0, x_train.shape[0],
                                            batch_size)
          train_images = x_train[train_indices]
  
          noises = np.random.normal(0, 1, (batch_size, self._noise_dim))
          generated_images = self._generator.predict(noises)
  
          self._discriminator.train_on_batch(train_images,
                                             np.ones((batch_size, 1)))
          self._discriminator.train_on_batch(generated_images,
                                             np.zeros((batch_size, 1)))
              
      # 训练生成器
      noises = np.random.normal(0, 1, (batch_size, self._noise_dim))
      labels = np.ones(batch_size)
  
      self._adversarial.train_on_batch(noises, labels)
  
  # 再省略一大坨代码
</code></pre></li>
</ul>

<p>在训练整个对抗网络的时候，我们对于一个给定的生成器，我们将生成器生成的数据作为负样本，将从真实数据中采样的数据作为正样本训练判别器。Goodfellow 在描述 GAN 训练的过程中，对于给定的生成器，训练判别器 <code>$k$</code> 次，不过通常取 <code>$k = 1$</code>。训练好判别器后，再随机生成噪音数据用于训练生成器，周而复始直至达到最大迭代次数。</p>

<p>在整个训练过程中，我们分别记录了判别器和生成器的损失的变化，以及判别器的准确率的变化，如下图所示：</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/mnist-gan-keras-train-history.png" alt="" /></p>

<p>从上图中我们可以看出，在训练开始阶段，判别器能够相对容易的识别出哪些数据是来自于真实数据的采样，哪些数据是来自于生成器的伪造数据。随着训练的不断进行，判别器的准确率逐渐下降，并稳定在 60% 左右，也就是说生成器伪造的数据越来越像真实的数据，判别器越来越难进行甄别。</p>

<p>下图中我们展示了利用 MNIST 数据集，进行 30000 次的迭代，每 1000 次截取 100 张生成器利用相同噪音数据伪造的图像，最后合成的一张生成图片的变化动图。</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/mnist-gan-generated-images.gif" alt="" /></p>

<h1 id="deep-convolutional-gan">Deep Convolutional GAN</h1>

<p>DCGAN (Deep Convolutional GAN) 是由 Radford <sup class="footnote-ref" id="fnref:radford2015unsupervised"><a href="#fn:radford2015unsupervised">6</a></sup> 等人提出的一种对原始 GAN 的变种，其基本的思想就是将原始 GAN 中的全链接层用卷积神经网络代替。在文中，Radford 等人给出构建一个稳定的 DCGAN 的建议，如下：</p>

<ul>
<li>在网络中不使用 pooling 层，而是使用多步长的卷积层 (判别器) 和多步长的反卷积层 (生成器)。</li>
<li>在生成器和判别器中均使用批标准化。</li>
<li>对于深层的框架，去掉全链接层。</li>
<li>在生成器中使用 ReLU 激活函数，最后一层使用 Tanh 激活函数。</li>
<li>在判别器中使用 LeakyReLU 激活函数。</li>
</ul>

<p>我们利用 MNIST 数据集测试 DCGAN 模型的效果，最终实现代码详见 <a href="https://github.com/leovan/leovan.me/tree/master/scripts/cn/2018-02-03-gan-introduction/image_dcgan_keras.py" rel="noreferrer" target="_blank"><code>image_dcgan_keras.py</code></a>。训练过程中判别器和生成器的损失的变化，以及判别器的准确率的变化，如下图所示：</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/mnist-dcgan-keras-train-history.png" alt="" /></p>

<p>下图中我们展示了利用 MNIST 数据集，进行 30000 次的迭代，每 1000 次截取 100 张生成器利用相同噪音数据伪造的图像，最后合成的一张生成图片的变化动图。</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/mnist-dcgan-generated-images.gif" alt="" /></p>

<p>从生成的结果中可以看出，DCGAN 生成的图片的质量还是优于原始的 GAN 的，在原始的 GAN 中我们能够明显的看出其中仍旧包含大量的噪音点，而在 DCGAN 中这种情况几乎不存在了。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:goodfellow2014generative">Goodfellow, Ian, et al. &ldquo;Generative adversarial nets.&rdquo; <em>Advances in neural information processing systems</em>. 2014.
 <a class="footnote-return" href="#fnref:goodfellow2014generative">↩</a></li>
<li id="fn:goodfellow2016nips">Goodfellow, Ian. &ldquo;NIPS 2016 tutorial: Generative adversarial networks.&rdquo; <em>arXiv preprint arXiv:1701.00160</em> (2016).
 <a class="footnote-return" href="#fnref:goodfellow2016nips">↩</a></li>
<li id="fn:kl-divergence"><a href="https://en.wikipedia.org/wiki/Kullback–Leibler_divergence" rel="noreferrer" target="_blank">https://en.wikipedia.org/wiki/Kullback–Leibler_divergence</a>
 <a class="footnote-return" href="#fnref:kl-divergence">↩</a></li>
<li id="fn:jsd-divergence"><a href="https://en.wikipedia.org/wiki/Jensen–Shannon_divergence" rel="noreferrer" target="_blank">https://en.wikipedia.org/wiki/Jensen–Shannon_divergence</a>
 <a class="footnote-return" href="#fnref:jsd-divergence">↩</a></li>
<li id="fn:arjovsky2017wasserstein">Arjovsky, Martin, Soumith Chintala, and Léon Bottou. &ldquo;Wasserstein gan.&rdquo; <em>arXiv preprint arXiv:1701.07875</em> (2017).
 <a class="footnote-return" href="#fnref:arjovsky2017wasserstein">↩</a></li>
<li id="fn:radford2015unsupervised">Radford, Alec, Luke Metz, and Soumith Chintala. &ldquo;Unsupervised representation learning with deep convolutional generative adversarial networks.&rdquo; <em>arXiv preprint arXiv:1511.06434</em> (2015).
 <a class="footnote-return" href="#fnref:radford2015unsupervised">↩</a></li>
<li id="fn:mlds-gan-basic-idea"><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2017/Lecture/GAN%20(v11).pdf" rel="noreferrer" target="_blank">http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2017/Lecture/GAN%20(v11).pdf</a>
 <a class="footnote-return" href="#fnref:mlds-gan-basic-idea">↩</a></li>
<li id="fn:che2016mode">Che, Tong, et al. &ldquo;Mode regularized generative adversarial networks.&rdquo; <em>arXiv preprint arXiv:1612.02136</em> (2016).
 <a class="footnote-return" href="#fnref:che2016mode">↩</a></li>
<li id="fn:salimans2016improved">Salimans, Tim, et al. &ldquo;Improved techniques for training gans.&rdquo; <em>Advances in Neural Information Processing Systems.</em> 2016.
 <a class="footnote-return" href="#fnref:salimans2016improved">↩</a></li>
<li id="fn:metz2016unrolled">Metz, Luke, et al. &ldquo;Unrolled generative adversarial networks.&rdquo; <em>arXiv preprint arXiv:1611.02163</em> (2016).
 <a class="footnote-return" href="#fnref:metz2016unrolled">↩</a></li>
<li id="fn:tolstikhin2017adagan">Tolstikhin, Ilya O., et al. &ldquo;Adagan: Boosting generative models.&rdquo; <em>Advances in Neural Information Processing Systems.</em> 2017.
 <a class="footnote-return" href="#fnref:tolstikhin2017adagan">↩</a></li>
</ol>
</div>



<link rel="stylesheet" href="/css/donate.css" />


<div class="donate">
  <div class="donate-header"></div>
  <div class="donate-slug" id="donate-slug">gan-introduction</div>
  <button class="donate-button">赞 赏</button>
  <div class="donate-footer">「真诚赞赏，手留余香」</div>
</div>
<div class="donate-modal-wrapper">
  <div class="donate-modal">
    <div class="donate-box">
      <div class="donate-box-content">
        <div class="donate-box-content-inner">
          <div class="donate-box-header">「真诚赞赏，手留余香」</div>
          <div class="donate-box-body">
            <div class="donate-box-money">
              <button class="donate-box-money-button donate-box-money-button-unchecked" id="donate-box-money-button-2" data-v="2" data-unchecked="￥ 2" data-checked="2 元">￥ 2</button>
              <button class="donate-box-money-button donate-box-money-button-unchecked" id="donate-box-money-button-5" data-v="5" data-unchecked="￥ 5" data-checked="5 元">￥ 5</button>
              <button class="donate-box-money-button donate-box-money-button-unchecked" id="donate-box-money-button-10" data-v="10" data-unchecked="￥ 10" data-checked="10 元">￥ 10</button>
              <button class="donate-box-money-button donate-box-money-button-unchecked" id="donate-box-money-button-50" data-v="50" data-unchecked="￥ 50" data-checked="50 元">￥ 50</button>
              <button class="donate-box-money-button donate-box-money-button-unchecked" id="donate-box-money-button-100" data-v="100" data-unchecked="￥ 100" data-checked="100 元">￥ 100</button>
              <button class="donate-box-money-button donate-box-money-button-unchecked" id="donate-box-money-button-custom" data-v="custom" data-unchecked="任意金额" data-checked="任意金额">任意金额</button>
            </div>
            <div class="donate-box-pay">
              <img class="donate-box-pay-qrcode" id="donate-box-pay-qrcode" src=""/>
            </div>
          </div>
          <div class="donate-box-footer">
            <div class="donate-box-pay-method donate-box-pay-method-checked" data-v="wechat-pay">
              <img class="donate-box-pay-method-image" id="donate-box-pay-method-image-wechat-pay" src=""/>
            </div>
            <div class="donate-box-pay-method" data-v="alipay">
              <img class="donate-box-pay-method-image"  id="donate-box-pay-method-image-alipay" src=""/>
            </div>
          </div>
        </div>
      </div>
    </div>
    <button type="button" class="donate-box-close-button">
      <svg class="donate-box-close-button-icon" fill="#fff" viewBox="0 0 24 24" width="24" height="24"><path d="M13.486 12l5.208-5.207a1.048 1.048 0 0 0-.006-1.483 1.046 1.046 0 0 0-1.482-.005L12 10.514 6.793 5.305a1.048 1.048 0 0 0-1.483.005 1.046 1.046 0 0 0-.005 1.483L10.514 12l-5.208 5.207a1.048 1.048 0 0 0 .006 1.483 1.046 1.046 0 0 0 1.482.005L12 13.486l5.207 5.208a1.048 1.048 0 0 0 1.483-.006 1.046 1.046 0 0 0 .005-1.482L13.486 12z" fill-rule="evenodd"></path></svg>
    </button>
  </div>
</div>

<script type="text/javascript" src="/js/donate.js"></script>
</script>


  <footer>
  
<nav class="post-nav">
  <span class="nav-prev">&larr; <a href="/cn/2018/01/ising-hopfield-and-rbm/">Ising 模型，Hopfield 网络和受限的玻尔兹曼机 (Ising, Hopfield and RBM)</a></span>
  <span class="nav-next"><a href="/cn/2018/02/optimization-methods-for-deeplearning/">深度学习优化算法 (Optimization Methods for Deeplearning)</a> &rarr;</span>
</nav>
<script type="text/javascript">
document.addEventListener('keyup', function(e) {
  if (e.target.nodeName.toUpperCase() != 'BODY') return;
  var url = false;
  if (e.which == 37) {  
    
    url = '\/cn\/2018\/01\/ising-hopfield-and-rbm\/';
    
  } else if (e.which == 39) {  
    
    url = '\/cn\/2018\/02\/optimization-methods-for-deeplearning\/';
    
  }
  if (url) window.location = url;
});
</script>




<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-2608165017777396"
     data-ad-slot="1261604535"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>





<section class="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
    this.page.url = "https:\/\/zeqiang.fun" + location.pathname;
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var disqus_js = '//Zeqiang.disqus.com/embed.js';
    var d = document, s = d.createElement('script');
    s.src = disqus_js; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    var t = d.getElementById('disqus_thread');
    var b = false, l = function(scroll) {
      if (b) return;
      (d.head || d.body).appendChild(s); b = true;
      if (scroll) t.scrollIntoView();
    }
    s.onerror = function(e) {
      if (sessionStorage.getItem('failure-note')) return;
      t.innerText = 'Sorry, but you cannot make comments because Disqus failed to load for some reason. It is known to be blocked in China. If you are sure it is not blocked in your region, please refresh the page. 中国大陆地区读者需要翻墙才能发表评论。';
      sessionStorage.setItem('failure-note', true);
    };
    
    if (location.hash.match(/^#comment-[0-9]+$/)) return l(true);
    var c = function() {
      if (b) return;
      var rect = t.getBoundingClientRect();
      if (rect.top < window.innerHeight && rect.bottom >= 0) l();
    };
    window.addEventListener('load', c);
    d.addEventListener('scroll', c);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>





<script src="//cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/plugins/autoloader/prism-autoloader.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/plugins/show-language/prism-show-language.min.js"></script>

<script>
    (function() {
        if (!self.Prism) {
            return;
        }

        Prism.languages.dos = Prism.languages.powershell;
        Prism.languages.gremlin = Prism.languages.groovy;

        var Languages = {
            'r': 'R', 'python': 'Python', 'xml': 'XML', 'html': 'HTML',
            'yaml': 'YAML', 'latex': 'LaTeX', 'tex': 'TeX',
            'powershell': 'PowerShell', 'javascript': 'JavaScript',
            'dos': 'DOS', 'qml': 'QML', 'json': 'JSON', 'bash': 'Bash',
            'text': 'Text', 'txt': 'Text', 'sparql': 'SPARQL',
            'gremlin': 'Gremlin', 'cypher': 'Cypher', 'ngql': 'nGQL',
            'shell': 'Shell', 'sql': 'SQL', 'apacheconf': 'Apache Configuration'
        };

        Prism.hooks.add('before-highlight', function(env) {
        	var language = Languages[env.language] || env.language;
        	env.element.setAttribute('data-language', language);
        });
    })();
</script>




<script async src="/js/fix-toc.js"></script>
<script async src="/js/center-img.js"></script>
<script async src="/js/right-quote.js"></script>
<script async src="/js/fix-footnote.js"></script>
<script async src="/js/external-link.js"></script>
<script async src="/js/alt-title.js"></script>
<script src="/js/no-highlight.js"></script>
<script src="/js/math-code.js"></script>


<script>
window.MathJax = {
  loader: {
    load: ['[tex]/boldsymbol']
  },
  tex: {
    tags: "all",
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    packages: {
      '[+]': ['boldsymbol']
    }
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-chtml.js" crossorigin></script>


<script src="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script type="text/javascript">
$(document).ready(function() {
    var captionCount = 0;
    $(".pseudocode").each(function() {
        var pseudocode_options = {
            indentSize: '1.2em',
            commentDelimiter: '\/\/',
            lineNumber:  true ,
            lineNumberPunc: ':',
            noEnd:  false 
        };
        pseudocode_options.captionCount = captionCount;
        captionCount += 1;
        var codeEl = $(this).get(0);
        pseudocode.render(codeEl.textContent, codeEl.parentElement, pseudocode_options);
    });
});
</script>






<script async src="/js/load-typekit.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lazysizes/5.3.2/lazysizes.min.js"></script>

<script src="//cdn.jsdelivr.net/npm/vanilla-back-to-top@latest/dist/vanilla-back-to-top.min.js"></script>
<script>
addBackToTop({
  diameter: 48
})
</script>



  <hr>
  <div class="copyright no-border-bottom">
    <div class="copyright-author-year">
      <span>&copy; 2017-2021 Leo Van</span>
    </div>
    <div class="copyright-links">
      <a href="https://github.com/leovan" rel="noreferrer" target="_blank">Github</a>
      <span> · </span>
      <a href="https://orcid.org/0000-0002-9556-7821" rel="noreferrer" target="_blank">ORCID</a>
      <span> · </span>
      <span>I am Mr. Black.</span>
    </div>
  </div>
  </footer>
  </article>
  </body>
</html>

