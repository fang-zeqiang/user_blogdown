<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on Zeqiang Fang | 方泽强</title>
    <link>http://zeqiang.fun/user_blogdown/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on Zeqiang Fang | 方泽强</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 17 Oct 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://zeqiang.fun/user_blogdown/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>你所应该知道的 A/B 测试 (A/B Test You Should Know)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2021/10/abtest-you-should-know/</link>
      <pubDate>Sun, 17 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2021/10/abtest-you-should-know/</guid>
      <description>
        <![CDATA[
        

<h2 id="什么是-a-b-测试">什么是 A/B 测试</h2>

<p><strong>A/B 测试</strong>是一种随机测试，将两个不同的东西（即 A 和 B）进行假设比较。A/B 测试可以用来测试某一个变量两个不同版本的差异，一般是让 A 和 B 只有该变量不同，再测试目标对于 A 和 B 的反应差异，再判断 A 和 B 的方式何者较佳 <sup class="footnote-ref" id="fnref:wikipedia-abtest"><a href="#fn:wikipedia-abtest">1</a></sup>。A/B 测试的前身为双盲测试 <sup class="footnote-ref" id="fnref:wikipedia-blinded-experiment"><a href="#fn:wikipedia-blinded-experiment">2</a></sup>，在双盲测试中人员会被随机分为两组，受试验的对象及研究人员并不知道哪些对象属于对照组，哪些属于实验组，通过一段时间的实验后对比两组人员的结果是否有明显差异。在各种科学研究领域中，从医学、食品、心理到社会科学及法证都有使用双盲方法进行实验。</p>

<p>一个简单的 A/B 测试流程如下：</p>

<p><img src="/images/cn/2021-10-17-abtest-you-should-know/abtest.png" alt="" /></p>

<ol>
<li>对目标人群进行随机划分，以进行有效的独立随机实验。</li>
<li>对不同分组应用不同的策略。</li>
<li>在确保实验有效的前提下，对不同分组的结果进行分析，以确定不同策略的优劣。</li>
</ol>

<p>A/B 测试的主要目的是帮助我们更加科学的判断不同策略的优劣性，避免拍脑门的决策，不给杠精们互相 BATTLE 的机会。同时我们也需要认识到 A/B 测试只是一个工具，它能够帮助我们对产品和策略进行不断优化，但对产品和策略的创新更多还是需要洞察力。它可以让我们在已达到的山上越来越高，却不能用它来发现一座新的山脉。一句话：A/B 测试不是万能的，但离开 A/B 测试是万万不能的。</p>

<h2 id="a-b-测试的科学性">A/B 测试的科学性</h2>

<h3 id="流量分配">流量分配</h3>

<p>进行 A/B 测试的第一个问题就是如何划分用户，如果采用上面简单五五开的方式我们一次只能做一个实验，当我们需要同时做多个实验时就无法满足了。如果对用户分成多个桶，当桶的数量过多时，每个桶中的用户数量就会过少，从而会导致实验的置信度下降。</p>

<p>为了保证可以使用相同的流量开展不同的实验，同时各个实验之间不能相关干扰，我们需要采用正交实验。正交实验的思想如下：</p>

<p><img src="/images/cn/2021-10-17-abtest-you-should-know/orthogonal-experiment.png" alt="" /></p>

<p>每个独立实验为一层，层与层之间的流量是正交的，流量经过一层实验后会再次被随机打散。</p>

<p>有些情况下实验并不是独立的，例如同时对按钮和背景的颜色进行实验，按钮和背景颜色之间并不是独立的（即有些按钮和背景颜色搭配从设计角度是不可行的，没有必要进行实验），这种情况下我们需要采用互斥实验。互斥实验的思想如下：</p>

<p><img src="/images/cn/2021-10-17-abtest-you-should-know/mutual-experiment.png" alt="" /></p>

<p>实验在同一层进行流量拆分，不同组之间的流量是没有重叠的。</p>

<p>在 A/B 测试中，当多个实验内容相互影响应选择互斥方法分配流量，当多个实验内容不会相互影响应选择正交方法分配流量。更加精细的流量分类和控制可以参考 Google 的论文 <em>Overlapping Experiment Infrastructure: More, Better, Faster Experimentation</em> <sup class="footnote-ref" id="fnref:tang2010overlapping"><a href="#fn:tang2010overlapping">3</a></sup>。</p>

<h3 id="评价指标选择">评价指标选择</h3>

<p>在设计实验之前我们需要明确实验的目标，根据目标才能确定合理的评价指标。更多情况下我们应该从业务的视角出发选择合适的评价指标，我们以风险策略模型实验为例，我们可以从技术和业务角度选择不同的评价指标：</p>

<ol>
<li>技术角度：准确率和召回率</li>
<li>业务角度：客诉率和追损金额</li>
</ol>

<p>单纯从技术角度出发我们会忽视很多现实问题，例如两个策略的准确率和召回率差不多，但识别的结果人群不一样，这些人造成的损失也可能不一样。因此能够帮助我们追回更多损失同时有更小的客诉率才是更优的策略。</p>

<p>在进行实验时结果指标至关重要，但有时我们也应该关注一些过程指标。以页面优化实验为例，可能的过程指标和结果指标有：</p>

<ol>
<li>过程指标：页面平均停留时间，页面跳出率等</li>
<li>结果指标：商品加购率，商品转化率等</li>
</ol>

<p>策略和模型最终都是要为业务服务的，因此我们应常关注业务指标，一些常用的业务指标有：点击率（CTR）、转化率（CVR）、千次展示收入（RPM）等。</p>

<h3 id="有效性检验">有效性检验</h3>

<p>当实验完成得到结果后，我们还需要判断实验结果是否有效，这部分主要依靠统计学中的假设检验进行分析。针对两个实验在确定合理的统计量后，需要构建如下两个假设：</p>

<ul>
<li><strong>原假设</strong> $H_0$：两个实验的统计量无差异</li>
<li><strong>备选假设</strong> $H_1$：两个实验的统计量有差异</li>
</ul>

<p>对于假设检验只可能有两种结果：一个是接受原假设，一个是拒绝原假设。在进行假设检验过程中，容易犯两类错误：</p>

<table>
<thead>
<tr>
<th align="center">是否接受原假设 \ 假设真伪</th>
<th align="center">$H_0$ 为真</th>
<th align="center">$H_1$ 为真</th>
</tr>
</thead>

<tbody>
<tr>
<td align="center">拒绝原假设</td>
<td align="center">第一类错误<br/>$\alpha$：显著水平</td>
<td align="center">正确决策<br/>$1 - \alpha$：置信度</td>
</tr>

<tr>
<td align="center">接受原假设</td>
<td align="center">正确决策<br/>$1 - \beta$：统计功效</td>
<td align="center">第二类错误<br/>$\beta$</td>
</tr>
</tbody>
</table>

<p>第一类错误（弃真）即原假设为真时拒绝原假设，犯第一类错误的概率为 $\alpha$，即显著水平。第二类错误（取伪）即原假设为假时未拒绝原假设，犯第二类错误的概率为 $\beta$。</p>

<p>在进行有效性检验时我们有多个指标可以参考：</p>

<ol>
<li>P 值。P 值就是当原假设为真时，比所得到的样本观察结果更极端的结果出现的概率。如果 P 值很小，说明原假设情况的发生的概率很小，而如果出现了，根据小概率原理，我们就有理由拒绝原假设，P 值越小，我们拒绝原假设的理由越充分。</li>
<li>置信区间。置信区间就是分别以统计量的置信上限和置信下限为上下界构成的区间。置信水平是指包含总体平均值的概率是多大，例如：95% 的置信水平表示，如果有 100 个样本，可以构造出 100 个这样的区间，有 95% 的可能性包含总体平均值。在 A/B 测试时，如果置信区间上下限的值同为正或负，则认为存在有显著差异的可能性；如果同时有正值和负值，则认为不存在有显著差异的可能性。</li>
<li>统计功效。一般情况下我们希望拒绝原假设，得到新的结论，即在进行 A/B 测试时希望实验组的效果优于对照组。也就是我们希望不要出现在应该拒绝原假设时却没有拒绝的情况，即犯第二类错误。统计功效就是我们没有犯第二类错误的概率 $1 - \beta$，在进行 A/B 测试时表示当两个策略之间存在显著差异时，实验能正确做出存在差异判断的概率。</li>
</ol>

<p>综上，我们可以认为当 A/B 测试实验数据在 95% 的置信水平区间内，P 值小于0.05，功效大于 80% 的情况下，实验结果是可信赖的。</p>

<h2 id="a-a-测试">A/A 测试</h2>

<p>在做 A/B 测试的时候，有时尽管我们发现 A/B 两组有明显差异，但我们依旧无法确认这种差异是由于实验条件不同还是 A/B 两组用户本身的差异带来的。尽管 A/B 两组用户是随机抽样，但两组用户在空跑期（即实验条件一致）也会出现显著差异。因此为了避免这个问题，我们会选择进行 A/A 测试，即在正式开启实验之前，先进行一段时间的空跑，对 A/B 两组用户采用同样的实验条件，一段时间后，再看两组之间的差异。如果差异显著，数据弃之不用，重新选组。如果差异不显著，记录两组之间的均值差，然后在实验期结束时，用实验期的组间差异减去空跑期的组间差异得到最终实验结果。</p>

<p>A/A 测试也会存在一些局限，在实际情况中，组间差异是一定存在。因此在这个前提下，可以用统计方式来衡量差异大小，在计算实验效果的时候，把差异考虑在内即可。差异产生的主要原因就是“随机性”，我们同样可以利用置信度和置信区间来描述 A/A 实验的波动。在进行实验时直接进行 A/B 测试，不需要考虑 A/A 测试，在分析结果时，需要考虑 A/B 测试实验之间的差异要大于 A/A 测试实验之间的差异。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:wikipedia-abtest"><a href="https://zh.wikipedia.org/wiki/A/B測試" rel="noreferrer" target="_blank">https://zh.wikipedia.org/wiki/A/B測試</a>
 <a class="footnote-return" href="#fnref:wikipedia-abtest">↩</a></li>
<li id="fn:wikipedia-blinded-experiment"><a href="https://zh.wikipedia.org/wiki/雙盲" rel="noreferrer" target="_blank">https://zh.wikipedia.org/wiki/雙盲</a>
 <a class="footnote-return" href="#fnref:wikipedia-blinded-experiment">↩</a></li>
<li id="fn:tang2010overlapping">Tang, Diane, et al. &ldquo;Overlapping experiment infrastructure: More, better, faster experimentation.&rdquo; <em>Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</em>. 2010.
 <a class="footnote-return" href="#fnref:tang2010overlapping">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>图存储与计算（Network Storage &amp; Computing)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2021/01/network-storage-and-computing/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2021/01/network-storage-and-computing/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文为<a href="/categories/复杂网络/">《复杂网络系列》</a>文章</p>
</blockquote>

<h2 id="图存储">图存储</h2>

<h3 id="语义网络与-rdf-存储">语义网络与 RDF 存储</h3>

<p>1968 年 Ross Quillian 在其博士论文中最先提出<strong>语义网络</strong>（Semantic Web），把它作为人类联想记忆的一个显式心理学模型，并在他设计的可教式语言理解器 TLC（Teachable Language Comprehenden）中用作知识表示方法。</p>

<p>语义网络的基本思想是在网络中，用“节点”代替概念，用节点间的“连接弧”（称为联想弧）代替概念之间的关系，因此，语义网络又称联想网络。它在形式上是一个带标识的有向图。由于所有的概念节点均通过联想弧彼此相连知识推导。</p>

<p>一个语义网络的基本构成如下：</p>

<ul>
<li>语义网络中的节点：表示各种事物、概念、情况、属性、动作、状态等，每个节点可以带有若干属性，一般用框架或元组表示。此外，节点还可以是一个语义子网络，形成一个多层次的嵌套结构。</li>
<li>语义网络中的弧：表示各种语义联系，指明它所连接的节点间某种语义关系。</li>
<li>节点和弧都必须带有标识，以便区分各种不同对象以及对象间各种不同的语义联系。</li>
</ul>

<p>之后 Tim Berners-Lee 又提出了<strong>语义网堆栈</strong>（Semantic Web Stack）的概念。语义网堆栈利用图示解释是不同层面的语言所构成的层级结构，其中，每一层面都将利用下游层面的能力，语义网堆栈如下图所示：</p>

<p><img src="/images/cn/2021-01-01-network-storage-and-computing/sweb-stack-zh.png" width="60%" /></p>

<p><strong>资源描述框架</strong>（Resource Description Framework，RDF）是用于描述网络资源的 W3C 标准，比如网页的标题、作者、修改日期、内容以及版权信息。</p>

<p>RDF 使用 Web 标识符来标识事物，并通过属性和属性值来描述资源。</p>

<p>对资源、属性和属性值的解释：</p>

<ul>
<li>资源是可拥有 URI 的任何事物，比如 <code>http://www.w3school.com.cn/rdf</code></li>
<li>属性是拥有名称的资源，比如 <code>author</code> 或 <code>homepage</code></li>
<li>属性值是某个属性的值，比如 <code>David</code> 或 <code>http://www.w3school.com.cn</code>（请注意一个属性值可以是另外一个资源)</li>
</ul>

<p>下面是一个 RDF 示例文档（这是一个简化的例子，命名空间被忽略了）：</p>

<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;

&lt;RDF&gt;
  &lt;Description about=&quot;http://www.w3school.com.cn/RDF&quot;&gt;
    &lt;author&gt;David&lt;/author&gt;
    &lt;homepage&gt;http://www.w3school.com.cn&lt;/homepage&gt;
  &lt;/Description&gt;
&lt;/RDF&gt;
</code></pre>

<p><strong>资源</strong>、<strong>属性</strong>和<strong>属性值</strong>的组合可形成一个陈述（被称为陈述的主体、谓语和客体)。上述的 RDF 文档包含了如下两个陈述：</p>

<ul>
<li>陈述：The <code>author</code> of <code>http://www.w3school.com.cn/rdf</code> is <code>David</code>

<ul>
<li>陈述的主体是：<code>http://www.w3school.com.cn/rdf</code></li>
<li>谓语是：<code>author</code></li>
<li>客体是：<code>David</code></li>
</ul></li>
<li>陈述：The <code>homepage</code> of <code>http://www.w3school.com.cn/rdf</code> is <code>http://www.w3school.com.cn</code>

<ul>
<li>陈述的主体是：<code>http://www.w3school.com.cn/rdf</code></li>
<li>谓语是：<code>homepage</code></li>
<li>客体是：<code>http://www.w3school.com.cn</code></li>
</ul></li>
</ul>

<p>更多 RDF 介绍请参见：<a href="https://www.w3school.com.cn/rdf/index.asp" rel="noreferrer" target="_blank">https://www.w3school.com.cn/rdf/index.asp</a> 。</p>

<p><a href="https://jena.apache.org/" rel="noreferrer" target="_blank">Apache Jena</a> 是一个用于构建<strong>语义网络</strong>（Semantic Web）和<strong>链接数据</strong>（Linked Data）应用的开源 Java 框架。Jena 提供了 3 大部分功能：</p>

<ol>
<li>RDF

<ul>
<li>RDF API：提供构建和读取 RDF 图的核心 API，并利用 <a href="https://en.wikipedia.org/wiki/RDF/XML" rel="noreferrer" target="_blank">RDF/XML</a> 或 <a href="https://en.wikipedia.org/wiki/Turtle_(syntax)" rel="noreferrer" target="_blank">Turtle</a> 等数据类型序列化数据。</li>
<li>ARQ（SPARQL)：提供一种 SPARQL 1.1 的编译引擎 ARQ 用于查询 RDF。</li>
</ul></li>
<li>Triple store

<ul>
<li>TDB：提供一种原生高效的 Triple 存储 TDB，全面支持 Jena APIs。</li>
<li>Fuseki：提供 REST 风格的 RDF 数据交互方式。</li>
</ul></li>
<li>OWL

<ul>
<li>Ontology API：通过 RDFS，OWL 等为 RDF 数据添加更多语义信息。</li>
<li>Inference API：通过内置的 OWL 和 RDFS <a href="https://en.wikipedia.org/wiki/Semantic_reasoner" rel="noreferrer" target="_blank">语义推理器</a> 构建个性化的推理规则。</li>
</ul></li>
</ol>

<p>下面以 <strong>Graph of The Gods</strong> 的关系图对 Jena 的基本功能进行说明。<strong>Graph of The Gods</strong> 是一张描述希腊神话相关事物之间关系的图，其中顶点的类型有：titan（泰坦，希腊神话中曾经统治师姐的古老神族)，god（神)，demigod（半神)，human（人)，monster（怪物)，location（地点)；关系的类型有：father（父亲)，brother（兄弟)，mother（母亲)，battled（战斗)，lives（居住)。</p>

<p><img src="/images/cn/2021-01-01-network-storage-and-computing/graph-of-the-gods.svg" alt="" /></p>

<p>以 Apache Tomcat 作为容器来安装 Apache Jena Fuseki，下载最新版的 Apache Jena Fuseki 并解压，将其中的 fuseki.war 复制到已经安装并运行的 Apache Tomcat 的 webapps 路径下。安装完毕后，进入 <a href="http://127.0.0.1:8080/fuseki" rel="noreferrer" target="_blank">http://127.0.0.1:8080/fuseki</a> 即可使用 Apache Jena Fuseki。</p>

<p><img src="/images/cn/2021-01-01-network-storage-and-computing/apache-jena-fuseki.png" alt="" /></p>

<p>在导入 Graph of The Gods 数据后，执行如下查询语句可以获得 <code>jupiter</code> 的所有兄弟：</p>

<pre><code class="language-sparql">PREFIX gods: &lt;http://leovan.me/gods/&gt;

SELECT DISTINCT ?god
WHERE {
  ?god gods:brother gods:jupiter
}
</code></pre>

<p>查询结果为：</p>

<table>
<thead>
<tr>
<th></th>
<th>god</th>
</tr>
</thead>

<tbody>
<tr>
<td>1</td>
<td>gods:pluto</td>
</tr>

<tr>
<td>2</td>
<td>gods:neptune</td>
</tr>
</tbody>
</table>

<h3 id="图数据库">图数据库</h3>

<p><strong>图数据库</strong>是一个使用图结构进行语义查询的数据库，它使用节点、边和属性来表示和存储数据。不同于关系型数据库，图数据库为 NoSQL（Not Only SQL）的一种，属于联机事务处理（OLTP）的范畴，可以解决现有关系数据库的局限性。</p>

<p>下图展示了近年来不同类型数据库的流行度趋势，不难看出近年来越来越多的人开始关注图数据库。</p>

<figure>
  <img data-src="/images/cn/2021-01-01-network-storage-and-computing/db-engines-database-categories-trend.png" class="lazyload"/>
  <figcaption><p class="figcaption">数据库流行度趋势 <a href="https://db-engines.com/en/ranking_categories" rel="noreferrer" target="_blank">https://db-engines.com/en/ranking_categories</a></p></figcaption>
</figure>

<p>截止到 2020 年 12 月，图数据库的排名如下图所示：</p>

<figure>
  <img data-src="/images/cn/2021-01-01-network-storage-and-computing/db-engines-graph-database-ranking.png" class="lazyload"/>
  <figcaption><p class="figcaption">图数据库排名 <a href="https://db-engines.com/en/ranking/graph+dbms" rel="noreferrer" target="_blank">https://db-engines.com/en/ranking/graph+dbms</a></p></figcaption>
</figure>

<p>其中，<a href="https://neo4j.com/" rel="noreferrer" target="_blank">Neo4j</a>、<a href="https://janusgraph.org/" rel="noreferrer" target="_blank">JanusGraph</a>、<a href="https://dgraph.io/" rel="noreferrer" target="_blank">Dgraph</a>、<a href="https://www.tigergraph.com/" rel="noreferrer" target="_blank">TigerGraph</a>、<a href="https://nebula-graph.io/" rel="noreferrer" target="_blank">Nebula Graph</a> 均为时下常用的图数据库。从下图的流行度趋势角度来看，JanusGraph、Dgraph、TigerGraph 和 Nebula Graph 等后起之秀发展迅速。</p>

<figure>
  <img data-src="/images/cn/2021-01-01-network-storage-and-computing/db-engines-graph-database-trend.png" class="lazyload"/>
  <figcaption><p class="figcaption">图数据库流行度趋势 <a href="https://db-engines.com/en/ranking_trend/graph+dbms" rel="noreferrer" target="_blank">https://db-engines.com/en/ranking_trend/graph+dbms</a></p></figcaption>
</figure>

<p>不同的图数据库有着不同的优劣势，用户可以根据实际业务场景选择合适的图数据库。下面给到一些较新的图数据库对比和评测：</p>

<ol>
<li><a href="https://nebula-graph.com.cn/posts/benchmarking-mainstraim-graph-databases-dgraph-nebula-graph-janusgraph/" rel="noreferrer" target="_blank">主流开源分布式图数据库 Benchmark</a></li>
<li><a href="https://nebula-graph.com.cn/posts/performance-comparison-neo4j-janusgraph-nebula-graph/" rel="noreferrer" target="_blank">图数据库对比：Neo4j vs Nebula Graph vs HugeGraph</a></li>
<li><a href="https://www.tigergraph.com.cn/wp-content/uploads/2018/10/TigerGraph-Benchmark-Report-2018-1.pdf" rel="noreferrer" target="_blank">图分析系统基准测试报告</a></li>
<li><a href="https://fma-ai.cn/pdf/FMA_benchmark.pdf" rel="noreferrer" target="_blank">图数据平台产品测试报告</a></li>
</ol>

<h3 id="查询语言">查询语言</h3>

<p><strong>图查询语言</strong>（Graph Query Language，GQL）是一种用于图数据库的查询语言，类比于关系型数据库的查询语言 SQL。2019 年 9 月，GQL 被提议为一种新的数据库查询语言（<a href="https://www.iso.org/standard/76120.html" rel="noreferrer" target="_blank">ISO/IEC WD 39075</a>），目前仍处于开发当中，因此市面上还没有统一的图查询语言标准。</p>

<h4 id="gremlin">Gremlin</h4>

<p><a href="https://tinkerpop.apache.org/gremlin.html" rel="noreferrer" target="_blank">Gremlin</a> 是 <a href="https://tinkerpop.apache.org/" rel="noreferrer" target="_blank">Apache TinkerPop</a> 框架下的图遍历语言。Gremlin 适用于基于 OLTP 的图数据库以及基于 OLAP 的图分析引擎，支持命令式和声明式查询。支持 Gremlin 的图数据库有：Neo4j、JanusGraph 等。</p>

<h4 id="cypher">Cypher</h4>

<p><a href="http://www.opencypher.org/" rel="noreferrer" target="_blank">Cypher</a> 是一种声明式图查询语言，这使得在不必编写遍历逻辑的情况下可以实现高效的查询。支持 Cypher 的图数据库有：Neo4j、RedisGraph、Nebula Graph 等。</p>

<h4 id="ngql">nGQL</h4>

<p><a href="https://docs.nebula-graph.com.cn/manual-CN/1.overview/1.concepts/2.nGQL-overview/" rel="noreferrer" target="_blank">nGQL</a> 是一种声明式的图查询语言，支持图遍历、模式匹配、聚合运算和图计算等特性。支持 nGQL 的图数据库有：Nebula Graph。</p>

<h4 id="比较">比较</h4>

<p>针对 3 种不同的查询语言，对于图中相关概念的表示也略有不同，如下表所示：</p>

<table>
<thead>
<tr>
<th align="left">术语</th>
<th align="left">Gremlin</th>
<th align="left">Cypher</th>
<th align="left">nGQL</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">点</td>
<td align="left">Vertex</td>
<td align="left">Node</td>
<td align="left">Vertex</td>
</tr>

<tr>
<td align="left">边</td>
<td align="left">Edge</td>
<td align="left">Relationship</td>
<td align="left">Edge</td>
</tr>

<tr>
<td align="left">点类型</td>
<td align="left">Label</td>
<td align="left">Label</td>
<td align="left">Tag</td>
</tr>

<tr>
<td align="left">边类型</td>
<td align="left">label</td>
<td align="left">RelationshipType</td>
<td align="left">edge type</td>
</tr>

<tr>
<td align="left">点 ID</td>
<td align="left">vid</td>
<td align="left">id(n)</td>
<td align="left">vid</td>
</tr>

<tr>
<td align="left">边 ID</td>
<td align="left">eid</td>
<td align="left">id(r)</td>
<td align="left">无</td>
</tr>

<tr>
<td align="left">插入</td>
<td align="left">add</td>
<td align="left">create</td>
<td align="left">insert</td>
</tr>

<tr>
<td align="left">删除</td>
<td align="left">drop</td>
<td align="left">delete</td>
<td align="left">delete / drop</td>
</tr>

<tr>
<td align="left">更新属性</td>
<td align="left">setProperty</td>
<td align="left">set</td>
<td align="left">update</td>
</tr>
</tbody>
</table>

<p>更多不同查询语言之间的详细对比可以参见如下资料：</p>

<ol>
<li><a href="https://nebula-graph.com.cn/posts/graph-query-language-comparison-cypher-gremlin-ngql/" rel="noreferrer" target="_blank">一文了解各大图数据库查询语言 | 操作入门篇</a></li>
<li><a href="https://nebula-graph.com.cn/posts/sql-vs-ngql-comparison/" rel="noreferrer" target="_blank">文档解读 ｜ SQL vs. nGQL</a></li>
</ol>

<h2 id="图计算">图计算</h2>

<h3 id="图计算框架">图计算框架</h3>

<h4 id="graphx">GraphX</h4>

<p><a href="https://spark.apache.org/graphx/" rel="noreferrer" target="_blank">GraphX</a> 是一个基于 <a href="https://spark.apache.org/" rel="noreferrer" target="_blank">Spark</a> 大规模图计算框架。GraphX 通过引入一个包含带有属性的顶点和变的有向图对 Spark 的 RDD 进行了扩展。通过 subgraph、joinVertices 和 aggregateMessages 等算子实现了 PageRank、连通子图、LPA 等图算法。</p>

<h4 id="plato">Plato</h4>

<p><a href="https://github.com/Tencent/plato" rel="noreferrer" target="_blank">Plato</a> 是由腾讯开源的高性能图计算框架。Plato 主要提供两方面的能力：离线图计算和图表示学习，目前支持的图算法如下：</p>

<table>
<thead>
<tr>
<th>算法分类</th>
<th>算法</th>
</tr>
</thead>

<tbody>
<tr>
<td>图特征</td>
<td>树深度/宽度；节点数/边数/密度/节点度分布；N-阶度；HyperANF</td>
</tr>

<tr>
<td>节点中心性指标</td>
<td>KCore；Pagerank；Closeness；Betweenness</td>
</tr>

<tr>
<td>连通图 &amp; 社团识别</td>
<td>Connected-Component；LPA；HANP</td>
</tr>

<tr>
<td>图表示学习</td>
<td>Node2Vec-Randomwalk；Metapath-Randomwalk</td>
</tr>

<tr>
<td>聚类/分圈算法</td>
<td>FastUnfolding</td>
</tr>

<tr>
<td>其他图相关算法</td>
<td>BFS；共同类计算</td>
</tr>

<tr>
<td>待开源算法</td>
<td>Word2Vec；Line；GraphVite；GCN</td>
</tr>
</tbody>
</table>

<p>在计算性能上，Plato 与 Spark GraphX 在 PageRank 和 LPA 两个算法上的计算耗时与内存消耗对比如下图所示：</p>

<p><img src="/images/cn/2021-01-01-network-storage-and-computing/plaot-spark-graphx-benchmark.png" alt="Plato &amp; Spark GraphX Benchmark" /></p>

<h4 id="graphscope">GraphScope</h4>

<p><a href="https://github.com/alibaba/GraphScope" rel="noreferrer" target="_blank">GraphScope</a> 由有阿里巴巴开源的一个统一的分布式图计算平台。GraphScope 提供了一个一站式环境，可以通过用户友好的 Python 接口在集群内对图进行操作。GraphScope 利用一系列开源技术使得集群上的大规模图数据的多阶段处理变得简单，这些技术包括：用于分析的 <a href="https://github.com/alibaba/libgrape-lite" rel="noreferrer" target="_blank">GRAPE</a>、用于查询的 <a href="https://github.com/alibaba/GraphScope/blob/master/interactive_engine" rel="noreferrer" target="_blank">MaxGraph</a> 、用于图神经网络计算的 <a href="https://github.com/alibaba/graph-learn" rel="noreferrer" target="_blank">Graph-Learn</a> 和用于提供高效内存数据交换的 <a href="https://github.com/alibaba/libvineyard" rel="noreferrer" target="_blank">vineyard</a>。GraphScope 的整体架构如下图所示：</p>

<p><img src="/images/cn/2021-01-01-network-storage-and-computing/architecture-of-graphscope.png" alt="Architecture of GraphScope" /></p>

<p>GraphScope Interactive Engine（GIE）是一个用于探索性分析大规模复杂图结构数据的引擎，它通过 Gremlin 提供高级别的图查询语言，同时提供自动并行执行功能。</p>

<p>GraphScope Analytical Engine（GAE）是一个基于 GRAPE <sup class="footnote-ref" id="fnref:fan2018parallelizing"><a href="#fn:fan2018parallelizing">1</a></sup> 提供并行图算法的分析引擎。除了提供基础的内置算法以外，GAE 允许用户利用 Python 基于 PIE <sup class="footnote-ref" id="fnref:fan2018parallelizing"><a href="#fn:fan2018parallelizing">1</a></sup> 编程模型编写自定义算法，PIE 编程模型的运行方式如下图所示：</p>

<p><img src="/images/cn/2021-01-01-network-storage-and-computing/execution-model-in-gae.png" alt="Execution Model in GAE" /></p>

<p>GraphScope 还提供以顶点为中心的 Pregel 模型 <sup class="footnote-ref" id="fnref:malewicz2010pregel"><a href="#fn:malewicz2010pregel">2</a></sup>，用户可以使用 Pregel 模型来实现自定义算法。</p>

<p>GraphScope Learning Engine（GLE）是一个用于开发和训练大规模图神经网络的分布式框架。GLE 提供基于全量图（用于 GCN、GAT 等算法）和采样子图（用于 GraphSAGE，FastGCN、GraphSAINT 等算法）两种不同方式训练图模型。整体架构如下图所示：</p>

<p><img src="/images/cn/2021-01-01-network-storage-and-computing/gle.png" alt="GLE" /></p>

<h4 id="galileo">Galileo</h4>

<p>Galileo 是由京东零售研发的图计算平台，提供离线和在线图计算和图数据服务能力。目前 Galileo 暂未开源，待开源后补充相关信息。</p>

<h3 id="图神经网络">图神经网络</h3>

<p>关于图神经网络内容，请参见之前的博客 <a href="/cn/2020/04/graph-embedding-and-gnn/">图嵌入 (Graph Embedding) 和图神经网络 (Graph Neural Network)</a>。</p>

<h2>🎉🎉🎉 Happe New Year! 🎉🎉🎉</h2>
<div class="footnotes">

<hr />

<ol>
<li id="fn:fan2018parallelizing">Fan, W., Yu, W., Xu, J., Zhou, J., Luo, X., Yin, Q., &hellip; &amp; Xu, R. (2018). Parallelizing sequential graph computations. <em>ACM Transactions on Database Systems (TODS)</em>, 43(4), 1-39.
 <a class="footnote-return" href="#fnref:fan2018parallelizing">↩</a></li>
<li id="fn:malewicz2010pregel">Malewicz, G., Austern, M. H., Bik, A. J., Dehnert, J. C., Horn, I., Leiser, N., &amp; Czajkowski, G. (2010, June). Pregel: a system for large-scale graph processing. In <em>Proceedings of the 2010 ACM SIGMOD International Conference on Management of data</em> (pp. 135-146).
 <a class="footnote-return" href="#fnref:malewicz2010pregel">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>网络算法 (Network Algorithms)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/12/network-algorithms/</link>
      <pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/12/network-algorithms/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文为<a href="/categories/复杂网络/">《复杂网络系列》</a>文章<br />
本文内容主要参考自：《网络科学引论》<sup class="footnote-ref" id="fnref:newman2014networks"><a href="#fn:newman2014networks">1</a></sup></p>
</blockquote>

<h2 id="网络基础算法">网络基础算法</h2>

<h3 id="最短路径">最短路径</h3>

<p><strong>最短路径</strong>（shortest path）算法是寻找两个顶点之间的最短路径，寻找网络中最短路径的标准算法称为<strong>广度优先搜索</strong>（breadth-first search）。算法的基本思想如下图所示：</p>

<p><img src="/images/cn/2020-12-12-network-algorithms/bfs.png" alt="" /></p>

<p>根据广度优先搜索的基本思想，不难证明距 <code>$s$</code> 最短距离为 <code>$d$</code> 的每个顶点都有一个到 <code>$s$</code> 的最短距离为 <code>$d - 1$</code> 的邻居顶点。一个简单的实现方式是，创建一个有 <code>$n$</code> 个元素的数组存储从源顶点 <code>$s$</code> 到其他所有顶点的距离，同时创建一个距离变量 <code>$d$</code> 来记录当前在搜索过程中所处的层数，算法的具体流程如下：</p>

<ol>
<li>遍历距离数组，查找到 <code>$s$</code> 的距离为 <code>$d$</code> 的所有顶点。</li>
<li>查找上述顶点的所有邻居顶点，如果同 <code>$s$</code> 的距离未知，则距离置为 <code>$d + 1$</code>。</li>
<li>如果距离未知的邻居顶点数量为零，则停止算法，否则将 <code>$d$</code> 的值加一并重复上述过程。</li>
</ol>

<p>这种方法在最坏的情况下时间复杂度为 <code>$O \left(m + n^2\right)$</code>，考虑多数网络的直径只随 <code>$\log n$</code> 增长，算法运行的时间复杂度为 <code>$O \left(m + n \log n\right)$</code>。</p>

<p>上述算法中步骤 1 是最耗时的部分，通过使用<strong>队列</strong>的数据结构我们可以避免每次都遍历列表来找到距离源顶点 <code>$s$</code> 距离为 <code>$d$</code> 的顶点。构造一个队列，一个指针指向下一个要读取的元素，另一个指针指向要填充的空位，这样距离为 <code>$d + 1$</code> 的顶点就会紧跟在距离为 <code>$d$</code> 的顶点后面，队列如下图所示：</p>

<p><img src="/images/cn/2020-12-12-network-algorithms/bfs-queue.png" alt="" /></p>

<p>通过队列可以将算法的时间复杂度降至 <code>$O \left(m + n\right)$</code>，对于 <code>$m \propto n$</code> 的稀疏网络而言，<code>$O \left(m + n\right)$</code> 相当于 <code>$O \left(n\right)$</code>，所以算法的时间复杂度同顶点数量成正比。</p>

<p>通过对算法进行进一步修改则可以得到源顶点 <code>$s$</code> 到其他任何顶点的最短路径。方法是在原来的网络上构建一个新的有向网络，该网络代表最短路径，称为<strong>最短路径树</strong>（shortest path tree），通常情况下，该网络是一个有向非循环网络，而不是树。</p>

<p>对于加权网络，利用广度优先搜索无法找到最短路径，这里需要用到 Dijkstra 算法 <sup class="footnote-ref" id="fnref:dijkstra-wikipedia"><a href="#fn:dijkstra-wikipedia">2</a></sup> 进行求解。算法将图中的顶点分成两组 <code>$S$</code> 和 <code>$U$</code>，整个算法过程如下：</p>

<ol>
<li>初始状态，<code>$S$</code> 仅包含源顶点，即 <code>$S = \left\{v\right\}$</code>，<code>$U$</code> 包含其余顶点。如果 <code>$v$</code> 与 <code>$U$</code> 中的顶点 <code>$u$</code> 为邻居，则距离为边的权重，否则为无穷大。</li>
<li>从 <code>$U$</code> 中选择一个距离 <code>$v$</code> 最短的顶点 <code>$k$</code>，并把 <code>$k$</code> 加入到 <code>$S$</code> 中。</li>
<li>若从源点 <code>$v$</code> 经过顶点 <code>$k$</code> 到达 <code>$u$</code> 的距离比之前 <code>$v$</code> 到 <code>$u$</code> 的距离短，则将距离修改为这个更短的距离。</li>
<li>重复步骤 2 和 3，直至所有顶点都包含在 <code>$S$</code> 中。</li>
</ol>

<p>整个算法过程的可视化效果如下图所示：</p>

<p><img src="/images/cn/2020-12-12-network-algorithms/dijkstras-progress.gif" alt="" /></p>

<p>Dijkstra 算法的时间复杂度为 <code>$O \left(m + n^2\right)$</code>，通过二叉堆的数据结构可以将时间复杂度优化至 <code>$O \left(\left(m + n\right) \log n\right)$</code>。</p>

<p>Dijkstra 算法虽然能够处理加权网络，但不能处理存在负权重的网络，需要利用 Floyd-Warshall 算法 <sup class="footnote-ref" id="fnref:floyd-warshall-wikipedia"><a href="#fn:floyd-warshall-wikipedia">3</a></sup> 进行求解。更多 Floyd-Warshall 算法的细节请参见之前的博客<a href="/cn/2018/11/computational-complexity-and-dynamic-programming/">计算复杂性 (Computational Complexity) 与动态规划 (Dynamic Programming)</a>。</p>

<h3 id="最大流和最小割">最大流和最小割</h3>

<p>对于连接给定顶点 <code>$s$</code> 和 <code>$t$</code> 的两条路径，若没有共享边，则这两条路径是<strong>边独立</strong>的；若除 <code>$s$</code> 和 <code>$t$</code> 外不共享任何其他顶点，则这两条路径是<strong>顶点独立</strong>的。顶点之间的<strong>边连通度</strong>和<strong>顶点连通度</strong>分别是顶点之间边独立路径数和顶点独立路径数。连通度是度量顶点之间连通鲁棒性的简单参数。假设一个网络是一个管线网络，其中每个管线的容量均为单位流量，那么边连通度等于从 <code>$s$</code> 流向 <code>$t$</code> 的<strong>最大流</strong>。</p>

<p><strong>增广路径算法</strong>（Ford-Fulkerson Algorithm，FFA）是计算最大流最简单的算法。基本思想是：首先利用广度优先搜索算法找到一条从源 <code>$s$</code> 到目标 <code>$t$</code> 的路径。该步骤“消耗”了网络中的一些边，将这些边的容量填充满后，它们不再承载更多流量。之后在剩余边中找到从 <code>$s$</code> 到 <code>$t$</code> 的另一条路径，重复该过程直到找不到更多的路径为止。</p>

<p>但这还不是一个有效的算法，如下图中的 (a) 所示，如果在 <code>$s$</code> 和 <code>$t$</code> 之间运用广度优先搜索，可以发现黑色标记的路径。一旦这些边的容量被填充满，就不能在剩余边中找到从 <code>$s$</code> 到 <code>$t$</code> 的更多路径，但很明显，从 <code>$s$</code> 到 <code>$t$</code> 有两条边独立路径（上下各一条）。</p>

<p><img src="/images/cn/2020-12-12-network-algorithms/augmenting-path-algorithm.png" alt="" /></p>

<p>解决该问题的一个简单修正方法是允许网络流量在一条边中能够同时在两个方向流动。更一般地，因为一条边容许承载的最大流是在任意方向的单位流量，那么一条边可以有多个单位流量，只要保证他们能够相互抵消，并且最终每条边承载不超过一个单位流量。</p>

<p>增广路径算法的实现利用了<strong>剩余图</strong>（residual graph），这是一个有向网络，该网络中的有向边连接原网络中相应的顶点对，并在指定方向承载一个或多个单位流量。例如上图中 (c) 和 (d) 就是对应 (a) 和 (b) 的流量状态的剩余图。算法的正确性在这里就不过多展开说明，该算法在计算两个顶点之间的最大流的平均时间复杂度为 <code>$O \left(\left(m + n\right) m / n\right)$</code>。</p>

<p>在图论中，去掉其中所有边使一张网络不再连通的边集为图的<strong>割</strong>，一张图上最小的割为<strong>最小割</strong>。通过对增广路径算法进行改动即可以寻找到边独立路径、最小边割集和顶点独立路径。</p>

<h2 id="图划分和社团发现">图划分和社团发现</h2>

<p><strong>图划分</strong>（graph partitioning）和<strong>社团发现</strong>（community detection）都是指根据网络中的边的连接模式，把网络顶点划分成群组、簇或社团。将网络顶点划分成群组后最常见的属性是，同一群组内部的顶点之间通过边紧密连接，而不同群组之间只有少数边。</p>

<h3 id="图划分">图划分</h3>

<p>最简单的图划分问题是把网络划分成两部分，有时也称其为<strong>图对分</strong>（graph bisection）。图对分是把一个网络中的顶点划分成为两个指定规模的非重叠群组，使得不同群组之间相互连接的边数最小。群组之间的边数称为<strong>割集规模</strong>（cut size）。 利用穷举搜索解决该问题是极为耗时的，通过启发式算法我们可以找到较好的网络划分。</p>

<h4 id="kernighan-lin-算法">Kernighan-Lin 算法</h4>

<p>Kernighan-Lin 算法是由 Brian Kernighan 和 Shen Lin 在 1970 年提出的 <sup class="footnote-ref" id="fnref:kernighan1970efficient"><a href="#fn:kernighan1970efficient">4</a></sup>，是图对分问题中最简单、最知名的启发式算法之一，如下图所示。</p>

<p><img src="/images/cn/2020-12-12-network-algorithms/kernighan–lin-algorithm.png" alt="" /></p>

<p>先以任意方式将网络顶点按指定规模划分成两个群组，对于任何由分属不同群组的顶点 <code>$i$</code> 和顶点 <code>$j$</code> 组成的顶点对 <code>$\left(i, j\right)$</code>，交换 <code>$i$</code> 和 <code>$j$</code> 的位置，并计算交换前后两个群组之间割集规模的变化量。在所有顶点对中找到使割集规模减小最多的顶点对，或者若没有使割集规模减小的顶点对，则找到使割集规模增加最小的顶点对，交换这两个顶点。重复这个过程，同时保证网络中的每个顶点只能移动一次。</p>

<p>继续算法，每一步都交换最大程度减少或最小程度增加群组之间边数的顶点对，直到没有可以变换的顶点对，此时本轮算法停止。在完成所有交换后，检查网络在此过程中经过的每一个状态，然后选择割集规模最小的状态。最后，重复执行上述整个过程，每次始于上次发现的最优网络划分，直到割集规模不在出现改善。</p>

<p>Kernighan-Lin 算法的主要缺点是运算速度缓慢，采用一些技巧来改善算法也只能使时间复杂度降至 <code>$O \left(n^3\right)$</code>，因此该算法仅适用于有几百或几千个顶点的网络，而不适用于更大规模的网络。</p>

<h4 id="谱划分">谱划分</h4>

<blockquote>
<p>请先了解<a href="#附录">附录</a>中的拉普拉斯算子和拉普拉斯矩阵等相关概念。</p>
</blockquote>

<p>考虑具有 <code>$n$</code> 个顶点 <code>$m$</code> 条边的网络，将其划分为两个群组，称为群组 1 和群组 2。可以把该划分的割集规模，也就是两个群组之间的边数表示为：</p>

<p><code>$$
\label{eq:r_1}
R = \dfrac{1}{2} \sum_{i, j \text{ 属于不同群组}} A_{ij}
$$</code></p>

<p>对于每个网络划分，定义有参数 <code>$s_i$</code> 组成的集合，集合中每个元素对应于一个顶点 <code>$i$</code>，则有：</p>

<p><code>$$
s_i = \left\{\begin{array}{ll}
+1 &amp; \text{顶点 } i \text{ 在群组 1 中} \\
-1 &amp; \text{顶点 } i \text{ 在群组 2 中}
\end{array}\right.
$$</code></p>

<p>那么：</p>

<p><code>$$
\dfrac{1}{2} \left(1 - s_i s_j\right) = \left\{\begin{array}{ll}
1 &amp; \text{顶点 } i \text{ 和 } j \text{ 在不同的群组中} \\
0 &amp; \text{顶点 } i \text{ 和 } j \text{ 在相同的群组中}
\end{array}\right.
$$</code></p>

<p>则式 \ref{eq:r_1} 可以改写为：</p>

<p><code>$$
\begin{aligned}
R &amp; = \dfrac{1}{4} \sum_{ij} A_{ij} \left(1 - s_i s_j\right) \\
&amp; = \dfrac{1}{4} \left(k_i \delta_{ij} - A_{ij}\right) s_i s_j \\
&amp; = \dfrac{1}{4} \sum_{ij} L_{ij} s_i s_j
\end{aligned}
$$</code></p>

<p>其中，<code>$\delta_{ij}$</code> 是克罗内克函数，<code>$L_{ij}$</code> 是图拉普拉斯矩阵的第 <code>$ij$</code> 个元素。写成矩阵的形式有：</p>

<p><code>$$
R = \dfrac{1}{4} \mathbf{s}^{\top} \mathbf{L} \mathbf{s}
$$</code></p>

<p>由于每个 <code>$s_i$</code> 的取值只能是 <code>$\left\{+1, -1\right\}$</code>，所以在给定 <code>$\mathbf{L}$</code> 时求解 <code>$\mathbf{s}$</code> 使其割集规模最小时并不容易。具体求解方法的推导在此不再展开说明，最终谱划分算法的过程如下所示：</p>

<ol>
<li>计算图拉普拉斯矩阵的第二小特征值 <code>$\lambda_2$</code>，称为网络的<strong>代数连通度</strong>（algebraic connectivity），及其对应的特征向量 <code>$\mathbf{v}_2$</code>。</li>
<li>按从大到小的顺序对特征向量的元素进行排序。</li>
<li>把前 <code>$n_1$</code> 个最大元素对应的顶点放入群组 1，其余放入群组 2，计算割集规模。</li>
<li>把前 <code>$n_1$</code> 个最小（注意：中文译本中有错误）元素对应的顶点放入群组 2，其余放入群组 1，并重新计算割集规模。</li>
<li>在两种网络划分中，选择割集规模较小的那个划分。</li>
</ol>

<p>谱划分方法在稀疏网络上的时间复杂度为 <code>$O \left(n^2\right)$</code>，这比 Kernighan-Lin 算法时间复杂度少了一个因子 <code>$n$</code>，从而使该算法能应用于更大规模的网络。</p>

<h3 id="社团发现">社团发现</h3>

<p><strong>社团发现</strong>（社区发现，社群发现，Community Detection）的基本目的与图划分类似，即把网络分成几个节点点群组，并使节点群组之间的连接较少。主要的差别就是群组的数量和规模是不确定的。社团发现的算法分类和具体实现很多，本文仅介绍几个常用的算法，更多方法及其细节请参见如下开放资源：</p>

<ol>
<li>Community Detection in Graphs <sup class="footnote-ref" id="fnref:fortunato2010community"><a href="#fn:fortunato2010community">5</a></sup></li>
<li>Deep Learning for Community Detection: Progress, Challenges and Opportunities <sup class="footnote-ref" id="fnref:liu2020deep"><a href="#fn:liu2020deep">6</a></sup></li>
<li>复杂网络社团发现算法研究新进展 <sup class="footnote-ref" id="fnref:luo2011new"><a href="#fn:luo2011new">7</a></sup></li>
<li><a href="https://github.com/benedekrozemberczki/awesome-community-detection" rel="noreferrer" target="_blank">benedekrozemberczki/awesome-community-detection</a></li>
</ol>

<h4 id="fast-unfolding-louvain">Fast Unfolding (Louvain)</h4>

<p><strong>Fast Unfolding (Louvain)</strong> <sup class="footnote-ref" id="fnref:blondel2008fast"><a href="#fn:blondel2008fast">8</a></sup> 是一种基于模块度的社团发现算法，通过模块度来衡量一个社团的紧密程度。算法包含两个阶段：</p>

<ol>
<li>历遍网络中所有的节点，通过比较将节点给每个邻居社团带来的模块度变化，将这个节点加入到使模块度增加最大的社团中。</li>
<li>对于步骤 1 的结果，将属于同一个社团的节点合并成为一个大的节点，进而重型构造网络。新的节点之间边的权重是所包含的之前所有节点之间相连的边权重之和，然后重复步骤 1。</li>
</ol>

<p>算法的两个步骤如下图所示：</p>

<p><img src="/images/cn/2020-12-12-network-algorithms/louvain.png" alt="" /></p>

<h4 id="label-propagation-algorithm-lpa">Label Propagation Algorithm (LPA)</h4>

<p><strong>标签传播算法</strong>（Label Propagation Algorithm，LPA）是一种基于半监督学习的社团发现算法。对于每个节点都有对应的标签（即节点所隶属的社团），在算法迭代过程中，节点根据其邻居节点更新自身的标签。更新的规则是选择邻居节点中最多的标签作为自身的标签。</p>

<p>标签传播的过程中，节点的标签更新方式分为<strong>同步更新</strong>和<strong>异步更新</strong>两种方式。同步更新是指对于节点 <code>$x$</code>，在第 <code>$t$</code> 步时，根据其所有邻居节点在 <code>$t - 1$</code> 步时的标签对其进行更新，即：</p>

<p><code>$$
C_{x}(t)=f\left(C_{x_{1}}(t-1), C_{x_{2}}(t-1), \cdots, C_{x_{k}}(t-1)\right)
$$</code></p>

<p>同步更新对于一个二分或者近似二分的网络来说可能会出现标签震荡的现象。对于异步更新方式，更新公式为：</p>

<p><code>$$
C_{x}(t)=f\left(C_{x_{i 1}}(t), \cdots, C_{x_{i m}}(t), C_{x_{i(m+1)}}(t-1), \cdots, C_{x_{i k}}(t-1)\right)
$$</code></p>

<p>其中，邻居节点 <code>$x_{i1}, \cdots, x_{im}$</code> 的标签在第 <code>$t$</code> 步时已经更新过，而 <code>$x_{i(m+1)}, \cdots, x_{ik}$</code> 的标签还未更新。</p>

<h2 id="附录">附录</h2>

<p><strong>拉普拉斯算子</strong>（Laplace operator，Laplacian）是由欧式空间中的一个函数的梯度的散度给出的微分算子，通常写作 <code>$\Delta$</code>，<code>$\nabla^2$</code> 或 <code>$\nabla \cdot \nabla$</code>。</p>

<p><strong>梯度</strong>（gradient）是对多元导数的概括，函数沿着梯度的方向变化最快，变化率则为梯度的模。假设二元函数 <code>$f \left(x, y\right)$</code> 在区域 <code>$G$</code> 内具有一阶连续偏导数，点 <code>$P \left(x, y\right) \in G$</code>，则称向量：</p>

<p><code>$$
\nabla f = \left(\dfrac{\partial f}{\partial x}, \dfrac{\partial f}{\partial y} \right) = \dfrac{\partial f}{\partial x} \mathbf{i} + \dfrac{\partial f}{\partial y} \mathbf{j}
$$</code></p>

<p>为函数 <code>$f$</code> 在点 <code>$P$</code> 处的梯度，其中 <code>$\mathbf{i}$</code> 和 <code>$\mathbf{j}$</code> 为单位向量，分别指向 <code>$x$</code> 和 <code>$y$</code> 坐标方向。</p>

<p><strong>散度</strong>（divergence）将向量空间上的一个向量场对应到一个标量场上，记为 <code>$\nabla \cdot$</code>。散度的意义是场的有源性，当 <code>$\nabla \cdot F &gt; 0$</code> 时，表示该点是发源点；当 <code>$\nabla \cdot F &lt; 0$</code> 时，表示该点是汇聚点；当 <code>$\nabla \cdot F = 0$</code> 时，表示该点无源，如下图所示。</p>

<p><img src="/images/cn/2020-12-12-network-algorithms/divergence.png" alt="" /></p>

<p>拉普拉斯离散化后即为<strong>拉普拉斯矩阵</strong>（laplacian matrix），也称为<strong>调和矩阵</strong>（harmonic matrix）。离散化的拉普拉斯算子形式如下：</p>

<p><code>$$
\begin{aligned}
\Delta f &amp; = \dfrac{\partial^2 f}{\partial x^2} + \dfrac{\partial^2 f}{\partial y^2} \\
&amp; = f \left(x + 1, y\right) + f \left(x - 1, y\right) - 2 f \left(x, y\right) + f \left(x, y + 1\right) + f \left(x, y - 1\right) - 2 f \left(x, y\right) \\
&amp; = f \left(x + 1, y\right) + f \left(x - 1, y\right) + f \left(x, y + 1\right) + f \left(x, y - 1\right) - 4 f \left(x, y\right)
\end{aligned}
$$</code></p>

<p>从上述离散化后的拉普拉斯算子形式可以看出，拉普拉斯矩阵表示的是对矩阵进行微小扰动后获得的收益。</p>

<p>设图 <code>$G$</code> 有 <code>$n$</code> 个节点，节点的邻域为 <code>$N$</code>，图上的函数 <code>$f = \left(f_1, f_2, \cdots, f_n\right)$</code>，其中 <code>$f_i$</code> 表示节点 <code>$i$</code> 处的函数值。对 <code>$i$</code> 进行扰动，其可能变为邻域内的任意一个节点 <code>$j \in N_i$</code>：</p>

<p><code>$$
\Delta f_{i}=\sum_{j \in N_{i}}\left(f_{i}-f_{j}\right)
$$</code></p>

<p>设每一条边 <code>$e_{ij}$</code> 的权重为 <code>$w_{ij}$</code>，<code>$w_{ij} = 0$</code> 表示节点 <code>$i$</code> 和节点 <code>$j$</code> 不相邻，则有：</p>

<p><code>$$
\begin{aligned}
\Delta f_i &amp; = \sum_{j \in N} w_{ij} \left(f_i - f_j\right) \\
&amp; = \sum_{j \in N} w_{ij} f_i - \sum_{j \in N} w_{ij} f_i \\
&amp; = d_i f_i - W_{i:} f 
\end{aligned}
$$</code></p>

<p>对于所有节点有：</p>

<p><code>$$
\begin{aligned}
\Delta f &amp; = \left(\begin{array}{c}
\Delta f_{1} \\
\vdots \\
\Delta f_{N}
\end{array}\right)=\left(\begin{array}{c}
d_{1} f_{1}-W_{1:} f \\
\vdots \\
d_{N} f_{N}-W_{N:} f
\end{array}\right) \\
&amp; = \left(\begin{array}{ccc}
d_{1} &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots \\
0 &amp; \cdots &amp; d_{N}
\end{array}\right) f-\left(\begin{array}{c}
W_{1:} \\
\vdots \\
W_{N:}
\end{array}\right) f \\
&amp; = diag \left(d_i\right) f - W f \\
&amp; = \left(D - W\right) f \\
&amp; = L f
\end{aligned}
$$</code></p>

<p>令图 <code>$G$</code> 的邻接矩阵为 <code>$W$</code>，度矩阵为 <code>$D$</code>，从上式可知拉普拉斯矩阵 <code>$L = D - W$</code>，其中：</p>

<p><code>$$
L_{ij} = \left\{\begin{array}{ll}
\deg \left(v_i\right) &amp; \text{如果 } i = j \\
-1 &amp; \text{如果 } i \neq j \text{ 且 } v_i \text{ 与 } v_j \text{ 相邻} \\
0 &amp; \text{其他情况}
\end{array}\right.
$$</code></p>

<p>以下面的图为例：</p>

<p><img src="/images/cn/2020-12-12-network-algorithms/laplacian-matrix-demo-graph.png" alt="" /></p>

<p>邻接矩阵为：</p>

<p><code>$$
\left(\begin{array}{llllll}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0
\end{array}\right)
$$</code></p>

<p>度矩阵为：</p>

<p><code>$$
\left(\begin{array}{cccccc}
2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 3 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 3 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{array}\right)
$$</code></p>

<p>拉普拉斯矩阵为：</p>

<p><code>$$
\left(\begin{array}{rrrrrr}
2 &amp; -1 &amp; 0 &amp; 0 &amp; -1 &amp; 0 \\
-1 &amp; 3 &amp; -1 &amp; 0 &amp; -1 &amp; 0 \\
0 &amp; -1 &amp; 2 &amp; -1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; -1 &amp; 3 &amp; -1 &amp; -1 \\
-1 &amp; -1 &amp; 0 &amp; -1 &amp; 3 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1
\end{array}\right)
$$</code></p>

<h2 id="开放资源">开放资源</h2>

<h3 id="常用网络算法包">常用网络算法包</h3>

<table>
<thead>
<tr>
<th>名称</th>
<th>语言</th>
</tr>
</thead>

<tbody>
<tr>
<td><a href="https://networkx.org/" rel="noreferrer" target="_blank">NetworkX</a></td>
<td><i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://graph-tool.skewed.de/" rel="noreferrer" target="_blank">graph-tool</a></td>
<td><i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://snap.stanford.edu/index.html" rel="noreferrer" target="_blank">SNAP</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/networkit/networkit" rel="noreferrer" target="_blank">NetworKit</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://igraph.org/" rel="noreferrer" target="_blank">igraph</a></td>
<td><i class="icon icon-c">C</i>, <i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i>, <i class="icon icon-r">R</i></td>
</tr>

<tr>
<td><a href="https://github.com/JuliaGraphs/LightGraphs.jl" rel="noreferrer" target="_blank">lightgraphs</a></td>
<td><i class="icon icon-julia">Julia</i></td>
</tr>
</tbody>
</table>

<p>不同扩展包之间的性能比较如下表所示 <sup class="footnote-ref" id="fnref:lin2020benchmark"><a href="#fn:lin2020benchmark">9</a></sup>：</p>

<table>
<thead>
<tr>
<th>数据集</th>
<th>算法</th>
<th>graph-tool</th>
<th>igraph</th>
<th>LightGraphs</th>
<th>NetworKit</th>
<th>NetworkX</th>
<th>SNAP</th>
</tr>
</thead>

<tbody>
<tr>
<td>Amazon</td>
<td>CC</td>
<td>0.08</td>
<td>0.22</td>
<td>0.07</td>
<td>0.09</td>
<td>2.22</td>
<td>0.31</td>
</tr>

<tr>
<td>Amazon</td>
<td>k-core</td>
<td>0.08</td>
<td>0.15</td>
<td>0.04</td>
<td>0.15</td>
<td>3.63</td>
<td>0.37</td>
</tr>

<tr>
<td>Amazon</td>
<td>loading</td>
<td>2.61</td>
<td>0.57</td>
<td>4.66</td>
<td>0.98</td>
<td>4.72</td>
<td>1.61</td>
</tr>

<tr>
<td>Amazon</td>
<td>page rank</td>
<td>0.04</td>
<td>0.57</td>
<td>0.02</td>
<td>0.02</td>
<td>8.59</td>
<td>0.58</td>
</tr>

<tr>
<td>Amazon</td>
<td>shortest path</td>
<td>0.03</td>
<td>0.05</td>
<td>0.01</td>
<td>0.04</td>
<td>1.37</td>
<td>0.12</td>
</tr>

<tr>
<td>Google</td>
<td>CC</td>
<td>0.28</td>
<td>1.38</td>
<td>0.29</td>
<td>0.37</td>
<td>7.77</td>
<td>1.56</td>
</tr>

<tr>
<td>Google</td>
<td>k-core</td>
<td>0.39</td>
<td>0.92</td>
<td>0.16</td>
<td>0.83</td>
<td>42.6</td>
<td>1.31</td>
</tr>

<tr>
<td>Google</td>
<td>loading</td>
<td>11.02</td>
<td>3.87</td>
<td>16.75</td>
<td>4.38</td>
<td>19.24</td>
<td>7.56</td>
</tr>

<tr>
<td>Google</td>
<td>page rank</td>
<td>0.36</td>
<td>2.42</td>
<td>0.06</td>
<td>0.1</td>
<td>33.5</td>
<td>2.31</td>
</tr>

<tr>
<td>Google</td>
<td>shortest path</td>
<td>0.08</td>
<td>0.41</td>
<td>0.01</td>
<td>0.14</td>
<td>3.41</td>
<td>0.26</td>
</tr>

<tr>
<td>Pokec</td>
<td>CC</td>
<td>1.83</td>
<td>3.96</td>
<td>1.5</td>
<td>1.75</td>
<td>61.74</td>
<td>9.75</td>
</tr>

<tr>
<td>Pokec</td>
<td>k-core</td>
<td>3.6</td>
<td>5.99</td>
<td>0.95</td>
<td>5.05</td>
<td>296.26</td>
<td>6.91</td>
</tr>

<tr>
<td>Pokec</td>
<td>loading</td>
<td>71.46</td>
<td>25.75</td>
<td>170.63</td>
<td>26.77</td>
<td>140.19</td>
<td>52.73</td>
</tr>

<tr>
<td>Pokec</td>
<td>page rank</td>
<td>1.1</td>
<td>23.39</td>
<td>0.21</td>
<td>0.24</td>
<td>239.75</td>
<td>8.62</td>
</tr>

<tr>
<td>Pokec</td>
<td>shortest path</td>
<td>0.48</td>
<td>0.6</td>
<td>0.05</td>
<td>0.56</td>
<td>5.65</td>
<td>2.3</td>
</tr>
</tbody>
</table>

<h3 id="常用网络可视化软件">常用网络可视化软件</h3>

<table>
<thead>
<tr>
<th>软件</th>
<th>平台</th>
</tr>
</thead>

<tbody>
<tr>
<td><a href="https://cytoscape.org/" rel="noreferrer" target="_blank">Cytoscape</a></td>
<td><i class="icon icon-windows">Windows</i>, <i class="icon icon-macos">macOS</i>, <i class="icon icon-linux">Linux</i></td>
</tr>

<tr>
<td><a href="https://gephi.org/" rel="noreferrer" target="_blank">Gephi</a></td>
<td><i class="icon icon-windows">Windows</i>, <i class="icon icon-macos">macOS</i>, <i class="icon icon-linux">Linux</i></td>
</tr>

<tr>
<td><a href="https://tulip.labri.fr/TulipDrupal/" rel="noreferrer" target="_blank">Tulip</a></td>
<td><i class="icon icon-windows">Windows</i>, <i class="icon icon-macos">macOS</i>, <i class="icon icon-linux">Linux</i></td>
</tr>

<tr>
<td><a href="http://mrvar.fdv.uni-lj.si/pajek/" rel="noreferrer" target="_blank">Pajek</a></td>
<td><i class="icon icon-windows">Windows</i></td>
</tr>
</tbody>
</table>

<p>不同可视化软件之间的比较如下表所示 <sup class="footnote-ref" id="fnref:pavlopoulos2017empirical"><a href="#fn:pavlopoulos2017empirical">10</a></sup>：</p>

<table>
<thead>
<tr>
<th></th>
<th>Cytoscape</th>
<th>Tulip</th>
<th>Gephi</th>
<th>Pajek</th>
</tr>
</thead>

<tbody>
<tr>
<td>Scalability</td>
<td>⭑⭑</td>
<td>⭑</td>
<td>⭑⭑⭑</td>
<td>⭑⭑⭑⭑</td>
</tr>

<tr>
<td>User friendliness</td>
<td>⭑⭑</td>
<td>⭑⭑⭑⭑</td>
<td>⭑⭑⭑</td>
<td>⭑</td>
</tr>

<tr>
<td>Visual styles</td>
<td>⭑⭑⭑⭑</td>
<td>⭑⭑</td>
<td>⭑⭑⭑</td>
<td>⭑</td>
</tr>

<tr>
<td>Edge bundling</td>
<td>⭑⭑⭑</td>
<td>⭑⭑⭑⭑</td>
<td>⭑⭑</td>
<td>-</td>
</tr>

<tr>
<td>Relevance to biology</td>
<td>⭑⭑⭑⭑</td>
<td>⭑⭑</td>
<td>⭑⭑⭑</td>
<td>⭑</td>
</tr>

<tr>
<td>Memory efficiency</td>
<td>⭑</td>
<td>⭑⭑</td>
<td>⭑⭑⭑</td>
<td>⭑⭑⭑⭑</td>
</tr>

<tr>
<td>Clustering</td>
<td>⭑⭑⭑⭑</td>
<td>⭑⭑⭑</td>
<td>⭑</td>
<td>⭑⭑</td>
</tr>

<tr>
<td>Manual node/edge editing</td>
<td>⭑⭑⭑</td>
<td>⭑⭑⭑⭑</td>
<td>⭑⭑⭑</td>
<td>⭑</td>
</tr>

<tr>
<td>Layouts</td>
<td>⭑⭑⭑</td>
<td>⭑⭑</td>
<td>⭑⭑⭑⭑</td>
<td>⭑</td>
</tr>

<tr>
<td>Network profiling</td>
<td>⭑⭑⭑⭑</td>
<td>⭑⭑</td>
<td>⭑⭑⭑</td>
<td>⭑</td>
</tr>

<tr>
<td>File formats</td>
<td>⭑⭑</td>
<td>⭑⭑⭑</td>
<td>⭑⭑⭑⭑</td>
<td>⭑</td>
</tr>

<tr>
<td>Plugins</td>
<td>⭑⭑⭑⭑</td>
<td>⭑⭑</td>
<td>⭑⭑⭑</td>
<td>⭑</td>
</tr>

<tr>
<td>Stability</td>
<td>⭑⭑⭑</td>
<td>⭑</td>
<td>⭑⭑⭑⭑</td>
<td>⭑⭑⭑</td>
</tr>

<tr>
<td>Speed</td>
<td>⭑⭑</td>
<td>⭑</td>
<td>⭑⭑⭑</td>
<td>⭑⭑⭑⭑</td>
</tr>

<tr>
<td>Documentation</td>
<td>⭑⭑⭑⭑</td>
<td>⭑</td>
<td>⭑⭑</td>
<td>⭑⭑⭑</td>
</tr>
</tbody>
</table>

<p>其中，⭑ 表示较弱、⭑⭑ 表示中等、⭑⭑⭑ 表示较好、⭑⭑⭑⭑ 表示优秀。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:newman2014networks">Newman, M. E. J. (2014) <em>网络科学引论</em>. 电子工业出版社.
 <a class="footnote-return" href="#fnref:newman2014networks">↩</a></li>
<li id="fn:dijkstra-wikipedia"><a href="https://zh.wikipedia.org/wiki/戴克斯特拉算法" rel="noreferrer" target="_blank">https://zh.wikipedia.org/wiki/戴克斯特拉算法</a>
 <a class="footnote-return" href="#fnref:dijkstra-wikipedia">↩</a></li>
<li id="fn:floyd-warshall-wikipedia"><a href="https://zh.wikipedia.org/zh-hans/Floyd-Warshall算法" rel="noreferrer" target="_blank">https://zh.wikipedia.org/zh-hans/Floyd-Warshall算法</a>
 <a class="footnote-return" href="#fnref:floyd-warshall-wikipedia">↩</a></li>
<li id="fn:kernighan1970efficient">Kernighan, B. W., &amp; Lin, S. (1970). An efficient heuristic procedure for partitioning graphs. <em>The Bell system technical journal</em>, 49(2), 291-307.
 <a class="footnote-return" href="#fnref:kernighan1970efficient">↩</a></li>
<li id="fn:fortunato2010community">Fortunato, S. (2010). Community detection in graphs. <em>Physics reports</em>, 486(3-5), 75-174.
 <a class="footnote-return" href="#fnref:fortunato2010community">↩</a></li>
<li id="fn:liu2020deep">Liu, F., Xue, S., Wu, J., Zhou, C., Hu, W., Paris, C., &hellip; &amp; Yu, P. S. (2020). Deep Learning for Community Detection: Progress, Challenges and Opportunities. <em>arXiv preprint arXiv:2005.08225</em>.
 <a class="footnote-return" href="#fnref:liu2020deep">↩</a></li>
<li id="fn:luo2011new">骆志刚, 丁凡, 蒋晓舟, &amp; 石金龙. (2011). 复杂网络社团发现算法研究新进展. <em>国防科技大学学报</em>, (1), 12.
 <a class="footnote-return" href="#fnref:luo2011new">↩</a></li>
<li id="fn:blondel2008fast">Blondel, V. D., Guillaume, J. L., Lambiotte, R., &amp; Lefebvre, E. (2008). Fast unfolding of communities in large networks. <em>Journal of statistical mechanics: theory and experiment</em>, 2008(10), P10008.
 <a class="footnote-return" href="#fnref:blondel2008fast">↩</a></li>
<li id="fn:lin2020benchmark"><a href="https://www.timlrx.com/2020/05/10/benchmark-of-popular-graph-network-packages-v2/" rel="noreferrer" target="_blank">Benchmark of popular graph/network packages v2</a>
 <a class="footnote-return" href="#fnref:lin2020benchmark">↩</a></li>
<li id="fn:pavlopoulos2017empirical">Pavlopoulos, G. A., Paez-Espino, D., Kyrpides, N. C., &amp; Iliopoulos, I. (2017). Empirical comparison of visualization tools for larger-scale network analysis. <em>Advances in bioinformatics</em>, 2017.
 <a class="footnote-return" href="#fnref:pavlopoulos2017empirical">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>真实世界网络结构 (Structure of Real-World Network)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/11/structure-of-real-world-network/</link>
      <pubDate>Sat, 28 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/11/structure-of-real-world-network/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文为<a href="/categories/复杂网络/">《复杂网络系列》</a>文章<br />
本文内容主要参考自：《网络科学引论》<sup class="footnote-ref" id="fnref:newman2014networks"><a href="#fn:newman2014networks">1</a></sup></p>
</blockquote>

<h2 id="分支">分支</h2>

<p>在无向网络中，一个典型的现象是很多网络都有一个分支，该分支占据了网络的绝大部分，而剩余部分则被划分为大量的小分支，这些小分支之间彼此并不相连。如下图所示：</p>

<p><img src="/images/cn/2020-11-28-structure-of-real-world-network/components-in-an-undirected-network.png" alt="" /></p>

<p>一个网络通常不能有两个或更多占据网络大部分的大分支。如果将一个 <code>$n$</code> 个顶点的网络分解为两个分支，每个分支约为 <code>$\dfrac{1}{2} n$</code> 个顶点，则两个分支的顶点之间会有 <code>$\dfrac{1}{4} n^2$</code> 个顶点对，这些顶点对有可能一个顶点在一个大分支中，而另一个顶点在另外一个大分支中。如果在任何一个顶点对之间有一条边，那么这两个分支就会合并为一个分支。</p>

<p>有向图中分支分为两种：<strong>弱连通分支</strong>和<strong>强连通分支</strong>。弱连通分支的定义与无向网络的分支定义类似，强连通分支是指网络顶点的一个最大子集，该子集中的顶点能够通过有向路径到达其余所有顶点，同时也能够通过有向路径从其余所有顶点到达。</p>

<p>每个连通分支拥有<strong>外向分支</strong>（即从强连通分支中的任意顶点出发，沿着有向路径能够到达的所有顶点的集合）和<strong>内向分支</strong>（即沿着有向路径能够到达强连通分支的所有顶点的集合）。利用<strong>“领结”图</strong>可以很好地刻画有向网络的总体情况，万维网的“领结”图如下所示：</p>

<p><img src="/images/cn/2020-11-28-structure-of-real-world-network/components-in-a-directed-network.png" alt="" /></p>

<h2 id="小世界效应">小世界效应</h2>

<p><strong>小世界效应</strong>（small-world effect）是指对于大多数网络而言，网络顶点之间的测地距离都惊人的小，例如：<a href="https://zh.wikipedia.org/wiki/%E5%85%AD%E5%BA%A6%E5%88%86%E9%9A%94%E7%90%86%E8%AE%BA" rel="noreferrer" target="_blank">六度分隔理论</a>。网络的数学模型显示出网络测地路径长度的数量级通常与网络定点数 <code>$n$</code> 成对数关系 ，即 <code>$\log n$</code>。</p>

<h2 id="度分布">度分布</h2>

<p>顶点的度是指连接到它的边的数量。<strong>度分布</strong>（degree distribution）<code>$p_k$</code> 是指网络中节点度的概率分布，也可以理解为从网络中随机选择一个顶点，其度为 <code>$k$</code> 的概率。<strong>度序列</strong>（degree sequence）是指所有顶点度的集合。</p>

<p>根据度 <code>$k$</code> 描述出大型网络的度分布有着非常重要的作用，下图给出了 Internet 的度分布：</p>

<p><img src="/images/cn/2020-11-28-structure-of-real-world-network/degree-distribution-of-the-internet.png" alt="" /></p>

<p>现实世界中，几乎所有网络的度分布都有类似的由度较大的核心顶点构成的尾部，统计上称为<strong>右偏</strong>（right-skewed）的。</p>

<h2 id="幂律和无标度网络">幂律和无标度网络</h2>

<p>以 Internet 为例，下图给出了度分布的一个有趣特征，下图使用了对数标度重新绘制了上图的直方图：</p>

<p><img src="/images/cn/2020-11-28-structure-of-real-world-network/power-law-degree-distribution-of-the-internet.png" alt="" /></p>

<p>如上图所示，对数处理后，分布大致遵循一条直线。度分布 <code>$p_k$</code> 的对数与度 <code>$k$</code> 的对数之间具有线性函数关系：</p>

<p><code>$$
\ln p_k = - \alpha \ln k + c
$$</code></p>

<p>对两侧同时做指数运算，有：</p>

<p><code>$$
p_k = C k^{- \alpha}
$$</code></p>

<p>其中，<code>$C = e^c$</code> 是一个常数。这种形式的分布，即按照 <code>$k$</code> 的幂变化，称为<strong>幂律</strong>（power law）。在不同类型的网络中，幂律度分布是普遍存在的，常数 <code>$\alpha$</code> 是幂律的指数，该值的典型取值区间为 <code>$2 \leq \alpha \leq 3$</code>。通常，度分布并非在整个区间都遵循幂律分布，当 <code>$k$</code> 较小时，度分布并不是单调的。具有幂律度分布的网络也称为<strong>无标度网络</strong>（scale-free network）。</p>

<p>观察幂律分布的另外一种方式是构建<strong>累积分布函数</strong>，定义如下：</p>

<p><code>$$
P_k = \sum_{k' = k}^{\infty} p_{k'}
$$</code></p>

<p>假设度分布 <code>$p_k$</code> 在尾部服从幂律，确切地讲，对于某个 <code>$k_{\min}$</code>，当 <code>$k \geq k_{\min}$</code> 时有 <code>$p_k = C k^{- \alpha}$</code>，则对于 <code>$k \geq k_{\min}$</code>，有：</p>

<p><code>$$
P_{k}=C \sum_{k^{\prime}=k}^{\infty} k^{\prime-\alpha} \simeq C \int_{k}^{\infty} k^{\prime-\alpha} \mathrm{d} k^{\prime}=\frac{C}{\alpha-1} k^{-(\alpha-1)}
$$</code></p>

<p>这里通过积分来近似求和是合理的，因为当 <code>$k$</code> 值较大时，幂律函数的变化率较小。所以，如果度分布 <code>$p_k$</code> 服从幂律，那么 <code>$p_k$</code> 的累积分布函数也服从幂律。</p>

<h2 id="聚类系数">聚类系数</h2>

<p>聚类系数是度量某个顶点的两个邻居顶点也互为邻居的平均概率。该测度计算值与随机条件下得到的期望值之间有较大的差异，这种巨大差异可能也显示出了真正发挥作用的社会效应。在合作网络中，与随机选择合作者相比，实际的合作网络中包含更多的三角形结构。这种现象背后有很多原因，其中一个原因可能是人们会介绍其合作者认识，而这些合作者两两之间也开始进行合作。</p>

<p>随着度的增加，局部聚类系数不断减少，这种现象的一个可能的解释是顶点分成紧密的群组或社团，同一个群组内部的顶点之间连接较多。在表现出此类行为的网络中，属于小型群组的顶点的度较小，因为这种群组的成员也相对较少，但在较大的群组中的顶点的度较大。同时，小型群组中的顶点的局部聚类系数较高。出现这种情况是因为将每个群组与网络的其余部分隔离开之后，每个群组大体上相当于一个小型网络，较小的网络会有更大的聚类系数。当对不同规模的网络取平均之后，会发现度小的顶点具有较高的聚类系数，如下图所示：</p>

<p><img src="/images/cn/2020-11-28-structure-of-real-world-network/local-clustering-as-a-function-of-degree-on-the-internet.png" alt="" /></p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:newman2014networks">Newman, M. E. J. (2014) <em>网络科学引论</em>. 电子工业出版社.
 <a class="footnote-return" href="#fnref:newman2014networks">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>网络表示，测度和度量 (Network Representation, Measures &amp; Metrics)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/11/graph-theory/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/11/graph-theory/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文为<a href="/categories/复杂网络/">《复杂网络系列》</a>文章<br />
本文内容主要参考自：《网络科学引论》<sup class="footnote-ref" id="fnref:newman2014networks"><a href="#fn:newman2014networks">1</a></sup></p>
</blockquote>

<p><strong>网络</strong>（network）也称为<strong>图</strong>（graph），是一个由多个<strong>顶点</strong>（vertex）及连接顶点的<strong>边</strong>（edge）组成的集合。在网络中，我们通常用 <code>$n$</code> 表示顶点的数目，用 <code>$m$</code> 表示边的数目。在大多数网络中两个顶点之间都只有一条边，极少数情况下，两个顶点之间有多条边，称之为<strong>重边</strong>（multiedge）。在极特殊情况下，还会存在连接到顶点自身的边，称之为<strong>自边</strong>（self-edge）。既没有自边也没有重边的图称之为<strong>简单网络</strong>（simple network）或<strong>简单图</strong>（simple graph），存在重边的网络称之为<strong>重图</strong>（multigraph）。相关概念示例如下：</p>

<p><img src="/images/cn/2020-11-21-network-representation-measures-and-metrics/graph.png" alt="" /></p>

<h2 id="网络表示">网络表示</h2>

<h3 id="无向网络">无向网络</h3>

<p>对于一个包含 <code>$n$</code> 个顶点的无向图，可以用整数 <code>$1$</code> 到 <code>$n$</code> 对各个顶点进行标注。如果用 <code>$\left(i, j\right)$</code> 表示顶点 <code>$i$</code> 和顶点 <code>$j$</code> 之间的边，那么通过给定 <code>$n$</code> 的值及所有边的列表就能表示一个完整的网络，这种表示方法称之为<strong>边列表</strong>（edge list）。</p>

<p>相比于边列表，<strong>邻接矩阵</strong>（adjacency matrix）可以更好地表示网络。一个简单图的邻接矩阵 <code>$\mathbf{A}$</code> 中元素 <code>$A_{ij}$</code> 的含义如下：</p>

<p><code>$$
A_{ij}=\left\{\begin{array}{ll}
1 &amp; \text{如果顶点 } i \text{ 和顶点 } j \text{ 之间存在一条边} \\
0 &amp; \text{其他}
\end{array}\right.
$$</code></p>

<p>对于一个没有自边的网络，其邻接矩阵有两个特点：</p>

<ol>
<li>邻接矩阵对角线上的元素取值均为零。</li>
<li>邻接矩阵是对称的。</li>
</ol>

<h3 id="加权网络">加权网络</h3>

<p>对于<strong>加权网络</strong>（weighted network）和<strong>赋值网络</strong>（valued network）可以将邻接矩阵中对应元素的值设定为相应的权重的方式来进行表示。</p>

<h3 id="有向网络">有向网络</h3>

<p><strong>有向网络</strong>（directed network）或<strong>有向图</strong>（directed graph）有时简称为 digraph，在这类网络中，每条边都有方向，从一个顶点指向另一个顶点，称之为<strong>有向边</strong>（directed edge）。</p>

<div class="blockquote" style='border-left: 4px solid #369BE5;'><strong>注意：</strong> 有向网络的邻接矩阵中元素 <code>$A_{ij} = 1$</code> 时表示存在从顶点 <code>$j$</code> 到顶点 <code>$i$</code> 的边。虽然表示方法有些出人意料，但在数据计算上会带来极大的方便。</div>

<h3 id="超图">超图</h3>

<p>在某些类型的网络中，一些边会同时连接多个顶点。例如：创建一个社会网络，用来表示一个大规模社区中的各个家庭。每个家庭都可能会有两名或多名成员，因此表示这些家庭之间关系的做好方法就是使用一种广义边来同时连接多个顶点。这样的边称之为<strong>超边</strong>（hyperedge），含有超边的网络称之为<strong>超图</strong>（hypergraph）。下图 (a) 表示一个小型超图，其中超边用环的形式表示。</p>

<p><img src="/images/cn/2020-11-21-network-representation-measures-and-metrics/hypergraph.png" alt="" /></p>

<p>当一个网络中的顶点因为某种群组之间的关系被连接在一起时，可以使用超图来表示这个网络，在社会学中，这样的网络称之为<strong>隶属网络</strong>。对于超图，可于采用<strong>二分图</strong>的方式进行表示，通过引入 4 个新的顶点代表 4 个群组，在顶点及其所属群组之间通过边连接，如上图 (b) 所示。</p>

<h3 id="二分网络">二分网络</h3>

<p>群组内成员之间的关系可以用超图中的超边表示，也可以等价地用更方便的<strong>二分图</strong>（bipartite network）表示。这种网络中有两类顶点，一类顶点代表原始顶点，另一类顶点则表示原始顶点所属的群组。</p>

<p>二分网络中，与邻接矩阵等价的是一个矩形矩阵，称之为<strong>关联矩阵</strong>（incidence matrix）。如果 <code>$n$</code> 代表人数或网络中的成员数目，<code>$g$</code> 是群组的数目，那么关联矩阵 <code>$\mathbf{B}$</code> 是一个 <code>$g \times n$</code> 的矩阵，其元素 <code>$B_{ij}$</code> 的取值含义如下：</p>

<p><code>$$
B_{ij}=\left\{\begin{array}{ll}
1 &amp; \text{如果顶点 } j  \text{ 属于群组 } i \\
0 &amp; \text{其他}
\end{array}\right.
$$</code></p>

<p>研究统一类型顶点之间的直接联系可以通过对二分网络进行<strong>单模投影</strong>（one-mode projection），推导出同类顶点之间的直接联系，如下图所示。</p>

<p><img src="/images/cn/2020-11-21-network-representation-measures-and-metrics/one-mode-projection.png" alt="" /></p>

<h3 id="树">树</h3>

<p><strong>树（tree）</strong>是连通的、无向的且不包含闭合循环的网络，如下图所示。</p>

<p><img src="/images/cn/2020-11-21-network-representation-measures-and-metrics/tree.png" alt="" /></p>

<p><strong>连通</strong>是指任意两个顶点之间都存在一条相互可达的路径。一个网络可能有两个或多个部分组成，每个部分相互之间不连通，如果任意单独的部分都为树，则称这个网络为<strong>森林</strong>（forest）。</p>

<p>由于树没有闭合循环，因此任意两个顶点之间有且只有一条相连的路径。如果一个树有 <code>$n$</code> 个顶点，那么它有且仅有 <code>$n - 1$</code> 条边。</p>

<h3 id="度">度</h3>

<p>图中顶点的<strong>度</strong>（degree）是指与其直接相连的边数目。将顶点 <code>$i$</code> 的度表示为 <code>$k_i$</code>，对于有 <code>$n$</code> 个顶点构成的无向图，可利用邻接矩阵将度表示为：</p>

<p><code>$$
k_i = \sum_{j=1}^{n} A_{ij}
$$</code></p>

<p>在无向图中，每个边都有两端，如果一共有 <code>$m$</code> 条边，那么就有 <code>$2m$</code> 个边的端点。同时，边的端点数与所有顶点度的总和相等：</p>

<p><code>$$
2m = \sum_{j=1}^{n} k_i
$$</code></p>

<p>即</p>

<p><code>$$
m = \dfrac{1}{2} \sum_{i=1}^{n} k_i = \dfrac{1}{2} \sum_{ij} A_{ij}
$$</code></p>

<p>无向图中顶点度的均值 <code>$c$</code> 为：</p>

<p><code>$$
c = \dfrac{1}{n} \sum_{i=1}^{n} k_i
$$</code></p>

<p>综上可得：</p>

<p><code>$$
c = \dfrac{2m}{n}
$$</code></p>

<p>在一个简单图中，可能的边数的最大值是 <code>$\dbinom{n}{2} = \dfrac{1}{2} n \left(n - 1\right)$</code> 个。图的<strong>连通度</strong>（connectance）或<strong>密度</strong>（density）<code>$\rho$</code> 是所有图中实际出现的边的数目与边数最大值之间的比值：</p>

<p><code>$$
\rho = \dfrac{m}{\dbinom{n}{2}} = \dfrac{2m}{n \left(n - 1\right)} = \dfrac{c}{n - 1}
$$</code></p>

<p>在有向图中，每个顶点有两个度：<strong>入度</strong>（in-degree）是连接到该顶点的入边的数目，<strong>出度</strong>（out-degree）是出边数目。当从顶点 <code>$j$</code> 到 <code>$i$</code> 有一条边时，邻接矩阵中对应的元素 <code>$A_{ij} = 1$</code>，则入度和出度记为：</p>

<p><code>$$
k_i^{\text{in}} = \sum_{j=1}^{n} A_{ij}, k_j^{\text{out}} = \sum_{i=1}^{n} A_{ij}
$$</code></p>

<p>在有向图中，边的数目 <code>$m$</code> 等于入边的端点数总和，也等于出边的端点数总和，有：</p>

<p><code>$$
m=\sum_{i=1}^{n} k_{i}^{\mathrm{in}}=\sum_{j=1}^{n} k_{j}^{\mathrm{out}}=\sum_{i j} A_{i j}
$$</code></p>

<p>每个有向图的入度的均值 <code>$c_{\text{in}}$</code> 和出度的均值 <code>$c_{\text{out}}$</code> 是相等的：</p>

<p><code>$$
c_{\text {in }}=\frac{1}{n} \sum_{i=1}^{n} k_{i}^{\text {in }}=\frac{1}{n} \sum_{j=1}^{n} k_{j}^{\text {out }}=c_{\text {out }}
$$</code></p>

<p>简化后有：</p>

<p><code>$$
c = \dfrac{m}{n}
$$</code></p>

<h3 id="路径">路径</h3>

<p>网络中的<strong>路径</strong>是指由一组顶点构成的序列，序列中每两个连续顶点都通过网络中的边连接在一起，路径长度等于该路径经过的边的数目（而非顶点的数目）。从顶点 <code>$j$</code> 到顶点 <code>$i$</code> 存在长度为 <code>$r$</code> 的路径总数为：</p>

<p><code>$$
N_{ij}^{\left(r\right)} = \left[\mathbf{A}^r\right]_{ij}
$$</code></p>

<p>其中，<code>$\left[\cdots\right]_{ij}$</code> 表示矩阵中的第 <code>$i$</code> 行、第 <code>$j$</code> 列的元素。</p>

<p><strong>测地路径</strong>（geodesic path），简称为<strong>最短路径</strong>（shortest path），即两个顶点间不存在更短路径的路径。图的<strong>直径</strong>（diameter）是指图中任意一对相互连接的顶点之间的最长测地路径长度。<strong>欧拉路径</strong>（Eulerian path）是经过网络中的所有边且每条边只经过一次的路径。<strong>哈密顿路径</strong>（Hamiltonian path）是访问网络的所有顶点且每个顶点只访问一次的路径。</p>

<h3 id="分支">分支</h3>

<p>如果一个网络中两个顶点之间不存在路径，则称这个网络是<strong>非连通</strong>（disconnected）的，如果网络中任意两个顶点之间都能找到一条路径，则称这个网络是<strong>连通</strong>（connected）的。</p>

<p>网络中的子群称为<strong>分支</strong>（component）。分支是网络中顶点的子集，该子集中任何两个顶点之间至少存在一条路径，在保证该性质的前提下，网络中其他顶点都不能被添加到这个子集中。在保证一个给定性质的前提下，不能再向它添加其他顶点，就称其为<strong>最大子集</strong>（maximal subset）。</p>

<h3 id="连通度">连通度</h3>

<p>如果两条路经除了起点和终点外，不共享其他任何顶点，那么这两条路径是<strong>顶点独立</strong>（vertex-independent）的。如果两条路径是顶点独立的，那么也是边独立的，反之则不成立。</p>

<p>两个顶点之间的独立路径数称为顶点之间的<strong>连通度</strong>（connectivity），如果明确考虑边还是顶点，则需利用<strong>边连通度</strong>（edge connectivity）及<strong>顶点连通度</strong>（vertex connectivity）的概念。</p>

<h3 id="子图">子图</h3>

<p>令原图表示为 <code>$G = \left(V, E\right)$</code>，其中，<code>$V$</code> 是图中所有顶点的集合，<code>$E$</code> 是图中所有边的集合，有：</p>

<ol>
<li><strong>子图</strong>（subgraph）：<code>$G'$</code> 中所有顶点和边均包含于原图 <code>$G$</code> 中，即 <code>$E' \in E, V' \in V$</code>。</li>
<li><strong>生成子图</strong>（spanning subgraph）：<code>$G'$</code> 中顶点同原图 <code>$G$</code> 相同，且 <code>$E' \in E$</code>。</li>
<li><strong>导出子图</strong>（induced subgraph）：<code>$G'$</code> 中，<code>$V' \in V$</code>，同时对于 <code>$V'$</code> 中任意一个顶点，只要在原图 <code>$G$</code> 中有对应的边，则也应包含在 <code>$E'$</code> 中。</li>
</ol>

<p><img src="/images/cn/2020-11-21-network-representation-measures-and-metrics/subgraph.png" alt="" /></p>

<h3 id="motif">Motif</h3>

<p>Motif <sup class="footnote-ref" id="fnref:milo2002network"><a href="#fn:milo2002network">2</a></sup> 被定义为反复出现的重要连接模式。这些模式在真实的网络中要比随机网络中出现的更加频繁，如下图所示：</p>

<p><img src="/images/cn/2020-11-21-network-representation-measures-and-metrics/motifs-real-randomized-networks.png" alt="" /></p>

<p>Motif 的显著性定义为：</p>

<p><code>$$
Z_i = \dfrac{N_i^{\text{real}} - \bar{N}_i^{\text{rand}}}{\text{std} \left(N_i^{\text{rand}}\right)}
$$</code></p>

<p>其中，<code>$N_i^{\text{real}}$</code> 为模式在真实图中出现的次数，<code>$N_i^{\text{rand}}$</code> 为模式在随机图中出现的次数。</p>

<h3 id="graphlets">Graphlets</h3>

<p>Graphlets 是对 Motif 的扩展，Motif 是从全局的角度发现模式，而 Graphlets 是从局部角度出发。Graphlets 是连接的非同构子图，这里要求子图为导出子图。下图展示了节点数为 2 至 5 的所有 Graphlets：</p>

<p><img src="/images/cn/2020-11-21-network-representation-measures-and-metrics/graphlets.png" alt="" /></p>

<p>更多关于 Motif 和 Graphlets 的细节请参见 <sup class="footnote-ref" id="fnref:jain2019network"><a href="#fn:jain2019network">3</a></sup> <sup class="footnote-ref" id="fnref:henderson2012rolx"><a href="#fn:henderson2012rolx">4</a></sup> 。</p>

<h2 id="测度和度量">测度和度量</h2>

<h3 id="中心性">中心性</h3>

<h4 id="度中心性">度中心性</h4>

<p><strong>中心性</strong>（centrality）是研究“网络中哪些顶点是最重要或最核心的？”这个问题的一个概念。网络中心性的最简单的测度是顶点的度，即与顶点相连的边的数量。有时为了强调度作为中心性测度的用途，在社会学中也称之为<strong>度中心性</strong>（degree centrality）。</p>

<h4 id="特征向量中心性">特征向量中心性</h4>

<p>度中心性可自然地扩展为<strong>特征向量中心性</strong>（eigenvector centrality）。可以将度中心性理解为给某顶点所有邻居顶点赋予一个“中心性值”，但并非所有连接顶点的值都是相同的。很多情况下，一个顶点会由于连接到一些本身很重要的点，而使自身的重要性得到提升，这就是特征向量中心性的本质。</p>

<p>对于每个顶点 <code>$i$</code>，假设其中心性为 <code>$x_i$</code>。对于所有 <code>$i$</code>，可以设其初始值 <code>$x_i = 1$</code>，利用该值可以计算出另一个更能体现中心性的值 <code>$x'_i$</code>，将 <code>$x'_i$</code> 定义为 <code>$i$</code> 所有邻居顶点的中心性之和：</p>

<p><code>$$
x'_i = \sum_{j} A_{ij} x_j
$$</code></p>

<p>重复该过程可以得到更好的估计值，重复 <code>$t$</code> 步后，中心性 <code>$\mathbf{x} \left(t\right)$</code> 的计算公式如下：</p>

<p><code>$$
\mathbf{x} \left(t\right) = \mathbf{A}^t \mathbf{x} \left(0\right)
$$</code></p>

<p>当 <code>$t \to \infty$</code> 时，中心性向量的极限与邻接矩阵中的主特征向量成正比。因此，可以等价地认为中心性 <code>$\mathbf{x}$</code> 满足：</p>

<p><code>$$
\mathbf{A} \mathbf{x} = \kappa_1 \mathbf{x}
$$</code></p>

<p>其中，<code>$\kappa_1$</code> 为矩阵 <code>$\mathbf{A}$</code> 的特征值中的最大值。</p>

<p>特征向量中心性对于有向图和无向图都适用。在有向图中，邻接矩阵是非对称的，因此网络有两类特征向量，通常情况下我们选择右特征向量来定义中心性。因为在有向网络中，中心性主要是由指向顶点的顶点，而不是由顶点指向的顶点赋予的。</p>

<h4 id="katz-中心性">Katz 中心性</h4>

<p><strong>Katz 中心性</strong>解决了特征向量中心性中节点中心性可能为零的问题。通过为网络中每个顶点赋予少量的“免费”中心性，可以定义：</p>

<p><code>$$
x_i = \alpha \sum_{j} A_{ij} x_j + \beta
$$</code></p>

<p>其中，<code>$\alpha$</code> 和 <code>$\beta$</code> 是正常数。使用矩阵表示可以写成：</p>

<p><code>$$
\mathbf{x} = \alpha \mathbf{A} \mathbf{x} + \beta \mathbf{1}
$$</code></p>

<p>其中，<code>$\mathbf{1}$</code> 代表向量 <code>$\left(1, 1, 1, \cdots\right)$</code>。重新整理有 <code>$\mathbf{x} = \beta \left(\mathbf{I} - \alpha \mathbf{A}\right)^{-1} \mathbf{1}$</code>，由于只关心相对值，通常可以设置 <code>$\beta = 1$</code>，则有：</p>

<p><code>$$
\mathbf{x} = \left(\mathbf{I} - \alpha \mathbf{A}\right)^{-1} \mathbf{1}
$$</code></p>

<h4 id="pagerank">PageRank</h4>

<p>Katz 中心性有一个不足，被一个 Katz 中心性较高的顶点指向的顶点具有较高的 Katz 中心性，但如果这个中心性较高的顶点指向大量顶点，那么这些大量被指向的顶点也会拥有较高的中心性，但这种估计并非总是恰当的。在新的中心性中，那些指向很多其他顶点的顶点，即使本身的中心性很高，但也只能传递给它指向的每个顶点少量的中心性，定义为：</p>

<p><code>$$
x_{i}=\alpha \sum_{j} A_{i j} \frac{x_{j}}{k_{j}^{\text {out }}}+\beta
$$</code></p>

<p>其中，<code>$k_j^{\text{out}}$</code> 为顶点的出度，当 <code>$k_j^{\text{out}} = 0$</code> 时可以将其设定为任何一个非零值，都不会影响计算结果。利用矩阵的形式，可以表示为：</p>

<p><code>$$
\mathbf{x}=\alpha \mathbf{AD}^{-1} \mathbf{x}+\beta \mathbf{1}
$$</code></p>

<p>其中，<code>$\mathbf{D}$</code> 为对角矩阵，<code>$D_{ii} = \max \left(k_j^{\text{out}}, 1\right)$</code>。同之前一样，<code>$\beta$</code> 只是整个公式的因子，设置 <code>$\beta = 1$</code>，有：</p>

<p><code>$$
\mathbf{x}=\left(\mathbf{I}-\alpha \mathbf{A} \mathbf{D}^{-1}\right)^{-1} \mathbf{1}
$$</code></p>

<p>该中心性即为 <strong>PageRank</strong>。</p>

<p>上述 4 种中心性的区别和联系如下表所示：</p>

<table>
<thead>
<tr>
<th></th>
<th>带有常数项</th>
<th>不带常数项</th>
</tr>
</thead>

<tbody>
<tr>
<td>除以出度</td>
<td><code>$\mathbf{x} = \left(\mathbf{I}-\alpha \mathbf{A} \mathbf{D}^{-1}\right)^{-1} \mathbf{1}$</code><br/>PageRank</td>
<td><code>$\mathbf{x} = \mathbf{A} \mathbf{D}^{-1} \mathbf{x}$</code><br/>度中心性</td>
</tr>

<tr>
<td>不除出度</td>
<td><code>$\mathbf{x} = \left(\mathbf{I} - \alpha \mathbf{A}\right)^{-1} \mathbf{1}$</code><br/>Katz 中心性</td>
<td><code>$\mathbf{x} = \kappa_1^{-1} \mathbf{A} \mathbf{x}$</code><br/>特征向量中心性</td>
</tr>
</tbody>
</table>

<h4 id="接近度中心性">接近度中心性</h4>

<p><strong>接近度中心性</strong>（closeness centrality）用于度量一个顶点到其他顶点的平均距离。</p>

<p><code>$$
C_{i}=\frac{1}{\ell_{i}}=\frac{n}{\sum_{j} d_{i j}}
$$</code></p>

<p>其中，<code>$d_{i j}$</code> 表示从顶点 <code>$i$</code> 到 <code>$j$</code> 的测地路径长度，即路径中边的总数，<code>$\ell_{i}$</code> 表示从 <code>$i$</code> 到 <code>$j$</code> 的平均测地距离。在大多数网络中，顶点之间的测地距离一般都较小，并且随着网络规模的增长，该值只是以对数级别速度缓慢增长。</p>

<p>在不同分支中的两个顶点之间的测地距离定义为无穷大，则 <code>$C_i$</code> 为零。为了解决这个问题，最常见的方法是只计算同一分支内部的顶点的平均测地距离。新的定义使用顶点之间的调和平均测地距离：</p>

<p><code>$$
C_{i}^{\prime}=\frac{1}{n-1} \sum_{j(\neq i)} \frac{1}{d_{i j}}
$$</code></p>

<p>公式中排除了 <code>$j = i$</code> 的情况，因为 <code>$d_{ii} = 0$</code>。结果也称之为<strong>调和中心性</strong>（harmonic centrality）。</p>

<h4 id="介数中心性">介数中心性</h4>

<p><strong>介数中心性</strong>（betweenness centrality）描述了一个顶点在其他顶点之间路径上的分布程度。假设在网络中每两个顶点之间，在每个单位时间内以相等的概率交换信息，信息总是沿着网络中最短测地路径传播，如果有多条最短测地路径则随机选择。由于消息是沿着最短路径以相同的速率传播，因此经过某个顶点的消息数与经过该顶点的测地路径数成正比。测地路径数就是所谓的介数中心性，简称<strong>介数</strong>。</p>

<p>定义 <code>$n_{st}^i$</code> 为从 <code>$s$</code> 到 <code>$t$</code> 经过 <code>$i$</code> 的测地路径数量，定义 <code>$g_{st}$</code> 为从 <code>$s$</code> 到 <code>$t$</code> 的测地路径总数，那么顶点 <code>$i$</code> 的介数中心性可以表示为：</p>

<p><code>$$
x_{i}=\sum_{s t} \frac{n_{s t}^{i}}{g_{s t}}
$$</code></p>

<p>高介数中心性的顶点由于控制着其他顶点之间的消息传递，在网络中有着很强的影响力。删除介数最高的顶点，也最有可能破坏其他顶点之间的通信。</p>

<p>不同中心性的可视化如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-11-21-network-representation-measures-and-metrics/centrality-measures.png" class="lazyload"/>
  <figcaption><p class="figcaption">不同中心性可视化 <a href="https://commons.wikimedia.org/w/index.php?curid=39064835" rel="noreferrer" target="_blank">By Tapiocozzo, CC BY-SA 4.0</a></p></figcaption>
</figure>

<p>其中，A：介数中心性；B：接近度中心性；C：特征向量中心性；D：度中心性；E：调和中心性；F：Katz 中心性。</p>

<h3 id="传递性">传递性</h3>

<p><strong>传递性</strong>（transitivity）在社会网络中的重要性要比其他网络中重要得多。在数学上，对于关系“<code>$\circ$</code>”，如果 <code>$a \circ b$</code> 和 <code>$b \circ c$</code>，若能推出 <code>$a \circ c$</code>，则称 <code>$\circ$</code> 具有传递性。</p>

<p>完全传递性值出现在每一个分支都是全连通的子图或团的网络中。<strong>团</strong>（clique）是指无向图网络中的一个最大顶点子集，在该子集中任何两个顶点之间都有一条边直接连接。完全传递性没有太多的实际意义，而部分传递性却很有用。在很多网络中，<code>$u$</code> 认识 <code>$v$</code> 且 <code>$v$</code> 认识 <code>$w$</code>，并不能保证 <code>$u$</code> 认识 <code>$w$</code>，但两者之间相互认识的概率很大。</p>

<p>如果 <code>$u$</code> 也认识 <code>$w$</code>，则称该路径是闭合的。在社会网络术语中，称 <code>$u, v, w$</code> 这 3 个顶点形成一个<strong>闭合三元组</strong>（closed triad）。我们将<strong>聚类系数</strong>（clustering coefficient）定义为网络中所有长度为 2 的路径中闭合路径所占的比例：</p>

<p><code>$$
C = \dfrac{\text{长度为 2 的路径中闭合路径数}}{\text{长度为 2 的路径数}}
$$</code></p>

<p>其取值范围在 0 到 1 之间。社会网络的聚类系数比其他网络偏高。</p>

<p>对于顶点 <code>$i$</code>，定地单个顶点的聚类系数为：</p>

<p><code>$$
C_i = \dfrac{\text{顶点 i 的邻居顶点中直接相连的顶点对数}}{\text{顶点 i 的邻居顶点对总数}}
$$</code></p>

<p><code>$C_i$</code> 也称为<strong>局部聚类系数</strong>（local clustering coefficient），该值代表了 <code>$i$</code> 的朋友之间互为朋友的平均概率。</p>

<h3 id="相互性">相互性</h3>

<p>聚类系数观察的是长度为 3 的循环，长度为 2 的循环的频率通过<strong>相互性</strong>（reciprocity）来度量，该频率描述了两个顶点之间相互指向的概率。</p>

<h3 id="相似性">相似性</h3>

<p>社会网络分析的另一个核心概念是顶点之间的相似性。构造网络相似性的测度有两种基本方法：<strong>结构等价</strong>（structural equivalence）和<strong>规则等价</strong>（regular equivalence），如下图所示：</p>

<p><img src="/images/cn/2020-11-21-network-representation-measures-and-metrics/structural-and-regular-equivalence.png" alt="" /></p>

<h4 id="结构等价">结构等价</h4>

<p>针对无向网络中，最简单和最显而易见的结构等价测度就是计算两个顶点的共享邻居顶点数。在无向网络中，顶点 <code>$i$</code> 和 <code>$j$</code> 的共享邻居顶点数表示为 <code>$n_{ij}$</code>，有：</p>

<p><code>$$
n_{ij} = \sum_{k} A_{ik} A_{kj}
$$</code></p>

<p>利用<strong>余弦相似度</strong>可以更好的对其进行度量。将邻接矩阵的第 <code>$i$</code> 和第 <code>$j$</code> 行分别看成两个向量，然后将这两个向量之间的夹角余弦值用于相似性度量，有：</p>

<p><code>$$
\sigma_{i j}=\cos \theta=\frac{\sum_{k} A_{i k} A_{k j}}{\sqrt{\sum_{k} A_{i k}^{2}} \sqrt{\Sigma_{k} A_{j k}^{2}}}
$$</code></p>

<p>假设网络是不带权重的简单图，上式可以化简为：</p>

<p><code>$$
\sigma_{i j}=\frac{\sum_{k} A_{i k} A_{k j}}{\sqrt{k_{i}} \sqrt{k_{j}}}=\frac{n_{i j}}{\sqrt{k_{i} k_{j}}}
$$</code></p>

<p>其中，<code>$k_i$</code> 是顶点 <code>$i$</code> 的度。余弦相似度的取值范围为从 0 到 1，1 表示两个顶点之间拥有完全相同的邻居节点。</p>

<p><strong>皮尔逊相关系数</strong>通过同随机选择邻居顶点条件下共享邻居顶点数的期望值进行比较的方式进行计算，得到的标准的皮尔逊相关系数为：</p>

<p><code>$$
r_{i j}=\frac{\sum_{k}\left(A_{i k}-\left\langle A_{i}\right\rangle\right)\left(A_{j k}-\left\langle A_{j}\right\rangle\right)}{\sqrt{\sum_{k}\left(A_{i k}-\left\langle A_{i}\right\rangle\right)^{2}} \sqrt{\sum_{k}\left(A_{j k}-\left\langle A_{j}\right\rangle\right)^{2}}}
$$</code></p>

<p>上式的取值范围从 -1 到 1，数值越大表明两者之间越相似。</p>

<h4 id="规则等价">规则等价</h4>

<p>规则等价的顶点不必共享邻居顶点，但是两个顶点的邻居顶点本身要具有相似性。一些简单的代数测度思想如下：定义一个相似性值 <code>$\sigma_{ij}$</code>，若顶点 <code>$i$</code> 和 <code>$j$</code> 各自的邻居顶点 <code>$k$</code> 和 <code>$l$</code> 本身具有较高的相似性，则 <code>$i$</code> 和 <code>$j$</code> 的相似性也较高。对于无向网络，有以下公式：</p>

<p><code>$$
\sigma_{i j}=\alpha \sum_{k l} A_{i k} A_{j l} \sigma_{k l}
$$</code></p>

<p>或者利用矩阵性质表示为 <code>$\mathbf{\sigma} = \alpha \mathbf{A \sigma A}$</code>。</p>

<h3 id="同质性">同质性</h3>

<p>在社会网络中，人们倾向于选择那些他们认为与其自身在某些方面相似的人作为朋友，这种倾向性称为<strong>同质性</strong>（homophily）或<strong>同配混合</strong>（assortative mixing）。</p>

<h4 id="依据枚举特征的同配混合">依据枚举特征的同配混合</h4>

<p>假设有一个网络，其顶点根据某个<strong>枚举特征</strong>（例如：国籍、种族、性别等）分类，且该特征的取值是一个有限集合。如果网络中连接相同类型顶点之间的边所占比例很大，那么该网络就是同配的。量化同配性简单的方法是观测这部分边占总边数的比例，但这并不是很好的度量方法，因为如果所有顶点都是同一个类型，那么测度值就是 1。</p>

<p>好的测度可以通过首先找出连接同类顶点的边所占的比例，然后减去在不考虑顶点类型时，随机连接的边中，连接两个同类顶点的边所占比例的期望值的方式得到。常用的测度为<strong>模块度</strong>（modularity）：</p>

<p><code>$$
Q=\frac{1}{2 m} \sum_{i j}\left(A_{i j}-\frac{k_{i} k_{j}}{2 m}\right) \delta_{g_{i} g_{i}}
$$</code></p>

<p>其中，<code>$k_i$</code> 为顶点 <code>$i$</code> 的度，<code>$g_i$</code> 为顶点 <code>$i$</code> 的类型，<code>$m$</code> 为总边数，<code>$\delta_{ij}$</code> 为<a href="https://zh.wikipedia.org/wiki/%E5%85%8B%E7%BD%97%E5%86%85%E5%85%8B%CE%B4%E5%87%BD%E6%95%B0" rel="noreferrer" target="_blank">克罗内克函数</a>。该值严格小于 1，如果同类顶点之间边数的实际值大于随机条件下的期望值，则该值为正数，否则为负数，值为正说明该网络是同配混合的。</p>

<h4 id="依据标量特征的同配混合">依据标量特征的同配混合</h4>

<p>如果根据<strong>标量特征</strong>（例如：年龄、收入等）来度量网络中的同质性。由于该类特征具有确定的顺序，因此根据标量的数值，不仅可以指出两个顶点在什么情况下是完全相同的，也可以指出它们在真么情况下是近似相同的。</p>

<p>令 <code>$x_i$</code> 为顶点 <code>$i$</code> 的标量值，<code>$\left(x_i, x_j\right)$</code> 为网络中每一条边 <code>$\left(i, j\right)$</code> 的两个端点的值，利用协方差可以得到<strong>同配系数</strong>：</p>

<p><code>$$
r=\frac{\sum_{i j}\left(A_{i j}-k_{i} k_{j} / 2 m\right) x_{i} x_{j}}{\sum_{i j}\left(k_{i} \delta_{i j}-k_{i} k_{j} / 2 m\right) x_{i} x_{j}}
$$</code></p>

<p>该系数在全同配混合网络中取最大值 1，在全异配混合网络中取最小值 -1，值 0 意味着边两端的顶点值是非相关的。</p>

<h4 id="依据度的同配混合">依据度的同配混合</h4>

<p>依据度的同配混合是依据标量特征的同配混合的一个特例。依据度的同配混合网络中，高度数顶点倾向于与其他高度数顶点相连，而低度数顶点倾向于与其他低度数顶点相连。</p>

<p>在同配网络中，度大的顶点倾向于聚集在一起的网络中，我们希望得到网络中这些度大的顶点构成的顶点块或核，它们周围是一些度小的顶点构成的低密度<strong>边缘</strong>（periphery）。这种<strong>核心/边缘结构</strong>（core/periphery structure）是社会网络的普遍特征。</p>

<p><img src="/images/cn/2020-11-21-network-representation-measures-and-metrics/core-periphery-structure.png" alt="" /></p>

<p>上图 (a) 给出了一个小型的同配混合网络，其核心/边缘结构明显，上图 (b) 给出了一个小型异配混合网络，通常不具备核心/边缘结构，但顶点的分布更加均匀。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:newman2014networks">Newman, M. E. J. (2014) <em>网络科学引论</em>. 电子工业出版社.
 <a class="footnote-return" href="#fnref:newman2014networks">↩</a></li>
<li id="fn:milo2002network">Milo, R., Shen-Orr, S., Itzkovitz, S., Kashtan, N., Chklovskii, D., &amp; Alon, U. (2002). Network motifs: simple building blocks of complex networks. <em>Science</em>, 298(5594), 824-827.
 <a class="footnote-return" href="#fnref:milo2002network">↩</a></li>
<li id="fn:jain2019network">Jain, D., &amp; Patgiri, R. (2019, April). Network Motifs: A Survey. In <em>International Conference on Advances in Computing and Data Sciences</em> (pp. 80-91). Springer, Singapore.
 <a class="footnote-return" href="#fnref:jain2019network">↩</a></li>
<li id="fn:henderson2012rolx">Henderson, K., Gallagher, B., Eliassi-Rad, T., Tong, H., Basu, S., Akoglu, L., &hellip; &amp; Li, L. (2012, August). Rolx: structural role extraction &amp; mining in large graphs. In <em>Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</em> (pp. 1231-1239).
 <a class="footnote-return" href="#fnref:henderson2012rolx">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>文本相似度 (Text Similarity)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/10/text-similarity/</link>
      <pubDate>Sat, 31 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/10/text-similarity/</guid>
      <description>
        <![CDATA[
        

<p>文本相似度是指衡量两个文本的相似程度，相似程度的评价有很多角度：单纯的字面相似度（例如：我和他 v.s. 我和她），语义的相似度（例如：爸爸 v.s. 父亲）和风格的相似度（例如：我喜欢你 v.s. 我好喜欢你耶）等等。</p>

<h2 id="文本表示角度">文本表示角度</h2>

<h3 id="统计模型">统计模型</h3>

<h4 id="文本切分">文本切分</h4>

<p>在中文和拉丁语系中，文本的直观表示就存在一定的差异，拉丁语系中词与词之间存在天然的分隔符，而中文则没有。</p>

<blockquote>
<p>I can eat glass, it doesn&rsquo;t hurt me.<br />
我能吞下玻璃而不伤身体。</p>
</blockquote>

<p>因此针对拉丁语系的文本切分相对中文容易许多。</p>

<ul>
<li><strong>N 元语法</strong></li>
</ul>

<p>N-gram (N 元语法) 是一种文本表示方法，指文中连续出现的 $n$ 个词语。N-gram 模型是基于 $n-1$ 阶马尔科夫链的一种概率语言模型，可以通过前 $n-1$ 个词对第 $n$ 个词进行预测。以 <code>南京市长江大桥</code> 为例，N-gram 的表示如下：</p>

<pre><code>一元语法（unigram）：南/京/市/长/江/大/桥
二元语法（bigram）：南京/京市/市长/长江/江大/大桥
三元语法（trigram）：南京市/京市长/市长江/长江大/江大桥
</code></pre>

<pre><code class="language-python">import re
from nltk.util import ngrams

s = '南京市长江大桥'
tokens = re.sub(r'\s', '', s)

list(ngrams(tokens, 1))
# [('南',), ('京',), ('市',), ('长',), ('江',), ('大',), ('桥',)]

list(ngrams(tokens, 2))
# [('南', '京'), ('京', '市'), ('市', '长'),
#  ('长', '江'), ('江', '大'), ('大', '桥')]

list(ngrams(tokens, 3, pad_left=True, pad_right=True, left_pad_symbol='&lt;s&gt;', right_pad_symbol='&lt;/s&gt;'))
# [('&lt;s&gt;', '&lt;s&gt;', '南'),
#  ('&lt;s&gt;', '南', '京'),
#  ('南', '京', '市'),
#  ('京', '市', '长'),
#  ('市', '长', '江'),
#  ('长', '江', '大'),
#  ('江', '大', '桥'),
#  ('大', '桥', '&lt;/s&gt;'),
#  ('桥', '&lt;/s&gt;', '&lt;/s&gt;')]
</code></pre>

<ul>
<li><strong>分词</strong></li>
</ul>

<p>分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。在英文的行文中，单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界符来简单划界，唯独词没有一个形式上的分界符，虽然英文也同样存在短语的划分问题，不过在词这一层上，中文比之英文要复杂得多、困难得多。</p>

<pre><code class="language-python">s = '南京市长江大桥'

# jieba
# https://github.com/fxsjy/jieba
import jieba

list(jieba.cut(s, cut_all=False))
# ['南京市', '长江大桥']

list(jieba.cut(s, cut_all=True))
# ['南京', '南京市', '京市', '市长', '长江', '长江大桥', '大桥']

list(jieba.cut_for_search(s))
# ['南京', '京市', '南京市', '长江', '大桥', '长江大桥']

# THULAC
# https://github.com/thunlp/THULAC-Python
import thulac

thulac_ins = thulac.thulac()

thulac_ins.cut(s)
# [['南京市', 'ns'], ['长江', 'ns'], ['大桥', 'n']]

# PKUSEG
# https://github.com/lancopku/PKUSeg-python
import pkuseg

seg = pkuseg.pkuseg(postag=True)

seg.cut(s)
# [('南京市', 'ns'), ('长江', 'ns'), ('大桥', 'n')]

# HanLP
# https://github.com/hankcs/HanLP
import hanlp

tokenizer = hanlp.load('LARGE_ALBERT_BASE')

tokenizer(s)
# ['南京市', '长江', '大桥']
</code></pre>

<h4 id="主题模型">主题模型</h4>

<p>除了对文本进行切分将切分后结果全部用于表示文本外，还可以用部分字词表示一篇文档。主题模型（Topic Model）在机器学习和自然语言处理等领域是用来在一系列文档中发现抽象主题的一种统计模型。</p>

<p><img src="/images/cn/2020-10-31-text-similarity/what-is-topic-model.png" alt="What is Topic Model" /></p>

<p>直观来讲，如果一篇文章有一个中心思想，那么一些特定词语会更频繁的出现。比方说，如果一篇文章是在讲狗的，那“狗”和“骨头”等词出现的频率会高些。如果一篇文章是在讲猫的，那“猫”和“鱼”等词出现的频率会高些。而有些词例如“这个”、“和”大概在两篇文章中出现的频率会大致相等。但真实的情况是，一篇文章通常包含多种主题，而且每个主题所占比例各不相同。因此，如果一篇文章 10% 和猫有关，90% 和狗有关，那么和狗相关的关键字出现的次数大概会是和猫相关的关键字出现次数的 9 倍。</p>

<p>一个主题模型试图用数学框架来体现文档的这种特点。主题模型自动分析每个文档，统计文档内的词语，根据统计的信息来断定当前文档含有哪些主题，以及每个主题所占的比例各为多少 <sup class="footnote-ref" id="fnref:topic-model-wiki"><a href="#fn:topic-model-wiki">1</a></sup>。</p>

<ul>
<li><strong>TF-IDF</strong></li>
</ul>

<p>TF-IDF 是 Term Frequency - Inverse Document Frequency 的缩写，即“词频-逆文本频率”。TF-IDF 可以用于评估一个字词在语料中的一篇文档中的重要程度，基本思想是如果某个字词在一篇文档中出现的频率较高，而在其他文档中出现频率较低，则认为这个字词更能够代表这篇文档。</p>

<p>形式化地，对于文档 $y$ 中的字词 $x$ 的 TF-IDF 重要程度可以表示为：</p>

<p><code>$$
w_{x, y} = tf_{x, y} \times \log \left(\dfrac{N}{df_{x}}\right)
$$</code></p>

<p>其中，<code>$tf_{x, y}$</code> 表示字词 <code>$x$</code> 在文档 <code>$y$</code> 中出现的频率，<code>$df_x$</code> 为包含字词 <code>$x$</code> 的文档数量，<code>$N$</code> 为语料中文档的总数量。</p>

<p>以 <a href="https://github.com/liuhuanyong/MusicLyricChatbot" rel="noreferrer" target="_blank">14 万歌词语料</a> 为例，通过 TF-IDF 计算周杰伦的《简单爱》中最重要的 3 个词为 <code>['睡着', '放开', '棒球']</code>。</p>

<ul>
<li><strong>BM25</strong></li>
</ul>

<p>BM25 算法的全称为 Okapi BM25，是一种搜索引擎用于评估查询和文档之间相关程度的排序算法，其中 BM 是 Best Match 的缩写。</p>

<p>对于一个给定的查询 <code>$Q$</code>，包含的关键词为 <code>$q_1, \cdots, q_n$</code>，一个文档 <code>$D$</code> 的 BM25 值定义为：</p>

<p><code>$$
\operatorname{score}(D, Q)=\sum_{i=1}^{n} \operatorname{IDF}\left(q_{i}\right) \cdot \frac{f\left(q_{i}, D\right) \cdot\left(k_{1}+1\right)}{f\left(q_{i}, D\right)+k_{1} \cdot\left(1-b+b \cdot \frac{|D|}{\text { avgdl }}\right)}
$$</code></p>

<p>其中，<code>$f\left(q_{i}, D\right)$</code> 表示 <code>$q_i$</code> 在文档 <code>$D$</code> 中的词频，<code>$|D|$</code> 表示文档 <code>$D$</code> 中的词数，<code>$\text{avgdl}$</code> 表示语料中所有文档的平均长度。<code>$k_1$</code> 和 <code>$b$</code> 为自由参数，通常取值为 <code>$k_1 \in \left[1.2, 2.0\right], b = 0.75$</code> <sup class="footnote-ref" id="fnref:manning2008introduction"><a href="#fn:manning2008introduction">2</a></sup>。<code>$\operatorname{IDF} \left(q_i\right)$</code> 表示词 <code>$q_i$</code> 的逆文档频率，通常计算方式如下：</p>

<p><code>$$
\operatorname{IDF}\left(q_{i}\right)=\ln \left(\frac{N-n\left(q_{i}\right)+0.5}{n\left(q_{i}\right)+0.5}+1\right)
$$</code></p>

<p>其中，<code>$N$</code> 为语料中文档的总数量，<code>$n \left(q_i\right)$</code> 表示包含 <code>$q_i$</code> 的文档数量。</p>

<p>BM25 算法是对 TF-IDF 算法的优化，在词频的计算上，BM25 限制了文档 <code>$D$</code> 中关键词 <code>$q_i$</code> 的词频对评分的影响。为了防止词频过大，BM25 将这个值的上限设置为 <code>$k_1 + 1$</code>。</p>

<p><img src="/images/cn/2020-10-31-text-similarity/bm25-tf-1.png" alt="" /></p>

<p>同时，BM25 还引入了平均文档长度 <code>$\text{avgdl}$</code>，不同的平均文档长度 <code>$\text{avgdl}$</code> 对 TF 分值的影响如下图所示：</p>

<p><img src="/images/cn/2020-10-31-text-similarity/bm25-tf-2.png" alt="" /></p>

<ul>
<li><strong>TextRank</strong></li>
</ul>

<p>TextRank <sup class="footnote-ref" id="fnref:mihalcea2004textrank"><a href="#fn:mihalcea2004textrank">3</a></sup> 是基于 PageRank <sup class="footnote-ref" id="fnref:page1999pagerank"><a href="#fn:page1999pagerank">4</a></sup> 算法的一种关键词提取算法。PageRank 最早是用于 Google 的网页排名，因此以公司创始人拉里·佩奇（Larry Page）的姓氏来命名。PageRank 的计算公式如下：</p>

<p><code>$$
S\left(V_{i}\right)=(1-d)+d * \sum_{V_{j} \in I n\left(V_{i}\right)} \frac{1}{\left|O u t\left(V_{j}\right)\right|} S\left(V_{j}\right)
$$</code></p>

<p>其中，<code>$V_i$</code> 表示任意一个网页，<code>$V_j$</code> 表示链接到网页 <code>$V_i$</code> 的网页，<code>$S \left(V_i\right)$</code> 表示网页 <code>$V_i$</code> 的 PageRank 值，<code>$In \left(V_i\right)$</code> 表示网页 <code>$V_i$</code> 所有的入链集合，<code>$Out \left(V_j\right)$</code> 表示网页 <code>$V_j$</code> 所有的出链集合，<code>$|\cdot|$</code> 表示集合的大小，<code>$d$</code> 为阻尼系数，是为了确保每个网页的 PageRank 值都大于 0。</p>

<p>TextRank 由 PageRank 改进而来，计算公式如下：</p>

<p><code>$$
WS \left(V_{i}\right)=(1-d)+d * \sum_{V_{j} \in In\left(V_{i}\right)} \frac{w_{j i}}{\sum_{V_{k} \in Out\left(V_{j}\right)} w_{j k}} WS \left(V_{j}\right)
$$</code></p>

<p>相比于 PageRank 公式增加了权重项 <code>$W_{ji}$</code>，用来表示两个节点之间的边的权重。TextRank 提取关键词的算法流程如下：</p>

<ol>
<li>将文本进行切分得到 <code>$S_i = \left[t_{i1}, t_{i2}, \cdots, t_{in}\right]$</code>。</li>
<li>将 <code>$S_i$</code> 中大小为 <code>$k$</code> 的滑动窗口中的词定义为共现关系，构建关键词图 <code>$G = \left(V, E\right)$</code>。</li>
<li>根据 TextRank 的计算公式对每个节点的值进行计算，直至收敛。</li>
<li>对节点的 TextRank 的值进行倒叙排序，获取前 <code>$n$</code> 个词作为关键词。</li>
</ol>

<ul>
<li><strong>LSA, PLSA, LDA &amp; HDP</strong></li>
</ul>

<p><strong>潜在语义分析（LSA, Latent Semantic Analysis）</strong><sup class="footnote-ref" id="fnref:deerwester1990indexing"><a href="#fn:deerwester1990indexing">5</a></sup> 的核心思想是将文本的高维词空间映射到一个低维的向量空间，我们称之为隐含语义空间。降维可以通过<a href="/cn/2017/12/evd-svd-and-pca/">奇异值分解（SVD）</a>实现，令 <code>$X$</code> 表示语料矩阵，元素 <code>$\left(i, j\right)$</code> 表示词 <code>$i$</code> 和文档 <code>$j$</code> 的共现情况（例如：词频）：</p>

<p><code>$$
X = \mathbf{d}_{j} \cdot \mathbf{t}_{i}^{T} = \left[\begin{array}{c} x_{1, j} \\ \vdots \\ x_{i, j} \\ \vdots \\ x_{m, j} \end{array}\right] \cdot \left[\begin{array}{ccccc}
x_{i, 1} &amp; \ldots &amp; x_{i, j} &amp; \ldots &amp; x_{i, n}
\end{array}\right]
= \left[\begin{array}{ccccc}
x_{1,1} &amp; \ldots &amp; x_{1, j} &amp; \ldots &amp; x_{1, n} \\
\vdots &amp; \ddots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_{i, 1} &amp; \ldots &amp; x_{i, j} &amp; \ldots &amp; x_{i, n} \\
\vdots &amp; \ddots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_{m, 1} &amp; \ldots &amp; x_{m, j} &amp; \ldots &amp; x_{m, n}
\end{array}\right]
$$</code></p>

<p>利用奇异值分解：</p>

<p><code>$$
X = U \Sigma V^{T}
$$</code></p>

<p>取最大的 <code>$K$</code> 个奇异值，则可以得到原始矩阵的近似矩阵：</p>

<p><code>$$
\widetilde{X} =U \widetilde{\Sigma} V^{T}
$$</code></p>

<p>在处理一个新的文档时，可以利用下面的公式将原始的词空间映射到潜在语义空间：</p>

<p><code>$$
\tilde{x} =\tilde{\Sigma} ^{-1} V^{T} x_{test}
$$</code></p>

<p>LSA 的优点：</p>

<ol>
<li>低维空间可以刻画同义词</li>
<li>无监督模型</li>
<li>降维可以减少噪声，使特征更加鲁棒</li>
</ol>

<p>LSA 的缺点：</p>

<ol>
<li>未解决多义词问题</li>
<li>计算复杂度高，增加新文档时需要重新训练</li>
<li>没有明确的物理解释</li>
<li>高斯分布假设不符合文本特征（词频不为负）</li>
<li>维度的确定是 Ad hoc 的</li>
</ol>

<p><strong>概率潜语义分析（Probabilistic Latent Semantic Analysis, PLSA）</strong><sup class="footnote-ref" id="fnref:hofmann1999probabilistic"><a href="#fn:hofmann1999probabilistic">6</a></sup> 相比于 LSA 增加了概率模型，每个变量以及相应的概率分布和条件概率分布都有明确的物理解释。</p>

<p>PLSA 认为一篇文档可以由多个主题混合而成，而每个主题都是词上的概率分布，文章中的每个词都是由一个固定的主题生成的，如下图所示：</p>

<p><img src="/images/cn/2020-10-31-text-similarity/plsa.png" alt="" /></p>

<p>针对第 <code>$m$</code> 篇文档 <code>$d_m$</code> 中的每个词的生成概率为：</p>

<p><code>$$
p\left(w \mid d_{m}\right)=\sum_{z=1}^{K} p(w \mid z) p\left(z \mid d_{m}\right)=\sum_{z=1}^{K} \varphi_{z w} \theta_{m z}
$$</code></p>

<p>因此整篇文档的生成概率为：</p>

<p><code>$$
p\left(\vec{w} \mid d_{m}\right)=\prod_{i=1}^{n} \sum_{z=1}^{K} p\left(w_{i} \mid z\right) p\left(z \mid d_{m}\right)=\prod_{i=1}^{n} \sum_{z=1}^{K} \varphi_{z w_{i}} \theta_{d z}
$$</code></p>

<p>PLSA 可以利用 EM 算法求得局部最优解。</p>

<p>PLSA 优点：</p>

<ol>
<li>定义了概率模型，有明确的物理解释</li>
<li>多项式分布假设更加符合文本特征</li>
<li>可以通过模型选择和复杂度控制来确定主题的维度</li>
<li>解决了同义词和多义词的问题</li>
</ol>

<p>PLSA 缺点：</p>

<ol>
<li>随着文本和词的增加，PLSA 模型参数也随之线性增加</li>
<li>可以生成语料中的文档的模型，但不能生成新文档的模型</li>
<li>EM 算法求解的计算量较大</li>
</ol>

<p><strong>隐含狄利克雷分布（Latent Dirichlet Allocation, LDA）</strong><sup class="footnote-ref" id="fnref:blei2003latent"><a href="#fn:blei2003latent">7</a></sup> 在 PLSA 的基础上增加了参数的先验分布。在 PLSA 中，对于一个新文档，是无法获取 <code>$p \left(d\right)$</code> 的，因此这个概率模型是不完备的。LDA 对于 <code>$\vec{\theta}_m$</code> 和 <code>$\vec{\phi}_k$</code> 都增加了多项式分布的共轭分布狄利克雷分布作为先验，整个 LDA 模型如下图所示：</p>

<p><img src="/images/cn/2020-10-31-text-similarity/lda.png" alt="" /></p>

<p>LDA 的参数估计可以通过<a href="/cn/2017/12/mcmc-and-gibbs-sampling/">吉布斯采样</a>实现。PLSA 和 LDA 的更多细节请参见《LDA 数学八卦》<sup class="footnote-ref" id="fnref:lda-math"><a href="#fn:lda-math">8</a></sup>。</p>

<p>LDA 在使用过程中仍需要指定主题的个数，而<strong>层次狄利克雷过程（Hierarchical Dirichlet Processes, HDP）</strong><sup class="footnote-ref" id="fnref:teh2006hierarchical"><a href="#fn:teh2006hierarchical">9</a></sup> 通过过程的构造可以自动训练出主题的个数，更多实现细节请参考论文。</p>

<p>LSA，PLSA，LDA 和 HDP 之间的演化关系如下图所示：</p>

<p><img src="/images/cn/2020-10-31-text-similarity/lsa-plsa-lda-hdp.png" alt="" /></p>

<blockquote>
<p>本节相关代码详见 <a href="https://github.com/leovan/leovan.me/tree/master/scripts/cn/2020-10-31-text-similarity/topic-model.py" rel="noreferrer" target="_blank">这里</a>。</p>
</blockquote>

<h4 id="距离度量">距离度量</h4>

<blockquote>
<p>本节内容源自 <a href="/cn/2019/01/similarity-and-distance-measurement/">相似性和距离度量 (Similarity &amp; Distance Measurement)</a>。</p>
</blockquote>

<p>相似性度量 (Similarity Measurement) 用于衡量两个元素之间的相似性程度或两者之间的距离 (Distance)。距离衡量的是指元素之间的不相似性 (Dissimilarity)，通常情况下我们可以利用一个距离函数定义集合 <code>$X$</code> 上元素间的距离，即：</p>

<p><code>$$
d: X \times X \to \mathbb{R}
$$</code></p>

<ul>
<li><strong>Jaccard 系数</strong></li>
</ul>

<p><code>$$
s = \dfrac{\left|X \cap Y\right|}{\left| X \cup Y \right|} = \dfrac{\left|X \cap Y\right|}{\left|X\right| + \left|Y\right| - \left|X \cap Y\right|}
$$</code></p>

<p>Jaccard 系数的取值范围为：<code>$\left[0, 1\right]$</code>，0 表示两个集合没有重合，1 表示两个集合完全重合。</p>

<ul>
<li><strong>Dice 系数</strong></li>
</ul>

<p><code>$$
s = \dfrac{2 \left| X \cap Y \right|}{\left|X\right| + \left|Y\right|}
$$</code></p>

<p>与 Jaccard 系数相同，Dice 系数的取值范围为：<code>$\left[0, 1\right]$</code>，两者之间可以相互转换 <code>$s_d = 2 s_j / \left(1 + s_j\right), s_j = s_d / \left(2 - s_d\right)$</code>。不同于 Jaccard 系数，Dice 系数的差异函数 <code>$d = 1 - s$</code> 并不是一个合适的距离度量，因为其并不满足距离函数的三角不等式。</p>

<ul>
<li><strong>Tversky 系数</strong></li>
</ul>

<p><code>$$
s = \dfrac{\left| X \cap Y \right|}{\left| X \cap Y \right| + \alpha \left| X \setminus Y \right| + \beta \left| Y \setminus X \right|}
$$</code></p>

<p>其中，<code>$X \setminus Y$</code> 表示集合的相对补集。Tversky 系数可以理解为 Jaccard 系数和 Dice 系数的一般化，当 <code>$\alpha = \beta = 1$</code> 时为 Jaccard 系数，当 <code>$\alpha = \beta = 0.5$</code> 时为 Dice 系数。</p>

<ul>
<li><strong>Levenshtein 距离</strong></li>
</ul>

<p>Levenshtein 距离是 <strong>编辑距离 (Editor Distance)</strong> 的一种，指两个字串之间，由一个转成另一个所需的最少编辑操作次数。允许的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。例如将 <strong>kitten</strong> 转成 <strong>sitting</strong>，转换过程如下：</p>

<p><code>$$
\begin{equation*}
\begin{split}
\text{kitten} \to \text{sitten} \left(k \to s\right) \\
\text{sitten} \to \text{sittin} \left(e \to i\right) \\
\text{sittin} \to \text{sitting} \left(\  \to g\right)
\end{split}
\end{equation*}
$$</code></p>

<p>编辑距离的求解可以利用动态规划的思想优化计算的时间复杂度。</p>

<ul>
<li><strong>Jaro-Winkler 距离</strong></li>
</ul>

<p>对于给定的两个字符串 <code>$s_1$</code> 和 <code>$s_2$</code>，Jaro 相似度定义为：</p>

<p><code>$$
sim =
\begin{cases}
0 &amp; \text{if} \  m = 0 \\
\dfrac{1}{3} \left(\dfrac{m}{\left|s_1\right|} + \dfrac{m}{\left|s_2\right|} + \dfrac{m-t}{m}\right) &amp; \text{otherwise}
\end{cases}
$$</code></p>

<p>其中，<code>$\left|s_i\right|$</code> 为字符串 <code>$s_i$</code> 的长度，<code>$m$</code> 为匹配的字符的个数，<code>$t$</code> 换位数目的一半。如果字符串 <code>$s_1$</code> 和 <code>$s_2$</code> 相差不超过 <code>$\lfloor \dfrac{\max \left(\left|s_1\right|, \left|s_2\right|\right)}{2} \rfloor - 1$</code>，我们则认为两个字符串是匹配的。例如，对于字符串 <strong>CRATE</strong> 和 <strong>TRACE</strong>，仅 <strong>R, A, E</strong> 三个字符是匹配的，因此 <code>$m = 3$</code>，尽管 <strong>C, T</strong> 均出现在两个字符串中，但是他们的距离超过了 1 (即，<code>$\lfloor \dfrac{5}{2} \rfloor - 1$</code>)，因此 <code>$t = 0$</code>。</p>

<p>Jaro-Winkler 相似度给予了起始部分相同的字符串更高的分数，其定义为：</p>

<p><code>$$
sim_w = sim_j + l p \left(1 - sim_j\right)
$$</code></p>

<p>其中，<code>$sim_j$</code> 为字符串 <code>$s_1$</code> 和 <code>$s_2$</code> 的 Jaro 相似度，<code>$l$</code> 为共同前缀的长度 (规定不超过 <code>$4$</code>)，<code>$p$</code> 为调整系数 (规定不超过 <code>$0.25$</code>)，Winkler 将其设置为 <code>$p = 0.1$</code>。</p>

<ul>
<li><strong>汉明距离</strong></li>
</ul>

<p>汉明距离为两个<strong>等长字符串</strong>对应位置的不同字符的个数，也就是将一个字符串变换成另外一个字符串所需要<strong>替换</strong>的字符个数。例如：<strong>10<span style="color:#0000ff;">1</span>1<span style="color:#0000ff;">1</span>01</strong> 与 <strong>10<span style="color:#ff0000;">0</span>1<span style="color:#ff0000;">0</span>01</strong> 之间的汉明距离是 2，<strong>“<span style="color:#0000ff;">t</span>o<span style="color:#0000ff;">n</span>e<span style="color:#0000ff;">d</span>”</strong> 与 <strong>“<span style="color:#ff0000;">r</span>o<span style="color:#ff0000;">s</span>e<span style="color:#ff0000;">s</span>”</strong> 之间的汉明距离是 3。</p>

<pre><code class="language-python">import textdistance as td

s1 = '南京市长江大桥'
s2 = '北京市三元桥'

td.jaccard(s1, s2)
# 0.6666666666666666

td.sorensen_dice(s1, s2)
# 0.46153846153846156

td.tversky(s1, s2)
# 0.3

td.levenshtein(s1, s2)
# 4

td.jaro(s1, s2)
# 0.6428571428571429

td.hamming(s1, s2)
# 5
</code></pre>

<h3 id="表示学习">表示学习</h3>

<p>基于表示学习的文本相似度计算方法的思路如下：</p>

<ol>
<li>利用表示学习方法将不定长的文本表示为定长的实值向量。</li>
<li>计算转换后的实值向量相似度，用于表示两个文本的相似度。</li>
</ol>

<p>关于文本表示学习和实值向量相似度计算请参见之前博客：<a href="/cn/2018/10/word-embeddings/">词向量 (Word Embeddings)</a>，<a href="/cn/2019/01/similarity-and-distance-measurement/">相似性和距离度量 (Similarity &amp; Distance Measurement)</a>，<a href="/cn/2020/03/pre-trained-model-for-nlp/">预训练自然语言模型 (Pre-trained Models for NLP)</a>。</p>

<h2 id="文本词法-句法和语义角度">文本词法，句法和语义角度</h2>

<blockquote>
<p>本节主要参考自《基于词法、句法和语义的句子相似度计算方法》<sup class="footnote-ref" id="fnref:zhai2019sentence"><a href="#fn:zhai2019sentence">10</a></sup>。</p>
</blockquote>

<p>一段文本的内容分析由浅及深可以分为词法，句法和语义三个层次。</p>

<ol>
<li>词法，以词为对象，研究包括分词，词性和命名实体等。</li>
<li>句法，以句子为对象，研究包括句子成分和句子结构等。</li>
<li>语义，研究文字所表达的含义和蕴含的知识等。</li>
</ol>

<p>词法和句法可以统一成为语法，如下图所示：</p>

<p><img src="/images/cn/2020-10-31-text-similarity/lexical-syntax.png" alt="" /></p>

<h3 id="词法">词法</h3>

<p>词法层以单个句子作为输入，其输出为已标记（词性，命名实体等）的词汇序列。</p>

<p><img src="/images/cn/2020-10-31-text-similarity/lexical-demo.png" alt="" /></p>

<p>词汇序列的相似度计算可以采用上文中的距离度量等方式实现。</p>

<h3 id="句法">句法</h3>

<p>句法层用于研究句子各个组成部分及其排列顺序，将文本分解为句法单位，以理解句法元素的排列方式。句法层接收词法层分析后的将其转化为依存图。</p>

<p><img src="/images/cn/2020-10-31-text-similarity/syntax-demo.png" alt="" /></p>

<p>对于依存图，我们可以利用三元组 <code>$S = \left(V_1, E, V_2\right)$</code> 表示任意一个依存关系，然后通过统计计算两个文本的依存图的三元组集合之间的相似度来评价句法层的相似度。此外，也可以从树结构的角度直接评价依存句法的相似度，更多细节可参考相关论文 <sup class="footnote-ref" id="fnref:zhang1989simple"><a href="#fn:zhang1989simple">11</a></sup> <sup class="footnote-ref" id="fnref:meila2000learning"><a href="#fn:meila2000learning">12</a></sup>。</p>

<h3 id="语义">语义</h3>

<p>语义层用于研究文本所蕴含的意义。例如“父亲”和“爸爸”在词法层完全不同，但在语义层却具有相同的含义。针对语义相似度的两种深度学习范式如下：</p>

<p><img src="/images/cn/2020-10-31-text-similarity/deep-learning-paradigms-for-text-similarity.png" alt="" /></p>

<p>第一种范式首先通过神经网络获取文本的向量表示，再通过向量之间的相似度来衡量文本的语义相似度。这种范式在提取特征时不考虑另一个文本的信息，更适合做大规模的语义相似召回，例如：DSSM <sup class="footnote-ref" id="fnref:huang2013learning"><a href="#fn:huang2013learning">13</a></sup>，ARC-I <sup class="footnote-ref" id="fnref:hu2014convolutional"><a href="#fn:hu2014convolutional">14</a></sup>，CNTN <sup class="footnote-ref" id="fnref:qiu2015convolutional"><a href="#fn:qiu2015convolutional">15</a></sup>，LSTM-RNN <sup class="footnote-ref" id="fnref:palangi2016deep"><a href="#fn:palangi2016deep">16</a></sup> 等。</p>

<p>第二种范式首先通过深度模型提取两个文本的交叉特征，得到匹配信号张量，再聚合为匹配分数。这种范式同时考虑两个文本的输入信息，更适合做小规模的语义相似精排，例如：ARC-II <sup class="footnote-ref" id="fnref:hu2014convolutional"><a href="#fn:hu2014convolutional">14</a></sup>，MatchPyramid <sup class="footnote-ref" id="fnref:pang2016text"><a href="#fn:pang2016text">17</a></sup>，Match-SRNN <sup class="footnote-ref" id="fnref:wan2016match"><a href="#fn:wan2016match">18</a></sup>，Duet <sup class="footnote-ref" id="fnref:mitra2017learning"><a href="#fn:mitra2017learning">19</a></sup> 等。</p>

<h2 id="文本长度角度">文本长度角度</h2>

<p>从文本长度角度出发，我们可以粗略的将文本分类为<strong>短文本</strong>和<strong>长文本</strong>。<strong>短文本</strong>包括“字词”，“短语”，“句子”等相对比较短的文本形式，<strong>长文本</strong>包括“段落”，“篇章”等相对比较长的文本形式。</p>

<h3 id="短文本-v-s-短文本">短文本 v.s. 短文本</h3>

<p>短文本同短文本的常见比较形式有：关键词（字词）同文本标题（句子）的匹配，相似查询（句子）的匹配等。如果单纯的希望获取字符层面的差异，可以通过距离度量进行相似度比较。如果需要从语义的角度获取相似度，则可以利用表示学习对需要比对的文本进行表示，在通过语义向量之间的相似程度来衡量原始文本之间的相似度，详情可参见上文。</p>

<h3 id="短文本-v-s-长文本">短文本 v.s. 长文本</h3>

<p>短文本同长文本的比较多见于文档的搜索，即给定相关的查询（字词），给出最相关的文档（段落和篇章）。对于这类问题常见的解决方式是对长文本利用 TF-IDF，BM25等方法或进行主题建模后，再同查询的关键词进行匹配计算相似度度。</p>

<h3 id="长文本-v-s-长文本">长文本 v.s. 长文本</h3>

<p>长文本同长文本的比较多见于文档的匹配和去重，对于这类问题常见的解决方式是利用关键词提取获取长文本的特征向量，然后利用特征向量之间的相似度衡量对应文本的相似程度。在针对海量文本的去重，还以应用 <a href="/cn/2020/08/nearest-neighbor-search/">SimHash</a> 等技术对文本生成一个指纹，从而实现快速去重。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:topic-model-wiki"><a href="https://zh.wikipedia.org/wiki/主题模型" rel="noreferrer" target="_blank">https://zh.wikipedia.org/wiki/主题模型</a>
 <a class="footnote-return" href="#fnref:topic-model-wiki">↩</a></li>
<li id="fn:manning2008introduction">Manning, C. D., Schütze, H., &amp; Raghavan, P. (2008). <em>Introduction to information retrieval</em>. Cambridge university press.
 <a class="footnote-return" href="#fnref:manning2008introduction">↩</a></li>
<li id="fn:mihalcea2004textrank">Mihalcea, R., &amp; Tarau, P. (2004, July). Textrank: Bringing order into text. In <em>Proceedings of the 2004 conference on empirical methods in natural language processing</em> (pp. 404-411).
 <a class="footnote-return" href="#fnref:mihalcea2004textrank">↩</a></li>
<li id="fn:page1999pagerank">Page, L., Brin, S., Motwani, R., &amp; Winograd, T. (1999). <em>The PageRank citation ranking: Bringing order to the web</em>. Stanford InfoLab.
 <a class="footnote-return" href="#fnref:page1999pagerank">↩</a></li>
<li id="fn:deerwester1990indexing">Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., &amp; Harshman, R. (1990). Indexing by latent semantic analysis. <em>Journal of the American society for information science</em>, 41(6), 391-407.
 <a class="footnote-return" href="#fnref:deerwester1990indexing">↩</a></li>
<li id="fn:hofmann1999probabilistic">Hofmann, T. (1999, August). Probabilistic latent semantic indexing. In <em>Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval</em> (pp. 50-57).
 <a class="footnote-return" href="#fnref:hofmann1999probabilistic">↩</a></li>
<li id="fn:blei2003latent">Blei, D. M., Ng, A. Y., &amp; Jordan, M. I. (2003). Latent dirichlet allocation. <em>Journal of machine Learning research</em>, 3(Jan), 993-1022.
 <a class="footnote-return" href="#fnref:blei2003latent">↩</a></li>
<li id="fn:lda-math">Rickjin(靳志辉). 2013. LDA数学八卦
 <a class="footnote-return" href="#fnref:lda-math">↩</a></li>
<li id="fn:teh2006hierarchical">Teh, Y. W., Jordan, M. I., Beal, M. J., &amp; Blei, D. M. (2006). Hierarchical dirichlet processes. <em>Journal of the american statistical association</em>, 101(476), 1566-1581.
 <a class="footnote-return" href="#fnref:teh2006hierarchical">↩</a></li>
<li id="fn:zhai2019sentence">翟社平, 李兆兆, 段宏宇, 李婧, &amp; 董迪迪. (2019). 基于词法, 句法和语义的句子相似度计算方法. <em>东南大学学报: 自然科学版</em>, 49(6), 1094-1100.
 <a class="footnote-return" href="#fnref:zhai2019sentence">↩</a></li>
<li id="fn:zhang1989simple">Zhang, K., &amp; Shasha, D. (1989). Simple fast algorithms for the editing distance between trees and related problems. <em>SIAM journal on computing</em>, 18(6), 1245-1262.
 <a class="footnote-return" href="#fnref:zhang1989simple">↩</a></li>
<li id="fn:meila2000learning">Meila, M., &amp; Jordan, M. I. (2000). Learning with mixtures of trees. <em>Journal of Machine Learning Research</em>, 1(Oct), 1-48.
 <a class="footnote-return" href="#fnref:meila2000learning">↩</a></li>
<li id="fn:huang2013learning">Huang, P. S., He, X., Gao, J., Deng, L., Acero, A., &amp; Heck, L. (2013, October). Learning deep structured semantic models for web search using clickthrough data. In <em>Proceedings of the 22nd ACM international conference on Information &amp; Knowledge Management</em> (pp. 2333-2338).
 <a class="footnote-return" href="#fnref:huang2013learning">↩</a></li>
<li id="fn:hu2014convolutional">Hu, B., Lu, Z., Li, H., &amp; Chen, Q. (2014). Convolutional neural network architectures for matching natural language sentences. In <em>Advances in neural information processing systems</em> (pp. 2042-2050).
 <a class="footnote-return" href="#fnref:hu2014convolutional">↩</a></li>
<li id="fn:qiu2015convolutional">Qiu, X., &amp; Huang, X. (2015, June). Convolutional neural tensor network architecture for community-based question answering. In <em>Twenty-Fourth international joint conference on artificial intelligence</em>.
 <a class="footnote-return" href="#fnref:qiu2015convolutional">↩</a></li>
<li id="fn:palangi2016deep">Palangi, H., Deng, L., Shen, Y., Gao, J., He, X., Chen, J., &hellip; &amp; Ward, R. (2016). Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval. <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 24(4), 694-707.
 <a class="footnote-return" href="#fnref:palangi2016deep">↩</a></li>
<li id="fn:pang2016text">Pang, L., Lan, Y., Guo, J., Xu, J., Wan, S., &amp; Cheng, X. (2016). Text matching as image recognition. In <em>Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI&rsquo;16)</em>. (pp. 2793–2799).
 <a class="footnote-return" href="#fnref:pang2016text">↩</a></li>
<li id="fn:wan2016match">Wan, S., Lan, Y., Xu, J., Guo, J., Pang, L., &amp; Cheng, X. (2016, July). Match-SRNN: modeling the recursive matching structure with spatial RNN. In <em>Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</em> (pp. 2922-2928).
 <a class="footnote-return" href="#fnref:wan2016match">↩</a></li>
<li id="fn:mitra2017learning">Mitra, B., Diaz, F., &amp; Craswell, N. (2017, April). Learning to match using local and distributed representations of text for web search. In <em>Proceedings of the 26th International Conference on World Wide Web</em> (pp. 1291-1299).
 <a class="footnote-return" href="#fnref:mitra2017learning">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>最近邻搜索 (Nearest Neighbor Search)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/08/nearest-neighbor-search/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/08/nearest-neighbor-search/</guid>
      <description>
        <![CDATA[
        

<p><strong>最近邻搜索（Nearest Neighbor Search）</strong>是指在一个确定的距离度量和一个搜索空间内寻找与给定查询项距离最小的元素。更精确地，对于一个包含 <code>$N$</code> 个元素的集合 <code>$\mathcal{X} = \left\{\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_n\right\}$</code>，给定查询项 <code>$\mathbf{q}$</code> 的最近邻 <code>$NN \left(\mathbf{q}\right) = \arg\min_{\mathbf{x} \in \mathcal{X}} dist \left(\mathbf{q}, \mathbf{x}\right)$</code>，其中 <code>$dist \left(\mathbf{q}, \mathbf{x}\right)$</code> 为 <code>$\mathbf{q}$</code> 和 <code>$\mathbf{x}$</code> 之间的距离。由于<a href="/cn/2018/10/word-embeddings/#维数灾难-the-curse-of-dimensionality">维数灾难</a>，我们很难在高维欧式空间中以较小的代价找到精确的最近邻。<strong>近似最近邻搜索（Approximate Nearest Neighbor Search）</strong>则是一种通过牺牲精度来换取时间和空间的方式从大量样本中获取最近邻的方法。</p>

<h2 id="精确搜索">精确搜索</h2>

<h3 id="暴力查找-brute-force-search">暴力查找（Brute-force Search）</h3>

<p>最简单的最邻近搜索便是遍历整个点集，计算它们和目标点之间的距离，同时记录目前的最近点。这样的算法较为初级，可以为较小规模的点集所用，但是对于点集的尺寸和空间的维数稍大的情况则不适用。对于 <code>$D$</code> 维的 <code>$N$</code> 个样本而言，暴力查找方法的复杂度为 <code>$O \left(DN\right)$</code>。</p>

<h3 id="k-d-树">k-D 树</h3>

<p>k-D 树（k-Dimesion Tree）<sup class="footnote-ref" id="fnref:bentley1975multidimensional"><a href="#fn:bentley1975multidimensional">1</a></sup> 是一种可以高效处理 <code>$k$</code> 维空间信息的数据结构。k-D 树具有二叉搜索树的形态，二叉搜索树上的每个结点都对应 <code>$k$</code> 维空间内的一个点。其每个子树中的点都在一个 <code>$k$</code> 维的超长方体内，这个超长方体内的所有点也都在这个子树中。k-D 树的构建过程如下：</p>

<ol>
<li>若当前超长方体中只有一个点，返回这个点。</li>
<li>选择一个维度，将当前超长方体按照这个维度分割为两个超长方体。</li>
<li>选择一个切割点，将小于这个点的归入其中一个超长方体（左子树），其余归入另一个超长方体（右子树）。</li>
<li>递归地对分出的两个超长方体构建左右子树。</li>
</ol>

<p>一个 <code>$k = 2$</code> 的例子如下：</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/k-d-tree.png" class="lazyload"/>
  
</figure>

<p>构建 k-D 树目前最优方法的时间复杂度为 <code>$O \left(n \log n\right)$</code>。对于单次查询，当 <code>$2$</code> 维时，查询时间复杂度最优为 <code>$O \left(\log n\right)$</code>，最坏为 <code>$O \left(\sqrt{n}\right)$</code>，扩展至 <code>$k$</code> 维，最坏为 <code>$O \left(n^{1 - \frac{1}{k}}\right)$</code>。k-D 树对于低维度最近邻搜索比较好，但当 <code>$k$</code> 增长到很大时，搜索的效率就变得很低，这也是“维数灾难”的一种体现。</p>

<h3 id="ball-树">Ball 树</h3>

<p>为了解决 k-D 树在高维数据上的问题，Ball 树 <sup class="footnote-ref" id="fnref:omohundro1989five"><a href="#fn:omohundro1989five">2</a></sup> 结构被提了出来。k-D 树是沿着笛卡尔积（坐标轴）方向迭代分割数据，而 Ball 树是通过一系列的超球体分割数据而非超长方体。Ball 树的构建过程如下：</p>

<ol>
<li>若当前超球体中只有一个点，返回这个点。</li>
<li>定义所有点的质心为 <code>$c$</code>，离质心 <code>$c$</code> 最远的点为 <code>$c_1$</code>，离 <code>$c_1$</code> 最远的点为 <code>$c_2$</code>。</li>
<li>将 <code>$c_1$</code> 和 <code>$c_2$</code> 作为聚类中心对数据点进行聚类得到两个簇 <code>$\left(c_1, r_1\right), \left(c_2, r_2\right)$</code>，将其归入左子树和右子树，其中 <code>$r$</code> 为超球的半径。</li>
<li>递归的对分出的两个超球体构建左右子树。</li>
</ol>

<p>一个二维的例子如下：</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/ball-tree.png" class="lazyload"/>
  
</figure>

<p>每个点必须只能隶属于一个簇，但不同簇的超球体之间是可以相交的。在利用 Ball 树进行查询时，首先自上而下的找到包含查询点的叶子簇 <code>$\left(c, r\right)$</code>，在这个簇中找到距离查询点最近的观测点，这两个点的距离 <code>$d_{upper}$</code> 即为<strong>最近邻的距离上界</strong>。之后检查该叶子簇的所有兄弟簇是否包含比这个上界更小的观测点，在检查时，如果查询节点距离兄弟簇圆心的距离大于兄弟簇的半径与之前计算的上界 <code>$d_{upper}$</code> 之和，则这个兄弟节点不可能包含所需要的最近邻。</p>

<p>构建 Ball 树的时间复杂度为 <code>$O \left(n \left(\log n\right)^2\right)$</code>，查询时间复杂度为 <code>$O \left(\log \left(n\right)\right)$</code>。</p>

<h2 id="近似搜索">近似搜索</h2>

<h3 id="基于哈希的算法">基于哈希的算法</h3>

<p>基于哈希的算法的目标是将一个高维数据点转换为哈希编码的表示方式，主要包含两类方法：<strong>局部敏感哈希（Local Sensitive Hash, LSH）</strong>和<strong>哈希学习（Learning to Hash, L2H）</strong>。</p>

<h4 id="局部敏感哈希">局部敏感哈希</h4>

<p>局部敏感哈希采用的是与数据无关的哈希函数，也就是说整个学习处理过程不依赖于任何的数据内容信息。LSH 通过一个局部敏感哈希函数将相似的数据点以更高的概率映射到相同的哈希编码上去。这样我们在进行查询时就可以先找到查询样本落入那个哈希桶，然后再在这个哈希桶内进行遍历比较就可以找到最近邻了。</p>

<p>要使得相近的数据点通过哈希后落入相同的桶中，哈希函数需要满足如下条件：</p>

<ol>
<li>如果 <code>$d \left(x, y\right) \leq d_1$</code>，则 <code>$Pr \left[h \left(x\right), h \left(y\right)\right] \geq p_1$</code>。</li>
<li>如果 <code>$d \left(x, y\right) \geq d_2$</code>，则 <code>$Pr \left[h \left(x\right), h \left(y\right)\right] \leq p_2$</code>。</li>
</ol>

<p>其中，<code>$x, y \in \mathbb{R}^n$</code> 表示 <code>$n$</code> 维度数据点，<code>$d \left(x, y\right)$</code> 表示 <code>$x, y$</code> 之间的距离，<code>$h$</code> 为哈希函数。满足上述两个条件的哈希函数称为是 <code>$\left(d_1, d_2, p_1, p_2\right)$</code> 敏感的。</p>

<ul>
<li>MinHash（Jaccard 距离）</li>
</ul>

<p>MinHash 算法的思路是：采用一种哈希函数将元素的位置均匀打乱，然后在新顺序下每个集合的第一个元素作为该集合的特征值。我们以 <code>$s_1 = \left\{a, d\right\}$</code>，<code>$s_2 = \left\{c\right\}$</code>，<code>$s_3 = \left\{b, d, e\right\}$</code>，<code>$s_4 = \left\{a, c, d\right\}$</code> 为例，集合中可能的元素为 <code>$\left\{a, b, c, d, e\right\}$</code>，则这四个集合可以表示为：</p>

<table>
<thead>
<tr>
<th align="center">元素</th>
<th align="center"><code>$s_1$</code></th>
<th align="center"><code>$s_2$</code></th>
<th align="center"><code>$s_3$</code></th>
<th align="center"><code>$s_4$</code></th>
</tr>
</thead>

<tbody>
<tr>
<td align="center"><code>$a$</code></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>

<tr>
<td align="center"><code>$b$</code></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>

<tr>
<td align="center"><code>$c$</code></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>

<tr>
<td align="center"><code>$d$</code></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>

<tr>
<td align="center"><code>$e$</code></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
</tbody>
</table>

<p>对矩阵进行随机打乱后有：</p>

<table>
<thead>
<tr>
<th align="center">元素</th>
<th align="center"><code>$s_1$</code></th>
<th align="center"><code>$s_2$</code></th>
<th align="center"><code>$s_3$</code></th>
<th align="center"><code>$s_4$</code></th>
</tr>
</thead>

<tbody>
<tr>
<td align="center"><code>$b$</code></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>

<tr>
<td align="center"><code>$e$</code></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>

<tr>
<td align="center"><code>$a$</code></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>

<tr>
<td align="center"><code>$d$</code></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>

<tr>
<td align="center"><code>$c$</code></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
</tbody>
</table>

<p>我们利用每个集合的第一个元素作为该集合的特征值，则有 <code>$h \left(s_1\right) = a$</code>，<code>$h \left(s_2\right) = c$</code>，<code>$h \left(s_3\right) = b$</code>，<code>$h \left(s_4\right) = a$</code>，可以看出 <code>$h \left(s_1\right) = h \left(s_4\right)$</code>。MinHash 能够保证在哈希函数均匀分布的情况下，哈希值相等的概率等于两个集合的 Jaccard 相似度，即：</p>

<p><code>$$
Pr \left(MinHash \left(s_1\right) = MinHash \left(s_2\right)\right) = Jaccard \left(s_1, s_2\right)
$$</code></p>

<ul>
<li>SimHash（汉明距离）</li>
</ul>

<p>SimHash 是由 Manku 等人 <sup class="footnote-ref" id="fnref:manku2007detecting"><a href="#fn:manku2007detecting">3</a></sup> 提出的一种用于用于进行网页去重的哈希算法。SimHash 作为局部敏感哈希算法的一种其主要思想是将高维特征映射到低维特征，再通过两个向量的汉明距离来确定是否存在重复或相似。算法步骤如下：</p>

<ol>
<li>对文本进行特征抽取（例如：分词），并为每个特征赋予一定的权重（例如：词频）。</li>
<li>计算每个特征的二进制哈希值。</li>
<li>计算加权后的哈希值，当哈希值为 1 时，则对应位置为 <code>$w_i$</code>，否则为 <code>$-w_i$</code>，其中 <code>$w_i$</code> 为该特征对应的权重。</li>
<li>将所有特征加权后的哈希值按对应的位置进行累加合并。</li>
<li>如果累加位置大于 0 则置为 1，否则置为 0，最终得到哈希结果。</li>
</ol>

<p>算法流程如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/simhash.png" class="lazyload"/>
  
</figure>

<p>在得到 SimHash 的值后，我们可以通过比较之间的汉明距离来判断相似性。为了提高海量数据的去重效率，以 64 位指纹为例，我们可以将其切分为 4 份 16 位的数据块，根据<a href="https://zh.wikipedia.org/wiki/%E9%B4%BF%E5%B7%A2%E5%8E%9F%E7%90%86" rel="noreferrer" target="_blank">鸽巢原理</a>，汉明距离为 3 的两个文档必定有一个数据块是相等的。将这 4 分数据利用 KV 数据库和倒排索引进行存储，Key 为 16 位的截断指纹，Value  为剩余的指纹集合，从而提高查询的效率。同时可以选择 16，8 和 4 位进行索引，位数越小越精确，但所需的存储空间越大。</p>

<ul>
<li>p-stable 分布（欧式距离）</li>
</ul>

<p>当一个在 <code>$\Re$</code> 上的分布 <code>$\mathcal{D}$</code> 为 <code>$p\text{-stable}$</code> 时，存在 <code>$p \geq 0$</code> 使得对于任意 <code>$n$</code> 个实数 <code>$v_1, \cdots, v_n$</code> 和独立同分布 <code>$\mathcal{D}$</code> 下的变量 <code>$X_1, \cdots, X_n$</code>，有随机变量 <code>$\sum_{i}{v_i X_i}$</code> 和 <code>$\left(\sum_{i}{\left|v_i\right|^p}\right)^{1/p} X$</code> 具有相同的分布，其中 <code>$X$</code> 为分布 <code>$\mathcal{D}$</code> 下的随机变量 <sup class="footnote-ref" id="fnref:datar2004locality"><a href="#fn:datar2004locality">4</a></sup>。常见的 p-stable 分布有：</p>

<ol>
<li>柯西分布：密度函数为 <code>$c \left(x\right) = \dfrac{1}{\pi} \dfrac{1}{1 + x^2}$</code>，为 <code>$1\text{-stable}$</code>。</li>
<li>正态分布：密度函数为 <code>$g \left(x\right) = \dfrac{1}{\sqrt{2 \pi}} e^{-x^2 / 2}$</code>，为 <code>$2\text{-stable}$</code>。</li>
</ol>

<p>p-stable 分布主要可以用于估计 <code>$\left\|v\right\|_p$</code>，对于两个相似的 <code>$v_1, v_2$</code>，它们应该具有更小的 <code>$\left\|v_1 - v_2\right\|_p$</code>，也就是对应的哈希值有更大的概率发生碰撞。对于 <code>$v_1, v_2$</code>，距离的映射 <code>$a \cdot v_1 - a \cdot v_2$</code> 和 <code>$\left\|v_1 - v_2\right\|_p \cdot X$</code> 具有相同的分布。<code>$a \cdot v$</code> 将向量 <code>$v$</code> 映射到实数集，如果将实轴以宽度 <code>$w$</code> 进行等分，<code>$a \cdot v$</code> 落在哪个区间中就将其编号赋予它，这样构造的哈希函数具有局部保持特性。构造的哈希函数族的形式为：</p>

<p><code>$$
h_{a, b} \left(v\right) = \left\lfloor \dfrac{a \cdot v + b}{w} \right\rfloor
$$</code></p>

<p>其中，向量 <code>$a$</code> 的元素 <code>$a_i \sim N \left(0, 1\right)$</code>，<code>$b \sim U \left(0, w\right)$</code>。令 <code>$c = \left\|u - v \right\|_p$</code>，则两个向量在被分配到一个桶中的概率为：</p>

<p><code>$$
Pr \left[h_{a, b} \left(u\right) = h_{a, b} \left(v\right)\right] = \int_{0}^{w} \dfrac{1}{c} \cdot f_p \left(\dfrac{t}{u}\right) \left(1 - \dfrac{t}{w}\right) dt
$$</code></p>

<p>其中，<code>$f_p$</code> 为概率密度函数。从上式中不难看出，随着距离 <code>$c$</code> 的减小，两个向量发生碰撞的概率增加。</p>

<ul>
<li>相关问题</li>
</ul>

<p>局部敏感哈希可以在次线性时间内完成搜索，但缺点在于需要比较长的比特哈希码和比较多的哈希表才能达到预期的性能。</p>

<p>在单表哈希中，当哈希编码位数 <code>$K$</code> 过小时，每个哈希桶中数据个数较多，从而会增加查询的响应时间。当哈希编码位数 <code>$K$</code> 较大时，查询样本同最近邻落入同一个桶中的概率会很小。针对这个问题，我们可以通过重复 <code>$L$</code> 次来增加最近邻的召回率。这个操作可以转化为构建 <code>$L$</code> 个哈希表，给定一个查询样本，我们可以找到 <code>$L$</code> 个哈希桶，然后再遍历这 <code>$L$</code> 个哈希桶中的数据。但这样会增加内存的消耗，因此需要选择合理的 <code>$K$</code> 和 <code>$L$</code> 来获得更好的性能。</p>

<p>Multi-probe LSH <sup class="footnote-ref" id="fnref:lv2007multiprobe"><a href="#fn:lv2007multiprobe">5</a></sup> 引入了一种新的策略解决召回的问题。Multi-probe LSH 不仅仅会遍历查询样本所在桶内的元素，同时还会查询一些其他有可能包含最近邻的桶，从而在避免构建多个哈希表的情况下增加召回率。</p>

<h4 id="哈希学习">哈希学习</h4>

<p>哈希学习（Learning to Hash）是由 Salakhutdinov 和 Hinton <sup class="footnote-ref" id="fnref:salakhutdinov2009semantic"><a href="#fn:salakhutdinov2009semantic">6</a></sup> 引入到机器学习领域，通过机器学习机制将数据映射成二进制串的形式，能显著减少数据的存储和通信开销，从而有效提高学习系统的效率 <sup class="footnote-ref" id="fnref:li2015big"><a href="#fn:li2015big">7</a></sup>。从原空间中的特征表示直接学习得到二进制的哈希编码是一个 NP-Hard 问题。现在很多的哈希学习方法都采用两步学习策略：</p>

<ol>
<li>先对原空间的样本采用度量学习（Metric Learning）进行降维，得到 1 个低维空间的实数向量表示。</li>
<li>对得到的实数向量进行量化（即离散化）得到二进制哈希码。</li>
</ol>

<p>现有的方法对第二步的处理大多很简单，即通过某个阈值函数将实数转换成二进制位。通常使用的量化方法为 1 个阈值为 0 的符号函数，即如果向量中某个元素大于 0，则该元素被量化为 1，否则如果小于或等于 0，则该元素被量化为 0。</p>

<p>哈希学习相关的具体算法不再一一展开，更多细节请参见下文提供的相关 Survey。</p>

<h3 id="矢量量化算法">矢量量化算法</h3>

<p><strong>矢量量化（Vector Quantization）</strong>是信息论中一种用于数据压缩的方法，其目的是减少表示空间的维度。一个量化器可以表示为由 <code>$D$</code> 维向量 <code>$x \in \mathbb{R}^D$</code> 到一个向量 <code>$q \left(x\right) \in \mathcal{C} = \left\{c_i; i \in \mathcal{I}\right\}$</code> 的映射 <code>$q$</code>，其中下标集合 <code>$\mathcal{I}$</code> 为有限集合，即 <code>$\mathcal{I} = 0, \cdots, k-1$</code>。<code>$c_i$</code> 称之为形心（centroids），<code>$\mathcal{C}$</code> 称之为大小为 <code>$k$</code> 的码本（codebook）。映射后的向量到一个给定下标 <code>$i$</code> 的集合 <code>$\mathcal{V}_i \triangleq \left\{x \in \mathbb{R}^D: q \left(x\right) = c_i\right\}$</code>（Voronoi），称之为一个单元（cell）。</p>

<p>以一个图像编码为例，我们通过 K-Means 算法得到 <code>$k$</code> 个 centroids，然后用这些 centroids 的像素值来替换对应簇中所有点的像素值。当 <code>$k = 2, 10, 100$</code> 时，压缩后的图像和原始图像的对比结果如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/lena-vq.png" class="lazyload"/>
  
</figure>

<p>当 <code>$k = 100$</code> 时，压缩后的图像和原始图像已经非常接近了，相关代码请参见<a href="https://github.com/leovan/leovan.me/tree/master/scripts/cn/2020-08-01-nearest-neighbor-search/vector-quantization.py" rel="noreferrer" target="_blank">这里</a>。</p>

<p>矢量量化以乘积量化（Product Quantization，PQ）最为典型，乘积量化的核心思想还是聚类，乘积量化生成码本和量化过程如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/product-quantization.png" class="lazyload"/>
  
</figure>

<p>在训练阶段，以维度为 128 的 <code>$N$</code> 个样本为例，我们将其切分为 4 个子空间，则每个子空间的维度为 32 维。对每一个子空间利用 K-Means 对其进行聚类，令聚类个数为 256，这样每个子空间就能得到一个 256 大小的码本。样本的每个子段都可以用子空间的聚类中心来近似，对应的编码即为类中心的 ID。利用这种编码方式可以将样本用一个很短的编码进行表示，从而达到量化的目的。</p>

<p>在查询阶段，我们将查询样本分成相同的子段，然后在每个子空间中计算子段到该子空间中所有聚类中心的距离，这样我们就得到了 <code>$4 \times 256$</code> 个距离。在计算某个样本到查询样本的距离时，我们仅需要从计算得到的 4 组距离中将对应编码的距离取出相加即可，所有距离计算完毕排序后即可得到结果。</p>

<p>乘积量化有两种计算距离的方式 <sup class="footnote-ref" id="fnref:jegou2010product"><a href="#fn:jegou2010product">8</a></sup>：<strong>对称距离</strong>和<strong>非对称距离</strong>，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/vq-symmetric-asymmetric-distance.png" class="lazyload"/>
  
</figure>

<p>对于 <code>$x$</code> 和 <code>$y$</code> 的距离 <code>$d \left(x, y\right)$</code>，对称距离利用 <code>$d \left(q \left(x\right), q \left(y\right)\right)$</code> 进行估计，非对称距离利用 <code>$d \left(x, q \left(y\right)\right)$</code> 进行估计。对称距离和非对称距离在不同阶段的时间复杂度如下表所示：</p>

<table>
<thead>
<tr>
<th></th>
<th>对称距离</th>
<th>非对称距离</th>
</tr>
</thead>

<tbody>
<tr>
<td>编码 <code>$x$</code></td>
<td><code>$k^* D$</code></td>
<td>0</td>
</tr>

<tr>
<td>计算 <code>$d \left(u_j \left(x\right), c_{j, i}\right)$</code></td>
<td>0</td>
<td><code>$k^* D$</code></td>
</tr>

<tr>
<td>对于 <code>$y \in \mathcal{Y}$</code>，计算 <code>$\hat{d} \left(x, y\right)$</code> 或 <code>$\tilde{d} \left(x, y\right)$</code></td>
<td><code>$nm$</code></td>
<td><code>$nm$</code></td>
</tr>

<tr>
<td>查找最小 <code>$k$</code> 个距离</td>
<td><code>$n + k$</code></td>
<td><code>$\log k \log \log n$</code></td>
</tr>
</tbody>
</table>

<p>其中，<code>$k^*$</code> 为 centroids 个数，<code>$D$</code> 为向量维度，<code>$n$</code> 为样本个数，<code>$m$</code> 为分割个数。通常情况下我们采用非对称距离，其更接近真实距离。</p>

<p>IVFADC <sup class="footnote-ref" id="fnref:jegou2010product"><a href="#fn:jegou2010product">8</a></sup> 是乘积量化的的加速版本，乘积量化在计算距离时仍需逐个遍历相加计算。倒排乘积量化首先对 <code>$N$</code> 个样本采用 K-Means 进行聚类，此处的聚类中心相比乘积量化应设置较小的数值。在得到聚类中心后，针对每一个样本 <code>$x_i$</code> 找到距离最近的类中心 <code>$c_i$</code>，两者相减后得到残差 <code>$x_i - c_i$</code>，然后对残差再进行乘积量化的全过程。在查询阶段，通过先前较粗力度的量化快速定位隶属于哪一个 <code>$c_i$</code>，然后在 <code>$c_i$</code> 区域利用乘积量化获取最终结果。整个流程如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/ivfadc.png" class="lazyload"/>
  
</figure>

<p>Optimized Product Quantization (OPQ) <sup class="footnote-ref" id="fnref:ge2013optimized"><a href="#fn:ge2013optimized">9</a></sup> 是乘积量化的一个优化方法。通常用于检索的原始特征维度较高，实践中利用乘积量化之前会对高维特征利用 PCA 等方法进行降维处理。这样在降低维度的时候还能够使得对向量进行子段切分的时候各个维度不相关。在利用 PCA 降维后，采用顺序切分子段仍存在一些问题，以 Iterative Quantization (ITQ) <sup class="footnote-ref" id="fnref:gong2012iterative"><a href="#fn:gong2012iterative">10</a></sup> 中的一个二维平面例子来说明，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/itq.png" class="lazyload"/>
  
</figure>

<p>在利用乘积量化进行编码时，对于切分的各个子空间，应尽可能使得各个子空间的方差接近。上图中 <code>$(a)$</code> 图在 x 和 y 轴上的方差较大，而 <code>$(c)$</code> 图在两个方向上比较接近。OPQ 致力解决的问题就是对各个子空间方差上的均衡，OPQ 对于该问题的求解分为非参数求解方法和参数求解方法两种，更多算法细节请参见 ITQ 和 OPQ 原文。</p>

<h3 id="基于图的算法">基于图的算法</h3>

<p>NSW（Navigable Small World）<sup class="footnote-ref" id="fnref:malkov2014approximate"><a href="#fn:malkov2014approximate">11</a></sup> 算法是一种由 Malkov 等人提出的基于图的索引的方法。我们将 Navigable Small World 网络表示为一个图 <code>$G \left(V, E\right)$</code>，其中数据集合 <code>$X$</code> 的点被唯一映射到集合 <code>$V$</code> 中的一条边，边集 <code>$E$</code> 由构造算法确定。对于与一个节点 <code>$v_i$</code> 共享一条边的所有节点，我们称之为该节点的“友集”。</p>

<p>之后我们可以利用一个贪婪搜索的变种算法实现一个基本的 KNN 搜索算法。通过选择友集中未被访问过的距离查询样本最近的节点，可以在图中一个接一个的访问不同的节点，直到达到停止准则。整个过程如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/nsw.png" class="lazyload"/>
  
</figure>

<p>上图中的边扮演着两种不同的角色：</p>

<ol>
<li>短距离边的子集作为 <a href="https://en.wikipedia.org/wiki/Delaunay_triangulation" rel="noreferrer" target="_blank">Delaunay 图</a>的近似用于贪婪搜索算法。</li>
<li>长距离边的子集用于对数尺度的贪婪搜索，负责构造图的 Navigable Small World 属性。</li>
</ol>

<p>其中，黑色的边为短距离边，红色的边为长距离边，箭头为迭代查询路径。整个结构的构建可以通过元素的连续插入实现，对于新的元素，我们从当前结构中找到最接近的邻居集合与之相连。随着越来越多的元素插入到结构中，之前的短距离连接就变成了长距离连接。</p>

<p>NSW 的 KNN 查询过程如下所示：</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{NSW 的 KNN 查询}
\begin{algorithmic}
\REQUIRE 查询样本 $q$，查询结果数量 $k$，最大迭代次数 $m$
\STATE $V_{cand} \gets \varnothing, V_{visited} \gets \varnothing, V_{res} \gets \varnothing$
\FOR{$i \gets 1$ \TO $m$}
  \STATE $V_{tmp} \gets \varnothing$
  \STATE $v_{rand} \gets $ 随机初始节点
  \STATE $V_{cand} \gets V_{cand} \cup v_{rand}$
  \WHILE{True}
    \STATE $v_c \gets V_{cand}$ 中距离 $q$ 最近的元素
    \STATE $V_{cand} \gets V_{cand} \setminus v_c$
    \IF{$v_c$ 比结果中的 $k$ 个元素距离 $q$ 还远}
      \BREAK
    \ENDIF
    \FOR{$v_e \in v_c$ 的“友集”}
      \IF{$v_e \notin V_{visited}$}
        \STATE $V_{visited} \gets V_{visited} \cup v_e, V_{cand} \gets V_{cand} \cup v_e, V_{tmp} \gets V_{tmp} \cup v_e$
      \ENDIF
    \ENDFOR
  \ENDWHILE
  \STATE $V_{res} \gets V_{res} \cup V_{tmp}$
\ENDFOR
\RETURN{$V_{res}$ 中与查询样本最近的 $k$ 个元素}
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>HNSW（Hierarchical Navigable Small World）<sup class="footnote-ref" id="fnref:malkov2018efficient"><a href="#fn:malkov2018efficient">12</a></sup> 是对 NSW 的一种改进。HNSW 的思想是根据连接的长度（距离）将连接划分为不同的层，然后就可以在多层图中进行搜索。在这种结构中，搜索从较长的连接（上层）开始，贪婪地遍历所有元素直到达到局部最小值，之后再切换到较短的连接（下层），然后重复该过程，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/hnsw.png" class="lazyload"/>
  
</figure>

<p>利用这种结构可以将原来 NSW 的多重对数（Polylogarithmic）计算复杂度降低至对数（Logarithmic）复杂度。更多关于数据插入和搜索的细节请参见原文。</p>

<p>NSG <sup class="footnote-ref" id="fnref:fu2019fast"><a href="#fn:fu2019fast">13</a></sup> 提出了一种新的图结构 Monotonic Relative Neighborhood Graph (MRNG) 用于保证一个平均的低搜索时间复杂度（接近对数复杂度）。同时为了进一步降低索引复杂度，作者从确保连接性、降低平均出度、缩短搜索路径和降低索引大小 4 个方面考虑，提出了一个用于近似 MRNG 的 Spreading-out Graph (NSG)。</p>

<p>基于图的方法 HNSW 和基于乘积量化的方法 OPQ 之间的特性对比如下：</p>

<table>
<thead>
<tr>
<th>特点</th>
<th>OPQ</th>
<th>HNSW</th>
</tr>
</thead>

<tbody>
<tr>
<td>内存占用</td>
<td>小</td>
<td>大</td>
</tr>

<tr>
<td>召回率</td>
<td>较高</td>
<td>高</td>
</tr>

<tr>
<td>数据动态增删</td>
<td>灵活</td>
<td>不易</td>
</tr>
</tbody>
</table>

<p>本文部分内容参考自 <a href="https://yongyuan.name/blog/vector-ann-search.html" rel="noreferrer" target="_blank">图像检索：向量索引</a>。</p>

<h3 id="算法对比">算法对比</h3>

<p>常用算法的开源实现的评测如下，更多评测结果请参见 <a href="https://github.com/erikbern/ann-benchmarks/" rel="noreferrer" target="_blank">erikbern/ann-benchmarks</a>。</p>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/glove-100-k-10.png" class="lazyload"/>
  <figcaption><p class="figcaption">Glove-100-Angular (K=10)</p></figcaption>
</figure>

<figure>
  <img data-src="/images/cn/2020-08-01-nearest-neighbor-search/sift-128-k-10.png" class="lazyload"/>
  <figcaption><p class="figcaption">SIFT-128-Euclidean (K=10)</p></figcaption>
</figure>

<h2 id="开放资源">开放资源</h2>

<h3 id="survey">Survey</h3>

<ul>
<li>A Survey on Learning to Hash <sup class="footnote-ref" id="fnref:wang2017survey"><a href="#fn:wang2017survey">14</a></sup></li>
<li>A Survey on Nearest Neighbor Search Methods <sup class="footnote-ref" id="fnref:reza2014survey"><a href="#fn:reza2014survey">15</a></sup></li>
<li>An Investigation of Practical Approximate Nearest Neighbor Algorithms <sup class="footnote-ref" id="fnref:liu2005investigation"><a href="#fn:liu2005investigation">16</a></sup></li>
<li>Approximate Nearest Neighbor Search on High Dimensional Data - Experiments, Analyses, and Improvement <sup class="footnote-ref" id="fnref:li2019approximate"><a href="#fn:li2019approximate">17</a></sup></li>
<li>Binary Hashing for Approximate Nearest Neighbor Search on Big Data: A Survey <sup class="footnote-ref" id="fnref:cao2017binary"><a href="#fn:cao2017binary">18</a></sup></li>
<li>Hashing for Similarity Search: A Survey <sup class="footnote-ref" id="fnref:wang2014hashing"><a href="#fn:wang2014hashing">19</a></sup></li>
</ul>

<h3 id="开源库">开源库</h3>

<table>
<thead>
<tr>
<th>库</th>
<th>API</th>
</tr>
</thead>

<tbody>
<tr>
<td><a href="https://github.com/spotify/annoy" rel="noreferrer" target="_blank">spotify/annoy</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i>, <i class="icon icon-go">Go</i></td>
</tr>

<tr>
<td><a href="https://github.com/vioshyvo/mrpt" rel="noreferrer" target="_blank">vioshyvo/mrpt</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i>, <i class="icon icon-go"><a href="https://github.com/rikonor/go-ann" rel="noreferrer" target="_blank">Go</a></i></td>
</tr>

<tr>
<td><a href="https://github.com/pixelogik/NearPy" rel="noreferrer" target="_blank">pixelogik/NearPy</a></td>
<td><i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/aaalgo/kgraph" rel="noreferrer" target="_blank">aaalgo/kgraph</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/nmslib/nmslib" rel="noreferrer" target="_blank">nmslib/nmslib</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/nmslib/hnswlib" rel="noreferrer" target="_blank">nmslib/hnswlib</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/lyst/rpforest" rel="noreferrer" target="_blank">lyst/rpforest</a></td>
<td><i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/facebookresearch/faiss" rel="noreferrer" target="_blank">facebookresearch/faiss</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/ekzhu/datasketch" rel="noreferrer" target="_blank">ekzhu/datasketch</a></td>
<td><i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/lmcinnes/pynndescent" rel="noreferrer" target="_blank">lmcinnes/pynndescent</a></td>
<td><i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/yahoojapan/NGT" rel="noreferrer" target="_blank">yahoojapan/NGT</a></td>
<td><i class="icon icon-c">C</i>, <i class="icon icon-cpp">C++</i>, <i class="icon icon-python"><a href="https://github.com/yahoojapan/NGT/blob/master/python/README.md" rel="noreferrer" target="_blank">Python</a></i>, <i class="icon icon-go"><a href="https://github.com/yahoojapan/gongt" rel="noreferrer" target="_blank">Go</a></i>, <i class="icon icon-ruby"><a href="https://github.com/ankane/ngt" rel="noreferrer" target="_blank">Ruby</a></i></td>
</tr>

<tr>
<td><a href="https://github.com/microsoft/SPTAG" rel="noreferrer" target="_blank">microsoft/SPTAG</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/puffinn/puffinn" rel="noreferrer" target="_blank">puffinn/puffinn</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i></td>
</tr>

<tr>
<td><a href="https://github.com/kakao/n2" rel="noreferrer" target="_blank">kakao/n2</a></td>
<td><i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i>, <i class="icon icon-go">Go</i></td>
</tr>

<tr>
<td><a href="https://github.com/ZJULearning/nsg" rel="noreferrer" target="_blank">ZJULearning/nsg</a></td>
<td><i class="icon icon-cpp">C++</i></td>
</tr>
</tbody>
</table>

<h3 id="开源搜索引擎">开源搜索引擎</h3>

<table>
<thead>
<tr>
<th>搜索引擎</th>
<th>API</th>
</tr>
</thead>

<tbody>
<tr>
<td><a href="https://github.com/milvus-io/milvus" rel="noreferrer" target="_blank">milvus-io/milvus</a></td>
<td><i class="icon icon-c">C</i>, <i class="icon icon-cpp">C++</i>, <i class="icon icon-python">Python</i>, <i class="icon icon-java">Java</i><br/><i class="icon icon-go">Go</i>, <i class="icon icon-nodejs">Node.js</i>, <i class="icon icon-restful">RESTful API</i></td>
</tr>

<tr>
<td><a href="https://github.com/vearch/vearch" rel="noreferrer" target="_blank">vearch/vearch</a></td>
<td><i class="icon icon-python">Python</i>, <i class="icon icon-go">Go</i></td>
</tr>
</tbody>
</table>

<h3 id="评测">评测</h3>

<ul>
<li><a href="https://github.com/erikbern/ann-benchmarks/" rel="noreferrer" target="_blank">https://github.com/erikbern/ann-benchmarks/</a></li>
<li><a href="https://github.com/DBWangGroupUNSW/nns_benchmark" rel="noreferrer" target="_blank">https://github.com/DBWangGroupUNSW/nns_benchmark</a></li>
</ul>
<div class="footnotes">

<hr />

<ol>
<li id="fn:bentley1975multidimensional">Bentley, J. L. (1975). Multidimensional binary search trees used for associative searching. <em>Communications of the ACM</em>, 18(9), 509-517.
 <a class="footnote-return" href="#fnref:bentley1975multidimensional">↩</a></li>
<li id="fn:omohundro1989five">Omohundro, S. M. (1989). <em>Five balltree construction algorithms</em> (pp. 1-22). Berkeley: International Computer Science Institute.
 <a class="footnote-return" href="#fnref:omohundro1989five">↩</a></li>
<li id="fn:manku2007detecting">Manku, G. S., Jain, A., &amp; Das Sarma, A. (2007, May). Detecting near-duplicates for web crawling. In <em>Proceedings of the 16th international conference on World Wide Web</em> (pp. 141-150).
 <a class="footnote-return" href="#fnref:manku2007detecting">↩</a></li>
<li id="fn:datar2004locality">Datar, M., Immorlica, N., Indyk, P., &amp; Mirrokni, V. S. (2004, June). Locality-sensitive hashing scheme based on p-stable distributions. In <em>Proceedings of the twentieth annual symposium on Computational geometry</em> (pp. 253-262).
 <a class="footnote-return" href="#fnref:datar2004locality">↩</a></li>
<li id="fn:lv2007multiprobe">Lv, Q., Josephson, W., Wang, Z., Charikar, M., &amp; Li, K. (2007, September). Multi-probe LSH: efficient indexing for high-dimensional similarity search. In <em>Proceedings of the 33rd international conference on Very large data bases</em> (pp. 950-961).
 <a class="footnote-return" href="#fnref:lv2007multiprobe">↩</a></li>
<li id="fn:salakhutdinov2009semantic">Salakhutdinov, Ruslan, and Geoffrey Hinton. &ldquo;Semantic hashing.&rdquo; <em>International Journal of Approximate Reasoning</em> 50.7 (2009): 969-978.
 <a class="footnote-return" href="#fnref:salakhutdinov2009semantic">↩</a></li>
<li id="fn:li2015big">李武军, &amp; 周志华. (2015). 大数据哈希学习: 现状与趋势. <em>科学通报, 60</em>(5-6), 485-490.
 <a class="footnote-return" href="#fnref:li2015big">↩</a></li>
<li id="fn:jegou2010product">Jegou, H., Douze, M., &amp; Schmid, C. (2010). Product quantization for nearest neighbor search. <em>IEEE transactions on pattern analysis and machine intelligence</em>, 33(1), 117-128.
 <a class="footnote-return" href="#fnref:jegou2010product">↩</a></li>
<li id="fn:ge2013optimized">Ge, T., He, K., Ke, Q., &amp; Sun, J. (2013). Optimized product quantization. <em>IEEE transactions on pattern analysis and machine intelligence</em>, 36(4), 744-755.
 <a class="footnote-return" href="#fnref:ge2013optimized">↩</a></li>
<li id="fn:gong2012iterative">Gong, Y., Lazebnik, S., Gordo, A., &amp; Perronnin, F. (2012). Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. <em>IEEE transactions on pattern analysis and machine intelligence, 35</em>(12), 2916-2929.
 <a class="footnote-return" href="#fnref:gong2012iterative">↩</a></li>
<li id="fn:malkov2014approximate">Malkov, Y., Ponomarenko, A., Logvinov, A., &amp; Krylov, V. (2014). Approximate nearest neighbor algorithm based on navigable small world graphs. <em>Information Systems</em>, 45, 61-68.
 <a class="footnote-return" href="#fnref:malkov2014approximate">↩</a></li>
<li id="fn:malkov2018efficient">Malkov, Y. A., &amp; Yashunin, D. A. (2018). Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. <em>IEEE transactions on pattern analysis and machine intelligence</em>.
 <a class="footnote-return" href="#fnref:malkov2018efficient">↩</a></li>
<li id="fn:fu2019fast">Fu, C., Xiang, C., Wang, C., &amp; Cai, D. (2019). Fast approximate nearest neighbor search with the navigating spreading-out graph. <em>Proceedings of the VLDB Endowment, 12</em>(5), 461-474.
 <a class="footnote-return" href="#fnref:fu2019fast">↩</a></li>
<li id="fn:wang2017survey">Wang, J., Zhang, T., Sebe, N., &amp; Shen, H. T. (2017). A survey on learning to hash. <em>IEEE transactions on pattern analysis and machine intelligence, 40</em>(4), 769-790.
 <a class="footnote-return" href="#fnref:wang2017survey">↩</a></li>
<li id="fn:reza2014survey">Reza, M., Ghahremani, B., &amp; Naderi, H. (2014). A Survey on nearest neighbor search methods. <em>International Journal of Computer Applications, 95</em>(25), 39-52.
 <a class="footnote-return" href="#fnref:reza2014survey">↩</a></li>
<li id="fn:liu2005investigation">Liu, T., Moore, A. W., Yang, K., &amp; Gray, A. G. (2005). An investigation of practical approximate nearest neighbor algorithms. In <em>Advances in neural information processing systems</em> (pp. 825-832).
 <a class="footnote-return" href="#fnref:liu2005investigation">↩</a></li>
<li id="fn:li2019approximate">Li, W., Zhang, Y., Sun, Y., Wang, W., Li, M., Zhang, W., &amp; Lin, X. (2019). Approximate nearest neighbor search on high dimensional data-experiments, analyses, and improvement. <em>IEEE Transactions on Knowledge and Data Engineering</em>.
 <a class="footnote-return" href="#fnref:li2019approximate">↩</a></li>
<li id="fn:cao2017binary">Cao, Y., Qi, H., Zhou, W., Kato, J., Li, K., Liu, X., &amp; Gui, J. (2017). Binary hashing for approximate nearest neighbor search on big data: A survey. <em>IEEE Access, 6</em>, 2039-2054.
 <a class="footnote-return" href="#fnref:cao2017binary">↩</a></li>
<li id="fn:wang2014hashing">Wang, J., Shen, H. T., Song, J., &amp; Ji, J. (2014). Hashing for similarity search: A survey. <em>arXiv preprint arXiv:1408.2927</em>.
 <a class="footnote-return" href="#fnref:wang2014hashing">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>无模型策略预测和控制 - 时序差分学习 (Model-Free Policy Prediction and Control - Temporal Difference Learning)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/07/model-free-policy-prediction-and-control-temporal-difference-learning/</link>
      <pubDate>Sat, 11 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/07/model-free-policy-prediction-and-control-temporal-difference-learning/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文为<a href="/categories/强化学习/">《强化学习系列》</a>文章<br />
本文内容主要参考自：<br />
1.《强化学习》<sup class="footnote-ref" id="fnref:sutton2018reinforcement"><a href="#fn:sutton2018reinforcement">1</a></sup><br />
2. CS234: Reinforcement Learning <sup class="footnote-ref" id="fnref:stanford-cs234"><a href="#fn:stanford-cs234">2</a></sup><br />
3. UCL Course on RL <sup class="footnote-ref" id="fnref:ucl-course-on-rl"><a href="#fn:ucl-course-on-rl">3</a></sup></p>
</blockquote>

<h2 id="时序差分预测">时序差分预测</h2>

<p><strong>时序差分（Temporal Difference，TD）</strong>和蒙特卡洛方法都利用经验来解决预测问题。给定策略 <code>$\pi$</code> 的一些经验，以及这些经验中的非终止状态 <code>$S_t$</code>，一个适用于非平稳环境的简单的每次访问型蒙特卡洛方法可以表示为：</p>

<p><code>$$
V\left(S_{t}\right) \gets V\left(S_{t}\right)+\alpha\left[G_{t}-V\left(S_{t}\right)\right] \label{eq:mc-update}
$$</code></p>

<p>其中，<code>$G_t$</code> 是时刻 <code>$t$</code> 真实的回报，<code>$\alpha$</code> 是步长参数，称之为常量 <code>$\alpha$</code> MC。MC 需要等到一幕的结尾才能确定对 <code>$V \left(S_t\right)$</code> 的增量（此时才能获得 <code>$G_t$</code>），而 TD 则只需要等到下一个时刻即可。在 <code>$t+1$</code> 时刻，TD 使用观察到的收益 <code>$R_{t+1}$</code> 和估计值 <code>$V \left(S_{t+1}\right)$</code> 来进行一次有效更新：</p>

<p><code>$$
V\left(S_{t}\right) \gets V\left(S_{t}\right)+\alpha\left[R_{t+1}+\gamma V\left(S_{t+1}\right)-V\left(S_{t}\right)\right] \label{eq:td-update}
$$</code></p>

<p>这种 TD 方法称之为 TD(0)，算法的完整过程如下：</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{表格型 TD(0) 算法，用于估计 $V \approx v_{\pi}$}
\begin{algorithmic}
\REQUIRE 待评估策略 $\pi$
\STATE 对于所有 $s \in \mathcal{S}^+$，任意初始化 $V \left(s\right)$，其中 $V \left(\text{终止状态}\right) = 0$
\FOR{每一幕}
  \STATE 初始化 $S$
  \REPEAT
    \STATE $A \gets$ 策略 $\pi$ 在状态 $S$ 下做出的决策动作
    \STATE 执行动作 $A$，观测到 $R, S'$
    \STATE $V\left(S\right) \gets V\left(S\right)+\alpha\left[R+\gamma V\left(S^{\prime}\right)-V\left(S\right)\right]$
    \STATE $S \gets S'$
  \UNTIL{$S$ 为终止状态}
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>TD(0) 的更新在某种程度上基于已存在的估计，我们称之为一种<strong>自举法</strong>。</p>

<p>TD 和 MC 方法都能渐进地收敛于正确的预测，但两种方法谁收敛的更快，目前暂时未能证明。但在如下的随机任务上，TD 方法通常比常量 <code>$\alpha$</code> MC 方法收敛得更快。假设如下 MRP 所有阶段都同中心 C 开始，每个时刻以相同的概率向左或向右移动一个状态。幕终止于最左侧或最右侧，终止于最右侧时有 +1 的收益，除此之外收益均为零。</p>

<figure>
  <img data-src="/images/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/random-walk-mrp.png" class="lazyload"/>
  
</figure>

<p>由于这个任务没有折扣，因此每个状态的真实价值是从这个状态开始并终止于最右侧的概率，即 A 到 E 的概率分别为 <code>$\frac{1}{6}, \frac{2}{6}, \frac{3}{6}, \frac{4}{6}, \frac{5}{6}$</code>。</p>

<figure>
  <img data-src="/images/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/random-walk-mc-td.png" class="lazyload"/>
  
</figure>

<p>上图左侧显示了在经历了不同数量的幕采样序列之后，运行一次 TD(0) 所得到的价值估计。在 100 幕后，估计值已经非常接近真实值了。上图右侧显示了不同的 <code>$\alpha$</code> 情况下学习到的价值函数和真实价值函数的均方根（RMS）误差，对于所有的 <code>$s$</code>，近似价值函数都被初始化为中间值 <code>$V \left(s\right) = 0.5$</code>，显示的误差是 5 个状态上运行 100 次的平均误差。</p>

<p>给定近似价值函数 <code>$V$</code>，在访问非终止状态的每个时刻 <code>$t$</code>，使用式 <code>$\ref{eq:mc-update}$</code> 和 <code>$\ref{eq:td-update}$</code> 计算相应的增量经验，产生新的总增量，以此类推，直到价值函数收敛。我们称这种方法为<strong>批量更新</strong>，因为只有在处理了<strong>整批</strong>的训练数据后才进行更新。批量蒙特卡洛方法总是找出最小化训练集上均方误差的估计，而批量 TD(0) 总是找出完全符合马尔可夫过程模型的最大似然估计参数。因此，MC 在非马尔可夫环境中更加高效，而 TD 在马尔可夫环境中更加高效。</p>

<p>DP，MC 和 TD 的状态价值更新回溯过程如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/dp-backup.png" class="lazyload"/>
  
</figure>

<p><code>$$
\textbf{DP} \quad V\left(S_{t}\right) \leftarrow \mathbb{E}_{\pi}\left[R_{t+1}+\gamma V\left(S_{t+1}\right)\right]
$$</code></p>

<figure>
  <img data-src="/images/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/mc-backup.png" class="lazyload"/>
  
</figure>

<p><code>$$
\textbf{MC} \quad V\left(S_{t}\right) \leftarrow V\left(S_{t}\right)+\alpha\left(G_{t}-V\left(S_{t}\right)\right)
$$</code></p>

<figure>
  <img data-src="/images/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/td-backup.png" class="lazyload"/>
  
</figure>

<p><code>$$
\textbf{TD} \quad V\left(S_{t}\right) \leftarrow V\left(S_{t}\right)+\alpha\left(R_{t+1}+\gamma V\left(S_{t+1}\right)-V\left(S_{t}\right)\right)
$$</code></p>

<h2 id="时序差分控制">时序差分控制</h2>

<p>利用时序差分方法解决控制问题，我们依然采用广义策略迭代（GPI），只是在评估和预测部分采用时序差分方法。同蒙特卡洛方法一样，我们需要在试探和开发之间做出权衡，因此方法又划分为同轨策略和离轨策略。</p>

<h3 id="sarsa-同轨策略下的时序差分控制">Sarsa：同轨策略下的时序差分控制</h3>

<p>在同轨策略中，我们需要对所有状态 <code>$s$</code> 以及动作 <code>$a$</code> 估计出在当前的行动策略下所有对应的 <code>$q_{\pi} \left(s, a\right)$</code>。确保状态值在 TD(0) 下收敛的定理同样也适用于对应的动作值的算法上</p>

<p><code>$$
Q\left(S_{t}, A_{t}\right) \leftarrow Q\left(S_{t}, A_{t}\right)+\alpha\left[R_{t+1}+\gamma Q\left(S_{t+1}, A_{t+1}\right)-Q\left(S_{t}, A_{t}\right)\right]
$$</code></p>

<p>每当从非终止状态的 <code>$S_t$</code> 出现一次转移之后，就进行上述的一次更新，如果 <code>$S_{t+1}$</code> 是终止状态，那么 <code>$Q \left(S_{t+1}, A_{t+1}\right)$</code> 则定义为 0。这个更新规则用到了描述这个事件的五元组 <code>$\left(S_t, A_t, R_{t+1}, S_{t+1}, A_{t+1}\right)$</code>，因此根据这五元组将这个算法命名为 <strong>Sarsa</strong>。Sarsa 控制算法的一般形式如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{Sarsa（同轨策略下的 TD 控制）算法，用于估计 $Q \approx q_*$}
\begin{algorithmic}
\STATE 对于所有 $s \in \mathcal{S}^+, a \in \mathcal{A} \left(s\right)$，任意初始化 $Q \left(s, a\right)$，其中 $Q \left(\text{终止状态}, \cdot\right) = 0$
\FOR{每一幕}
  \STATE 初始化 $S$
  \STATE 使用从 $Q$ 得到的策略（例如 $\epsilon-$ 贪心），在 $S$ 处选择 $A$
  \REPEAT
    \STATE 执行动作 $A$，观测到 $R, S'$
    \STATE 使用从 $Q$ 得到的策略（例如 $\epsilon-$ 贪心），在 $S'$ 处选择 $A'$
    \STATE $Q\left(S, A\right) \gets Q\left(S, A\right)+\alpha\left[R+\gamma Q\left(S', A'\right)-Q\left(S, A\right)\right]$
    \STATE $S \gets S'$
    \STATE $A \gets A'$
  \UNTIL{$S$ 为终止状态}
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<h3 id="q-learning-离轨策略下的时序差分控制">Q-Learning：离轨策略下的时序差分控制</h3>

<p>离轨策略下的时序差分控制算法被称为 <strong>Q-Learning</strong>，其定义为：</p>

<p><code>$$
Q\left(S_{t}, A_{t}\right) \gets Q\left(S_{t}, A_{t}\right)+\alpha\left[R_{t+1}+\gamma \max_{a} Q\left(S_{t+1}, a\right)-Q\left(S_{t}, A_{t}\right)\right]
$$</code></p>

<p>在这里，待学习的动作价值函数 <code>$Q$</code> 采用了对最优动作价值函数 <code>$q_*$</code> 的直接近似作为学习目标，而与用于生成智能体决策序例轨迹的行动策略是什么无关。Q-Learning 算法的流程如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{Q-Learning（离轨策略下的 TD 控制）算法，用于估计 $\pi \approx \pi_*$}
\begin{algorithmic}
\STATE 对于所有 $s \in \mathcal{S}^+, a \in \mathcal{A} \left(s\right)$，任意初始化 $Q \left(s, a\right)$，其中 $Q \left(\text{终止状态}, \cdot\right) = 0$
\FOR{每一幕}
  \STATE 初始化 $S$
  \REPEAT
    \STATE 使用从 $Q$ 得到的策略（例如 $\epsilon-$ 贪心），在 $S$ 处选择 $A$
    \STATE 执行动作 $A$，观测到 $R, S'$
    \STATE $Q\left(S, A\right) \gets Q\left(S, A\right)+\alpha\left[R+\gamma \max_{a} Q\left(S', a\right)-Q\left(S, A\right)\right]$
    \STATE $S \gets S'$
  \UNTIL{$S$ 为终止状态}
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<h3 id="期望-sarsa">期望 Sarsa</h3>

<p>如果将 Q-Learning 中对于下一个“状态-动作”二元组取最大值这一步换成取期望，即更新规则为：</p>

<p><code>$$
\begin{aligned}
Q\left(S_{t}, A_{t}\right) &amp; \gets Q\left(S_{t}, A_{t}\right)+\alpha\left[R_{t+1}+\gamma \mathbb{E}_{\pi}\left[Q\left(S_{t+1}, A_{t+1}\right) \mid S_{t+1}\right]-Q\left(S_{t}, A_{t}\right)\right] \\
&amp; \gets Q\left(S_{t}, A_{t}\right)+\alpha\left[R_{t+1}+\gamma \sum_{a} \pi\left(a \mid S_{t+1}\right) Q\left(S_{t+1}, a\right)-Q\left(S_{t}, A_{t}\right)\right]
\end{aligned}
$$</code></p>

<p>给定下一个状态 <code>$S_{t+1}$</code>，这个算法确定地向期望意义上的 Sarsa 算法所决定的方向上移动，因此这个算法被称为<strong>期望 Sarsa</strong>。期望 Sarsa 在计算上比 Sarsa 更加复杂，但它消除了因为随机选择 <code>$A_{t+1}$</code> 而产生的方差。</p>

<h3 id="双学习">双学习</h3>

<p>在上述算法中，在估计值的基础上进行最大化也可以被看做隐式地对最大值进行估计，而这会产生一个显著的正偏差。假设在状态 <code>$s$</code> 下可以选择多个动作 <code>$a$</code>，这些动作在该状态下的真实价值 <code>$q \left(s, a\right)$</code> 全为零，但他们的估计值 <code>$Q \left(s, a\right)$</code> 是不确定的，可能大于零也可能小于零。真实值的最大值是零，但估计值的最大值是正数，因此就产生了正偏差，我们称其为<strong>最大化偏差</strong>。</p>

<p>我们用下例进行说明，在如下这个 MDP 中有两个非终止节点 A 和 B。每幕都从 A 开始并选择向左或向右的动作。向右则会立即转移到终止状态并得到值为 0 的收益和回报。向左则会是状态转移到 B，得到的收益也是 0。而在 B 这个状态下有很多种可能的动作，每种动作被选择后会立刻停止并得到一个从均值为 -0.1 方差为 1.0 的分布中采样得到的收益。</p>

<figure>
  <img data-src="/images/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/double-learning-example.png" class="lazyload"/>
  
</figure>

<p>因此，任何一个以向左开始的轨迹的期望回报均为 -0.1，则在 A 这个状态中根本就不该选择向左。然而使用 <code>$\epsilon-$</code> 贪心策略来选择动作的 Q-Learning 算法会在开始阶段非常明显地选择向左这个动作。即使在算法收敛到稳定时，它选择向左这个动作的概率也比最优值高了大约 5%，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/double-learning-example-left-probability.png" class="lazyload"/>
  
</figure>

<p>解决该问题的一种方法为<strong>双学习</strong>。如果们将样本划分为两个集合，并用它们学习两个独立的对真实价值 <code>$q \left(a\right), \forall a \in A$</code> 的估计 <code>$Q_1 \left(a\right)$</code> 和 <code>$Q_2 \left(a\right)$</code>。则我们可以使用其中一个 <code>$Q_1$</code> 来确认最大的动作 <code>$A^* = \arg\max_a Q_1 \left(a\right)$</code>，用另一个 <code>$Q_2$</code> 来计算其价值的估计 <code>$Q_2 \left(A^*\right) = Q_2 \left(\arg\max_a Q_1 \left(a \right)\right)$</code>。由于 <code>$\mathbb{E} \left[Q_2 \left(A^*\right)\right] = q \left(A^*\right)$</code>，因此这个估计是无偏的。我们可以交换两个估计 <code>$Q_1 \left(a\right)$</code> 和 <code>$Q_2 \left(a\right)$</code> 的角色再执行一遍上面的过程，就可以得到另一个无偏的估计 <code>$Q_1 \left(\arg\max_a Q_2 \left(a\right)\right)$</code>。</p>

<p>双学习的 Q-Learning 版本为 Double Q-Learning。Double Q-Learning 在学习时会以 0.5 的概率进行如下更新：</p>

<p><code>$$
Q_{1}\left(S_{t}, A_{t}\right) \leftarrow Q_{1}\left(S_{t}, A_{t}\right)+\alpha\left[R_{t+1}+\gamma Q_{2}\left(S_{t+1}, \underset{a}{\arg \max } Q_{1}\left(S_{t+1}, a\right)\right)-Q_{1}\left(S_{t}, A_{t}\right)\right]
$$</code></p>

<p>以 0.5 的概率交换 <code>$Q_1$</code> 和 <code>$Q_2$</code> 的角色进行同样的更新。使用 <code>$\epsilon-$</code> 贪心策略的 Double Q-Learning 的完整算法流程如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{Double Q-Learning，用于估计 $Q_1 \approx Q_2 \approx q_*$}
\begin{algorithmic}
\REQUIRE 步长 $\alpha \in \left(0, 1\right]$，很小的 $\epsilon > 0$
\STATE 对于所有 $s \in \mathcal{S}^+, a \in \mathcal{A} \left(s\right)$，任意初始化 $Q_1 \left(s, a\right), Q_2 \left(s, a\right)$，其中 $Q \left(\text{终止状态}, \cdot\right) = 0$
\FOR{每一幕}
  \STATE 初始化 $S$
  \REPEAT
    \STATE 基于 $Q_1 + Q_2$ 使用 $\epsilon-$ 贪心策略在 $S$ 处选择 $A$
    \STATE 执行动作 $A$，观测到 $R, S'$
    \IF{$Random(0, 1] > 0.5$}
      \STATE $Q_{1}(S, A) \leftarrow Q_{1}(S, A)+\alpha\left(R+\gamma Q_{2}\left(S^{\prime}, \arg \max _{a} Q_{1}\left(S^{\prime}, a\right)\right)-Q_{1}(S, A)\right)$
    \ELSE
      \STATE $Q_{2}(S, A) \leftarrow Q_{2}(S, A)+\alpha\left(R+\gamma Q_{1}\left(S^{\prime}, \arg \max _{a} Q_{2}\left(S^{\prime}, a\right)\right)-Q_{2}(S, A)\right)$
    \ENDIF
    \STATE $S \gets S'$
  \UNTIL{$S$ 为终止状态}
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<h2 id="taxi-v3-示例">Taxi-v3 示例</h2>

<p>我们以 <a href="https://gym.openai.com/envs/Taxi-v3/" rel="noreferrer" target="_blank">Taxi-v3</a> 为示例来测试 Sarsa，Q-Learning 和 期望 Sarsa 三种不同的算法。Taxi-v3 包含了一个 5x5 的网格，即 25 个可能的位置，我们需要驾驶一辆出租车分别在图中的 R、G、Y、B 四个位置接送乘客。客人共计存在 4 种可能的上车点，4 种可能的下车点，同时考虑出租车的位置，整个环境共有 <code>$5 \times 5 \times \left(4 + 1\right) \times 4 = 500$</code> 种可能的状态，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/taxi-v3-env.png" class="lazyload"/>
  <figcaption><p class="figcaption">图片来源：<a href="https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/" rel="noreferrer" target="_blank">https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/</a></p></figcaption>
</figure>

<p>出租车需要根据当前环境采取不同的动作，共计 6 种可能的动作：向南走，向北走，向东走，向西走，接上乘客，放下乘客。由于环境中存在墙，出租车每次撞墙不会发生任何移动。每一步动作默认 -1 的回报，当选择错误的地点接上或放下乘客时获得 -10 的回报，在成功运送一个客人后获得 +20 的回报。</p>

<p>分别利用 Sarsa，Q-Learning 和 期望 Sarsa 三种不同的算法训练模型，我们以 100 幕作为窗口计算平均回报，前 1000 个平均回报的对比结果如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/taxi-v3-rewards.png" class="lazyload"/>
  
</figure>

<p>Taxi-v3 的成绩排行榜可参见 <a href="https://github.com/openai/gym/wiki/Leaderboard#taxi-v3" rel="noreferrer" target="_blank">这里</a>。利用训练好的模型执行预测的效果如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/taxi-v3-evaluation.gif" class="lazyload"/>
  
</figure>

<p>本文示例代码实现请参见<a href="https://github.com/leovan/leovan.me/tree/master/scripts/cn/2020-07-11-model-free-policy-prediction-and-control-temporal-difference-learning/" rel="noreferrer" target="_blank">这里</a>。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:sutton2018reinforcement">Sutton, R. S., &amp; Barto, A. G. (2018). <em>Reinforcement learning: An introduction</em>. MIT press.
 <a class="footnote-return" href="#fnref:sutton2018reinforcement">↩</a></li>
<li id="fn:stanford-cs234">CS234: Reinforcement Learning <a href="http://web.stanford.edu/class/cs234/index.html" rel="noreferrer" target="_blank">http://web.stanford.edu/class/cs234/index.html</a>
 <a class="footnote-return" href="#fnref:stanford-cs234">↩</a></li>
<li id="fn:ucl-course-on-rl">UCL Course on RL <a href="https://www.davidsilver.uk/teaching" rel="noreferrer" target="_blank">https://www.davidsilver.uk/teaching</a>
 <a class="footnote-return" href="#fnref:ucl-course-on-rl">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>无模型策略预测和控制 - 蒙特卡洛方法 (Model-Free Policy Prediction and Control - Monte-Carlo Learning)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/07/model-free-policy-prediction-and-control-monte-carlo-learning/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/07/model-free-policy-prediction-and-control-monte-carlo-learning/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文为<a href="/categories/强化学习/">《强化学习系列》</a>文章<br />
本文内容主要参考自：<br />
1.《强化学习》<sup class="footnote-ref" id="fnref:sutton2018reinforcement"><a href="#fn:sutton2018reinforcement">1</a></sup><br />
2. CS234: Reinforcement Learning <sup class="footnote-ref" id="fnref:stanford-cs234"><a href="#fn:stanford-cs234">2</a></sup><br />
3. UCL Course on RL <sup class="footnote-ref" id="fnref:ucl-course-on-rl"><a href="#fn:ucl-course-on-rl">3</a></sup></p>
</blockquote>

<p>蒙特卡洛算法仅需要<strong>经验</strong>，即从真实或者模拟的环境交互中采样得到的状态、动作、收益的序例。从<strong>真实</strong>经验中学习不需要关于环境动态变化规律的先验知识，却依然能够达到最优的行为；从<strong>模拟</strong>经验中学习尽管需要一个模型，但这个模型只需要能够生成状态转移的一些样本，而不需要像动态规划那样生成所有可能的转移概率分布。</p>

<h2 id="蒙特卡洛预测">蒙特卡洛预测</h2>

<p>一个状态的价值是从该状态开始的期望回报，即未来的折扣收益累积值的期望。那么一个显而易见的方式是根据经验进行估计，即对所有经过这个状态之后产生的回报进行平均。随着越来越多的回报被观察到，平均值就会收敛到期望值，这就是蒙特卡洛算法的基本思想。</p>

<p>假设给定策略 <code>$\pi$</code> 下途径状态 <code>$s$</code> 的多幕数据，我们需要估计策略 <code>$\pi$</code> 下状态 <code>$s$</code> 的价值函数 <code>$v_{\pi} \left(s\right)$</code>。在同一幕中，<code>$s$</code> 可能多次被访问，因此蒙特卡洛方法分为<strong>首次访问型 MC 算法</strong>和<strong>每次访问型 MC 算法</strong>，两者的区别在于更新时是否校验 <code>$S_t$</code> 已经在当前幕中出现过。以首次访问型 MC 预测算法为例，算法流程如下：</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{首次访问型 MC 预测算法，用于估计 $V \approx v_{\pi}$}
\begin{algorithmic}
\REQUIRE 待评估策略 $\pi$
\STATE 对于所有 $s \in \mathcal{S}$，任意初始化 $V \left(s\right) \in \mathbb{R}$
\STATE 对于所有 $s \in \mathcal{S}$，$Returns \left(s\right) \gets \varnothing$
\WHILE{TRUE}
  \STATE 根据 $\pi$ 生成一幕序列 $S_0, A_0, R_1, \cdots, S_{T-1}, A_{T-1}, R_T$
  \STATE $G \gets 0$
  \FOR{$t \in T-1, T-2, \cdots, 0$}
    \STATE $G \gets \gamma G + R_{t+1}$
    \IF{$S_t$ 在 $S_0, S_1, \cdots, S_{t-1}$ 中出现过}
      \STATE $Returns \left(S_t\right) \gets Resurn \left(S_t\right) \cup G$
      \STATE $V \left(S_t\right) \gets avg \left(Returns \left(S_t\right)\right)$
    \ENDIF
  \ENDFOR
\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>以<a href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E5%8D%81%E4%B8%80%E9%BB%9E" rel="noreferrer" target="_blank">二十一点</a>游戏为例，每一局可以看作一幕，胜、负、平分别获得收益 <code>$+1, -1, 0$</code>。每局游戏进行中的收益都为 <code>$0$</code>，并且不打折扣（<code>$\gamma = 1$</code>），最终的收益即为整个游戏的回报。玩家的动作为要牌（Hit）或停牌（Stand），状态则取决于玩家的牌和庄家显示的牌。假设所有牌来自无穷多的一组牌（即每次取出的牌都会再放回牌堆）。如果玩家手上有一张 A，可以视作 11 而不爆掉，那么称这张 A 为<strong>可用的</strong>，此时这张牌总会被视作 11。因此，玩家做出的选择只会依赖于三个变量：他手牌的总和（12-31），庄家显示的牌（A-10），以及他是否有可用的 A，共计 200 个状态。</p>

<p>考虑如下策略，玩家在手牌点数之和小于 20 时均要牌，否则停牌。通过该策略多次模型二十一点游戏，并且计算每一个状态的回报的平均值。模拟结果如下：</p>

<figure>
  <img data-src="/images/cn/2020-07-01-model-free-policy-prediction-and-control-monte-carlo-learning/blackjack-monte-carlo-on-policy.png" class="lazyload"/>
  
</figure>

<p>有可用 A 的状态的估计会更不确定、不规律，因为这样的状态更加罕见。无论哪种情况，在大于约 500000 局游戏后，价值函数都能很好地近似。</p>

<h2 id="蒙特卡洛控制">蒙特卡洛控制</h2>

<p>如果无法得到环境的模型，那么计算动作的价值（“状态-动作”二元组的价值）比计算状态的价值更加有用。动作价值函数的策略评估的目标是估计 <code>$q_{\pi} \left(s, a\right)$</code>，即在策略 <code>$\pi$</code> 下从状态 <code>$s$</code> 采取动作 <code>$a$</code> 的期望回报。只需将对状态的访问改为对“状态-动作”二元组的访问，蒙特卡洛算法就可以几乎和之前完全相同的方式解决该问题，唯一复杂之处在于一些“状态-动作”二元组可能永远不会被访问到。为了实现基于动作价值函数的策略评估，我们必须保证持续的试探。一种方式是将指定的“状态-动作”二元组作为起点开始一幕采样，同时保证所有“状态-动作”二元组都有非零的概率可以被选为起点。这样就保证了在采样的幕个数趋于无穷时，每一个“状态-动作”二元组都会被访问到无数次。我们把这种假设称为<strong>试探性出发</strong>。</p>

<p>策略改进的方法是在当前价值函数上贪心地选择动作。由于我们有动作价值函数，所以在贪心的时候完全不需要使用任何的模型信息。对于任意的一个动作价值函数 <code>$q$</code>，对应的贪心策略为：对于任意一个状态 <code>$s \in \mathcal{S}$</code>，必定选择对应动作价值函数最大的动作：</p>

<p><code>$$
\pi \left(s\right) = \arg\max_a q \left(s, a\right)
$$</code></p>

<p>策略改进可以通过将 <code>$q_{\pi_k}$</code> 对应的贪心策略作为 <code>$\pi_{k+1}$</code> 来进行。这样的 <code>$\pi_k$</code> 和 <code>$\pi_{k+1}$</code> 满足策略改进定理，因为对于所有的状态 <code>$s \in \mathcal{S}$</code>：</p>

<p><code>$$
\begin{aligned}
q_{\pi_{k}}\left(s, \pi_{k+1}(s)\right) &amp;=q_{\pi_{k}}\left(s, \underset{a}{\arg \max } q_{\pi_{k}}(s, a)\right) \\
&amp;=\max _{a} q_{\pi_{k}}(s, a) \\
&amp; \geqslant q_{\pi_{k}}\left(s, \pi_{k}(s)\right) \\
&amp; \geqslant v_{\pi_{k}}(s)
\end{aligned}
$$</code></p>

<p>对于蒙特卡洛策略迭代，可以逐幕交替进行评估与改进。每一幕结束后，使用观测到的回报进行策略评估，然后在该幕序列访问到的每一个状态上进行策略改进。使用这个思路的一个简单算法称为<strong>基于试探性出发的蒙特卡洛（蒙特卡洛 ES）</strong>，算法流程如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{蒙特卡洛 ES（试探性出发），用于估计 $\pi \approx \pi_*$}
\begin{algorithmic}
\STATE 对于所有 $s \in \mathcal{S}$，任意初始化 $\pi \left(s\right) \in \mathcal{A} \left(s\right)$
\STATE 对于所有 $s \in \mathcal{S}, a \in \mathcal{A} \left(s\right)$，任意初始化 $Q \left(s, a\right) \in \mathbb{R}$
\STATE 对于所有 $s \in \mathcal{S}, a \in \mathcal{A} \left(s\right)$，$Returns \left(s, a\right) \gets \varnothing$
\WHILE{TRUE}
  \STATE 选择 $S_0 \in \mathcal{S}$ 和 $A_0 \in \mathcal{A} \left(S_0\right)$ 以使得所有“状态-动作”二元组的概率都 $> 0$
  \STATE 从 $S_0, A_0$ 开始根据 $\pi$ 生成一幕序列 $S_0, A_0, R_1, \cdots, S_{T-1}, A_{T-1}, R_T$
  \STATE $G \gets 0$
  \FOR{$t \in T-1, T-2, \cdots, 0$}
    \STATE $G \gets \gamma G + R_{t+1}$
    \IF{$S_t, A_t$ 在 $S_0, A_0, S_1, A_1, \cdots, S_{t-1}, A_{t-1}$ 中出现过}
      \STATE $Returns \left(S_t, A_t\right) \gets Resurn \left(S_t, A_t\right) \cup G$
      \STATE $Q \left(S_t, A_t\right) \gets avg \left(Returns \left(S_t, A_t\right)\right)$
      \STATE $\pi \left(S_t\right) \gets \arg\max_a Q \left(S_t, a\right)$
    \ENDIF
  \ENDFOR
\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>利用蒙特卡洛 ES 可以很直接地解决二十一点游戏，只需随机等概率选择庄家的扑克牌、玩家手牌的点数，以及确定是否有可用的 A 即可。令只在 20 或 21 点停牌为初始策略，初始动作价值函数全部为零，下图展示了蒙特卡洛 ES 得出的最优策略：</p>

<figure>
  <img data-src="/images/cn/2020-07-01-model-free-policy-prediction-and-control-monte-carlo-learning/blackjack-monte-carlo-exploring-starts.png" class="lazyload"/>
  
</figure>

<h2 id="同轨策略和离轨策略">同轨策略和离轨策略</h2>

<h3 id="同轨策略">同轨策略</h3>

<p>为了避免很难被满足的试探性出发假设，一般性的解法是智能体能够持续不断地选择所有可能的动作，有两种方法可以保证这一点，<strong>同轨策略（on-policy）</strong>和<strong>离轨策略（off-policy）</strong>。在同轨策略中，用于生成采样数据序列的策略和用于实际决策的待评估和改进的策略是相同的；而在离轨策略中，用于评估或改进的策略与生成采样数据的策略是不同的，即生成的数据“离开”了待优化的策略所决定的决策序列轨迹。</p>

<p>在同轨策略中，策略一般是“软性”的，即对于任意 <code>$s \in \mathcal{S}$</code> 以及 <code>$a \in \mathcal{A} \left(s\right)$</code>，都有 <code>$\pi \left(a | s\right) &gt; 0$</code>，但他们会逐渐地逼近一个确定性的策略。<code>$\epsilon-$</code> 贪心策略是指在绝大多数时候都采取获得最大估计值的动作价值函数对应的动作，但同时以一个较小的概率 <code>$\epsilon$</code> 随机选择一个动作。因此对于所有非贪心的动作都以 <code>$\frac{\epsilon}{|\mathcal{A} \left(s\right)|}$</code> 的概率被选中，贪心动作则以 <code>$1 - \epsilon + \frac{\epsilon}{|\mathcal{A} \left(s\right)|}$</code> 的概率被选中。同轨策略的蒙特卡洛控制</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{同轨策略的首次访问型 MC 控制算法（对于 $\epsilon-$ 软性策略），用于估计 $\pi \approx \pi_*$}
\begin{algorithmic}
\STATE $\pi \gets$ 一个任意的 $\epsilon-$ 软性策略
\STATE 对于所有 $s \in \mathcal{S}, a \in \mathcal{A} \left(s\right)$，任意初始化 $Q \left(s, a\right) \in \mathbb{R}$
\STATE 对于所有 $s \in \mathcal{S}, a \in \mathcal{A} \left(s\right)$，$Returns \left(s, a\right) \gets \varnothing$
\WHILE{TRUE}
  \STATE 根据 $\pi$ 生成一幕序列 $S_0, A_0, R_1, \cdots, S_{T-1}, A_{T-1}, R_T$
  \STATE $G \gets 0$
  \FOR{$t \in T-1, T-2, \cdots, 0$}
    \STATE $G \gets \gamma G + R_{t+1}$
    \IF{$S_t, A_t$ 在 $S_0, A_0, S_1, A_1, \cdots, S_{t-1}, A_{t-1}$ 中出现过}
      \STATE $Returns \left(S_t, A_t\right) \gets Resurn \left(S_t, A_t\right) \cup G$
      \STATE $Q \left(S_t, A_t\right) \gets avg \left(Returns \left(S_t, A_t\right)\right)$
      \STATE $A^* \gets \arg\max_a Q \left(S_t, a\right)$
      \STATE 对于所有 $a \in \mathcal{A} \left(S_t\right)$，$\pi\left(a \mid S_{t}\right) \leftarrow\left\{\begin{array}{ll}
1-\varepsilon+\varepsilon /\left|\mathcal{A}\left(S_{t}\right)\right| & \text { if } a=A^{*} \\
\varepsilon /\left|\mathcal{A}\left(S_{t}\right)\right| & \text { if } a \neq A^{*}
\end{array}\right.$
    \ENDIF
  \ENDFOR
\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre></div>


<h3 id="离轨策略">离轨策略</h3>

<p>所有的学习控制方法都面临一个困境：它们希望学到的动作可以使随后的智能体行为是最优的，但是为了搜索所有的动作（以保证找到最优动作），它们需要采取非最优的行动。同轨策略采用一种妥协的方法，它并不学习最优策略的动作值，而是学习一个接近最优而且仍能进行试探的策略的动作值。一个更加直接的方法是采用两个策略，一个用来学习并成为最优策略，另一个更加有试探性，用来产生智能体的行动样本。用来学习的策略被称为<strong>目标策略</strong>，用于生成行动样本的策略被称为<strong>行动策略</strong>。在这种情况下，我们认为学习所用的数据“离开”了待学习的目标策略，因此整个过程称为<strong>离轨策略学习</strong>。</p>

<p>几乎所有的离轨策略方法都采用了<strong>重要度采样</strong>，重要度采样是一种在给定来自其他分布的样本的条件下，估计某种分布的期望值的通用方法。在离轨策略学习中，对回报值根据其轨迹在目标策略与行动策略中出现的相对概率进行加权，这个相对概率称为<strong>重要度采样比</strong>。给定起始状态 <code>$S_t$</code>，后续的“状态-动作”轨迹 <code>$A_t, S_{t+1}, A_{t+1}, \cdots, S_T$</code> 在策略 <code>$\pi$</code> 下发生的概率为：</p>

<p><code>$$
\begin{aligned}
\operatorname{Pr}\left\{A_{t},\right.&amp;\left.S_{t+1}, A_{t+1}, \ldots, S_{T} \mid S_{t}, A_{t: T-1} \sim \pi\right\} \\
&amp;=\pi\left(A_{t} \mid S_{t}\right) p\left(S_{t+1} \mid S_{t}, A_{t}\right) \pi\left(A_{t+1} \mid S_{t+1}\right) \cdots p\left(S_{T} \mid S_{T-1}, A_{T-1}\right) \\
&amp;=\prod_{k=t}^{T-1} \pi\left(A_{k} \mid S_{k}\right) p\left(S_{k+1} \mid S_{k}, A_{k}\right)
\end{aligned}
$$</code></p>

<p>其中，<code>$p$</code> 为状态转移概率函数。因此，在目标策略和行动策略轨迹下的相对概率（重要度采样比）为：</p>

<p><code>$$
\rho_{t: T-1} \doteq \frac{\prod_{k=t}^{T-1} \pi\left(A_{k} \mid S_{k}\right) p\left(S_{k+1} \mid S_{k}, A_{k}\right)}{\prod_{k=t}^{T-1} b\left(A_{k} \mid S_{k}\right) p\left(S_{k+1} \mid S_{k}, A_{k}\right)}=\prod_{k=t}^{T-1} \frac{\pi\left(A_{k} \mid S_{k}\right)}{b\left(A_{k} \mid S_{k}\right)}
$$</code></p>

<p>化简后，重要度采样比只与两个策略和样本序列数据相关，而与 MDP 的动态特性（状态转移概率）无关。我们希望估计目标策略下的期望回报（价值），但我们只有行动策略中的回报 <code>$G_t$</code>。直接使用行动策略中的回报进行估计是不准的，因此需要使用重要度采样比调整回报从而得到正确的期望值：</p>

<p><code>$$
\mathbb{E}\left[\rho_{t: T-1} G_{t} \mid S_{t}=s\right]=v_{\pi}(s)
$$</code></p>

<p>定义所有访问过状态 <code>$s$</code> 的时刻集合为 <code>$\mathcal{T} \left(s\right)$</code>，<code>$T \left(t\right)$</code> 表示时刻 <code>$t$</code> 后的首次终止，用 <code>$G_t$</code> 表示在 <code>$t$</code> 之后到达 <code>$T \left(t\right)$</code> 时的回报值。则 <code>$\left\{G_t\right\}_{t \in \mathcal{T} \left(s\right)}$</code> 就是状态 <code>$s$</code> 对应的回报值，<code>$\left\{\rho_{t:T \left(t\right) - 1}\right\}_{t \in \mathcal{T} \left(s\right)}$</code> 是相应的重要度采样比。则为了预测 <code>$v_{\pi} \left(s\right)$</code>，有：</p>

<p><code>$$
V(s) \doteq \frac{\sum_{t \in \mathcal{T}(s)} \rho_{t: T(t)-1} G_{t}}{|\mathcal{T}(s)|} \label{eq:ordinary-importance-sampling}
$$</code></p>

<p>为一种简单平均实现的重要度采样，称之为<strong>普通重要度采样</strong>。</p>

<p><code>$$
V(s) \doteq \frac{\sum_{t \in \mathcal{T}(s)} \rho_{t: T(t)-1} G_{t}}{\sum_{t \in \mathcal{T}(s)} \rho_{t: T(t)-1}} \label{eq:weighted-importance-sampling}
$$</code></p>

<p>为一种加权的重要度采样，称之为<strong>加权重要度采样</strong>，如果分母为零，则式 <code>$\ref{eq:weighted-importance-sampling}$</code> 的值也为零。式 <code>$\ref{eq:ordinary-importance-sampling}$</code> 得到的结果在期望上是 <code>$v_{\pi} \left(s\right)$</code> 的无偏估计，但其值可能变得很极端，式 <code>$\ref{eq:weighted-importance-sampling}$</code> 的估计是有偏的，但其估计的方差可以收敛到 0。</p>

<p>我们对二十一点游戏的状态值进行离轨策略估计。评估的状态为玩家有一张 A，一张 2（或者等价情况，有三张 A），从这个状态开始等概率选择要牌或停牌得到采样数据，目标策略只在和达到 20 或 21 时停牌。</p>

<figure>
  <img data-src="/images/cn/2020-07-01-model-free-policy-prediction-and-control-monte-carlo-learning/blackjack-monte-carlo-off-policy.png" class="lazyload"/>
  
</figure>

<p>在目标策略中，这个状态的值大概为 -0.27726（利用目标策略独立生成 1 亿幕数据后对回报进行平均得到）。两种离轨策略方法在采样随机策略经过 1000 幕离轨策略数据采样后都很好地逼近了这个值，但加权重要度采样在开始时错误率明显较低，这也是实践中的典型现象。</p>

<p>假设一个回报序列 <code>$G_1, G_2, \cdots, G_{n-1}$</code>，它们都从相同的状态开始，且每一个回报都对应一个随机权重 <code>$W_i$</code>，我们希望获得如下式子的估计：</p>

<p><code>$$
V_{n} \doteq \frac{\sum_{k=1}^{n-1} W_{k} G_{k}}{\sum_{k=1}^{n-1} W_{k}}, \quad n \geq 2
$$</code></p>

<p>同时在获得一个额外的回报 <code>$G_n$</code> 时能保持更新。为了能不断跟踪 <code>$V_n$</code> 的变化，我们必须为每一个状态维护前 <code>$n$</code> 个回报对应的权值的累加和 <code>$C_n$</code>。<code>$V_n$</code> 的更新方法如下：</p>

<p><code>$$
\begin{array}{l}
V_{n+1} \doteq V_{n}+\dfrac{W_{n}}{C_{n}}\left[G_{n}-V_{n}\right], \quad n \geq 1 \\
C_{n+1} \doteq C_{n}+W_{n+1}
\end{array}
$$</code></p>

<p>其中，<code>$C_0 = 0$</code>，<code>$V_1$</code> 是任意值。一个完整的用于蒙特卡洛策略评估的逐幕增量算法如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{离轨策略 MC 预测算法（策略评估），用于估计 $Q \approx q_{\pi}$}
\begin{algorithmic}
\REQUIRE 一个任意的目标策略 $\pi$
\STATE 对于所有 $s \in \mathcal{S}, a \in \mathcal{A} \left(s\right)$，任意初始化 $Q \left(s, a\right) \in \mathbb{R}$
\STATE 对于所有 $s \in \mathcal{S}, a \in \mathcal{A} \left(s\right)$，$C \left(s, a\right) \gets 0$
\WHILE{TRUE}
  \STATE $b \gets$ 任何能包括 $\pi$ 的策略
  \STATE 根据 $b$ 生成一幕序列 $S_0, A_0, R_1, \cdots, S_{T-1}, A_{T-1}, R_T$
  \STATE $G \gets 0$
  \STATE $W \gets 1$
  \FOR{$t \in T-1, T-2, \cdots, 0$}
    \STATE $G \gets \gamma G + R_{t+1}$
    \STATE $C \left(S_t, A_t\right) \gets C \left(S_t, A_t\right) + W$
    \STATE $Q \left(S_{t}, A_{t}\right) \leftarrow Q\left(S_{t}, A_{t}\right)+\frac{W}{C\left(S_{t}, A_{t}\right)}\left[G-Q\left(S_{t}, A_{t}\right)\right]$
    \STATE $W \leftarrow W \frac{\pi\left(A_{t} \mid S_{t}\right)}{b\left(A_{t} \mid S_{t}\right)}$
    \IF{$W = 0$}
      \BREAK
    \ENDIF
  \ENDFOR
\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>在离轨策略中，策略的价值评估和策略的控制是分开的，用于生成行动数据的策略被称为<strong>行动策略</strong>，行动策略可能与实际上被评估和改善的策略无关，而被评估和改善的策略称为<strong>目标策略</strong>。这样分离的好处在于当行动策略能对所有可能的动作继续进行采样时，目标策略可以是确定的（贪心的）。</p>

<p>离轨策略蒙特卡洛控制方法要求行动策略对目标策略可能做出的所有动作都有非零的概率被选择。为了试探所有的可能性，要求行动策略是软性的。一个基于通用迭代策略（GPI）和重要度采样的离轨策略蒙特卡洛控制方法如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{离轨策略 MC 控制算法，用于估计 $\pi \approx \pi_*$}
\begin{algorithmic}
\STATE 对于所有 $s \in \mathcal{S}, a \in \mathcal{A} \left(s\right)$，任意初始化 $Q \left(s, a\right) \in \mathbb{R}$
\STATE 对于所有 $s \in \mathcal{S}, a \in \mathcal{A} \left(s\right)$，$C \left(s, a\right) \gets 0$
\STATE 对于所有 $s \in \mathcal{S}, a \in \mathcal{A} \left(s\right)$，$\pi \left(s\right) \gets \arg\max_a Q \left(s, a\right)$
\STATE \COMMENT{出现平分情况选取方法应保持一致}
\WHILE{TRUE}
  \STATE $b \gets$ 任意软性策略
  \STATE 根据 $b$ 生成一幕序列 $S_0, A_0, R_1, \cdots, S_{T-1}, A_{T-1}, R_T$
  \STATE $G \gets 0$
  \STATE $W \gets 1$
  \FOR{$t \in T-1, T-2, \cdots, 0$}
    \STATE $G \gets \gamma G + R_{t+1}$
    \STATE $C \left(S_t, A_t\right) \gets C \left(S_t, A_t\right) + W$
    \STATE $Q \left(S_{t}, A_{t}\right) \leftarrow Q\left(S_{t}, A_{t}\right)+\frac{W}{C\left(S_{t}, A_{t}\right)}\left[G-Q\left(S_{t}, A_{t}\right)\right]$
    \STATE $\pi\left(S_{t}\right) \leftarrow \arg \max _{a} Q\left(S_{t}, a\right)$
    \STATE \COMMENT{出现平分情况选取方法应保持一致}
    \IF{$A_t \neq \pi \left(S_t\right)$}
      \BREAK
    \ENDIF
    \STATE $W \leftarrow W \frac{1}{b\left(A_{t} \mid S_{t}\right)}$
  \ENDFOR
\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>本文示例代码实现请参见<a href="https://github.com/leovan/leovan.me/blob/master/scripts/cn/2020-07-01-model-free-policy-prediction-and-control-monte-carlo-learning/blackjack.py" rel="noreferrer" target="_blank">这里</a>。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:sutton2018reinforcement">Sutton, R. S., &amp; Barto, A. G. (2018). <em>Reinforcement learning: An introduction</em>. MIT press.
 <a class="footnote-return" href="#fnref:sutton2018reinforcement">↩</a></li>
<li id="fn:stanford-cs234">CS234: Reinforcement Learning <a href="http://web.stanford.edu/class/cs234/index.html" rel="noreferrer" target="_blank">http://web.stanford.edu/class/cs234/index.html</a>
 <a class="footnote-return" href="#fnref:stanford-cs234">↩</a></li>
<li id="fn:ucl-course-on-rl">UCL Course on RL <a href="https://www.davidsilver.uk/teaching" rel="noreferrer" target="_blank">https://www.davidsilver.uk/teaching</a>
 <a class="footnote-return" href="#fnref:ucl-course-on-rl">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>利用动态规划求解马尔可夫决策过程 (Planning by Dynamic Programming)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/06/planning-by-dynamic-programming/</link>
      <pubDate>Sat, 13 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/06/planning-by-dynamic-programming/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文为<a href="/categories/强化学习/">《强化学习系列》</a>文章<br />
本文内容主要参考自：<br />
1.《强化学习》<sup class="footnote-ref" id="fnref:sutton2018reinforcement"><a href="#fn:sutton2018reinforcement">1</a></sup><br />
2. CS234: Reinforcement Learning <sup class="footnote-ref" id="fnref:stanford-cs234"><a href="#fn:stanford-cs234">2</a></sup><br />
3. UCL Course on RL <sup class="footnote-ref" id="fnref:ucl-course-on-rl"><a href="#fn:ucl-course-on-rl">3</a></sup></p>
</blockquote>

<h2 id="动态规划">动态规划</h2>

<p><a href="/cn/2018/11/computational-complexity-and-dynamic-programming/"><strong>动态规划</strong></a>（Dynamic Programming，DP）是一种用于解决具有如下两个特性问题的通用算法：</p>

<ol>
<li>优化问题可以分解为子问题。</li>
<li>子问题出现多次并可以被缓存和复用。</li>
</ol>

<p>马尔可夫决策过程正符合这两个特性：</p>

<ol>
<li>贝尔曼方程给定了迭代过程的分解。</li>
<li>价值函数保存并复用了解决方案。</li>
</ol>

<p>在强化学习中，DP 的核心思想是使用价值函数来结构化地组织对最优策略的搜索。一旦得到了满足贝尔曼最优方程的价值函数 <code>$v_*$</code> 或 <code>$q_*$</code>，得到最优策略就容易了。对于任意 <code>$s \in \mathcal{S}$</code>（状态集合），<code>$a \in \mathcal{A} \left(s\right)$</code>（动作集合）和 <code>$s' \in \mathcal{S}^{+}$</code>（在分幕式任务下 <code>$\mathcal{S}$</code> 加上一个终止状态），有：</p>

<p><code>$$
\begin{aligned}
v_{*}(s) &amp;=\max _{a} \mathbb{E}\left[R_{t+1}+\gamma v_{*}\left(S_{t+1}\right) | S_{t}=s, A_{t}=a\right] \\
&amp;=\max _{a} \sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma v_{*}\left(s^{\prime}\right)\right]
\end{aligned}
$$</code></p>

<p><code>$$
\begin{aligned}
q_{*}(s, a) &amp;=\mathbb{E}\left[R_{t+1}+\gamma \max _{a^{\prime}} q_{*}\left(S_{t+1}, a^{\prime}\right) | S_{t}=s, A_{t}=a\right] \\
&amp;\left.=\sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma \max _{a^{\prime}}\right] q_{*}\left(s^{\prime}, a^{\prime}\right)\right]
\end{aligned}
$$</code></p>

<p>将贝尔曼方程转化成为近似逼近理想价值函数的递归更新公式，我们就得到了 DP 算法。</p>

<h2 id="策略评估">策略评估</h2>

<p>对于一个策略 <code>$\pi$</code>，如何计算其状态价值函数 <code>$v_{\pi}$</code> 被称为<strong>策略评估</strong>。对于任意 <code>$s \in \mathcal{S}$</code>，有：</p>

<p><code>$$
\begin{aligned}
v_{\pi}(s) &amp; \doteq \mathbb{E}_{\pi}\left[G_{t} | S_{t}=s\right] \\
&amp;=\mathbb{E}_{\pi}\left[R_{t+1}+\gamma G_{t+1} | S_{t}=s\right] \\
&amp;=\mathbb{E}_{\pi}\left[R_{t+1}+\gamma v_{\pi}\left(S_{t+1}\right) | S_{t}=s\right] \\
&amp;=\sum_{a} \pi(a | s) \sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma v_{\pi}\left(s^{\prime}\right)\right]
\end{aligned}
$$</code></p>

<p>其中 <code>$\pi \left(a | s\right)$</code> 表示在环境 <code>$s$</code> 中智能体在策略 <code>$\pi$</code> 下采取动作 <code>$a$</code> 的概率。只要 <code>$\gamma &lt; 1$</code> 或者任何状态在 <code>$\pi$</code> 下都能保证最后终止，则 <code>$v_{\pi}$</code> 唯一存在。</p>

<p>考虑一个近似的价值函数序列 <code>$v_0, v_1, \cdots$</code>，从 <code>$\mathcal{S}^{+}$</code> 映射到 <code>$\mathbb{R}$</code>，初始的近似值 <code>$v_0$</code> 可以任意选取（除了终止状态必须为 0 外）。下一轮迭代的近似可以使用 <code>$v_{\pi}$</code> 的贝尔曼方程进行更新，对于任意 <code>$s \in \mathcal{S}$</code> 有：</p>

<p><code>$$
\begin{aligned}
v_{k+1}(s) &amp; \doteq \mathbb{E}_{\pi}\left[R_{t+1}+\gamma v_{k}\left(S_{t+1}\right) | S_{t}=s\right] \\
&amp;=\sum_{a} \pi(a | s) \sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma v_{k}\left(s^{\prime}\right)\right]
\end{aligned}
$$</code></p>

<p>显然，<code>$v_k = v_{\pi}$</code> 是这个更新规则的一个不动点。在保证 <code>$v_{\pi}$</code> 存在的条件下，序列 <code>$\left\{v_k\right\}$</code> 在 <code>$k \to \infty$</code> 时将会收敛到 <code>$v_{\pi}$</code>，这个算法称作 <strong>迭代策略评估</strong>。</p>

<h2 id="策略改进">策略改进</h2>

<p>对于任意一个确定的策略 <code>$\pi$</code>，我们已经确定了它的价值函数 <code>$v_{\pi}$</code>。对于某个状态 <code>$s$</code>，我们想知道是否应该选择一个不同于给定的策略的动作 <code>$a \neq \pi \left(s\right)$</code>。如果从状态 <code>$s$</code> 继续使用现有策略，则最后的结果就是 <code>$v \left(s\right)$</code>，但我们并不知道换成一个新策略后是得到更好的结果还是更坏的结果。一种解决方法是在状态 <code>$s$</code> 选择动作 <code>$a$</code> 后，继续遵循现有的策略 <code>$\pi$</code>，则这种方法的价值为：</p>

<p><code>$$
\begin{aligned}
q_{\pi}(s, a) &amp; \doteq \mathbb{E}\left[R_{t+1}+\gamma v_{\pi}\left(S_{t+1}\right) | S_{t}=s, A_{t}=a\right] \\
&amp;=\sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma v_{\pi}\left(s^{\prime}\right)\right]
\end{aligned}
$$</code></p>

<p>一个关键的准则就是这个值是大于还是小于 <code>$v_{\pi} \left(s\right)$</code>。如果这个值更大，则说明在状态 <code>$s$</code> 选择动作 <code>$a$</code>，然后继续使用策略 <code>$\pi$</code> 会比使用始终使用策略 <code>$\pi$</code> 更优。</p>

<p>上述情况是<strong>策略改进定理</strong>的一个特例，一般来说，如果 <code>$\pi$</code> 和 <code>$\pi'$</code> 是任意两个确定的策略，对于任意 <code>$s \in \mathcal{S}$</code>：</p>

<p><code>$$
q_{\pi}\left(s, \pi^{\prime}(s)\right) \geq v_{\pi}(s)
$$</code></p>

<p>则称策略 <code>$\pi'$</code> 相比于 <code>$\pi$</code> 一样好或更好。也就是说，对于任意状态 <code>$s \in \mathcal{S}$</code>，这样肯定能得到一样或更好的期望回报：</p>

<p><code>$$
v_{\pi^{\prime}}(s) \geq v_{\pi}(s)
$$</code></p>

<p>延伸到所有状态和所有可能的动作，即在每个状态下根据 <code>$q_{\pi} \left(s, a\right)$</code> 选择一个最优的，换言之，考虑一个新的<strong>贪心</strong>策略 <code>$\pi'$</code>，满足：</p>

<p><code>$$
\begin{aligned}
\pi^{\prime}(s) &amp; \doteq \underset{a}{\arg \max } q_{\pi}(s, a) \\
&amp;=\underset{a}{\arg \max } \mathbb{E}\left[R_{t+1}+\gamma v_{\pi}\left(S_{t+1}\right) | S_{t}=s, A_{t}=a\right] \\
&amp;=\underset{a}{\arg \max } \sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma v_{\pi}\left(s^{\prime}\right)\right]
\end{aligned}
$$</code></p>

<p>这样构造出的贪心策略满足策略改进定理的条件，所以它和原策略相比一样好或更好。这种根据原策略的价值函数执行贪心算法，来构造一个更好策略的过程称之为<strong>策略改进</strong>。如果新的贪心策略 <code>$\pi'$</code> 和原策略 <code>$\pi$</code> 一样好而不是更好，则有 <code>$v_{\pi} = v_{\pi'}$</code>，对任意 <code>$s \in \mathcal{S}$</code>：</p>

<p><code>$$
\begin{aligned}
v_{\pi^{\prime}}(s) &amp;=\max _{a} \mathbb{E}\left[R_{t+1}+\gamma v_{\pi^{\prime}}\left(S_{t+1}\right) | S_{t}=s, A_{t}=a\right] \\
&amp;=\max _{a} \sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma v_{\pi^{\prime}}\left(s^{\prime}\right)\right]
\end{aligned}
$$</code></p>

<p>这同贝尔曼方程完全相同，因此 <code>$v_{\pi}$</code> 一定与 <code>$v_*$</code> 相同，<code>$\pi$</code> 与 <code>$\pi'$</code> 均必须为最优策略。因此，在除了原策略即为最优策略的情况下，策略改进一定会给出一个更优的结果。</p>

<h2 id="策略迭代">策略迭代</h2>

<p>一个策略 <code>$\pi$</code> 根据 <code>$v_{\pi}$</code> 产生了一个更好的策略 <code>$\pi'$</code>，进而我们可以通过计算 <code>$v_{\pi'}$</code> 来得到一个更优的策略 <code>$\pi''$</code>。这样一个链式的方法可以得到一个不断改进的策略和价值函数序列：</p>

<p><code>$$
\pi_{0} \stackrel{E}{\longrightarrow} v_{\pi_{0}} \stackrel{I}{\longrightarrow} \pi_{1} \stackrel{E}{\longrightarrow} v_{\pi_{1}} \stackrel{I}{\longrightarrow} \pi_{2} \stackrel{E}{\longrightarrow} \cdots \stackrel{I}{\longrightarrow} \pi_{*} \stackrel{E}{\longrightarrow} v_{*}
$$</code></p>

<p>其中 <code>$\stackrel{E}{\longrightarrow}$</code> 表示策略评估，<code>$\stackrel{I}{\longrightarrow}$</code> 表示策略改进。每一个策略都能保证同前一个一样或者更优，由于一个有限 MDP 必然只有有限种策略，所以在有限次的迭代后，这种方法一定收敛到一个最优的策略与最优价值函数。这种寻找最优策略的方法叫做<strong>策略迭代</strong>。整个策略迭代算法如下：</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{迭代策略算法}
\begin{algorithmic}
\FUNCTION{PolicyIteration}{}
\STATE \COMMENT{初始化}
\FOR{$s \in \mathcal{S}$}
  \STATE 初始化 $V \left(s\right) \in \mathbb{R}$
  \STATE 初始化 $\pi \left(s\right) \in \mathcal{A} \left(s\right)$
\ENDFOR
\WHILE{true}
  \STATE \COMMENT{策略评估}
  \REPEAT
    \STATE $\Delta \gets 0$
    \FOR{$s \in \mathcal{S}$}
      \STATE $v \gets V \left(s\right)$
      \STATE $V \left(s\right) \gets \sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, \pi \left(s\right)\right)\left[r+\gamma V\left(s^{\prime}\right)\right]$
      \STATE $\Delta \gets \max\left(\Delta, \left|v - V \left(s\right)\right|\right)$
    \ENDFOR
  \UNTIL{$\Delta < \theta$}
  \STATE \COMMENT{策略改进}
  \STATE policy-stable $\gets$ true
  \FOR{$s \in \mathcal{S}$}
    \STATE $\pi' \left(s\right) \gets \pi \left(s\right)$
    \STATE $\pi \left(s\right) \gets \sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma V\left(s^{\prime}\right)\right]$
    \IF{$\pi' \left(s\right) \neq \pi \left(s\right)$}
      \STATE policy-stable $\gets$ flase
    \ENDIF
  \ENDFOR
  \IF{policy-stable $=$ true}
    \BREAK
  \ENDIF
\ENDWHILE
\RETURN $V, \pi$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>以<strong>杰克租车（Jack&rsquo;s Car）问题</strong>为例：杰克在两地运营租车公司，每租出一辆车获得 10 元收益，为了保证每个地点有车可用，杰克需要夜间在两地之间移动车辆，每辆车的移动代价为 2 元。假设每个地点租车和还车的数量符合泊松分布 <code>$\dfrac{\lambda^n}{n!} e^{- \lambda}$</code>，其中 <code>$\lambda$</code> 为期望值，租车的 <code>$\lambda$</code> 在两地分别为 3 和 4，还车的 <code>$\lambda$</code> 在两地分别为 3 和 2。假设任何一个地点不超过 20 辆车，每天最多移动 5 辆车，折扣率 <code>$\gamma = 0.9$</code>，将问题描述为一个持续的有限 MPD，时刻按天计算，状态为每天结束时每个地点的车辆数，动作则为夜间在两个地点之间移动的车辆数。策略从不移动任何车辆开始，整个策略迭代过程如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-06-13-planning-by-dynamic-programming/car-rental-policy-history.png" class="lazyload"/>
  
</figure>

<p>上例代码实现请参见<a href="https://github.com/leovan/leovan.me/blob/master/scripts/cn/2020-06-13-planning-by-dynamic-programming/car_rental.py" rel="noreferrer" target="_blank">这里</a>。</p>

<h2 id="价值迭代">价值迭代</h2>

<p>策略迭代算法的一个缺点是每一次迭代都涉及了策略评估，这是一个需要多次遍历状态集合的迭代过程。如果策略评估是迭代进行的，那么收敛到 <code>$v_{\pi}$</code> 理论上在极限处才成立，实际中不必等到其完全收敛，可以提前截断策略评估过程。有多种方式可以截断策略迭代中的策略评估步骤，并且不影响其收敛，一种重要的特殊情况是在一次遍历后即刻停止策略评估，该算法称为<strong>价值迭代</strong>。可以将此表示为结合了策略改进与阶段策略评估的简单更新公式，对任意 <code>$s \in \mathcal{S}$</code>：</p>

<p><code>$$
\begin{aligned}
v_{k+1}(s) &amp; \doteq \max _{a} \mathbb{E}\left[R_{t+1}+\gamma v_{k}\left(S_{t+1}\right) | S_{t}=s, A_{t}=a\right] \\
&amp;=\max _{a} \sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma v_{k}\left(s^{\prime}\right)\right]
\end{aligned}
$$</code></p>

<p>可以证明，对任意 <code>$v_0$</code>，在 <code>$v_*$</code> 存在的条件下，序列 <code>$\left\{v_k\right\}$</code> 都可以收敛到 <code>$v_*$</code>。整个价值迭代算法如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{价值迭代算法}
\begin{algorithmic}
\FUNCTION{ValueIteration}{}
\STATE \COMMENT{初始化}
\FOR{$s \in \mathcal{S}^{+}$}
  \STATE 初始化 $V \left(s\right)$，其中 $V \left(\text{终止状态}\right) = 0$
\ENDFOR
\STATE \COMMENT{价值迭代}
\REPEAT
  \STATE $\Delta \gets 0$
  \FOR{$s \in \mathcal{S}$}
    \STATE $v \gets V \left(s\right)$
    \STATE $V \left(s\right) \gets\sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma V\left(s^{\prime}\right)\right]$
    \STATE $\Delta \gets \max\left(\Delta, \left|v - V \left(s\right)\right|\right)$
  \ENDFOR
\UNTIL{$\Delta < \theta$}
\STATE 输出一个确定的策略 $\pi \approx \pi_*$ 使得 $\pi(s)=\arg \max _{a} \sum_{s^{\prime}, r} p\left(s^{\prime}, r | s, a\right)\left[r+\gamma V\left(s^{\prime}\right)\right]$
\RETURN $V, \pi$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>以<strong>赌徒问题（Gambler’s Problem）</strong>为例：一个赌徒下注猜一系列抛硬币实验的结果，如果正面朝上则获得这一次下注的钱，如果背面朝上则失去这一次下注的钱，游戏在达到目标收益 100 元或全部输光时结束。每抛一次硬币，赌徒必须从他的赌资中选取一个整数来下注，这个问题可以表示为一个非折扣的分幕式有限 MDP。状态为赌徒的赌资 <code>$s \in \left\{1, 2, \cdots, 99\right\}$</code>，动作为赌徒下注的金额 <code>$a \in \left\{0, 1, \cdots, \min \left(s, 100 - s\right)\right\}$</code>，收益在一般情况下为 0，只有在赌徒达到获利 100 元的终止状态时为 1。</p>

<p>令 <code>$p_h$</code> 为抛硬币正面朝上的概率，如果 <code>$p_h$</code> 已知，那么整个问题可以由价值迭代或其他类似算法解决。下图为当 <code>$p_h = 0.4$</code> 时，价值迭代连续遍历得到的价值函数和最后的策略。</p>

<figure>
  <img data-src="/images/cn/2020-06-13-planning-by-dynamic-programming/gamblers-problem-value-iteration.png" class="lazyload"/>
  
</figure>

<figure>
  <img data-src="/images/cn/2020-06-13-planning-by-dynamic-programming/gamblers-problem-optimal-policy.png" class="lazyload"/>
  
</figure>

<p>上例代码实现请参见<a href="https://github.com/leovan/leovan.me/blob/master/scripts/cn/2020-06-13-planning-by-dynamic-programming/gamblers_problem.py" rel="noreferrer" target="_blank">这里</a>。</p>

<h2 id="异步动态规划">异步动态规划</h2>

<p>之前讨论的 DP 方法的一个主要缺点是它们涉及对 MDP 的整个状态集的操作，如果状态集很大，即使单次遍历也会十分昂贵。<strong>异步动态规划</strong>算法是一类就地迭代的 DP 算法，其不以系统遍历状态集的形式来组织算法。这些算法使用任意可用的状态值，以任意顺序来更新状态值，在某些状态的值更新一次之前，另一些状态的值可能已经更新了好几次。然而为了正确收敛，异步算法必须要不断地更新所有状态的值：在某个计算节点后，它不能忽略任何一个状态。</p>

<h2 id="广义策略迭代">广义策略迭代</h2>

<p>策略迭代包含两个同时进行的相互作用的流程，一个使得价值函数与当前策略一致（策略评估），另一个根据当前价值函数贪心地更新策略（策略改进）。在策略迭代中，这两个流程交替进行，每个流程都在另一个开始前完成。然而这也不是必须的，在异步方法中，评估和改进流程则以更细的粒度交替进行。我们利用<strong>广义策略迭代（GPI）</strong>一词来指代策略评估和策略改进相互作用的一般思路，与这两个流程的力度和其他细节无关。</p>

<p>几乎所有的强化学习方法都可以被描述为 GPI，几乎所有方法都包含明确定义的策略和价值函数。策略总是基于特定的价值函数进行改进，价值函数也始终会向对应特定策略的真实价值函数收敛。</p>

<figure>
  <img data-src="/images/cn/2020-06-13-planning-by-dynamic-programming/generalized-policy-iteration.png" class="lazyload"/>
  
</figure>

<p>GPI 的评估和改进流程可以视为两个约束或目标之间的相互作用的流程。每个流程都把价值函数或策略推向其中的一条线，该线代表了对于两个目标中的某一个目标的解决方案，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-06-13-planning-by-dynamic-programming/policy-improvement.png" class="lazyload"/>
  
</figure>
<div class="footnotes">

<hr />

<ol>
<li id="fn:sutton2018reinforcement">Sutton, R. S., &amp; Barto, A. G. (2018). <em>Reinforcement learning: An introduction</em>. MIT press.
 <a class="footnote-return" href="#fnref:sutton2018reinforcement">↩</a></li>
<li id="fn:stanford-cs234">CS234: Reinforcement Learning <a href="http://web.stanford.edu/class/cs234/index.html" rel="noreferrer" target="_blank">http://web.stanford.edu/class/cs234/index.html</a>
 <a class="footnote-return" href="#fnref:stanford-cs234">↩</a></li>
<li id="fn:ucl-course-on-rl">UCL Course on RL <a href="https://www.davidsilver.uk/teaching" rel="noreferrer" target="_blank">https://www.davidsilver.uk/teaching</a>
 <a class="footnote-return" href="#fnref:ucl-course-on-rl">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>贝叶斯优化 (Bayesian Optimization)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/06/bayesian-optimization/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/06/bayesian-optimization/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文内容主要参考自：<br />
1. <a href="https://zhuanlan.zhihu.com/p/139478368" rel="noreferrer" target="_blank">从高斯分布到高斯过程、高斯过程回归、贝叶斯优化</a><br />
2. <a href="https://distill.pub/2019/visual-exploration-gaussian-processes/" rel="noreferrer" target="_blank">A Visual Exploration of Gaussian Processes</a><br />
3. <a href="https://www.aidanscannell.com/post/gaussian-process-regression/" rel="noreferrer" target="_blank">Gaussian Process Regression</a><br />
4. <a href="https://distill.pub/2020/bayesian-optimization/" rel="noreferrer" target="_blank">Exploring Bayesian Optimization</a></p>
</blockquote>

<h2 id="高斯分布">高斯分布</h2>

<h3 id="一元高斯分布">一元高斯分布</h3>

<p>若随机变量 <code>$X$</code> 服从一个均值为 <code>$\mu$</code>，方差为 <code>$\sigma^2$</code> 的高斯分布，则记为：</p>

<p><code>$$
X \sim N \left(\mu, \sigma^2\right)
$$</code></p>

<p>其概率密度函数为：</p>

<p><code>$$
f \left(x\right) = \dfrac{1}{\sigma \sqrt{2 \pi}} e^{- \dfrac{\left(x - \mu\right)^2}{2 \sigma^2}}
$$</code></p>

<figure>
  <img data-src="/images/cn/2020-06-06-bayesian-optimization/univariate-gaussian-distribution.png" class="lazyload"/>
  <figcaption><p class="figcaption">图片来源：<a href="https://zh.wikipedia.org/wiki/正态分布" rel="noreferrer" target="_blank">https://zh.wikipedia.org/wiki/正态分布</a></p></figcaption>
</figure>

<h3 id="二元高斯分布">二元高斯分布</h3>

<p>若随机变量 <code>$X, Y$</code> 服从均值为 <code>$\mu = \left(\mu_X, \mu_Y\right)^{\top}$</code>，方差为 <code>$\mu = \left(\sigma_X, \sigma_Y\right)^{\top}$</code> 的高斯分布，则记为：</p>

<p><code>$$
\left(X, Y\right) \sim \mathcal{N} \left(\mu, \sigma\right)
$$</code></p>

<p>其概率密度函数为：</p>

<p><code>$$
f(x, y)=\frac{1}{2 \pi \sigma_{X} \sigma_{Y} \sqrt{1-\rho^{2}}} e^{-\dfrac{1}{2\left(1-\rho^{2}\right)}\left[\dfrac{\left(x-\mu_{X}\right)^{2}}{\sigma_{X}^{2}}+\dfrac{\left(y-\mu_{Y}\right)^{2}}{\sigma_{Y}^{2}}-\dfrac{2 \rho\left(x-\mu_{X}\right)\left(y-\mu_{X}\right)}{\sigma_{X} \sigma_{Y}}\right]}
$$</code></p>

<p>其中，<code>$\rho$</code> 是 <code>$X$</code> 和 <code>$Y$</code> 之间的相关系数，<code>$\sigma_X &gt; 0$</code> 且 <code>$\sigma_Y &gt; 0$</code>。</p>

<figure>
  <img data-src="/images/cn/2020-06-06-bayesian-optimization/bivariate-gaussian-distribution.png" class="lazyload"/>
  <figcaption><p class="figcaption">图片来源：Bayesian tracking of multiple point targets using expectation maximization</p></figcaption>
</figure>

<h3 id="多元高斯分布">多元高斯分布</h3>

<p>若 <code>$K$</code> 维随机向量 <code>$X = \left[X_1, \cdots, X_K\right]^{\top}$</code> 服从多元高斯分布，则必须满足如下三个等价条件：</p>

<ol>
<li>任何线性组合 <code>$Y = a_1 X_1 + \cdots a_K X_K$</code> 均服从高斯分布。</li>
<li>存在随机向量 <code>$Z = \left[Z_1, \cdots, Z_L\right]^{\top}$</code>（每个元素服从独立标准高斯分布），向量 <code>$\mu = \left[\mu_1, \cdots, \mu_K\right]^{\top}$</code> 以及 <code>$K \times L$</code> 的矩阵 <code>$A$</code>，满足 <code>$X = A Z + \mu$</code>。</li>
<li>存在 <code>$\mu$</code> 和一个对称半正定矩阵 <code>$\Sigma$</code> 满足 <code>$X$</code> 的特征函数 <code>$\phi_X \left(u; \mu, \Sigma\right) = \exp \left(i \mu^{\top} u - \dfrac{1}{2} u^{\top} \Sigma u\right)$</code></li>
</ol>

<p>如果 <code>$\Sigma$</code> 是非奇异的，则概率密度函数为：</p>

<p><code>$$
f \left(x_1, \cdots, x_k\right) = \dfrac{1}{\sqrt{\left(2 \pi\right)^k \lvert\Sigma\rvert}} e^{- \dfrac{1}{2} \left(x - \mu\right)^{\top} \Sigma^{-1} \left(x - \mu\right)}
$$</code></p>

<p>其中 <code>$\lvert\Sigma\rvert$</code> 表示协方差矩阵的行列式。</p>

<h3 id="边缘化和条件化">边缘化和条件化</h3>

<p>高斯分布具有一个优秀的代数性质，即在边缘化和条件化下是闭合的，也就是说从这些操作中获取的结果分布也是高斯的。<strong>边缘化（Marginalization）</strong>和<strong>条件化（Conditioning）</strong>都作用于原始分布的子集上：</p>

<p><code>$$
P_{X, Y}=\left[\begin{array}{l}
X \\
Y
\end{array}\right] \sim \mathcal{N}(\mu, \Sigma)=\mathcal{N}\left(\left[\begin{array}{l}
\mu_{X} \\
\mu_{Y}
\end{array}\right],\left[\begin{array}{l}
\Sigma_{X X} \Sigma_{X Y} \\
\Sigma_{Y X} \Sigma_{Y Y}
\end{array}\right]\right)
$$</code></p>

<p>其中，<code>$X$</code> 和 <code>$Y$</code> 表示原始随机变量的子集。</p>

<p>对于随机向量 <code>$X$</code> 和 <code>$Y$</code> 的高斯概率分布 <code>$P \left(X, Y\right)$</code>，其边缘概率分布为：</p>

<p><code>$$
\begin{array}{l}
X \sim \mathcal{N}\left(\mu_{X}, \Sigma_{X X}\right) \\
Y \sim \mathcal{N}\left(\mu_{Y}, \Sigma_{Y Y}\right)
\end{array}
$$</code></p>

<p><code>$X$</code> 和 <code>$Y$</code> 两个子集各自只依赖于 <code>$\mu$</code> 和 <code>$\Sigma$</code> 中它们对应的值。因此从高斯分布中边缘化一个随机变量仅需从 <code>$\mu$</code> 和 <code>$\Sigma$</code> 中舍弃相应的变量即可：</p>

<p><code>$$
p_{X}(x)=\int_{y} p_{X, Y}(x, y) d y=\int_{y} p_{X | Y}(x | y) p_{Y}(y) d y
$$</code></p>

<p>条件化可以用于得到一个变量在另一个变量条件下的概率分布：</p>

<p><code>$$
\begin{array}{l}
X | Y \sim \mathcal{N}\left(\mu_{X}+\Sigma_{X Y} \Sigma_{Y Y}^{-1}\left(Y-\mu_{Y}\right), \Sigma_{X X}-\Sigma_{X Y} \Sigma_{Y Y}^{-1} \Sigma_{Y X}\right) \\
Y | X \sim \mathcal{N}\left(\mu_{Y}+\Sigma_{Y X} \Sigma_{X X}^{-1}\left(X-\mu_{X}\right), \Sigma_{Y Y}-\Sigma_{Y X} \Sigma_{X X}^{-1} \Sigma_{X Y}\right)
\end{array}
$$</code></p>

<p>需要注意新的均值仅依赖于作为条件的变量，协方差矩阵和这个变量无关。</p>

<p>边缘化可以理解为在高斯分布的一个维度上的累加，条件化可以理解为在多元分布上切一刀从而获得一个维数更少的高斯分布，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-06-06-bayesian-optimization/marginalization-and-conditioning.png" class="lazyload"/>
  
</figure>

<h2 id="高斯过程">高斯过程</h2>

<p><strong>高斯过程（Gaussian Process）</strong>是观测值出现在一个连续域（例如时间或空间）的随机过程。在高斯过程中，连续输入空间中每个点都是与一个正态分布的随机变量相关联。此外，这些随机变量的每个有限集合都有一个多元正态分布，换句话说它们的任意有限线性组合是一个正态分布。高斯过程的分布是所有那些（无限多个）随机变量的联合分布，正因如此，它是连续域（例如时间或空间）上函数的分布。</p>

<p>简单而言，高斯过程即为一系列随机变量，这些随机变量的任意有限集合均为一个多元高斯分布。从<strong>一元高斯分布</strong>到<strong>多元高斯分布</strong>相当于增加了空间维度，从<strong>高斯分布</strong>到<strong>高斯过程</strong>相当于引入了时间维度。一个高斯过程可以被均值函数 <code>$m \left(x\right)$</code> 和协方差函数 <code>$K \left(x, x'\right)$</code> 共同唯一确定：</p>

<p><code>$$
\begin{aligned}
m(x) &amp;=\mathbb{E}[f(x)] \\
K\left(x, x'\right) &amp;=\mathbb{E}\left[(f(x)-m(x))\left(f\left(x^{\prime}\right)-m\left(x^{\prime}\right)\right)\right]
\end{aligned}
$$</code></p>

<p>则高斯过程可以表示为：</p>

<p><code>$$
f \left(x\right) \sim \mathcal{GP} \left(m \left(x\right), K \left(x, x'\right)\right)
$$</code></p>

<p>均值函数决定了样本出现的整体位置，如果为零则表示以 <code>$y = 0$</code> 为基准线。协方差函数描述了不同点之间的关系，从而可以利用输入的训练数据预测未知点的值。常用的协方差函数有：</p>

<ul>
<li>常数：<code>$K_c \left(x, x'\right) = C$</code></li>
<li>线性：<code>$K_L \left(x, x'\right) = x^{\top} x'$</code></li>
<li>高斯噪声：<code>$K_{GN} \left(x, x'\right) = \sigma^2 \delta_{x, x'}$</code></li>
<li>指数平方：<code>$K_{\mathrm{SE}}\left(x, x^{\prime}\right)=\exp \left(-\dfrac{|d|^{2}}{2 \ell^{2}}\right)$</code></li>
<li>Ornstein-Uhlenbeck：<code>$K_{\mathrm{OU}}\left(x, x^{\prime}\right)=\exp \left(-\dfrac{|d|}{\ell}\right)$</code></li>
<li>Matérn：<code>$K_{\text {Matern }}\left(x, x^{\prime}\right)=\dfrac{2^{1-\nu}}{\Gamma(\nu)}\left(\dfrac{\sqrt{2 \nu}|d|}{\ell}\right)^{\nu} K_{\nu}\left(\dfrac{\sqrt{2 \nu}|d|}{\ell}\right)$</code></li>
<li>周期：<code>$K_{\mathrm{P}}\left(x, x^{\prime}\right)=\exp \left(-\dfrac{2 \sin ^{2}\left(\dfrac{d}{2}\right)}{\ell^{2}}\right)$</code></li>
<li>有理平方：<code>$K_{\mathrm{RQ}}\left(x, x^{\prime}\right)=\left(1+|d|^{2}\right)^{-\alpha}, \quad \alpha \geq 0$</code></li>
</ul>

<h2 id="高斯过程回归">高斯过程回归</h2>

<p>回归任务的目标是给定一个输入变量 <code>$x \in \mathbb{R}^D$</code> 预测一个或多个连续目标变量 <code>$y$</code> 的值。更确切的说，给定一个包含 <code>$N$</code> 个观测值的训练集 <code>$\mathbf{X} = \left\{x_n\right\}^N_1$</code> 和对应的目标值 <code>$\mathbf{Y} = \left\{y_n\right\}^N_1$</code>，回归的目标是对于一个新的 <code>$x$</code> 预测对应的 <code>$y$</code>。目标值和观测值之间通过一个映射进行关联：</p>

<p><code>$$
f: X \to Y
$$</code></p>

<p>在贝叶斯模型中，我们通过观测数据 <code>$\mathcal{D} = \left\{\left(\mathbf{x}_n, \mathbf{y}_n\right)\right\}^N_{n=1}$</code> 更新先验分布 <code>$P \left(\mathbf{\Theta}\right)$</code>。通过贝叶斯公式我们可以利用先验概率 <code>$P \left(\mathbf{\Theta}\right)$</code> 和似然函数 <code>$P \left(\mathcal{D} | \mathbf{\Theta}\right)$</code> 推导出后验概率：</p>

<p><code>$$
p\left(\mathbf{\Theta} | \mathcal{D}\right)=\frac{p\left(\mathcal{D} | \mathbf{\Theta}\right) p\left(\mathbf{\Theta}\right)}{p\left(\mathcal{D}\right)}
$$</code></p>

<p>其中 <code>$p\left(\mathcal{D}\right)$</code> 为边际似然。在贝叶斯回归中我们不仅希望获得未知输入对应的预测值 <code>$\mathbf{y}_*$</code> ，还希望知道预测的不确定性。因此我们需要利用联合分布和边缘化模型参数 <code>$\mathbf{\Theta}$</code> 来构造预测分布：</p>

<p><code>$$
p\left(\mathbf{y}_{*} | \mathbf{x}_{*}, \mathcal{D}\right)=\int p\left(\mathbf{y}_{*}, \mathbf{\Theta} | \mathbf{x}_{*}, \mathcal{D}\right) \mathrm{d} \Theta=\int p\left(\mathbf{y}_{*} | \mathbf{x}_{*}, \mathbf{\Theta}, \mathcal{D}\right) p(\mathbf{\Theta} | \mathcal{D}) \mathrm{d} \mathbf{\Theta}
$$</code></p>

<p>通常情况下，由于积分形式 <code>$p \left(\Theta | \mathcal{D}\right)$</code> 不具有解析可解性（Analytically Tractable）：</p>

<p><code>$$
p\left(\mathcal{D}\right)=\int p\left(\mathcal{D} | \mathbf{\Theta}\right) p\left(\mathbf{\Theta}\right) d \Theta
$$</code></p>

<p>但在高斯似然和高斯过程先验的前提下，后验采用函数的高斯过程的形式，同时是解析可解的。</p>

<p>对于高斯过程回归，我们构建一个贝叶斯模型，首先定义函数输出的先验为一个高斯过程：</p>

<p><code>$$
p \left(f | \mathbf{X}, \theta\right) = \mathcal{N} \left(\mathbf{0}, K \left(\mathbf{X}, \mathbf{X}\right)\right)
$$</code></p>

<p>其中 <code>$K \left(\cdot, \cdot\right)$</code> 为协方差函数，<code>$\theta$</code> 为过程的超参数。假设数据已经变换为零均值，因此我们不需要在先验中设置均值函数，则令似然形式如下：</p>

<p><code>$$
p \left(\mathbf{Y} | f\right) \sim \mathcal{N} \left(f, \sigma^2_n \mathbf{I}\right)
$$</code></p>

<p>假设观测值为独立同分布的高斯噪音的累加，则整个模型的联合分布为：</p>

<p><code>$$
p \left(\mathbf{Y} , f | \mathbf{X}, \theta\right) = p \left(\mathbf{Y} | f\right) p \left(f | \mathbf{X}, \theta\right)
$$</code></p>

<p>虽然我们并不关心变量 <code>$f$</code>，但由于我们需要对不确定性进行建模，我们仍需考虑 <code>$\mathbf{Y}$</code> 和 <code>$f$</code> 以及 <code>$f$</code> 和 <code>$\mathbf{X}$</code> 之间的关系。高斯过程作为一个非参数模型，其先验分布构建于映射 <code>$f$</code> 之上，<code>$f$</code> 仅依赖于核函数的超参数 <code>$\theta$</code>，且这些超参数可以通过数据进行估计。我们可以将超参数作为先验，即：</p>

<p><code>$$
p \left(\mathbf{Y} , f | \mathbf{X}, \theta\right) = p \left(\mathbf{Y} | f\right) p \left(f | \mathbf{X}, \theta\right) p \left(\theta\right)
$$</code></p>

<p>然后进行贝叶斯推断和模型选择，但是通常情况下这是不可解的。David MacKay 引入了一个利用最优化边际似然来估计贝叶斯平均的框架，即计算如下积分：</p>

<p><code>$$
p \left(\mathbf{Y} | \mathbf{X}, \theta\right) = \int p \left(\mathbf{Y} | f\right) p \left(f | \mathbf{X}, \theta\right) df
$$</code></p>

<p>其中，高斯似然 <code>$p \left(\mathbf{Y} | f\right)$</code> 表示模型拟合数据的程度，<code>$p \left(f | \mathbf{X}, \theta\right)$</code> 为高斯过程先验。经过边缘化后，<code>$\mathbf{Y}$</code> 不在依赖于 <code>$f$</code> 而仅依赖于 <code>$\theta$</code>。</p>

<p>假设采用零均值函数，对于一个高斯过程先验，我们仅需指定一个协方差函数。以指数平方协方差函数为例，选择一系列测试输入点 <code>$X_*$</code>，利用协方差矩阵和测试输入点可以生成一个高斯向量：</p>

<p><code>$$
\mathbf{f}_* \sim \mathcal{N} \left(\mathbf{0}, K \left(X_*, X_*\right)\right)
$$</code></p>

<p>从高斯先验中进行采样，我们首先需要利用标准正态来表示多元正态：</p>

<p><code>$$
\mathbf{f}_* \sim \mu + \mathbf{B} \mathcal{N} \left(0, \mathbf{I}\right)
$$</code></p>

<p>其中，<code>$\mathbf{BB}^{\top} = K \left(X_*, X_*\right)$</code>，<code>$\mathbf{B}$</code> 本质上是协方差矩阵的平方根，可以通过 <a href="https://zh.wikipedia.org/wiki/Cholesky分解" rel="noreferrer" target="_blank">Cholesky 分解</a>获得。</p>

<figure>
  <img data-src="/images/cn/2020-06-06-bayesian-optimization/gp-prior.png" class="lazyload"/>
  
</figure>

<p>上图（左）为从高斯先验中采样的 10 个序列，上图（右）为先验的协方差。如果输入点 <code>$x_n$</code> 和 <code>$x_m$</code> 接近，则对应的 <code>$f \left(x_n\right)$</code> 和 <code>$f \left(x_m\right)$</code> 相比于不接近的点是强相关的。</p>

<p>我们关注的并不是这些随机的函数，而是如何将训练数据中的信息同先验进行合并。假设观测数据为 <code>$\left\{\left(\mathbf{x}_{i}, f_{i}\right) | i=1, \ldots, n\right\}$</code>，则训练目标 <code>$\mathbf{f}$</code> 和测试目标 <code>$\mathbf{f}_*$</code> 之间的联合分布为：</p>

<p><code>$$
\left[\begin{array}{l}
\mathbf{f} \\
\mathbf{f}_{*}
\end{array}\right] \sim \mathcal{N}\left(\mathbf{0},\left[\begin{array}{ll}
K(X, X) &amp; K\left(X, X_{*}\right) \\
K\left(X_{*}, X\right) &amp; K\left(X_{*}, X_{*}\right)
\end{array}\right]\right)
$$</code></p>

<p>根据观测值对联合高斯先验分布进行条件化处理可以得到高斯过程回归的关键预测方程：</p>

<p><code>$$
\mathbf{f}_{*} | X, X_{*}, \mathbf{f} \sim \mathcal{N}\left(\overline{\mathbf{f}}_{*}, \operatorname{cov}\left(\mathbf{f}_{*}\right)\right)
$$</code></p>

<p>其中</p>

<p><code>$$
\begin{aligned}
\overline{\mathbf{f}}_{*} &amp; \triangleq \mathbb{E}\left[\mathbf{f}_{*} | X, X_{*}, \mathbf{f}\right]=K\left(X_{*}, X\right) K(X, X)^{-1} \mathbf{f} \\
\operatorname{cov}\left(\mathbf{f}_{*}\right) &amp;=K\left(X_{*}, X_{*}\right)-K\left(X_{*}, X\right) K(X, X)^{-1} K\left(X, X_{*}\right)
\end{aligned}
$$</code></p>

<p>函数值可以通过对联合后验分布采样获得。</p>

<p>我们以三角函数作为给定的函数，并随机采样一些训练数据 <code>$\left\{\left(\mathbf{x}_{i}, f_{i}\right) | i=1, \ldots, n\right\}$</code>，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-06-06-bayesian-optimization/underlying-functions-and-training-points.png" class="lazyload"/>
  
</figure>

<p>我们希望将训练数据和高斯过程先验进行合并得到联合后验分布，我们可以通过在观测值上条件化联合高斯先验分布，预测的均值和协方差为：</p>

<p><code>$$
\begin{aligned}
\overline{\mathbf{f}}_{*} &amp;=K\left(X_{*}, X\right) K(X, X)^{-1} \mathbf{f} \\
\operatorname{cov}\left(\mathbf{f}_{*}\right) &amp;=K\left(X_{*}, X_{*}\right)-K\left(X_{*}, X\right) K(X, X)^{-1} K\left(X, X_{*}\right)
\end{aligned}
$$</code></p>

<p><a href="http://www.gaussianprocess.org/gpml/" rel="noreferrer" target="_blank">Rasmussen 和 Williams</a> 给出了一个实现高斯过程回归的实用方法：</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{高斯过程回归算法}
\begin{algorithmic}
\REQUIRE \\
    输入 $\mathbf{X}$ \\
    目标 $\mathbf{y}$ \\
    协方差函数 $k$ \\
    噪音水平 $\sigma^2_n$ \\
    测试输入 $\mathbf{x}_*$
\ENSURE \\
    均值 $\bar{f}_*$ \\
    方差 $\mathbb{V}\left[f_{*}\right]$
\FUNCTION{GaussianProcessRegression}{$\mathbf{X}, \mathbf{y}, k, \sigma^2_n, \mathbf{x}_*$}
\STATE $L \gets \text{cholesky} \left(K + \sigma^2_n I\right)$
\STATE $\alpha \gets L^{\top} \setminus \left(L \setminus \mathbf{y}\right)$
\STATE $\bar{f}_* \gets \mathbf{k}^{\top}_* \alpha$
\STATE $\mathbf{v} \gets L \setminus \mathbf{k}_*$
\STATE $\mathbb{V}\left[f_{*}\right] \gets k \left(\mathbf{x}_*, \mathbf{x}_*\right) - \mathbf{v}^{\top} \mathbf{v}$
\RETURN $\bar{f}_*, \mathbb{V}\left[f_{*}\right]$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>高斯过程后验和采样的序列如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-06-06-bayesian-optimization/gp-posterior.png" class="lazyload"/>
  
</figure>

<p>先验的协方差矩阵和后验的协方差矩阵可视化如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-06-06-bayesian-optimization/prior-posterior-convariance.png" class="lazyload"/>
  
</figure>

<p>本小结代码请参见<a href="https://github.com/leovan/leovan.me/blob/master/scripts/cn/2020-06-06-bayesian-optimization/gaussian-process-regression.py" rel="noreferrer" target="_blank">这里</a>。</p>

<h2 id="贝叶斯优化">贝叶斯优化</h2>

<h3 id="主动学习">主动学习</h3>

<p>在很多机器学习问题中，数据标注往往需要耗费很大成本。<strong>主动学习（Active Learning）</strong>在最大化模型准确率时最小化标注成本，例如对不确定性最高的数据进行标注。由于我们仅知道少量数据点，因此我们需要一个代理模型（Surrogate Model）来建模真正的模型。高斯过程因其灵活性和具有估计不确定性估计的特性不失为一个常用的代理模型。</p>

<p>在估计 <code>$f \left(x\right)$</code> 的过程中，我们希望最小化评估的次数，因此我们可以通过主动学习来“智能”地选择下一个评估的数据点。通过不断的选择具有最高不确定性的数据点来获得 <code>$f \left(x\right)$</code> 更准确的估计，直至收敛或达到停止条件。下图展示了利用主动学习估计真实数据分布的过程：</p>


  
  <link rel="stylesheet" href="/css/figure-slider.css"/>


<div class="figure-slider">
  <div class="figure-slider-parameters">
    <span class="base-url">/images/cn/2020-06-06-bayesian-optimization/</span>
    <span class="image-filename-prefix">active-gp-</span>
    <span class="image-format">png</span>
    <span class="milliseconds">300</span>
  </div>
  <div class="figure-slider-image-container">
    <img class="figure-slider-image" src='/images/cn/2020-06-06-bayesian-optimization/active-gp-0.png'>
  </div>
  <div class="figure-slider-controls">
    <div class="figure-slider-buttons">
      <button class="figure-slider-button-previous">
        <span class="mdi mdi-skip-previous"></span>
      </button>
    </div>
    <div class="figure-slider-scroll-bar-container">
      <input class="figure-slider-scroll-bar" type="range" min='0' max='9' value='0'>
    </div>
    <div class="figure-slider-buttons">
      <button class="figure-slider-button-next">
        <span class="mdi mdi-skip-next"></span>
      </button>
    </div>
    <div class="figure-slider-buttons">
      <button class="figure-slider-button-play-pause figure-slider-button-play">
        <span class="mdi mdi-play"></span>
      </button>
    </div>
  </div>
</div>


<h3 id="贝叶斯优化问题">贝叶斯优化问题</h3>

<p>贝叶斯优化的核心问题是：基于现有的已知情况，如果选择下一步评估的数据点？在主动学习中我们选择不确定性最大的点，但在贝叶斯优化中我们需要在探索不确定性区域（探索）和关注已知具有较优目标值的区域之间进行权衡（开发）。这种评价的依据称之为<strong>采集函数（Acquisition Functions）</strong>，采集函数通过当前模型启发式的评估是否选择一个数据点。</p>

<p>贝叶斯优化的目标是找到一个函数 <code>$f: \mathbb{R}^d \mapsto \mathbb{R}$</code> 最大值（或最小值）对应的位置 <code>$x \in \mathbb{R}^d$</code>。为了解决这个问题，我们遵循如下算法：</p>

<ol>
<li>选择一个代理模型用于建模真实函数 <code>$f$</code> 和定义其先验。</li>
<li>给定观测集合，利用贝叶斯公式获取后验。</li>
<li>利用采集函数 <code>$\alpha \left(x\right)$</code> 确性下一个采样点 <code>$x_t = \arg\max_x \alpha \left(x\right)$</code>。</li>
<li>将采样的点加入观测集合，重复步骤 2 直至收敛或达到停止条件。</li>
</ol>

<h3 id="采集函数">采集函数</h3>

<ul>
<li>Probability of Improvement (PI)</li>
</ul>

<p>Probability of Improvement (PI) 采集函数会选择具有最大可能性提高当前最大的 <code>$f \left(x^{+}\right)$</code> 值的点作为下一个查询点，即：</p>

<p><code>$$
x_{t+1} = \arg\max \left(\alpha_{PI} \left(x\right)\right) = \arg\max \left(P \left(f \left(x\right)\right) \geq \left(f \left(x^{+}\right) + \epsilon\right)\right)
$$</code></p>

<p>其中，<code>$P \left(\cdot\right)$</code> 表示概率，<code>$\epsilon$</code> 为一个较小的正数，<code>$x^{+} = \arg\max_{x_i \in x_{1:t}} f \left(x_i\right)$</code>，<code>$x_i$</code> 为第 <code>$i$</code> 步查询点的位置。如果采用高斯过程作为代理模型，上式则转变为：</p>

<p><code>$$
x_{t+1} = \arg\max_x \Phi \left(\dfrac{\mu_t \left(x\right) - f \left(x^{+}\right) - \epsilon}{\sigma_t \left(x\right)}\right)
$$</code></p>

<p>其中，<code>$\Phi \left(\cdot\right)$</code> 表示标准正态分布累积分布函数。PI 利用 <code>$\epsilon$</code> 来权衡探索和开发，增加 <code>$\epsilon$</code> 的值会更加倾向进行探索。</p>

<ul>
<li>Expected Improvement (EI)</li>
</ul>

<p>PI 仅关注了有多大的可能性能够提高，而没有关注能够提高多少。Expected Improvement (EI) 则会选择具有最大期望提高的点作为下一个查询点，即：</p>

<p><code>$$
x_{t+1} = \arg\min_x \mathbb{E} \left(\left\|h_{t+1} \left(x\right) - f \left(x^*\right)\right\| | \mathcal{D}_t\right)
$$</code></p>

<p>其中，<code>$f$</code> 为真实函数，<code>$h_{t+1}$</code> 为代理模型在 <code>$t+1$</code> 步的后验均值，<code>$\mathcal{D}_t = \left\{\left(x_i, f\left(x_i\right)\right)\right\}, \forall x \in x_{1:t}$</code> 为训练数据，<code>$x^*$</code> 为 <code>$f$</code> 取得最大值的真实位置。</p>

<p>上式中我们希望选择能够最小化与最大目标值之间距离的点，由于我们并不知道真实函数 <code>$f$</code>，Mockus <sup class="footnote-ref" id="fnref:mockus1991bayesian"><a href="#fn:mockus1991bayesian">1</a></sup> 提出了一种解决办法：</p>

<p><code>$$
x_{t+1} = \arg\max_x \mathbb{E} \left(\max \left\{0, h_{t+1} \left(x\right) - f \left(x^{+}\right)\right\} | \mathcal{D}_t\right)
$$</code></p>

<p>其中，<code>$f \left(x^{+}\right)$</code> 为到目前为止遇见的最大函数值，如果采用高斯过程作为代理模型，上式则转变为：</p>

<p><code>$$
\begin{aligned}
EI(x) &amp;= \left\{\begin{array}{ll}
\left(\mu_{t}(x)-f\left(x^{+}\right)-\epsilon\right) \Phi(Z)+\sigma_{t}(x) \phi(Z), &amp; \text { if } \sigma_{t}(x)&gt;0 \\
0 &amp; \text { if } \sigma_{t}(x)=0
\end{array}\right. \\
Z &amp;= \frac{\mu_{t}(x)-f\left(x^{+}\right)-\epsilon}{\sigma_{t}(x)}
\end{aligned}
$$</code></p>

<p>其中 <code>$\Phi \left(\cdot\right)$</code> 表示标准正态分布累积分布函数，<code>$\phi \left(\cdot\right)$</code> 表示标准正态分布概率密度函数。类似 PI，EI 也可以利用 <code>$\epsilon$</code> 来权衡探索和开发，增加 <code>$\epsilon$</code> 的值会更加倾向进行探索。</p>

<ul>
<li>对比和其他采集函数</li>
</ul>

<figure>
  <img data-src="/images/cn/2020-06-06-bayesian-optimization/pi-vs-ei.svg" class="lazyload"/>
  
</figure>

<p>上图展示了在仅包含一个训练观测数据 <code>$\left(0.5, f \left(0.5\right)\right)$</code> 情况下不同点的采集函数值。可以看出 <code>$\alpha_{EI}$</code> 和 <code>$\alpha_{PI}$</code> 的最大值分别为 0.3 和 0.47。选择一个具有较小的 <code>$\alpha_{PI}$</code> 和一个较大的 <code>$\alpha_{EI}$</code> 的点可以理解为一个高的风险和高的回报。因此，当多个点具有相同的 <code>$\alpha_{EI}$</code> 时，我们应该优先选择具有较小风险（高 <code>$\alpha_{PI}$</code>）的点，类似的，当多个点具有相同的 <code>$\alpha_{PI}$</code> 时，我们应该优先选择具有较大回报（高 <code>$\alpha_{EI}$</code>）的点。</p>

<p>其他采集函数还有 Thompson Sampling <sup class="footnote-ref" id="fnref:thompson1993likelihood"><a href="#fn:thompson1993likelihood">2</a></sup>，Upper Confidence Bound (UCB)，Gaussian Process Upper Confidence Bound (GP-UCB) <sup class="footnote-ref" id="fnref:auer2002using"><a href="#fn:auer2002using">3</a></sup>，Entropy Search <sup class="footnote-ref" id="fnref:hennig2012entropy"><a href="#fn:hennig2012entropy">4</a></sup>，Predictive Entropy Search <sup class="footnote-ref" id="fnref:hern-ndez2014predictive"><a href="#fn:hern-ndez2014predictive">5</a></sup> 等，细节请参见原始论文或 A Tutorial on Bayesian Optimization <sup class="footnote-ref" id="fnref:frazier2018tutorial"><a href="#fn:frazier2018tutorial">6</a></sup>。</p>

<h2 id="开放资源">开放资源</h2>

<ul>
<li><a href="https://github.com/scikit-optimize/scikit-optimize" rel="noreferrer" target="_blank">scikit-optimize/scikit-optimize</a></li>
<li><a href="https://github.com/hyperopt/hyperopt" rel="noreferrer" target="_blank">hyperopt/hyperopt</a></li>
<li><a href="https://github.com/automl/SMAC3" rel="noreferrer" target="_blank">automl/SMAC3</a></li>
<li><a href="https://github.com/fmfn/BayesianOptimization" rel="noreferrer" target="_blank">fmfn/BayesianOptimization</a></li>
<li><a href="https://github.com/pytorch/botorch" rel="noreferrer" target="_blank">pytorch/botorch</a></li>
<li><a href="https://github.com/GPflow/GPflowOpt" rel="noreferrer" target="_blank">GPflow/GPflowOpt</a></li>
<li><a href="https://github.com/keras-team/keras-tuner" rel="noreferrer" target="_blank">keras-team/keras-tuner</a></li>
<li><a href="https://github.com/tobegit3hub/advisor" rel="noreferrer" target="_blank">tobegit3hub/advisor</a></li>
</ul>
<div class="footnotes">

<hr />

<ol>
<li id="fn:mockus1991bayesian">Mockus, J. B., &amp; Mockus, L. J. (1991). Bayesian approach to global optimization and application to multiobjective and constrained problems. <em>Journal of Optimization Theory and Applications, 70</em>(1), 157-172.
 <a class="footnote-return" href="#fnref:mockus1991bayesian">↩</a></li>
<li id="fn:thompson1993likelihood">Thompson, W. R. (1933). On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. <em>Biometrika, 25</em>(<sup>3</sup>&frasl;<sub>4</sub>), 285-294.
 <a class="footnote-return" href="#fnref:thompson1993likelihood">↩</a></li>
<li id="fn:auer2002using">Auer, P. (2002). Using confidence bounds for exploitation-exploration trade-offs. <em>Journal of Machine Learning Research, 3</em>(Nov), 397-422.
 <a class="footnote-return" href="#fnref:auer2002using">↩</a></li>
<li id="fn:hennig2012entropy">Hennig, P., &amp; Schuler, C. J. (2012). Entropy search for information-efficient global optimization. <em>Journal of Machine Learning Research, 13</em>(Jun), 1809-1837.
 <a class="footnote-return" href="#fnref:hennig2012entropy">↩</a></li>
<li id="fn:hern-ndez2014predictive">Hernández-Lobato, J. M., Hoffman, M. W., &amp; Ghahramani, Z. (2014). Predictive entropy search for efficient global optimization of black-box functions. <em>In Advances in neural information processing systems</em> (pp. 918-926).
 <a class="footnote-return" href="#fnref:hern-ndez2014predictive">↩</a></li>
<li id="fn:frazier2018tutorial">Frazier, P. I. (2018). A tutorial on bayesian optimization. <em>arXiv preprint arXiv:1807.02811</em>.
 <a class="footnote-return" href="#fnref:frazier2018tutorial">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>马尔可夫决策过程 (Markov Decision Process)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/05/markov-decision-process/</link>
      <pubDate>Sat, 23 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/05/markov-decision-process/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文为<a href="/categories/强化学习/">《强化学习系列》</a>文章<br />
本文内容主要参考自：<br />
1.《强化学习》<sup class="footnote-ref" id="fnref:sutton2018reinforcement"><a href="#fn:sutton2018reinforcement">1</a></sup><br />
2. CS234: Reinforcement Learning <sup class="footnote-ref" id="fnref:stanford-cs234"><a href="#fn:stanford-cs234">2</a></sup><br />
3. UCL Course on RL <sup class="footnote-ref" id="fnref:ucl-course-on-rl"><a href="#fn:ucl-course-on-rl">3</a></sup></p>
</blockquote>

<h2 id="马尔可夫模型">马尔可夫模型</h2>

<p>马尔可夫模型是一种用于序列数据建模的随机模型，其假设未来的状态仅取决于当前的状态，即：</p>

<p><code>$$
\mathbb{P} \left[S_{t+1} | S_t\right] = \mathbb{P} \left[S_{t+1} | S_1, \cdots, S_t\right]
$$</code></p>

<p>也就是认为当前状态捕获了历史中所有相关的信息。根据系统状态是否完全可被观测以及系统是自动的还是受控的，可以将马尔可夫模型分为 4 种，如下表所示：</p>

<table>
<thead>
<tr>
<th></th>
<th>状态状态完全可被观测</th>
<th>系统状态不是完全可被观测</th>
</tr>
</thead>

<tbody>
<tr>
<td><strong>状态是自动的</strong></td>
<td>马尔可夫链（MC）</td>
<td>隐马尔可夫模型（HMM）</td>
</tr>

<tr>
<td><strong>系统是受控的</strong></td>
<td>马尔可夫决策过程（MDP）</td>
<td>部分可观测马尔可夫决策过程（POMDP）</td>
</tr>
</tbody>
</table>

<p>马尔可夫链（Markov Chain，MC）为从一个状态到另一个状态转换的随机过程，当马尔可夫链的状态只能部分被观测到时，即为<a href="/cn/2020/05/hmm-crf-and-sequence-labeling/">隐马尔可夫模型（Hidden Markov Model，HMM）</a>，也就是说观测值与系统状态有关，但通常不足以精确地确定状态。马尔可夫决策过程（Markov Decision Process，MDP）也是马尔可夫链，但其状态转移取决于当前状态和采取的动作，通常一个马尔可夫决策过程用于计算依据期望回报最大化某些效用的行动策略。部分可观测马尔可夫决策过程（Partially Observable Markov Decision Process，POMDP）即为系统状态仅部分可见情况下的马尔可夫决策过程。</p>

<h2 id="马尔可夫过程">马尔可夫过程</h2>

<p>对于一个马尔可夫状态 <code>$s$</code> 和一个后继状态 <code>$s'$</code>，状态转移概率定义为：</p>

<p><code>$$
\mathcal{P}_{ss'} = \mathbb{P} \left[S_t = s' | S_{t-1} = s\right]
$$</code></p>

<p><strong>状态概率矩阵</strong> <code>$\mathcal{P}$</code> 定义了从所有状态 <code>$s$</code> 到后继状态 <code>$s'$</code> 的转移概率：</p>

<p><code>$$
\mathcal{P} = \left[\begin{array}{ccc}
\mathcal{P}_{11} &amp; \cdots &amp; \mathcal{P}_{1 n} \\
\vdots &amp; &amp; \\
\mathcal{P}_{n 1} &amp; \cdots &amp; \mathcal{P}_{n n}
\end{array}\right]
$$</code></p>

<p>其中每一行的加和为 1。</p>

<p><strong>马尔可夫过程（马尔可夫链）</strong>是一个无记忆的随机过程，一个马尔可夫过程可以定义为 <code>$\langle \mathcal{S}, \mathcal{P} \rangle$</code>，其中 <code>$\mathcal{S}$</code> 是一个有限状态集合，<code>$\mathcal{P}_{ss'} = \mathbb{P} \left[S_t = s' | S_{t-1} = s\right]$</code>，<code>$\mathcal{P}$</code> 为状态转移概率矩阵。以一个学生的日常生活为例，Class <code>$i$</code> 表示第 <code>$i$</code> 门课程，Facebook 表示在 Facebook 上进行社交，Pub 表示去酒吧，Pass 表示通过考试，Sleep 表示睡觉，这个马尔可夫过程如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/student-markov-chain.png" class="lazyload"/>
  
</figure>

<p>从而可以产生多种不同的序列，例如：</p>

<pre><code>C1 -&gt; C2 -&gt; C3 -&gt; Pass -&gt; Sleep
C1 -&gt; FB -&gt; FB -&gt; C1 -&gt; C2 -&gt; Sleep
C1 -&gt; C2 -&gt; C3 -&gt; Pub -&gt; C2 -&gt; C3 -&gt; Pass -&gt; Sleep
</code></pre>

<p>状态转移概率矩阵如下所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/student-markov-chain-transition-matrix.png" class="lazyload"/>
  
</figure>

<p>据此我们可以定义<strong>马尔可夫奖励过程（Markov Reward Process，MRP）</strong>为 <code>$\langle \mathcal{S, P, R}, \gamma \rangle$</code>，其中 <code>$\mathcal{S}$</code> 和 <code>$\mathcal{P}$</code> 同马尔可夫过程定义中的参数相同，<code>$\mathcal{R}$</code> 为收益函数，<code>$\mathcal{R}_s = \mathbb{E} \left[R_t | S_{t-1} = s\right]$</code>，<code>$\gamma \in \left[0, 1\right]$</code> 为<strong>折扣率</strong>。如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/student-mrp.png" class="lazyload"/>
  
</figure>

<p><strong>期望回报</strong> <code>$G_t$</code> 定义为从时刻 <code>$t$</code> 之后的所有衰减的收益之和，即：</p>

<p><code>$$
G_t = R_{t+1} + \gamma R_{t+2} + \cdots = \sum_{k=0}^{\infty} \gamma^k R_{t+k+1}
$$</code></p>

<p>当 <code>$\gamma$</code> 接近 <code>$0$</code> 时，智能体更倾向于近期收益，当 <code>$\gamma$</code> 接近 <code>$1$</code> 时，智能体更侧重考虑长远收益。邻接时刻的收益可以按如下递归方式表示：</p>

<p><code>$$
G_t = R_{t+1} + \gamma G_{t+1}
$$</code></p>

<p>对于存在“最终时刻”的应用中，智能体和环境的交互能被自然地分成一个系列子序列，每个子序列称之为“<strong>幕（episodes）</strong>”，例如一盘游戏、一次走迷宫的过程，每幕都以一种特殊状态结束，称之为<strong>终结状态</strong>。这些幕可以被认为在同样的终结状态下结束，只是对不同的结果有不同的收益，具有这种<strong>分幕</strong>重复特性的任务称之为<strong>分幕式任务</strong>。</p>

<p>MRP 的状态价值函数 <code>$v \left(s\right)$</code> 给出了状态 <code>$s$</code> 的长期价值，定义为：</p>

<p><code>$$
\begin{aligned}
v(s) &amp;=\mathbb{E}\left[G_{t} | S_{t}=s\right] \\
&amp;=\mathbb{E}\left[R_{t+1}+\gamma R_{t+2}+\gamma^{2} R_{t+3}+\ldots | S_{t}=s\right] \\
&amp;=\mathbb{E}\left[R_{t+1}+\gamma\left(R_{t+2}+\gamma R_{t+3}+\ldots\right) | S_{t}=s\right] \\
&amp;=\mathbb{E}\left[R_{t+1}+\gamma G_{t+1} | S_{t}=s\right] \\
&amp;=\mathbb{E}\left[R_{t+1}+\gamma v\left(S_{t+1}\right) | S_{t}=s\right]
\end{aligned}
$$</code></p>

<p>价值函数可以分解为两部分：即时收益 <code>$R_{t+1}$</code> 和后继状态的折扣价值 <code>$\gamma v \left(S_{t+1}\right)$</code>。上式我们称之为<strong>贝尔曼方程（Bellman Equation）</strong>，其衡量了状态价值和后继状态价值之间的关系。</p>

<h2 id="马尔可夫决策过程">马尔可夫决策过程</h2>

<p>一个<strong>马尔可夫决策过程（Markov Decision Process，MDP）</strong>定义为包含决策的马尔可夫奖励过程 <code>$\langle\mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R}, \gamma\rangle$</code>，在这个环境中所有的状态均具有马尔可夫性。其中，<code>$\mathcal{S}$</code> 为有限的状态集合，<code>$\mathcal{A}$</code> 为有限的动作集合，<code>$\mathcal{P}$</code> 为状态转移概率矩阵，<code>$\mathcal{P}_{s s^{\prime}}^{a}=\mathbb{P}\left[S_{t+1}=s^{\prime} | S_{t}=s, A_{t}=a\right]$</code>，<code>$\mathcal{R}$</code> 为奖励函数，<code>$\mathcal{R}_{s}^{a}=\mathbb{E}\left[R_{t+1} | S_{t}=s, A_{t}=a\right]$</code>，<code>$\gamma \in \left[0, 1\right]$</code> 为折扣率。上例中的马尔可夫决策过程如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/student-mdp.png" class="lazyload"/>
  
</figure>

<p><strong>策略（Policy）</strong>定义为给定状态下动作的概率分布：</p>

<p><code>$$
\pi \left(a | s\right) = \mathbb{P} \left[A_t = a | S_t = s\right]
$$</code></p>

<p>一个策略完全确定了一个智能体的行为，同时 MDP 策略仅依赖于当前状态。给定一个 MDP <code>$\mathcal{M}=\langle\mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R}, \gamma\rangle$</code> 和一个策略 <code>$\pi$</code>，状态序列 <code>$S_1, S_2, \cdots$</code> 为一个马尔可夫过程 <code>$\langle \mathcal{S}, \mathcal{P}^{\pi} \rangle$</code>，状态和奖励序列 <code>$S_1, R_2, S_2, \cdots$</code> 为一个马尔可夫奖励过程 <code>$\left\langle\mathcal{S}, \mathcal{P}^{\pi}, \mathcal{R}^{\pi}, \gamma\right\rangle$</code>，其中</p>

<p><code>$$
\begin{aligned}
\mathcal{P}_{s s^{\prime}}^{\pi} &amp;=\sum_{a \in \mathcal{A}} \pi(a | s) \mathcal{P}_{s s^{\prime}}^{a} \\
\mathcal{R}_{s}^{\pi} &amp;=\sum_{a \in \mathcal{A}} \pi(a | s) \mathcal{R}_{s}^{a}
\end{aligned}
$$</code></p>

<p>在策略 <code>$\pi$</code> 下，状态 <code>$s$</code> 的价值函数记为 <code>$v_{\pi} \left(s\right)$</code>，即从状态 <code>$s$</code> 开始，智能体按照策略进行决策所获得的回报的概率期望值，对于 MDP 其定义为：</p>

<p><code>$$
\begin{aligned}
v_{\pi} \left(s\right) &amp;= \mathbb{E}_{\pi} \left[G_t | S_t = s\right] \\
&amp;= \mathbb{E}_{\pi} \left[\sum_{k=0}^{\infty} \gamma^k R_{t+k+1} | S_t = s\right]
\end{aligned}
$$</code></p>

<p>在策略 <code>$\pi$</code> 下，在状态 <code>$s$</code> 时采取动作 <code>$a$</code> 的价值记为 <code>$q_\pi \left(s, a\right)$</code>，即根据策略 <code>$\pi$</code>，从状态 <code>$s$</code> 开始，执行动作 <code>$a$</code> 之后，所有可能的决策序列的期望回报：</p>

<p><code>$$
\begin{aligned}
q_\pi \left(s, a\right) &amp;= \mathbb{E}_{\pi} \left[G_t | S_t = s, A_t = a\right] \\
&amp;= \mathbb{E}_{\pi} \left[\sum_{k=0}^{\infty} \gamma^k R_{t+k+1} | S_t = s, A_t = a\right]
\end{aligned}
$$</code></p>

<p>状态价值函数 <code>$v_{\pi}$</code> 和动作价值函数 <code>$q_{\pi}$</code> 都能从经验中估计得到，两者都可以分解为当前和后继两个部分：</p>

<p><code>$$
\begin{aligned}
v_{\pi}(s) &amp;= \mathbb{E}_{\pi}\left[R_{t+1}+\gamma v_{\pi}\left(S_{t+1}\right) | S_{t}=s\right] \\
q_{\pi}(s, a) &amp;= \mathbb{E}_{\pi}\left[R_{t+1}+\gamma q_{\pi}\left(S_{t+1}, A_{t+1}\right) | S_{t}=s, A_{t}=a\right]
\end{aligned}
$$</code></p>

<p>从一个状态 <code>$s$</code> 出发，采取一个行动 <code>$a$</code>，状态价值函数为：</p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/bellman-expection-eq-state-value-1.png" class="lazyload"/>
  
</figure>

<p><code>$$
v_{\pi}(s)=\sum_{a \in \mathcal{A}} \pi(a | s) q_{\pi}(s, a)
$$</code></p>

<p>从一个动作 <code>$s$</code> 出发，再采取一个行动 <code>$a$</code> 后，动作价值函数为：</p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/bellman-expection-eq-action-value-1.png" class="lazyload"/>
  
</figure>

<p><code>$$
q_{\pi}(s, a)=\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} v_{\pi}\left(s^{\prime}\right)
$$</code></p>

<p>利用后继状态价值函数表示当前状态价值函数为：</p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/bellman-expection-eq-state-value-2.png" class="lazyload"/>
  
</figure>

<p><code>$$
v_{\pi}(s)=\sum_{a \in \mathcal{A}} \pi(a | s)\left(\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} v_{\pi}\left(s^{\prime}\right)\right)
$$</code></p>

<p>利用后继动作价值函数表示当前动作价值函数为：</p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/bellman-expection-eq-action-value-2.png" class="lazyload"/>
  
</figure>

<p><code>$$
q_{\pi}(s, a)=\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} \sum_{a^{\prime} \in \mathcal{A}} \pi\left(a^{\prime} | s^{\prime}\right) q_{\pi}\left(s^{\prime}, a^{\prime}\right)
$$</code></p>

<p><strong>最优状态价值函数</strong> <code>$v_* \left(s\right)$</code> 定义为所有策略上最大值的状态价值函数：</p>

<p><code>$$
v_* \left(s\right) = \mathop{\max}_{\pi} v_{\pi} \left(s\right)
$$</code></p>

<p><strong>最优动作价值函数</strong> <code>$q_* \left(s, a\right)$</code> 定义为所有策略上最大值的动作价值函数：</p>

<p><code>$$
q_* \left(s, a\right) = \mathop{\max}_{\pi} q_{\pi} \left(s, a\right)
$$</code></p>

<p>定义不同策略之间的大小关系为：</p>

<p><code>$$
\pi \geq \pi^{\prime} \text { if } v_{\pi}(s) \geq v_{\pi^{\prime}}(s), \forall s
$$</code></p>

<p>对于任意一个马尔可夫决策过程有：</p>

<ul>
<li>存在一个比其他策略更优或相等的策略，<code>$\pi_* \geq \pi, \forall \pi$</code></li>
<li>所有的最优策略均能够获得最优的状态价值函数，<code>$v_{\pi_*} \left(s\right) = v_* \left(s\right)$</code></li>
<li>所有的最优策略均能够获得最优的动作价值函数，<code>$q_{\pi_*} \left(s, a\right) = q_* \left(s, a\right)$</code></li>
</ul>

<p>一个最优策略可以通过最大化 <code>$q_* \left(s, a\right)$</code> 获得：</p>

<p><code>$$
\pi_{*}(a | s)=\left\{\begin{array}{ll}
1 &amp; \text { if } a=\underset{a \in \mathcal{A}}{\operatorname{argmax}} q_{*}(s, a) \\
0 &amp; \text { otherwise }
\end{array}\right.
$$</code></p>

<p>对于任意一个 MDP 均会有一个确定的最优策略，如果已知 <code>$q_* \left(s, a\right)$</code> 即可知晓最优策略。</p>

<p>最优状态价值函数循环依赖于贝尔曼最优方程：</p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/bellman-optimality-eq-state-value-1.png" class="lazyload"/>
  
</figure>

<p><code>$$
v_{*}(s)=\max _{a} q_{*}(s, a)
$$</code></p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/bellman-optimality-eq-action-value-1.png" class="lazyload"/>
  
</figure>

<p><code>$$
q_{*}(s, a)=\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} v_{*}\left(s^{\prime}\right)
$$</code></p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/bellman-optimality-eq-state-value-2.png" class="lazyload"/>
  
</figure>

<p><code>$$
v_{*}(s)=\max _{a} \mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} v_{*}\left(s^{\prime}\right)
$$</code></p>

<figure>
  <img data-src="/images/cn/2020-05-23-markov-decision-process/bellman-optimality-eq-action-value-2.png" class="lazyload"/>
  
</figure>

<p><code>$$
q_{*}(s, a)=\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} \max _{a^{\prime}} q_{*}\left(s^{\prime}, a^{\prime}\right)
$$</code></p>

<p>显式求解贝尔曼最优方程给出了找到一个最优策略的方法，但这种解法至少依赖于三条实际情况很难满足的假设：</p>

<ol>
<li>准确地知道环境的动态变化特性</li>
<li>有足够的计算资源来求解</li>
<li>马尔可夫性质</li>
</ol>

<p>尤其是假设 2 很难满足，现实问题中状态的数量一般很大，即使利用最快的计算机也需要花费难以接受的时间才能求解完成。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:sutton2018reinforcement">Sutton, R. S., &amp; Barto, A. G. (2018). <em>Reinforcement learning: An introduction</em>. MIT press.
 <a class="footnote-return" href="#fnref:sutton2018reinforcement">↩</a></li>
<li id="fn:stanford-cs234">CS234: Reinforcement Learning <a href="http://web.stanford.edu/class/cs234/index.html" rel="noreferrer" target="_blank">http://web.stanford.edu/class/cs234/index.html</a>
 <a class="footnote-return" href="#fnref:stanford-cs234">↩</a></li>
<li id="fn:ucl-course-on-rl">UCL Course on RL <a href="https://www.davidsilver.uk/teaching" rel="noreferrer" target="_blank">https://www.davidsilver.uk/teaching</a>
 <a class="footnote-return" href="#fnref:ucl-course-on-rl">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>多臂赌博机 (Multi-armed Bandit)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/05/multi-armed-bandit/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/05/multi-armed-bandit/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文为<a href="/categories/强化学习/">《强化学习系列》</a>文章<br />
本文内容主要参考自《强化学习》<sup class="footnote-ref" id="fnref:sutton2018reinforcement"><a href="#fn:sutton2018reinforcement">1</a></sup></p>
</blockquote>

<h2 id="多臂赌博机问题">多臂赌博机问题</h2>

<p>一个赌徒，要去摇老虎机，走进赌场一看，一排老虎机，外表一模一样，但是每个老虎机吐钱的概率可不一样，他不知道每个老虎机吐钱的概率分布是什么，那么每次该选择哪个老虎机可以做到最大化收益呢？这就是<strong>多臂赌博机问题 (Multi-armed bandit problem, K- or N-armed bandit problem, MAB)</strong> <sup class="footnote-ref" id="fnref:mab-problem"><a href="#fn:mab-problem">2</a></sup>。</p>

<figure>
  <img data-src="/images/cn/2020-05-16-multi-armed-bandit/compulsive-gambling.png" class="lazyload"/>
  <figcaption><p class="figcaption">图片来源：<a href="http://hagencartoons.com/cartoons_166_170.html" rel="noreferrer" target="_blank">http://hagencartoons.com/cartoons_166_170.html</a></p></figcaption>
</figure>

<p><code>$k$</code> 臂赌博机问题中，<code>$k$</code> 个动作的每一个在被选择时都有一个期望或者平均收益，称之为这个动作的<strong>“价值”</strong>。令 <code>$t$</code> 时刻选择的动作为 <code>$A_t$</code>，对应的收益为 <code>$R_t$</code>，任一动作 <code>$a$</code> 对应的价值为 <code>$q_* \left(a\right)$</code>，即给定动作 <code>$a$</code> 时收益的期望：</p>

<p><code>$$
q_* \left(a\right) = \mathbb{E} \left[R_t | A_t = a\right]
$$</code></p>

<p>我们将对动作 <code>$a$</code> 在时刻 <code>$t$</code> 的价值的估计记做 <code>$Q_t \left(a\right)$</code>，我们希望它接近 <code>$q_* \left(a\right)$</code>。</p>

<p>如果持续对动作的价值进行估计，那么在任一时刻都会至少有一个动作的估计价值是最高的，将这些对应最高估计价值的动作成为<strong>贪心</strong>的动作。当从这些动作中选择时，称此为<strong>开发</strong>当前所知道的关于动作的价值的知识。如果不是如此，而是选择非贪心的动作，称此为<strong>试探</strong>，因为这可以让你改善对非贪心动作的价值的估计。“开发”对于最大化当前这一时刻的期望收益是正确的做法，但是“试探”从长远来看可能会带来总体收益的最大化。到底选择“试探”还是“开发”一种复杂的方式依赖于我们得到的函数估计、不确定性和剩余时刻的精确数值。</p>

<h2 id="动作价值估计方法">动作价值估计方法</h2>

<p>我们以一种自然的方式，就是通过计算实际收益的平均值来估计动作的价值：</p>

<p><code>$$
\begin{aligned}
Q_t \left(a\right) &amp;= \dfrac{t \text{ 时刻前执行动作 } a \text{ 得到的收益总和 }}{t \text{ 时刻前执行动作 } a \text{ 的次数}} \\
&amp;= \dfrac{\sum_{i=1}^{t-1}{R_i \cdot \mathbb{1}_{A_i = a}}}{\sum_{i=1}^{t-1}{\mathbb{1}_{A_i = a}}}
\end{aligned}
$$</code></p>

<p>其中，<code>$\mathbb{1}_{\text{predicate}}$</code> 表示随机变量，当 predicate 为真时其值为 1，反之为 0。当分母为 0 时，<code>$Q_t \left(a\right) = 0$</code>，当分母趋向无穷大时，根据大数定律，<code>$Q_t \left(a\right)$</code> 会收敛到 <code>$q_* \left(a\right)$</code>。这种估计动作价值的方法称为<strong>采样平均方法</strong>，因为每一次估计都是对相关收益样本的平均。</p>

<p>当然，这只是估计动作价值的一种方法，而且不一定是最好的方法。例如，我们也可以利用累积遗憾（Regret）来评估动作的价值：</p>

<p><code>$$
\rho = T \mu^* - \sum_{t=1}^{T} \hat{r}_t
$$</code></p>

<p>其中，<code>$\mu^* = \mathop{\max}_{k} \left\{\mu_k\right\}$</code> 为最大的回报，<code>$\hat{r}_t$</code> 为 <code>$t$</code> 时刻的回报。</p>

<h2 id="多臂赌博机算法">多臂赌博机算法</h2>

<p>以 10 臂赌博机为例，动作的收益分布如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-16-multi-armed-bandit/action-reward-distribution.png" class="lazyload"/>
  
</figure>

<p>动作的真实价值 <code>$q_* \left(a\right), a = 1, \cdots, 10$</code> 为从一个均值为 0 方差为 1 的标准正态分布中选择。当对于该问题的学习方法在 <code>$t$</code> 时刻选择 <code>$A_t$</code> 时，实际的收益 <code>$R_t$</code> 则由一个均值为 <code>$q_* \left(A_t\right)$</code> 方差为 1 的正态分布决定。</p>

<h3 id="epsilon-greedy"><code>$\epsilon$</code>-Greedy</h3>

<p><code>$\epsilon$</code>-Greedy 采用的动作选择逻辑如下：</p>

<ul>
<li>确定一个 <code>$\epsilon \in \left(0, 1\right)$</code>。</li>
<li>每次以 <code>$\epsilon$</code> 的概率随机选择一个臂，以 <code>$1 - \epsilon$</code> 选择平均收益最大的那个臂。</li>
</ul>

<p>下图分别展示了 <code>$\epsilon = 0$</code>（贪婪），<code>$\epsilon = 0.01$</code> 和 <code>$\epsilon = 0.1$</code> 三种情况下的平均收益和最优动作占比随训练步数的变化情况。</p>

<figure>
  <img data-src="/images/cn/2020-05-16-multi-armed-bandit/epsilon-greedy-step-average-reward.png" class="lazyload"/>
  
</figure>

<figure>
  <img data-src="/images/cn/2020-05-16-multi-armed-bandit/epsilon-greedy-step-best-action-ratio.png" class="lazyload"/>
  
</figure>

<p><code>$\epsilon$</code>-Greedy 相比于 <code>$\epsilon = 0$</code>（贪婪）算法的优势如下：</p>

<ul>
<li>对于更大方差的收益，找到最优的动作需要更多次的试探。</li>
<li>对于非平稳的任务，即动作的真实价值会随着时间而改变，这种情况下即使有确定性的情况下，也需要进行试探。</li>
</ul>

<p>令 <code>$R_i$</code> 表示一个动作被选择 <code>$i$</code> 次后获得的收益，<code>$Q_n$</code> 表示被选择 <code>$n - 1$</code> 次后它的估计的动作价值，其可以表示为增量计算的形式：</p>

<p><code>$$
\begin{aligned}
Q_{n+1} &amp;= \dfrac{1}{n} \sum_{i=1}^{n}{R_i} \\
&amp;= \dfrac{1}{n} \left(R_n + \sum_{i=1}^{n-1}{R_i}\right) \\
&amp;= \dfrac{1}{n} \left(R_n + \left(n - 1\right) \dfrac{1}{n-1} \sum_{i=1}^{n-1}{R_i}\right) \\
&amp;= \dfrac{1}{n} \left(R_n + \left(n - 1\right) Q_n\right) \\
&amp;= \dfrac{1}{n} \left(R_n + n Q_n - Q_n\right) \\
&amp;= Q_n + \dfrac{1}{n} \left[R_n - Q_n\right]
\end{aligned}
$$</code></p>

<p>上述我们讨论的都是平稳的问题，即收益的概率分布不随着时间变化的赌博机问题。对于非平稳的问题，给近期的收益赋予比过去更高的权值是一个合理的处理方式。则收益均值 <code>$Q_n$</code> 的增量更新规则为：</p>

<p><code>$$
\begin{aligned}
Q_{n+1} &amp;= Q_n + \alpha \left[R_n - Q_n\right] \\
&amp;= \left(1 - \alpha\right)^n Q_1 + \sum_{i=1}^{n} \alpha \left(1 - \alpha\right)^{n-i} R_i
\end{aligned}
$$</code></p>

<p>赋给收益 <code>$R_i$</code> 的权值 <code>$\alpha \left(1 - \alpha\right)^{n-i}$</code> 依赖于它被观测到的具体时刻和当前时刻的差，权值以指数形式递减，因此这个方法也称之为<strong>指数近因加权平均</strong>。</p>

<p>上述讨论中所有方法都在一定程度上依赖于初始动作值 <code>$Q_1 \left(a\right)$</code> 的选择。从统计学角度，初始估计值是有偏的，对于平均采样来说，当所有动作都至少被选择一次时，偏差会消失；对于步长为常数的情况，偏差会随时间而减小。</p>

<p>下图展示了不同初始动作估计值下最优动作占比随训练步数的变化情况：</p>

<figure>
  <img data-src="/images/cn/2020-05-16-multi-armed-bandit/epsilon-greedy-different-parameters-best-action-ratio.png" class="lazyload"/>
  
</figure>

<p>设置较大初始动作估计值会鼓励进行试探，这种方法称之为<strong>乐观初始价值</strong>，该方法在平稳问题中非常有效。</p>

<h3 id="ucb">UCB</h3>

<p><code>$\epsilon$</code>-Greedy 在进行尝试时是盲目地选择，因为它不大会选择接近贪心或者不确定性特别大的动作。在非贪心动作中，最好是根据它们的潜力来选择可能事实上是最优的动作，这要考虑它们的估计有多接近最大值，以及这些估计的不确定性。</p>

<p>一种基于<strong>置信度上界</strong>（Upper Confidence Bound，UCB）思想的选择动作依据如下：</p>

<p><code>$$
A_t = \mathop{\arg\max}_{a} \left[Q_t \left(a\right) + c \sqrt{\dfrac{\ln t}{N_t \left(a\right)}}\right]
$$</code></p>

<p>其中，<code>$N_t \left(a\right)$</code> 表示在时刻 <code>$t$</code> 之前动作 <code>$a$</code> 被选择的次数，<code>$c &gt; 0$</code> 用于控制试探的程度。平方根项是对 <code>$a$</code> 动作值估计的不确定性或方差的度量，最大值的大小是动作 <code>$a$</code> 的可能真实值的上限，参数 <code>$c$</code> 决定了置信水平。</p>

<p>下图展示了 UCB 算法和 <code>$\epsilon$</code>-Greedy 算法平均收益随着训练步数的变化：</p>

<figure>
  <img data-src="/images/cn/2020-05-16-multi-armed-bandit/epsilon-greedy-ucb-step-average-reward.png" class="lazyload"/>
  
</figure>

<h3 id="梯度赌博机算法">梯度赌博机算法</h3>

<p>针对每个动作 <code>$a$</code>，考虑学习一个数值化的偏好函数 <code>$H_t \left(a\right)$</code>，偏好函数越大，动作就约频繁地被选择，但偏好函数的概念并不是从“收益”的意义上提出的。基于随机梯度上升的思想，在每个步骤中，在选择动作 <code>$A_t$</code> 并获得收益 <code>$R_t$</code> 之后，偏好函数会按如下方式更新：</p>

<p><code>$$
\begin{aligned}
H_{t+1} \left(A_t\right) &amp;eq H_t \left(A_t\right) + \alpha \left(R_t - \bar{R}_t\right) \left(1 - \pi_t \left(A_t\right)\right) \\
H_{t+1} \left(a\right) &amp;eq H_t \left(a\right) - \alpha \left(R_t - \bar{R}_t\right) \pi_t \left(a\right)
\end{aligned}
$$</code></p>

<p>其中，<code>$\alpha &gt; 0$</code> 表示步长，<code>$\bar{R}_t \in \mathbb{R}$</code> 表示时刻 <code>$t$</code> 内所有收益的平均值。<code>$\bar{R}_t$</code> 项作为比较收益的一个基准项，如果收益高于它，那么在未来选择动作 <code>$A_t$</code> 的概率就会增加，反之概率就会降低，未选择的动作被选择的概率会上升。</p>

<p>下图展示了在 10 臂测试平台问题的变体上采用梯度赌博机算法的结果，在这个问题中，它们真实的期望收益是按照平均值为 4 而不是 0 的正态分布来选择的。所有收益的这种变化对梯度赌博机算法没有任何影响，因为收益基准项让它可以马上适应新的收益水平，如果没有基准项，那么性能将显著降低。</p>

<figure>
  <img data-src="/images/cn/2020-05-16-multi-armed-bandit/gradient-different-parameters-best-action-ratios.png" class="lazyload"/>
  
</figure>

<h2 id="算法性能比较">算法性能比较</h2>

<p><code>$\epsilon$</code>-Greedy 方法在一段时间内进行随机的动作选择；UCB 方法虽然采用确定的动作选择，但可以通过每个时刻对具有较少样本的动作进行优先选择来实现试探；梯度赌博机算法则不估计动作价值，而是利用偏好函数，使用 softmax 分布来以一种分级的、概率式的方式选择更优的动作；简单地将收益的初值进行乐观的设置，可以让贪心方法也能进行显示试探。</p>

<p>下图展示了上述算法在不同参数下的平均收益，每条算法性能曲线都看作一个自己参数的函数。<code>$x$</code> 轴上参数值的变化是 2 的倍数，并以对数坐标轴进行表示。</p>

<figure>
  <img data-src="/images/cn/2020-05-16-multi-armed-bandit/different-methods-performance.png" class="lazyload"/>
  
</figure>

<p>在评估方法时，不仅要关注它在最佳参数设置上的表现，还要注意它对参数值的敏感性。总的来说，在本文的问题上，UCB 表现最好。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:sutton2018reinforcement">Sutton, R. S., &amp; Barto, A. G. (2018). <em>Reinforcement learning: An introduction</em>. MIT press.
 <a class="footnote-return" href="#fnref:sutton2018reinforcement">↩</a></li>
<li id="fn:mab-problem"><a href="https://cosx.org/2017/05/bandit-and-recommender-systems" rel="noreferrer" target="_blank">https://cosx.org/2017/05/bandit-and-recommender-systems</a>
 <a class="footnote-return" href="#fnref:mab-problem">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>强化学习简介 (Introduction of Reinforcement Learning)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/05/introduction-of-reinforcement-learning/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/05/introduction-of-reinforcement-learning/</guid>
      <description>
        <![CDATA[
        

<blockquote>
<p>本文为<a href="/categories/强化学习/">《强化学习系列》</a>文章</p>
</blockquote>

<h2 id="强化学习简介">强化学习简介</h2>

<p><strong>强化学习（Reinforcement Learning，RL）</strong>是机器学习中的一个领域，是学习“做什么（即如何把当前的情景映射成动作）才能使得数值化的收益信号最大化”。学习者不会被告知应该采取什么动作，而是必须自己通过尝试去发现哪些动作会产生最丰厚的收益。</p>

<p>强化学习同机器学习领域中的<strong>有监督学习</strong>和<strong>无监督学习</strong>不同，有监督学习是从外部监督者提供的带标注训练集中进行学习（任务驱动型），无监督学习是一个典型的寻找未标注数据中隐含结构的过程（数据驱动型）。强化学习是与两者并列的第三种机器学习范式，强化学习带来了一个独有的挑战——<strong>“试探”</strong>与<strong>“开发”</strong>之间的折中权衡，智能体必须开发已有的经验来获取收益，同时也要进行试探，使得未来可以获得更好的动作选择空间（即从错误中学习）。</p>

<figure>
  <img data-src="/images/cn/2020-05-09-introduction-of-reinforcement-learning/machine-learning-types.png" class="lazyload"/>
  
</figure>

<p>在强化学习中，有两个可以进行交互的对象：<strong>智能体（Agnet）</strong>和<strong>环境（Environment）</strong>：</p>

<ul>
<li>智能体：可以感知环境的<strong>状态（State）</strong>，并根据反馈的<strong>奖励（Reward）</strong>学习选择一个合适的<strong>动作（Action）</strong>，来最大化长期总收益。</li>
<li>环境：环境会接收智能体执行的一系列动作，对这一系列动作进行评价并转换为一种可量化的信号反馈给智能体。</li>
</ul>

<figure>
  <img data-src="/images/cn/2020-05-09-introduction-of-reinforcement-learning/reinforcement-learning.png" class="lazyload"/>
  <figcaption><p class="figcaption">图片来源：<a href="https://en.wikipedia.org/wiki/Reinforcement_learning" rel="noreferrer" target="_blank">https://en.wikipedia.org/wiki/Reinforcement_learning</a></p></figcaption>
</figure>

<p>除了智能体和环境之外，强化学习系统有四个核心要素：<strong>策略（Policy）</strong>、<strong>回报函数（收益信号，Reward Function）</strong>、<strong>价值函数（Value Function）</strong>和<strong>环境模型（Environment Model）</strong>，其中环境模型是可选的。</p>

<ul>
<li>策略：定义了智能体在特定时间的行为方式。策略是环境状态到动作的映射。</li>
<li>回报函数：定义了强化学习问题中的目标。在每一步中，环境向智能体发送一个称为收益的标量数值。</li>
<li>价值函数：表示了从长远的角度看什么是好的。一个状态的价值是一个智能体从这个状态开始，对将来累积的总收益的期望。</li>
<li>环境模型：是一种对环境的反应模式的模拟，它允许对外部环境的行为进行推断。</li>
</ul>

<p>强化学习是一种对目标导向的学习与决策问题进行理解和自动化处理的计算方法。它强调智能体通过与环境的直接互动来学习，而不需要可效仿的监督信号或对周围环境的完全建模，因而与其他的计算方法相比具有不同的范式。</p>

<p>强化学习使用马尔可夫决策过程的形式化框架，使用<strong>状态</strong>，<strong>动作</strong>和<strong>收益</strong>定义学习型智能体与环境的互动过程。这个框架力图简单地表示人工智能问题的若干重要特征，这些特征包含了对<strong>因果关系</strong>的认知，对<strong>不确定性</strong>的认知，以及对<strong>显式目标存在性</strong>的认知。</p>

<p>价值与价值函数是强化学习方法的重要特征，价值函数对于策略空间的有效搜索来说十分重要。相比于进化方法以对完整策略的反复评估为引导对策略空间进行直接搜索，使用价值函数是强化学习方法与进化方法的不同之处。</p>

<h2 id="示例和应用">示例和应用</h2>

<p>以经典的 Flappy Bird 游戏为例，智能体就是游戏中我们操作的小鸟，整个游戏中的天空和遮挡管道即为环境，动作为玩家单击屏幕使小鸟飞起的行为，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-09-introduction-of-reinforcement-learning/flappy-bird-rl.png" class="lazyload"/>
  <figcaption><p class="figcaption">图片来源：<a href="https://easyai.tech/ai-definition/reinforcement-learning" rel="noreferrer" target="_blank">https://easyai.tech/ai-definition/reinforcement-learning</a></p></figcaption>
</figure>

<p>目前，强化学习在包括<strong>游戏</strong>，<strong>广告和推荐</strong>，<strong>对话系统</strong>，<strong>机器人</strong>等多个领域均展开了广泛的应用。</p>

<h3 id="游戏">游戏</h3>

<p><strong>AlphaGo</strong> <sup class="footnote-ref" id="fnref:alphago"><a href="#fn:alphago">1</a></sup> 是于 2014 年开始由英国伦敦 Google DeepMind 开发的人工智能围棋软件。AlphaGo 使用蒙特卡洛树搜索（Monte Carlo tree search），借助估值网络（value network）与走棋网络（policy network）这两种深度神经网络，通过估值网络来评估大量选点，并通过走棋网络选择落点。</p>

<figure>
  <img data-src="/images/cn/2020-05-09-introduction-of-reinforcement-learning/alphago.png" class="lazyload"/>
  
</figure>

<p><strong>AlphaStar</strong> <sup class="footnote-ref" id="fnref:alphastar-1"><a href="#fn:alphastar-1">2</a></sup> <sup class="footnote-ref" id="fnref:alphastar-2"><a href="#fn:alphastar-2">3</a></sup> 是由 DeepMind 开发的玩 <a href="https://zh.wikipedia.org/wiki/%E6%98%9F%E6%B5%B7%E7%88%AD%E9%9C%B8II%EF%BC%9A%E8%87%AA%E7%94%B1%E4%B9%8B%E7%BF%BC" rel="noreferrer" target="_blank">星际争霸 II</a> 游戏的人工智能程序。AlphaStar 是由一个深度神经网路生成的，它接收来自原始游戏界面的输入数据，并输出一系列指令，构成游戏中的一个动作。</p>

<p>更具体地说，神经网路体系结构将 Transformer 框架运用于模型单元（类似于关系深度强化学习），结合一个深度 LSTM 核心、一个带有 pointer network 的自回归策略前端和一个集中的值基线。这种先进的模型将有助于解决机器学习研究中涉及长期序列建模和大输出空间（如翻译、语言建模和视觉表示）的许多其他挑战。</p>

<p>AlphaStar 还使用了一种新的多智能体学习算法。该神经网路最初是通过在 Blizzard 发布的匿名人类游戏中进行监督学习来训练的。这使得 AlphaStar 能够通过模仿学习星际争霸上玩家所使用的基本微观和宏观策略。这个初级智能体在 95% 的游戏中击败了内置的「精英」AI 关卡（相当于人类玩家的黄金级别）。</p>

<figure>
  <img data-src="/images/cn/2020-05-09-introduction-of-reinforcement-learning/alphastar.png" class="lazyload"/>
  
</figure>

<p><strong>OpenAI Five</strong> <sup class="footnote-ref" id="fnref:openai-five"><a href="#fn:openai-five">4</a></sup> 是一个由 OpenAI 开发的用于多人视频游戏 <a href="https://zh.wikipedia.org/zh-hans/Dota_2" rel="noreferrer" target="_blank">Dota 2</a> 的人工智能程序。OpenAI Five 通过与自己进行超过 10,000 年时长的游戏进行优化学习，最终获得了专家级别的表现。</p>

<figure>
  <img data-src="/images/cn/2020-05-09-introduction-of-reinforcement-learning/openai-five.png" class="lazyload"/>
  
</figure>

<p><strong>Pluribus</strong> <sup class="footnote-ref" id="fnref:pluribus"><a href="#fn:pluribus">5</a></sup> 是由 Facebook 开发的第一个在六人无限注德州扑克中击败人类专家的 AI 智能程序，其首次在复杂游戏中击败两个人或两个团队。</p>

<figure>
  <img data-src="/images/cn/2020-05-09-introduction-of-reinforcement-learning/facebook-pluribus.jpg" class="lazyload"/>
  
</figure>

<h3 id="广告和推荐">广告和推荐</h3>

<figure>
  <img data-src="/images/cn/2020-05-09-introduction-of-reinforcement-learning/recommendation.png" class="lazyload"/>
  <figcaption><p class="figcaption">图片来源：A Reinforcement Learning Framework for Explainable Recommendation</p></figcaption>
</figure>

<h3 id="对话系统">对话系统</h3>

<figure>
  <img data-src="/images/cn/2020-05-09-introduction-of-reinforcement-learning/dialogue-system.png" class="lazyload"/>
  <figcaption><p class="figcaption">图片来源：End-to-End Task-Completion Neural Dialogue Systems</p></figcaption>
</figure>

<h3 id="机器人">机器人</h3>

<figure>
  <img data-src="/images/cn/2020-05-09-introduction-of-reinforcement-learning/robot.png" class="lazyload"/>
  <figcaption><p class="figcaption">图片来源：Learning Synergies between Pushing and Grasping with Self-supervised Deep Reinforcement Learning</p></figcaption>
</figure>

<h2 id="开放资源">开放资源</h2>

<h3 id="开源实验平台">开源实验平台</h3>

<ul>
<li><a href="https://github.com/openai/gym" rel="noreferrer" target="_blank">openai/gym</a></li>
<li><a href="http://mujoco.org/" rel="noreferrer" target="_blank">MuJoCo</a></li>
<li><a href="https://github.com/openai/mujoco-py" rel="noreferrer" target="_blank">openai/mujoco-py</a></li>
<li><a href="https://github.com/deepmind/lab" rel="noreferrer" target="_blank">deepmind/lab</a></li>
</ul>

<h3 id="开源框架">开源框架</h3>

<ul>
<li><a href="https://github.com/deepmind/trfl/" rel="noreferrer" target="_blank">deepmind/trfl/</a> <i class="icon icon-tensorflow"></i></li>
<li><a href="https://github.com/deepmind/open_spiel" rel="noreferrer" target="_blank">deepmind/open_spiel</a> <i class="icon icon-tensorflow"></i></li>
<li><a href="https://github.com/google/dopamine" rel="noreferrer" target="_blank">google/dopamine</a> <i class="icon icon-tensorflow"></i></li>
<li><a href="https://github.com/tensorflow/agents" rel="noreferrer" target="_blank">tensorflow/agents</a> <i class="icon icon-tensorflow"></i></li>
<li><a href="https://github.com/keras-rl/keras-rl" rel="noreferrer" target="_blank">keras-rl/keras-rl</a> <i class="icon icon-keras"></i></li>
<li><a href="https://github.com/tensorforce/tensorforce" rel="noreferrer" target="_blank">tensorforce/tensorforce</a> <i class="icon icon-tensorflow"></i></li>
<li><a href="https://github.com/facebookresearch/ReAgent" rel="noreferrer" target="_blank">facebookresearch/ReAgent</a> <i class="icon icon-pytorch"></i></li>
<li><a href="https://github.com/thu-ml/tianshou" rel="noreferrer" target="_blank">thu-ml/tianshou</a> <i class="icon icon-pytorch"></i></li>
<li><a href="https://github.com/astooke/rlpyt" rel="noreferrer" target="_blank">astooke/rlpyt</a> <i class="icon icon-pytorch"></i></li>
<li><a href="https://github.com/NervanaSystems/coach" rel="noreferrer" target="_blank">NervanaSystems/coach</a> <i class="icon icon-tensorflow"></i></li>
<li><a href="https://github.com/PaddlePaddle/PARL" rel="noreferrer" target="_blank">PaddlePaddle/PARL</a> <i class="icon icon-paddlepaddle"></i></li>
</ul>

<h3 id="开源模型">开源模型</h3>

<ul>
<li><a href="https://github.com/dennybritz/reinforcement-learning" rel="noreferrer" target="_blank">dennybritz/reinforcement-learning</a> <i class="icon icon-tensorflow"></i></li>
<li><a href="https://github.com/openai/baselines" rel="noreferrer" target="_blank">openai/baselines</a> <i class="icon icon-tensorflow"></i></li>
</ul>

<h3 id="其他资源">其他资源</h3>

<ul>
<li><a href="https://github.com/ShangtongZhang/reinforcement-learning-an-introduction" rel="noreferrer" target="_blank">ShangtongZhang/reinforcement-learning-an-introduction</a></li>
<li><a href="https://github.com/aikorea/awesome-rl" rel="noreferrer" target="_blank">aikorea/awesome-rl</a></li>
<li><a href="https://github.com/openai/spinningup" rel="noreferrer" target="_blank">openai/spinningup</a></li>
<li><a href="https://github.com/udacity/deep-reinforcement-learning" rel="noreferrer" target="_blank">udacity/deep-reinforcement-learning</a></li>
</ul>
<div class="footnotes">

<hr />

<ol>
<li id="fn:alphago"><a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far" rel="noreferrer" target="_blank">https://deepmind.com/research/case-studies/alphago-the-story-so-far</a>
 <a class="footnote-return" href="#fnref:alphago">↩</a></li>
<li id="fn:alphastar-1"><a href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii" rel="noreferrer" target="_blank">https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii</a>
 <a class="footnote-return" href="#fnref:alphastar-1">↩</a></li>
<li id="fn:alphastar-2"><a href="https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning" rel="noreferrer" target="_blank">https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning</a>
 <a class="footnote-return" href="#fnref:alphastar-2">↩</a></li>
<li id="fn:openai-five"><a href="https://openai.com/projects/five/" rel="noreferrer" target="_blank">https://openai.com/projects/five/</a>
 <a class="footnote-return" href="#fnref:openai-five">↩</a></li>
<li id="fn:pluribus"><a href="https://ai.facebook.com/blog/pluribus-first-ai-to-beat-pros-in-6-player-poker/" rel="noreferrer" target="_blank">https://ai.facebook.com/blog/pluribus-first-ai-to-beat-pros-in-6-player-poker/</a>
 <a class="footnote-return" href="#fnref:pluribus">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>隐马尔可夫 (Hidden Markov Model, HMM)，条件随机场 (Conditional Random Fields, CRF) 和序列标注 (Sequence Labeling)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2020/05/hmm-crf-and-sequence-labeling/</link>
      <pubDate>Sat, 02 May 2020 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2020/05/hmm-crf-and-sequence-labeling/</guid>
      <description>
        <![CDATA[
        

<h2 id="隐马尔可夫">隐马尔可夫</h2>

<p>隐马尔可夫模型（Hidden Markov Model，HMM）是一个描述包含隐含未知参数的马尔可夫过程的统计模型。马尔可夫过程（Markov Process）是因俄国数学家安德雷·安德耶维齐·马尔可夫（Андрей Андреевич Марков）而得名一个随机过程，在该随机过程中，给定当前状态和过去所有状态的条件下，其下一个状态的条件概率分布仅依赖于当前状态，通常具备离散状态的马尔可夫过程称之为马尔可夫链（Markov Chain）。因此，马尔可夫链可以理解为一个有限状态机，给定了当前状态为 <code>$S_i$</code> 时，下一时刻状态为 <code>$S_j$</code> 的概率，不同状态之间变换的概率称之为转移概率。下图描述了 3 个状态 <code>$S_a, S_b, S_c$</code> 之间转换状态的马尔可夫链。</p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/hmm-markov-chain-example.png" class="lazyload"/>
  
</figure>

<p>隐马尔可夫模型中包含两种序列：随机生成的状态构成的序列称之为状态序列（state sequence），状态序列是不可被观测到的；每个状态对应的观测值组成的序列称之为观测序列（observation sequence）。令 <code>$I = \left(i_1, i_2, \cdots, i_T\right)$</code> 为状态序列，其中 <code>$i_t$</code> 为第 <code>$t$</code> 时刻系统的状态值，对应的有 <code>$O = \left(o_1, o_2, \cdots, o_T\right)$</code> 为观测序列，其中 <code>$o_t$</code> 为第 <code>$t$</code> 时刻系统的观测值，系统的所有可能的状态集合为 <code>$Q = \{q_1, q_2, \cdots, q_N\}$</code>，所有可能的观测集合为 <code>$V= \{v_1, v_2, \cdots, v_M\}$</code>。</p>

<p>隐马尔可夫模型主要由三组参数构成：</p>

<ol>
<li>状态转移矩阵：
<code>$$
A = \left[a_{ij}\right]_{N \times N}
$$</code>
其中，
<code>$$
a_{ij} = P \left(i_{t+1} = q_j | i_t = q_i\right), 1 \leq i, j \leq N
$$</code>
表示 <code>$t$</code> 时刻状态为 <code>$q_i$</code> 的情况下，在 <code>$t+1$</code> 时刻状态转移到 <code>$q_j$</code> 的概率。</li>
<li>观测概率矩阵：
<code>$$
B = \left[b_j \left(k\right)\right]_{N \times M}
$$</code>
其中，
<code>$$
b_j \left(k\right) = P \left(o_t = v_k | i_t = q_j\right), k = 1, 2, \cdots, M, j = 1, 2, \cdots, N
$$</code>
表示 <code>$t$</code> 时刻状态为 <code>$q_i$</code> 的情况下，观测值为 <code>$v_k$</code> 的概率。</li>
<li>初始状态概率向量：
<code>$$
\pi = \left(\pi_i\right)
$$</code>
其中，
<code>$$
\pi_i = P \left(i_1 = q_i\right), i = 1, 2, \cdots, N
$$</code>
表示 <code>$t = 1$</code> 时刻，系统处于状态 <code>$q_i$</code> 的概率。</li>
</ol>

<p>初始状态概率向量 <code>$\pi$</code> 和状态转移矩阵 <code>$A$</code> 决定了状态序列，观测概率矩阵 <code>$B$</code> 决定了状态序列对应的观测序列，因此马尔可夫模型可以表示为：</p>

<p><code>$$
\lambda = \left(A, B, \pi\right)
$$</code></p>

<p>对于马尔可夫模型 <code>$\lambda = \left(A, B, \pi\right)$</code>，通过如下步骤生成观测序列 <code>$\{o_1, o_2, \cdots, o_T\}$</code>：</p>

<ol>
<li>按照初始状态分布 <code>$\pi$</code> 产生状态 <code>$i_1$</code>.</li>
<li>令 <code>$t = 1$</code>。</li>
<li>按照状态 <code>$i_t$</code> 的观测概率分布 <code>$b_{i_t} \left(k\right)$</code> 生成 <code>$o_t$</code>。</li>
<li>按照状态 <code>$i_t$</code> 的状态转移概率分布 <code>$\left\{a_{i_t i_{t+1}}\right\}$</code> 产生状态 <code>$i_{t+1}$</code>，<code>$i_{t+1} = 1, 2, \cdots, N$</code>。</li>
<li>令 <code>$t = t + 1$</code>，如果 <code>$t &lt; T$</code>，转步骤 3；否则，终止。</li>
</ol>

<p>马尔可夫模型在应用过程中有 3 个基本问题 <sup class="footnote-ref" id="fnref:li2019tongji"><a href="#fn:li2019tongji">1</a></sup>：</p>

<ol>
<li>概率计算问题。给定模型 <code>$\lambda = \left(A, B, \pi\right)$</code> 和观测序列 <code>$O = \{o_1, o_2, \cdots, o_T\}$</code>，计算在模型 <code>$\lambda$</code> 下观测序列 <code>$O$</code> 出现的概率 <code>$P\left(O | \lambda \right)$</code>。</li>
<li>学习问题。已知观测序列 <code>$O = \{o_1, o_2, \cdots, o_T\}$</code>，估计模型 <code>$\lambda = \left(A, B, \pi\right)$</code> 参数，使得在该模型下观测序列概率 <code>$P\left(X | \lambda \right)$</code> 最大。即用极大似然估计的方法估计参数。</li>
<li>预测问题，也称为解码（decoding）问题。已知模型 <code>$\lambda = \left(A, B, \pi\right)$</code> 和观测序列 <code>$O = \{o_1, o_2, \cdots, o_T\}$</code>，求对给定观测序列条件概率 <code>$P \left(I | O\right)$</code> 最大的状态序列 <code>$I = \{i_1, i_2, \cdots, i_T\}$</code>。即给定观测序列，求最有可能的对应的状态序列。</li>
</ol>

<h3 id="概率计算">概率计算</h3>

<h4 id="直接计算法">直接计算法</h4>

<p>给定模型 <code>$\lambda = \left(A, B, \pi \right)$</code> 和观测序列 <code>$O = \{o_1, o_2, ..., o_T\}$</code>，计算在模型 <code>$\lambda$</code> 下观测序列 <code>$O$</code> 出现的概率 <code>$P\left(O | \lambda \right)$</code>。最简单的办法就是列举出左右可能的状态序列 <code>$I = \{i_1, i_2, ..., i_T\}$</code>，再根据观测概率矩阵 <code>$B$</code>，计算每种状态序列对应的联合概率 <code>$P \left(O, I | \lambda\right)$</code>，对其进行求和得到概率 <code>$P\left(O | \lambda \right)$</code>。</p>

<p>状态序列 <code>$I = \{i_1, i_2, ..., i_T\}$</code> 的概率是：</p>

<p><code>$$
P \left(I | \lambda \right) = \pi_{y_1} \prod_{t = 1}^{T - 1} a_{{i_t}{i_{t+1}}}
$$</code></p>

<p>对于固定的状态序列 <code>$I = \{i_1, i_2, ..., i_T\}$</code>，观测序列 <code>$O = \{o_1, o_2, ..., o_T\}$</code> 的概率是：</p>

<p><code>$$
P \left(O | I, \lambda \right) = \prod_{t = 1}^{T} b_{i_t} \left(o_t\right)
$$</code></p>

<p><code>$O$</code> 和 <code>$I$</code> 同时出现的联合概率为：</p>

<p><code>$$
\begin{split}
P \left(O, I | \lambda \right) &amp;= P \left(O | I, \lambda \right) P \left(I | \lambda \right) \\
&amp;= \pi_{y_1} \prod_{t = 1}^{T - 1} a_{{i_t}{i_{t+1}}} \prod_{t = 1}^{T} b_{i_t} \left(o_t\right)
\end{split}
$$</code></p>

<p>然后，对于所有可能的状态序列 <code>$I$</code> 求和，得到观测序列 <code>$O$</code> 的概率 <code>$P \left(O | \lambda\right)$</code>，即：</p>

<p><code>$$
\begin{split}
P\left(O | \lambda \right) &amp;= \sum_{I} P \left(O | I, \lambda \right) P \left(I | \lambda \right)  \\
&amp;= \sum_{i_1, i_2, \cdots, i_T} \pi_{y_1} \prod_{t = 1}^{T - 1} a_{{i_t}{i_{t+1}}} \prod_{t = 1}^{T} b_{i_t} \left(o_t\right)
\end{split}
$$</code></p>

<p>但利用上式的计算量很大，是 <code>$O \left(T N^T\right)$</code> 阶的，这种算法不可行。</p>

<h4 id="前向算法">前向算法</h4>

<p><strong>前向概率</strong>：给定马尔可夫模型 <code>$\lambda$</code>，给定到时刻 <code>$t$</code> 部分观测序列为 <code>$o_1, o_2, \cdots, o_t$</code> 且状态为 <code>$q_i$</code> 的概率为前向概率，记作：</p>

<p><code>$$
\alpha_t \left(i\right) = P \left(o_1, o_2, \cdots, o_t, i_t = q_i | \lambda\right)
$$</code></p>

<p>可以递推地求得前向概率 <code>$\alpha_t \left(i\right)$</code> 及观测序列概率 <code>$P \left(O | \lambda\right)$</code>，前向算法如下：</p>

<ol>
<li>初值
<code>$$
\alpha_{1}(i)=\pi_{i} b_{i}\left(o_{1}\right), \quad i=1,2, \cdots, N
$$</code></li>
<li>递推，对 <code>$t = 1, 2, \cdots, T-1$</code>
<code>$$
\alpha_{t+1}(i)=\left[\sum_{j=1}^{N} \alpha_{t}(j) a_{j i}\right] b_{i}\left(o_{t+1}\right), \quad i=1,2, \cdots, N
$$</code></li>
<li>终止
<code>$$
P(O | \lambda)=\sum_{i=1}^{N} \alpha_{T}(i)
$$</code></li>
</ol>

<h4 id="后向算法">后向算法</h4>

<p><strong>后向概率</strong>：给定隐马尔可夫模型 <code>$\lambda$</code>，给定在时刻 <code>$t$</code> 状态为 <code>$q_i$</code> 的条件下，从 <code>$t+1$</code> 到 <code>$T$</code> 的部分观测序列为 <code>$o_{t+1}, o_{t+2}, \cdots, o_T$</code> 的概率为后向概率，记作：</p>

<p><code>$$
\beta_{t}(i)=P\left(o_{t+1}, o_{t+2}, \cdots, o_{T} | i_{t}=q_{i}, \lambda\right)
$$</code></p>

<p>可以递推地求得后向概率 <code>$\alpha_t \left(i\right)$</code> 及观测序列概率 <code>$P \left(O | \lambda\right)$</code>，后向算法如下：</p>

<ol>
<li>初值
<code>$$
\beta_{T}(i)=1, \quad i=1,2, \cdots, N
$$</code></li>
<li>递推，对 <code>$t = T-1, T-2, \cdots, 1$</code>
<code>$$
\beta_{t}(i)=\sum_{j=1}^{N} a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j), \quad i=1,2, \cdots, N
$$</code></li>
<li>终止
<code>$$
P(O | \lambda)=\sum_{i=1}^{N} \pi_{i} b_{i}\left(o_{1}\right) \beta_{1}(i)
$$</code></li>
</ol>

<h3 id="学习算法">学习算法</h3>

<h4 id="监督学习算法">监督学习算法</h4>

<p>假设以给训练数据包含 <code>$S$</code> 个长度相同的观测序列和对应的状态序列 <code>$\left\{\left(O_1, I_1\right), \left(O_2, I_2\right), \cdots, \left(O_S, I_S\right)\right\}$</code>，那么可以利用极大似然估计法来估计隐马尔可夫模型的参数。</p>

<p>设样本中时刻 <code>$t$</code> 处于状态 <code>$i$</code> 时刻 <code>$t+1$</code> 转移到状态 <code>$j$</code> 的频数为 <code>$A_{ij}$</code>，那么转移概率 <code>$a_{ij}$</code> 的估计是：</p>

<p><code>$$
\hat{a}_{i j}=\frac{A_{i j}}{\sum_{j=1}^{N} A_{i j}}, \quad i=1,2, \cdots, N ; \quad j=1,2, \cdots, N
$$</code></p>

<p>设样本中状态为 <code>$j$</code> 并观测为 <code>$k$</code> 的频数是 <code>$B_{jk}$</code>，那么状态为 <code>$j$</code> 观测为 <code>$k$</code> 的概率 <code>$b_j \left(k\right)$</code> 的估计是：</p>

<p><code>$$
\hat{b}_{j}(k)=\frac{B_{j k}}{\sum_{k=1}^{M} B_{j k}}, \quad j=1,2, \cdots, N ; \quad k=1,2, \cdots, M
$$</code></p>

<p>初始状态概率 <code>$\pi_i$</code> 的估计 <code>$\hat{\pi}_i$</code> 为 <code>$S$</code> 个样本中初始状态为 <code>$q_i$</code> 的频率。</p>

<h4 id="无监督学习算法">无监督学习算法</h4>

<p>假设给定训练数据值包含 <code>$S$</code> 个长度为 <code>$T$</code> 的观测序列 <code>$\left\{O_1, O_2, \cdots, O_S\right\}$</code> 而没有对应的状态序例，目标是学习隐马尔可夫模型 <code>$\lambda = \left(A, B, \pi\right)$</code> 的参数。我们将观测序列数据看做观测数据 <code>$O$</code>，状态序列数据看作不可观测的隐数据 <code>$I$</code>，那么马尔可夫模型事实上是一个含有隐变量的概率模型：</p>

<p><code>$$
P(O | \lambda)=\sum_{I} P(O | I, \lambda) P(I | \lambda)
$$</code></p>

<p>它的参数学习可以由 EM 算法实现。EM 算法在隐马尔可夫模型学习中的具体实现为 Baum-Welch 算法：</p>

<ol>
<li>初始化。对 <code>$n = 0$</code>，选取 <code>$a_{i j}^{(0)}, b_{j}(k)^{(0)}, \pi_{i}^{(0)}$</code>，得到模型 <code>$\lambda^{(0)}=\left(A^{(0)}, B^{(0)}, \pi^{(0)}\right)$</code>。</li>
<li>递推。对 <code>$n = 1, 2, \cdots$</code>：
<code>$$
\begin{aligned}
a_{i j}^{(n+1)} &amp;= \frac{\sum_{t=1}^{T-1} \xi_{t}(i, j)}{\sum_{t=1}^{T-1} \gamma_{t}(i)} \\
b_{j}(k)^{(n+1)} &amp;= \frac{\sum_{t=1, o_{t}=v_{k}}^{T} \gamma_{t}(j)}{\sum_{t=1}^{T} \gamma_{t}(j)} \\
\pi_{i}^{(n+1)} &amp;= \gamma_{1}(i)
\end{aligned}
$$</code>
右端各按照观测 <code>$O=\left(o_{1}, o_{2}, \cdots, o_{T}\right)$</code> 和模型 <code>$\lambda^{(n)}=\left(A^{(n)}, B^{(n)}, \pi^{(n)}\right)$</code> 计算，
<code>$$
\begin{aligned}
\gamma_{t}(i) &amp;= \frac{\alpha_{t}(i) \beta_{t}(i)}{P(O | \lambda)}=\frac{\alpha_{t}(i) \beta_{t}(i)}{\sum_{j=1}^{N} \alpha_{t}(j) \beta_{t}(j)} \\
\xi_{t}(i, j) &amp;= \frac{\alpha_{t}(i) a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j)}{\sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{t}(i) a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j)}
\end{aligned}
$$</code></li>
<li>终止。得到模型参数 <code>$\lambda^{(n+1)}=\left(A^{(n+1)}, B^{(n+1)}, \pi^{(n+1)}\right)$</code>。</li>
</ol>

<h3 id="预测算法">预测算法</h3>

<h4 id="近似算法">近似算法</h4>

<p>近似算法的思想是，在每个时刻 <code>$t$</code> 选择在该时刻最有可能出现的状态 <code>$i_t^*$</code>，从而得到一个状态序列 <code>$I^{*}=\left(i_{1}^{*}, i_{2}^{*}, \cdots, i_{T}^{*}\right)$</code>，将它作为预测的结果。给定隐马尔可夫模型 <code>$\lambda$</code> 和观测序列 <code>$O$</code>，在时刻 <code>$t$</code> 处于状态 <code>$q_i$</code> 的概率 <code>$\gamma_t \left(i\right)$</code> 是：</p>

<p><code>$$
\gamma_{t}(i)=\frac{\alpha_{t}(i) \beta_{t}(i)}{P(O | \lambda)}=\frac{\alpha_{t}(i) \beta_{t}(i)}{\sum_{j=1}^{N} \alpha_{t}(j) \beta_{t}(j)}
$$</code></p>

<p>在每一时刻 <code>$t$</code> 最有可能的状态 <code>$i_t^*$</code> 是：</p>

<p><code>$$
i_{t}^{*}=\arg \max _{1 \leqslant i \leqslant N}\left[\gamma_{t}(i)\right], \quad t=1,2, \cdots, T
$$</code></p>

<p>从而得到状态序列 <code>$I^{*}=\left(i_{1}^{*}, i_{2}^{*}, \cdots, i_{T}^{*}\right)$</code>。</p>

<p>近似算法的优点是计算简单，其缺点是不能保证预测的状态序列整体是最有可能的状态序列，因为预测的状态序列可能有实际不发生的部分。事实上，上述方法得到的状态序列中有可能存在转移概率为0的相邻状态，即对某些 <code>$i, j, a_{ij} = 0$</code> 。尽管如此，近似算法仍然是有用的。</p>

<h4 id="维特比算法">维特比算法</h4>

<p>维特比算法（Viterbi Algorithm）实际是用动态规划（Dynamic Programming）解隐马尔可夫模型预测问题，即用动态规划求概率最大路径（最优路径）。这时一条路径对应着一个状态序列。</p>

<p>首先导入两个变量 <code>$\sigma$</code> 和 <code>$\Psi$</code>。定义在时刻 <code>$t$</code> 状态为 <code>$i$</code> 的所有单个路径 <code>$\left(i_1, i_2, \cdots, i_t\right)$</code> 中概率最大值为：</p>

<p><code>$$
\delta_{t}(i)=\max _{i_{1}, i_{2}, \cdots, i_{t-1}} P\left(i_{t}=i, i_{t-1}, \cdots, i_{1}, o_{t}, \cdots, o_{1} | \lambda\right), \quad i=1,2, \cdots, N
$$</code></p>

<p>由定义可得变量 <code>$\sigma$</code> 的递推公式：</p>

<p><code>$$
\begin{aligned}
\delta_{t+1}(i) &amp;=\max _{i_{1}, i_{2}, \cdots, i_{t}} P\left(i_{t+1}=i, i_{t}, \cdots, i_{1}, o_{t+1}, \cdots, o_{1} | \lambda\right) \\
&amp;=\max _{1 \leqslant j \leqslant N}\left[\delta_{t}(j) a_{j i}\right] b_{i}\left(o_{t+1}\right), \quad i=1,2, \cdots, N ; \quad t=1,2, \cdots, T-1
\end{aligned}
$$</code></p>

<p>定义在时刻 <code>$t$</code> 状态为 <code>$i$</code> 的所有单个路径 <code>$\left(i_1, i_2, \cdots, i_{t-1}, i\right)$</code> 中概率最大的路径的第 <code>$t - 1$</code> 个结点为：</p>

<p><code>$$
\Psi_{t}(i)=\arg \max _{1 \leqslant j \leqslant N}\left[\delta_{t-1}(j) a_{j i}\right], \quad i=1,2, \cdots, N
$$</code></p>

<p>维特比算法流程如下：</p>

<ol>
<li>初始化
<code>$$
\begin{array}{c}
\delta_{1}(i)=\pi_{i} b_{i}\left(o_{1}\right), \quad i=1,2, \cdots, N \\
\Psi_{1}(i)=0, \quad i=1,2, \cdots, N
\end{array}
$$</code></li>
<li>递推。对 <code>$t = 2, 3, \cdots, T$</code>
<code>$$
\begin{array}{c}
\delta_{t}(i)=\max _{1 \leqslant j \leqslant N}\left[\delta_{t-1}(j) a_{j i}\right] b_{i}\left(o_{t}\right), \quad i=1,2, \cdots, N \\
\Psi_{t}(i)=\arg \max _{1 \leqslant j \leqslant N}\left[\delta_{t-1}(j) a_{j i}\right], \quad i=1,2, \cdots, N
\end{array}
$$</code></li>
<li>终止。
<code>$$
\begin{array}{c}
P^{*}=\max _{1 \leqslant i \leqslant N} \delta_{T}(i) \\
i_{T}^{*}=\arg \max _{1 \leqslant i \leqslant N}\left[\delta_{T}(i)\right]
\end{array}
$$</code></li>
<li>最优路径回溯。对 <code>$t = T - 1, T - 2, \cdots, 1$</code>
<code>$$
i_{t}^{*}=\Psi_{t+1}\left(i_{t+1}^{*}\right)
$$</code></li>
</ol>

<p>求的最优路径 <code>$I^{*}=\left(i_{1}^{*}, i_{2}^{*}, \cdots, i_{T}^{*}\right)$</code>。</p>

<h2 id="条件随机场">条件随机场</h2>

<p>概率无向图模型（Probabilistic Undirected Graphical Model）又称为马尔可夫随机场（Markov Random Field），是一个可以由无向图表示的联合概率分布。概率图模型（Probabilistic Graphical Model）是由图表示的概率分布，设有联合概率分布 <code>$P \left(Y\right), Y \in \mathcal{Y}$</code> 是一组随机变量。由无向图 <code>$G = \left(V, E\right)$</code> 表示概率分布 <code>$P \left(Y\right)$</code>，即在图 <code>$G$</code> 中，结点 <code>$v \in V$</code> 表示一个随机变量 <code>$Y_v, Y = \left(Y_v\right)_{v \in V}$</code>，边 <code>$e \in E$</code> 表示随机变量之间的概率依赖关系。</p>

<p><strong>成对马尔可夫性</strong>：设 <code>$u$</code> 和 <code>$v$</code> 是无向图 <code>$G$</code> 中任意两个没有边连接的结点，结点 <code>$u$</code> 和 <code>$v$</code> 分别对应随机变量 <code>$Y_u$</code> 和 <code>$Y_v$</code>。其他所有结点为 <code>$O$</code>，对应的随机变量组是 <code>$Y_O$</code>。成对马尔可夫是指给定随机变量组 <code>$Y_O$</code> 的条件下随机变量 <code>$Y_u$</code> 和 <code>$Y_v$</code> 是条件独立的，即：</p>

<p><code>$$
P\left(Y_{u}, Y_{v} | Y_{O}\right)=P\left(Y_{u} | Y_{O}\right) P\left(Y_{v} | Y_{O}\right)
$$</code></p>

<p><strong>局部马尔可夫性</strong>：设 <code>$v \in V$</code> 是无向图 <code>$G$</code> 中任意一个结点，<code>$W$</code> 是与 <code>$v$</code> 有边连接的所有结点，<code>$O$</code> 是 <code>$v$</code> 和 <code>$W$</code> 以外的其他所有结点。<code>$v$</code> 表示的随机变量是 <code>$Y_v$</code>，<code>$W$</code> 表示的随机变量组是 <code>$Y_W$</code>，<code>$O$</code> 表示的随机变量组是 <code>$Y_O$</code>。局部马尔可夫性是指在给定随机变量组 <code>$Y_W$</code> 的条件下随机变量 <code>$Y_v$</code> 与随机变量组 <code>$Y_O$</code> 是独立的，即：</p>

<p><code>$$
P\left(Y_{v}, Y_{O} | Y_{W}\right)=P\left(Y_{v} | Y_{W}\right) P\left(Y_{O} | Y_{W}\right)
$$</code></p>

<p>在 <code>$P \left(Y_O | Y_W\right) &gt; 0$</code> 时，等价地：</p>

<p><code>$$
P\left(Y_{v} | Y_{W}\right)=P\left(Y_{v} | Y_{W}, Y_{O}\right)
$$</code></p>

<p>局部马尔可夫性如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/local-markov.png" class="lazyload"/>
  
</figure>

<p><strong>全局马尔可夫性</strong>：设结点结合 <code>$A, B$</code> 是在无向图 <code>$G$</code> 中被结点集合 <code>$C$</code> 分开的任意结点集合，如下图所示。结点集合 <code>$A, B$</code> 和 <code>$C$</code> 所对应的随机变量组分别是 <code>$Y_A, Y_B$</code> 和 <code>$Y_C$</code>。全局马尔可夫性是指给定随机变量组 <code>$Y_C$</code> 条件下随机变量组 <code>$Y_A$</code> 和 <code>$Y_B$</code> 是条件独立的，即：</p>

<p><code>$$
P\left(Y_{A}, Y_{B} | Y_{C}\right)=P\left(Y_{A} | Y_{C}\right) P\left(Y_{B} | Y_{C}\right)
$$</code></p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/global-markov.png" class="lazyload"/>
  
</figure>

<p><strong>概率无向图模型</strong>定义为：设有联合概率分布 <code>$P \left(Y\right)$</code>，由无向图 <code>$G = \left(V, E\right)$</code> 表示，在图 <code>$G$</code> 中，结点表示随机变量，边表示随机变量之间的依赖关系。如果联合概率分布 <code>$P \left(Y\right)$</code> 满足成对、局部或全局马尔可夫性，就称此联合概率分布为概率无向图模型（Probabilistic Undirected Graphical Model），或马尔可夫随机场（Markov Random Field）。</p>

<p><strong>团与最大团</strong>：无向图 <code>$G$</code> 中任何两个结点均有边连接的结点子集称为团（Clique）。若 <code>$C$</code> 是无向图 <code>$G$</code> 的一个团，并且不能再加进任何一个 <code>$G$</code> 的结点时期成为一个更大的团，则称此 <code>$C$</code> 为最大团（Maximal Clique）。</p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/clique.png" class="lazyload"/>
  <figcaption><p class="figcaption">无向图的团和最大团</p></figcaption>
</figure>

<p>上图表示 4 个结点组成的无向图。图中有 2 个结点组成的团有 5 个：<code>$\left\{Y_1, Y_2\right\}$</code>，<code>$\left\{Y_2, Y_3\right\}$</code>，<code>$\left\{Y_3, Y_4\right\}$</code>，<code>$\left\{Y_4, Y_2\right\}$</code> 和 <code>$\left\{Y_1, Y_3\right\}$</code>。有 2 个最大团：<code>$\left\{Y_1, Y_2, Y_3\right\}$</code> 和 <code>$\left\{Y_2, Y_3, Y_4\right\}$</code>。而 <code>$\left\{Y_1, Y_2, Y_3, Y_4\right\}$</code> 不是一个团，因为 <code>$Y_1$</code> 和 <code>$Y_4$</code> 没有边连接。</p>

<p>将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解。给定无向图模型，设其无向图为 <code>$G$</code>，<code>$C$</code> 为 <code>$G$</code> 上的最大团，<code>$Y_C$</code> 表示 <code>$C$</code> 对应的随机变量。那么概率无向图模型的联合概率分布 <code>$P \left(Y\right)$</code> 可以写作图中所有最大团 <code>$C$</code> 上的函数 <code>$\Psi_C \left(Y_C\right)$</code> 的乘积形式，即：</p>

<p><code>$$
P(Y)=\frac{1}{Z} \prod_{C} \Psi_{C}\left(Y_{C}\right)
$$</code></p>

<p>其中，<code>$Z$</code> 是规范化因子：</p>

<p><code>$$
Z=\sum_{Y} \prod_{C} \Psi_{C}\left(Y_{C}\right)
$$</code></p>

<p>规范化因子保证 <code>$P \left(Y\right)$</code> 构成一个概率分布。函数 <code>$\Psi_C \left(Y_C\right)$</code> 称为<strong>势函数</strong>，这里要求势函数 <code>$\Psi_C \left(Y_C\right)$</code> 是严格正的，通常定义为指数函数：</p>

<p><code>$$
\Psi_{C}\left(Y_{C}\right)=\exp \left\{-E\left(Y_{C}\right)\right\}
$$</code></p>

<p>概率无向图模型的因子分解由这个 Hammersley-Clifford 定理来保证。</p>

<p><strong>条件随机场</strong>（Conditional Random Field）是给定随机变量 <code>$X$</code> 条件下，随机变量 <code>$Y$</code> 的马尔可夫随机场。设 <code>$X$</code> 与 <code>$Y$</code> 是随机变量，<code>$P \left(Y | X\right)$</code> 是给定 <code>$X$</code> 的条件下 <code>$Y$</code> 的条件概率分布。若随机变量 <code>$Y$</code> 构成一个有无向图 <code>$G = \left(V, E\right)$</code> 表示的马尔可夫随机场，即：</p>

<p><code>$$
P\left(Y_{v} | X, Y_{w}, w \neq v\right)=P\left(Y_{v} | X, Y_{w}, w \sim v\right)
$$</code></p>

<p>对任意结点 <code>$v$</code> 成立，则称条件概率分布 <code>$P \left(Y | X\right)$</code> 为条件随机场。其中，<code>$w \sim v$</code> 表示在图 <code>$G = \left(V, E\right)$</code> 中与结点 <code>$v$</code> 有边连接的所有结点 <code>$w$</code>，<code>$w \neq v$</code> 表示结点 <code>$v$</code> 以外的所有结点，<code>$Y_v, Y_u$</code> 与 <code>$Y_w$</code> 为结点 <code>$v, u$</code> 和 <code>$w$</code> 对应的随机变量。</p>

<p>定义中并没有要求 <code>$X$</code> 和 <code>$Y$</code> 具有相同的结构，一般假设 <code>$X$</code> 和 <code>$Y$</code> 有相同的图结构，下图展示了无向图的线性链情况，即：</p>

<p><code>$$
G=(V=\{1,2, \cdots, n\}, E=\{(i, i+1)\}), \quad i=1,2, \cdots, n-1
$$</code></p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/linear-crf-1.png" class="lazyload"/>
  <figcaption><p class="figcaption">线性链条件随机场</p></figcaption>
</figure>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/linear-crf-2.png" class="lazyload"/>
  <figcaption><p class="figcaption">X 和 Y 有相同的图结构的线性链条件随机场</p></figcaption>
</figure>

<p>此情况下，<code>$X=\left(X_{1}, X_{2}, \cdots, X_{n}\right), Y=\left(Y_{1}, Y_{2}, \cdots, Y_{n}\right)$</code>，最大团是相邻两个结点的集合。</p>

<p><strong>线性链条件随机场</strong>：设 <code>$X=\left(X_{1}, X_{2}, \cdots, X_{n}\right), Y=\left(Y_{1}, Y_{2}, \cdots, Y_{n}\right)$</code> 均为线性链表示的随机变量序列，若在给定随机变量序列 <code>$X$</code> 的条件下，随机变量序列 <code>$Y$</code> 的条件概率分布 <code>$P \left(Y | X\right)$</code> 构成条件随机场，即满足马尔可夫性：</p>

<p><code>$$
\begin{array}{c}
P\left(Y_{i} | X, Y_{1}, \cdots, Y_{i-1}, Y_{i+1}, \cdots, Y_{n}\right)=P\left(Y_{i} | X, Y_{i-1}, Y_{i+1}\right) \\
i=1,2, \cdots, n \quad (\text { 在 } i=1 \text { 和 } n \text { 时只考虑单边 })
\end{array}
$$</code></p>

<p>则称 <code>$P \left(Y | X\right)$</code> 为线性链条件随机场。在标注问题中，<code>$X$</code> 表示输入观测序列，<code>$Y$</code> 表示对应的输出标记序列或状态序列。</p>

<p>根据 Hammersley-Clifford 定理，设 <code>$P \left(Y | X\right)$</code> 为线性链条件随机场，则在随机变量 <code>$X$</code> 取值为 <code>$x$</code> 的条件下，随机变量 <code>$Y$</code> 取值为 <code>$y$</code> 的条件概率有如下形式：</p>

<p><code>$$
P(y | x)=\frac{1}{Z(x)} \exp \left(\sum_{i, k} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, x, i\right)+\sum_{i, l} \mu_{l} s_{l}\left(y_{i}, x, i\right)\right)
$$</code></p>

<p>其中，</p>

<p><code>$$
Z(x)=\sum_{y} \exp \left(\sum_{i, k} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, x, i\right)+\sum_{i, l} \mu_{l} s_{l}\left(y_{i}, x, i\right)\right)
$$</code></p>

<p>其中，<code>$t_k$</code> 和 <code>$s_l$</code> 是特征函数，<code>$\lambda_k$</code> 和 <code>$\mu_l$</code> 是对应的权值。<code>$Z \left(x\right)$</code> 是规范化因子，求和是在所有可能的输出序列上进行的。</p>

<p>条件随机场的概率计算，学习算法和预测算法类似隐马尔可夫模型，在此不进行过多赘述，有兴趣的同学可以参见 <sup class="footnote-ref" id="fnref:li2019tongji"><a href="#fn:li2019tongji">1</a></sup>。</p>

<p>综上所述，隐马尔可夫模型和条件随机场的主要联系和区别如下：</p>

<ol>
<li>HMM 是概率有向图，CRF 是概率无向图</li>
<li>HMM 是生成模型，CRF 是判别模型</li>
</ol>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/relationship-between-nb-lr-hmm-lcrf-gdm-gcrf.png" class="lazyload"/>
  <figcaption><p class="figcaption">图片来源：An Introduction to Conditional Random Fields</p></figcaption>
</figure>

<p>如上图所示，上面部分为生成式模型，下面部分为判别式模型，生成式模型尝试构建联合分布 <code>$P \left(Y, X\right)$</code>，而判别模型则尝试构建条件分布 <code>$P \left(Y | X\right)$</code>。</p>

<h2 id="序列标注">序列标注</h2>

<p>序列标注（Sequence Labeling）是自然语言处理中的一项重要任务，对于给定的文本序列需要给出对应的标注序列。常见的序列标注任务包含：组块分析（Chunking），词性标注（Part-of-Speech，POS）和命名实体识别（Named Entity Recognition，NER）。</p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/pos-ner-demo.png" class="lazyload"/>
  
</figure>

<p>上图为一段文本的词性标注和命名实体识别的结果。</p>

<h3 id="词性标注">词性标注</h3>

<p>词性标注是指为分词结果中的每个单词标注一个正确的词性，即确定每个词是名词、动词、形容词或其他词性的过程。</p>

<p>一些常用中文标注规范如下：</p>

<ol>
<li>北京大学现代汉语语料库基本加工规范 <sup class="footnote-ref" id="fnref:yu2002pku"><a href="#fn:yu2002pku">2</a></sup></li>
<li>北大语料库加工规范：切分·词性标注·注音 <sup class="footnote-ref" id="fnref:yu2003pku"><a href="#fn:yu2003pku">3</a></sup></li>
<li>计算所汉语词性标记集 3.0（ICTPOS 3.0）<sup class="footnote-ref" id="fnref:liu-ictclas"><a href="#fn:liu-ictclas">4</a></sup></li>
<li>The Part-Of-Speech Tagging Guidelines for the Penn Chinese Treebank (3.0) <sup class="footnote-ref" id="fnref:xia2000pos"><a href="#fn:xia2000pos">5</a></sup></li>
<li>中文文本标注规范（微软亚洲研究院）<sup class="footnote-ref" id="fnref:huang2006tokenization"><a href="#fn:huang2006tokenization">6</a></sup></li>
</ol>

<h3 id="命名实体识别">命名实体识别</h3>

<p>命名实体识别，又称作“专名识别”，是指识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等。简单的讲，就是识别自然文本中的实体指称的边界和类别。</p>

<p>常用的标注标准有 IO，BIO，BIOES，BMEWO 和 BMEWO+ 等。（参考自：<a href="https://lingpipe-blog.com/2009/10/14/coding-chunkers-as-taggers-io-bio-bmewo-and-bmewo/" rel="noreferrer" target="_blank">Coding Chunkers as Taggers: IO, BIO, BMEWO, and BMEWO+</a>）</p>

<ol>
<li>IO 标注标准是最简单的标注方式，对于命名实体类别 X 标注为 <code>I_X</code>，其他则标注为 <code>O</code>。由于没有标签界线表示，这种方式无法表示两个相邻的同类命名实体。</li>
<li>BIO 标注标准将命名实体的起始部分标记为 <code>B_X</code>，其余部分标记为 <code>I_X</code>。</li>
<li>BIOES 标注标准将命名实体的起始部分标记为 <code>B_X</code>，中间部分标记为 <code>I_X</code>，结尾部分标记为 <code>E_X</code>，对于单个字符成为命名实体的情况标记为 <code>S_X</code>。</li>
<li>BMEWO 标注标准将命名实体的起始部分标记为 <code>B_X</code>，中间部分标记为 <code>M_X</code>，结尾部分标记为 <code>E_X</code>，对于单个字符成为命名实体的情况标记为 <code>W_X</code>。</li>
<li>BMEWO+ 标注标准在 BMEWO 的基础上针对不同情况的非命名实体标签的标注进行了扩展，同时增加了一个句外（out-of-sentence）标签 <code>W_OOS</code>，句子起始标签 <code>BB_O_OOS</code> 和句子结束标签 <code>WW_O_OOS</code>，如 <a href="http://www.alias-i.com/lingpipe/docs/api/com/aliasi/chunk/HmmChunker.html" rel="noreferrer" target="_blank">下表</a> 所示：</li>
</ol>

<table>
<thead>
<tr>
<th>标签</th>
<th>描述</th>
<th>可能上接的标签</th>
<th>可能下接的标签</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>B_X</code></td>
<td>命名实体类型 X 的起始</td>
<td><code>E_Y, W_Y, EE_O_X, WW_O_X</code></td>
<td><code>M_X, W_X</code></td>
</tr>

<tr>
<td><code>M_X</code></td>
<td>命名实体类型 X 的中间</td>
<td><code>B_X, M_X</code></td>
<td><code>M_X, W_X</code></td>
</tr>

<tr>
<td><code>E_X</code></td>
<td>命名实体类型 X 的结尾</td>
<td><code>B_X, M_X</code></td>
<td><code>B_Y, W_Y, BB_O_X, WW_O_X</code></td>
</tr>

<tr>
<td><code>W_X</code></td>
<td>命名实体类型 X 的单个字符</td>
<td><code>E_Y, W_Y, EE_O_X, WW_O_X</code></td>
<td><code>B_Y, W_Y, BB_O_X, WW_O_X</code></td>
</tr>

<tr>
<td><code>BB_O_X</code></td>
<td>非命名实体的起始，上接命名实体类型 X</td>
<td><code>E_X, W_X</code></td>
<td><code>MM_O, EE_O_Y</code></td>
</tr>

<tr>
<td><code>MM_O</code></td>
<td>非命名实体的中间</td>
<td><code>BB_O_Y, MM_O</code></td>
<td><code>MM_O, EE_O_Y</code></td>
</tr>

<tr>
<td><code>EE_O_X</code></td>
<td>非命名实体的结尾，下接命名实体类型 X</td>
<td><code>BB_O_Y, MM_O</code></td>
<td><code>B_X, W_X</code></td>
</tr>

<tr>
<td><code>WW_O_X</code></td>
<td>非命名实体，上接命名实体，下接命名实体类型 X</td>
<td><code>E_X, W_X</code></td>
<td><code>B_Y, W_Y</code></td>
</tr>
</tbody>
</table>

<p>不同标注标准的差别示例如下：</p>

<table>
<thead>
<tr>
<th>字符</th>
<th>IO</th>
<th>BIO</th>
<th>BIOES</th>
<th>BMEWO</th>
<th>BMEWO+</th>
</tr>
</thead>

<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><code>W_OOS</code></td>
</tr>

<tr>
<td>Yesterday</td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>BB_O_OOS</code></td>
</tr>

<tr>
<td>afternoon</td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>MM_O</code></td>
</tr>

<tr>
<td>,</td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>EE_O_PER</code></td>
</tr>

<tr>
<td>John</td>
<td><code>I_PER</code></td>
<td><code>B_PER</code></td>
<td><code>B_PER</code></td>
<td><code>B_PER</code></td>
<td><code>B_PER</code></td>
</tr>

<tr>
<td>J</td>
<td><code>I_PER</code></td>
<td><code>I_PER</code></td>
<td><code>I_PER</code></td>
<td><code>M_PER</code></td>
<td><code>M_PER</code></td>
</tr>

<tr>
<td>.</td>
<td><code>I_PER</code></td>
<td><code>I_PER</code></td>
<td><code>I_PER</code></td>
<td><code>M_PER</code></td>
<td><code>M_PER</code></td>
</tr>

<tr>
<td>Smith</td>
<td><code>I_PER</code></td>
<td><code>I_PER</code></td>
<td><code>E_PER</code></td>
<td><code>E_PER</code></td>
<td><code>E_PER</code></td>
</tr>

<tr>
<td>traveled</td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>BB_O_PER</code></td>
</tr>

<tr>
<td>to</td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>EE_O_LOC</code></td>
</tr>

<tr>
<td>Washington</td>
<td><code>I_LOC</code></td>
<td><code>B_LOC</code></td>
<td><code>S_LOC</code></td>
<td><code>W_LOC</code></td>
<td><code>W_LOC</code></td>
</tr>

<tr>
<td>.</td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>O</code></td>
<td><code>WW_O_OOS</code></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><code>W_OOS</code></td>
</tr>
</tbody>
</table>

<p>不同标准的标签数量如下表所示：</p>

<table>
<thead>
<tr>
<th>标注标准</th>
<th>标签数量</th>
<th>N=1</th>
<th>N=3</th>
<th>N=20</th>
</tr>
</thead>

<tbody>
<tr>
<td>IO</td>
<td>N+1</td>
<td>2</td>
<td>4</td>
<td>21</td>
</tr>

<tr>
<td>BIO</td>
<td>2N+1</td>
<td>3</td>
<td>7</td>
<td>41</td>
</tr>

<tr>
<td>BIOES</td>
<td>4N+1</td>
<td>5</td>
<td>13</td>
<td>81</td>
</tr>

<tr>
<td>BMEWO</td>
<td>4N+1</td>
<td>5</td>
<td>13</td>
<td>81</td>
</tr>

<tr>
<td>BMEWO+</td>
<td>7N+3</td>
<td>10</td>
<td>24</td>
<td>143</td>
</tr>
</tbody>
</table>

<p>其中，N 为命名实体类型的数量。</p>

<h4 id="bilstm-crf-huang2015bidirectional">BiLSTM CRF <sup class="footnote-ref" id="fnref:huang2015bidirectional"><a href="#fn:huang2015bidirectional">7</a></sup></h4>

<blockquote>
<p>本小节内容参考和修改自 <a href="https://github.com/createmomo/CRF-Layer-on-the-Top-of-BiLSTM" rel="noreferrer" target="_blank">CRF-Layer-on-the-Top-of-BiLSTM</a>。</p>
</blockquote>

<p>Huang 等人提出了一种基于 BiLSTM 和 CRF 的神经网络模型用于序例标注。整个网络如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/bilstm-crf.png" class="lazyload"/>
  
</figure>

<p>关于模型中的 BiLSTM 部分在此不过多赘述，相关细节可以参见之前的博客：<a href="/cn/2018/09/rnn/">循环神经网络 (Recurrent Neural Network, RNN)</a> 和 <a href="/cn/2020/03/pre-trained-model-for-nlp/">预训练自然语言模型 (Pre-trained Models for NLP)</a>。BiLSTM-CRF 模型的输入是词嵌入向量，输出是对应的预测标注标签，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/bilstm-crf-1.png" class="lazyload"/>
  
</figure>

<p>BiLSTM 层的输出为每个标签的分数，对于 <code>$w_0$</code>，BiLSTM 的输出为 1.5 (<code>B_PER</code>)，0.9 (<code>I_PER</code>)，0.1 (<code>B_ORG</code>)，0.08 (<code>I_ORG</code>) 和 0.05 (<code>O</code>)，这些分数为 CRF 层的输入，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/bilstm-crf-2.png" class="lazyload"/>
  
</figure>

<p>经过 CRF 层后，具有最高分数的预测序列被选择为最优预测结果。如果没有 CRF 层，我们可以直接选择 BiLSTM 层输出分数的最大值对应的序列为预测结果。例如，对于 <code>$w_0$</code>，最高分数为 1.5，对应的预测标签则为 <code>B_PER</code>，类似的 <code>$w_1, w_2, w_3, w_4$</code> 对应的预测标签为 <code>I_PER, O, B_ORG, O</code>，如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/bilstm-crf-3.png" class="lazyload"/>
  
</figure>

<p>虽然我们在上例中得到了正确的结果，但通常情况下并非如此。对于如下的示例，预测结果为 <code>I_ORG, I_PER, O, I_ORG, I_PER</code>，这显然是不正确的。</p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/bilstm-crf-4.png" class="lazyload"/>
  
</figure>

<p>CRF 层在进行预测时可以添加一些约束，这些约束可以在训练时被 CRF 层学习得到。可能的约束有：</p>

<ul>
<li>句子的第一个词的标签可以是 <code>B_X</code> 或 <code>O</code>，而非 <code>I_X</code>。</li>
<li><code>B_X, I_X</code> 是有效的标签，而 <code>B_X, I_Y</code> 是无效的标签。</li>
<li>一个命名实体的起始标签应为 <code>B_X</code> 而非 <code>I_X</code>。</li>
</ul>

<p>CRF 层的损失包含两部分，这两部分构成了 CRF 层的关键：</p>

<ul>
<li>发射分数（Emission Score）<br /></li>
</ul>

<p>发射分数即为 BiLSTM 层的输出分数，例如 <code>$w_0$</code> 对应的标签 <code>B_PER</code> 的分数为 1.5。为了方便起见，对于每类标签给定一个索引：</p>

<table>
<thead>
<tr>
<th>标签</th>
<th>索引</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>B_PER</code></td>
<td>0</td>
</tr>

<tr>
<td><code>I_PER</code></td>
<td>1</td>
</tr>

<tr>
<td><code>B_ORG</code></td>
<td>2</td>
</tr>

<tr>
<td><code>I_ORG</code></td>
<td>3</td>
</tr>

<tr>
<td><code>O</code></td>
<td>4</td>
</tr>
</tbody>
</table>

<p>我们利用 <code>$x_{i y_{j}}$</code> 表示发射分数，<code>$i$</code> 为词的索引，<code>$y_i$</code> 为标注标签的索引。例如：<code>$x_{i=1, y_{j}=2} = x_{w_1, \text{B_ORG}} = 0.1$</code>，表示 <code>$w_1$</code> 为 <code>B_ORG</code> 的分数为 0.1。</p>

<ul>
<li>转移分数（Transition Score）</li>
</ul>

<p>我们利用 <code>$t_{y_i, y_j}$</code> 表示转移分数，例如 <code>$t_{\text{B_PER}, \text{I_PER}} = 0.9$</code> 表示由标签 <code>B_PER</code> 转移到 <code>I_PER</code> 的分数为 0.9。因此，需要一个转移分数矩阵用于存储所有标注标签之间的转移分数。为了使得转移分数矩阵更加鲁棒，需要添加两个标签 <code>START</code> 和 <code>END</code>，分别表示一个句子的开始和结束。下表为一个转移分数矩阵的示例：</p>

<table>
<thead>
<tr>
<th></th>
<th><code>START</code></th>
<th><code>B-PER</code></th>
<th><code>I-PER</code></th>
<th><code>B-ORG</code></th>
<th><code>I-ORG</code></th>
<th><code>O</code></th>
<th><code>END</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><code>START</code></td>
<td>0</td>
<td>0.8</td>
<td>0.007</td>
<td>0.7</td>
<td>0.0008</td>
<td>0.9</td>
<td>0.08</td>
</tr>

<tr>
<td><code>B_PER</code></td>
<td>0</td>
<td>0.6</td>
<td>0.9</td>
<td>0.2</td>
<td>0.0006</td>
<td>0.6</td>
<td>0.009</td>
</tr>

<tr>
<td><code>I_PER</code></td>
<td>-1</td>
<td>0.5</td>
<td>0.53</td>
<td>0.55</td>
<td>0.0003</td>
<td>0.85</td>
<td>0.008</td>
</tr>

<tr>
<td><code>B_ORG</code></td>
<td>0.9</td>
<td>0.5</td>
<td>0.0003</td>
<td>0.25</td>
<td>0.8</td>
<td>0.77</td>
<td>0.006</td>
</tr>

<tr>
<td><code>I_ORG</code></td>
<td>-0.9</td>
<td>0.45</td>
<td>0.007</td>
<td>0.7</td>
<td>0.65</td>
<td>0.76</td>
<td>0.2</td>
</tr>

<tr>
<td><code>O</code></td>
<td>0</td>
<td>0.65</td>
<td>0.0007</td>
<td>0.7</td>
<td>0.0008</td>
<td>0.9</td>
<td>0.08</td>
</tr>

<tr>
<td><code>END</code></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>转移分数矩阵作为 BiLSTM-CRF 模型的一个参数，随机初始化并通过模型的训练不断更新，最终学习得到约束条件。</p>

<p>CRF 层的损失函数包含两个部分：真实路径分数和所有可能路径的总分数。假设每个可能的路径有一个分数 <code>$P_i$</code>，共 <code>$N$</code> 种可能的路径，所有路径的总分数为：</p>

<p><code>$$
P_{\text {total}}=P_{1}+P_{2}+\ldots+P_{N}=e^{S_{1}}+e^{S_{2}}+\ldots+e^{S_{N}}
$$</code></p>

<p>则损失函数定义为：</p>

<p><code>$$
\text{Loss} = \dfrac{P_{\text{RealPath}}}{\sum_{i=1}^{N} P_i}
$$</code></p>

<p>对于 <code>$S_i$</code>，共包含两部分：发射分数和转移分数。以路径 <code>START -&gt; B_PER -&gt; I_PER -&gt; O -&gt; B_ORG -&gt; O -&gt; END</code> 为例，发射分数为：</p>

<p><code>$$
\begin{aligned}
\text{EmissionScore} = \ &amp;x_{0, \text{START}} + x_{1, \text{B_PER}} + x_{2, \text{I_PER}} \\
&amp;+ x_{3, \text{O}} + x_{4, \text{B_ORG}} + x_{5, \text{O}} + x_{6, \text{END}}
\end{aligned}
$$</code></p>

<p>其中 <code>$x_{i, y_j}$</code> 表示第 <code>$i$</code> 个词标签为 <code>$y_j$</code> 的分数，为 BiLSTM 的输出，<code>$x_{0, \text{START}}$</code> 和 <code>$x_{6, \text{END}}$</code> 可以设置为 0。转换分数为：</p>

<p><code>$$
\begin{aligned}
\text{TransitionScore} = \ &amp;t_{\text{START}, \text{B_PER}} + t_{\text{B_PER}, \text{I_PER}} + t_{\text{I_PER}, \text{O}} \\
&amp;+ t_{\text{O}, \text{B_ORG}} + t_{\text{B_ORG}, \text{O}} + t_{\text{O}, \text{END}}
\end{aligned}
$$</code></p>

<p>其中 <code>$t_{y_i, y_j}$</code> 表示标注标签由 <code>$y_i$</code> 转移至 <code>$y_j$</code> 的分数。</p>

<p>对于所有路径的总分数的计算过程采用了类似 <a href="/cn/2018/11/computational-complexity-and-dynamic-programming/">动态规划</a> 的思想，整个过程计算比较复杂，在此不再详细展开，详细请参见参考文章。</p>

<p>利用训练好的 BiLSTM-CRF 模型进行预测时，首先我们可以得到序列的发射分数和转移分数，其次用维特比算法可以得到最终的预测标注序列。</p>

<h4 id="lattice-lstm-zhang2018chinese">Lattice LSTM <sup class="footnote-ref" id="fnref:zhang2018chinese"><a href="#fn:zhang2018chinese">8</a></sup></h4>

<p>Zhang 等人针对中文提出了一种基于 Lattice LSTM 的命名实体识别方法，Lattice LSTM 的结构如下图所示：</p>

<figure>
  <img data-src="/images/cn/2020-05-02-hmm-and-crf/lattice-lstm.png" class="lazyload"/>
  
</figure>

<p>模型的基本思想是将句子中的词汇（例如：南京，长江大桥等）信息融入到基于字符的 LSTM 模型中，从而可以显性地利用词汇信息。</p>

<p>模型的输入为一个字符序列 <code>$c_1, c_2, \cdots, c_m$</code> 和词汇表 <code>$\mathbb{D}$</code> 中所有匹配的字符子序列，其中词汇表 <code>$\mathbb{D}$</code> 利用大量的原始文本通过分词构建。令 <code>$w_{b, e}^d$</code> 表示有以第 <code>$b$</code> 个字符起始，以第 <code>$e$</code> 个字符结尾的子序列，例如：<code>$w_{1,2}^d$</code> 表示“南京
”，<code>$w_{7,8}^d$</code> 表示“大桥”。</p>

<p>不同于一般的字符级模型，LSTM 单元的状态考虑了句子中的子序列 <code>$w_{b,e}^d$</code>，每个子序列 <code>$w_{b,e}^d$</code> 表示为：</p>

<p><code>$$
\mathbf{x}_{b, e}^{w}=\mathbf{e}^{w}\left(w_{b, e}^{d}\right)
$$</code></p>

<p>其中，<code>$\mathbf{e}^{w}$</code> 为词向量查询表。一个词单元 <code>$\mathbf{c}_{b,e}^w$</code> 用于表示 <code>$\mathbf{x}_{b,e}^w$</code> 的循环状态：</p>

<p><code>$$
\begin{aligned}
\left[\begin{array}{c}
\mathbf{i}_{b, e}^{w} \\
\mathbf{f}_{b, e}^{w} \\
\widetilde{c}_{b, e}^{w}
\end{array}\right] &amp;=\left[\begin{array}{c}
\sigma \\
\sigma \\
\tanh
\end{array}\right]\left(\mathbf{W}^{w \top}\left[\begin{array}{c}
\mathbf{x}_{b, e}^{w} \\
\mathbf{h}_{b}^{c}
\end{array}\right]+\mathbf{b}^{w}\right) \\
\mathbf{c}_{b, e}^{w} &amp;=\mathbf{f}_{b, e}^{w} \odot \mathbf{c}_{b}^{c}+\mathbf{i}_{b, e}^{w} \odot \widetilde{c}_{b, e}^{w}
\end{aligned}
$$</code></p>

<p>其中，<code>$\mathbf{i}_{b, e}^{w}$</code> 和 <code>$\mathbf{f}_{b, e}^{w}$</code> 分别为输入门和遗忘门。由于仅在字符级别上进行标注，因此对于词单元来说没有输出门。</p>

<p>对于 <code>$\mathbf{c}_{j}^c$</code> 来说可能有多条信息流，例如 <code>$\mathbf{c}_7^c$</code> 的输入包括 <code>$\mathbf{x}_7^c$</code>（桥），<code>$\mathbf{c}_{6,7}^w$</code>（大桥）和 <code>$\mathbf{c}_{4,7}^w$</code>（长江大桥）。论文采用了一个新的门 <code>$\mathbf{i}_{b,e}^c$</code> 来控制所有子序列单元 <code>$\mathbf{c}_{b,e}^w$</code> 对 <code>$\mathbf{c}_{j}^c$</code> 的贡献：</p>

<p><code>$$
\mathbf{i}_{b, e}^{c}=\sigma\left(\mathbf{W}^{l \top}\left[\begin{array}{c}
\mathbf{x}_{e}^{c} \\
\mathbf{c}_{b, e}^{w}
\end{array}\right]+\mathbf{b}^{l}\right)
$$</code></p>

<p>则单元状态 <code>$\mathbf{c}_j^c$</code> 的计算变为：</p>

<p><code>$$
\mathbf{c}_{j}^{c}=\sum_{b \in\left\{b^{\prime} | w_{b^{\prime}, j} \in \mathbb{D}\right\}} \boldsymbol{\alpha}_{b, j}^{c} \odot \boldsymbol{c}_{b, j}^{w}+\boldsymbol{\alpha}_{j}^{c} \odot \widetilde{\boldsymbol{c}}_{j}^{c}
$$</code></p>

<p>在上式中，<code>$\mathbf{i}_{b,j}^c$</code> 和 <code>$\mathbf{i}_j^c$</code> 标准化为 <code>$\boldsymbol{\alpha}_{b, j}^{c}$</code> 和 <code>$\boldsymbol{\alpha}_{j}^{c}$</code>：</p>

<p><code>$$
\begin{aligned}
\boldsymbol{\alpha}_{b, j}^{c} &amp;=\frac{\exp \left(\mathbf{i}_{b, j}^{c}\right)}{\exp \left(\mathbf{i}_{j}^{c}\right)+\sum_{b^{\prime} \in\left\{b^{\prime \prime} | w_{b^{\prime \prime}, j}^{d} \in \mathbb{D}\right\}} \exp \left(\mathbf{i}_{b^{\prime}, j}^{c}\right)} \\
\boldsymbol{\alpha}_{j}^{c} &amp;=\frac{\exp \left(\mathbf{i}_{j}^{c}\right)}{\exp \left(\mathbf{i}_{j}^{c}\right)+\sum_{b^{\prime} \in\left\{b^{\prime \prime} | w_{b^{\prime \prime}, j}^{d} \in \mathbb{D}\right\}} \exp \left(\mathbf{i}_{b^{\prime}, j}^{c}\right)}
\end{aligned}
$$</code></p>

<h2 id="开放资源">开放资源</h2>

<h3 id="标注工具">标注工具</h3>

<ol>
<li><a href="https://github.com/synyi/poplar" rel="noreferrer" target="_blank">synyi/poplar</a></li>
<li><a href="https://github.com/nlplab/brat" rel="noreferrer" target="_blank">nlplab/brat</a></li>
<li><a href="https://github.com/doccano/doccano" rel="noreferrer" target="_blank">doccano/doccano</a></li>
<li><a href="https://github.com/heartexlabs/label-studio" rel="noreferrer" target="_blank">heartexlabs/label-studio</a></li>
<li><a href="https://github.com/deepwel/Chinese-Annotator" rel="noreferrer" target="_blank">deepwel/Chinese-Annotator</a></li>
<li><a href="https://github.com/jiesutd/YEDDA" rel="noreferrer" target="_blank">jiesutd/YEDDA</a></li>
</ol>

<h3 id="开源模型-框架和代码">开源模型，框架和代码</h3>

<ol>
<li><a href="https://github.com/pytorch/text" rel="noreferrer" target="_blank">pytorch/text</a></li>
<li><a href="https://github.com/flairNLP/flair" rel="noreferrer" target="_blank">flairNLP/flair</a></li>
<li><a href="https://github.com/PetrochukM/PyTorch-NLP" rel="noreferrer" target="_blank">PetrochukM/PyTorch-NLP</a></li>
<li><a href="https://github.com/allenai/allennlp" rel="noreferrer" target="_blank">allenai/allennlp</a></li>
<li><a href="https://github.com/fastnlp/fastNLP" rel="noreferrer" target="_blank">fastnlp/fastNLP</a></li>
<li><a href="https://stanfordnlp.github.io/CoreNLP/index.html" rel="noreferrer" target="_blank">Stanford CoreNLP</a></li>
<li><a href="http://neuroner.com/" rel="noreferrer" target="_blank">NeuroNER</a></li>
<li><a href="https://spacy.io/" rel="noreferrer" target="_blank">spaCy</a></li>
<li><a href="https://www.nltk.org/" rel="noreferrer" target="_blank">NLTK</a></li>
<li><a href="https://github.com/BrikerMan/Kashgari" rel="noreferrer" target="_blank">BrikerMan/Kashgari</a></li>
<li><a href="https://github.com/Hironsan/anago" rel="noreferrer" target="_blank">Hironsan/anago</a></li>
<li><a href="https://github.com/crownpku/Information-Extraction-Chinese" rel="noreferrer" target="_blank">crownpku/Information-Extraction-Chinese</a></li>
<li><a href="https://github.com/thunlp/OpenNRE" rel="noreferrer" target="_blank">thunlp/OpenNRE</a></li>
<li><a href="https://github.com/hankcs/HanLP" rel="noreferrer" target="_blank">hankcs/HanLP</a></li>
<li><a href="https://github.com/jiesutd/NCRFpp" rel="noreferrer" target="_blank">jiesutd/NCRFpp</a></li>
</ol>

<h3 id="其他资源">其他资源</h3>

<ol>
<li><a href="https://github.com/keon/awesome-nlp" rel="noreferrer" target="_blank">keon/awesome-nlp</a></li>
<li><a href="https://github.com/crownpku/Awesome-Chinese-NLP" rel="noreferrer" target="_blank">crownpku/Awesome-Chinese-NLP</a></li>
<li><a href="https://github.com/sebastianruder/NLP-progress" rel="noreferrer" target="_blank">sebastianruder/NLP-progress</a></li>
<li><a href="https://github.com/thunlp/NREPapers" rel="noreferrer" target="_blank">thunlp/NREPapers</a></li>
</ol>
<div class="footnotes">

<hr />

<ol>
<li id="fn:li2019tongji">李航. (2019). <em>统计学习方法（第二版）</em>. 清华大学出版社.
 <a class="footnote-return" href="#fnref:li2019tongji">↩</a></li>
<li id="fn:yu2002pku">俞士汶, 段慧明, 朱学锋, &amp; 孙斌. (2002). 北京大学现代汉语语料库基本加工规范. <em>中文信息学报</em>, 16(5), 51-66.
 <a class="footnote-return" href="#fnref:yu2002pku">↩</a></li>
<li id="fn:yu2003pku">俞士汶, 段慧明, 朱学锋, 孙斌, &amp; 常宝宝. (2003). 北大语料库加工规范: 切分· 词性标注· 注音. <em>汉语语言与计算学报</em>, 13(2), 121-158.
 <a class="footnote-return" href="#fnref:yu2003pku">↩</a></li>
<li id="fn:liu-ictclas"><a href="http://ictclas.nlpir.org/nlpir/html/readme.htm" rel="noreferrer" target="_blank">http://ictclas.nlpir.org/nlpir/html/readme.htm</a>
 <a class="footnote-return" href="#fnref:liu-ictclas">↩</a></li>
<li id="fn:xia2000pos">Xia, F. (2000). The part-of-speech tagging guidelines for the Penn Chinese Treebank (3.0). <em>IRCS Technical Reports Series</em>, 38.
 <a class="footnote-return" href="#fnref:xia2000pos">↩</a></li>
<li id="fn:huang2006tokenization">Huang, C. N., Li, Y., &amp; Zhu, X. (2006). Tokenization guidelines of Chinese text (v5.0, in Chinese). <em>Microsoft Research Asia</em>.
 <a class="footnote-return" href="#fnref:huang2006tokenization">↩</a></li>
<li id="fn:huang2015bidirectional">Huang, Z., Xu, W., &amp; Yu, K. (2015). Bidirectional LSTM-CRF models for sequence tagging. <em>arXiv preprint arXiv:1508.01991</em>.
 <a class="footnote-return" href="#fnref:huang2015bidirectional">↩</a></li>
<li id="fn:zhang2018chinese">Zhang, Y., &amp; Yang, J. (2018). Chinese NER Using Lattice LSTM. In <em>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em> (pp. 1554-1564).
 <a class="footnote-return" href="#fnref:zhang2018chinese">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>相似性和距离度量 (Similarity &amp; Distance Measurement)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2019/01/similarity-and-distance-measurement/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2019/01/similarity-and-distance-measurement/</guid>
      <description>
        <![CDATA[
        

<p>相似性度量 (Similarity Measurement) 用于衡量两个元素之间的相似性程度或两者之间的距离 (Distance)。距离衡量的是指元素之间的不相似性 (Dissimilarity)，通常情况下我们可以利用一个距离函数定义集合 <code>$X$</code> 上元素间的距离，即：</p>

<p><code>$$
d: X \times X \to \mathbb{R}
$$</code></p>

<p>同时，对于集合 <code>$X$</code> 内的元素 <code>$x, y, z$</code>，距离函数一般满足如下条件：</p>

<ol>
<li><code>$d \left(x, y\right) \geq 0$</code> (非负性)</li>
<li><code>$d \left(x, y\right) = 0, \text{当且仅当} \ x = y$</code> (同一性)</li>
<li><code>$d \left(x, y\right) = d \left(y, x\right)$</code> (对称性)</li>
<li><code>$d \left(x, z\right) \leq d \left(x, y\right) + d \left(y, z\right)$</code> (三角不等式)</li>
</ol>

<h2 id="明可夫斯基距离-明氏距离-minkowski-distance">明可夫斯基距离 (明氏距离, Minkowski Distance)</h2>

<p>对于点 <code>$x = \left(x_1, x_2, ..., x_n\right)$</code> 和点 <code>$y = \left(y_1, y_2, ..., y_n\right)$</code>，<code>$p$</code> <strong>阶明可夫斯基距离</strong> 定义为：</p>

<p><code>$$
d \left(x, y\right) = \left(\sum_{i=1}^{n} |x_i - y_i|^p\right)^{\frac{1}{p}}
$$</code></p>

<p>当 <code>$p = 1$</code> 时，称之为 <strong>曼哈顿距离 (Manhattan Distance)</strong> 或 <strong>出租车距离</strong>：</p>

<p><code>$$
d \left(x, y\right) = \sum_{i=1}^{n} |x_i - y_i|
$$</code></p>

<p>当 <code>$p = 2$</code> 时，称之为 <strong>欧式距离 (Euclidean Distance)</strong> ：</p>

<p><code>$$
d \left(x, y\right) = \sqrt{\sum_{i=1}^{n} \left(x_i - y_i\right)^2}
$$</code></p>

<p><img src="/images/cn/2019-01-01-similarity-and-distance-measurement/manhattan-distance.svg" alt="Manhattan Distance" /></p>

<p>上图中 <span style="color:#00d100;"><strong>绿色</strong></span> 的直线为两点间的欧式距离，<span style="color:#ff0000;"><strong>红色</strong></span> <span style="color:#ffd600;"><strong>黄色</strong></span> <span style="color:#0000ff;"><strong>蓝色</strong></span> 的折线均为两点间的曼哈顿距离，不难看出 3 条折线的长度是相同的。</p>

<p>当 <code>$p \to \infty$</code> 时，称之为 <strong>切比雪夫距离 (Chebyshev Distance)</strong> ：</p>

<p><code>$$
d \left(x, y\right) = \lim_{p \to \infty} \left(\sum_{i=1}^{n} |x_i - y_i|^p\right)^{\frac{1}{p}} = \max_{i=1}^{n} |x_i - y_i|
$$</code></p>

<p>下图展示了不同的 <code>$p$</code> 值下单位圆，即 <code>$x^p + y^p = 1$</code>，便于大家理解不同 <code>$p$</code> 值下的明可夫斯基距离：</p>

<p><img src="/images/cn/2019-01-01-similarity-and-distance-measurement/2D-unit-balls.png" alt="2D Unit Balls" /></p>

<h2 id="马哈拉诺比斯距离-马氏距离-mahalanobis-distance">马哈拉诺比斯距离 (马氏距离, Mahalanobis Distance)</h2>

<p>马哈拉诺比斯距离表示数据的 <strong>协方差距离</strong>，与欧式距离不同其考虑到各种特性之间的联系是 <strong>尺度无关 (Scale Invariant)</strong> 的。对于一个协方差矩阵为 <code>$\sum$</code> 的变量 <code>$x$</code> 和 <code>$y$</code>，马氏距离定义为：</p>

<p><code>$$
d \left(x, y\right) = \sqrt{\left(x - y\right)^{\top} {\sum}^{-1} \left(x - y\right)}
$$</code></p>

<p>马氏距离的最大优势就是其不受不同维度之间量纲的影响，同时引入的问题便是扩大了变化量较小的变量的影响。以下图为例 (源码详见 <a href="https://github.com/leovan/leovan.me/tree/master/scripts/cn/2019-01-01-similarity-and-distance-measurement/mahalanobis-distance.R" rel="noreferrer" target="_blank">这里</a>)：</p>

<p><img src="/images/cn/2019-01-01-similarity-and-distance-measurement/mahalanobis-distance.png" alt="Mahalanobis Distance" /></p>

<p>左侧图中根据欧式距离计算，<span style="color:#F07769;"><strong>红色</strong></span> 的点距离 <span style="color:#34BA27;"><strong>绿色</strong></span> 的点更近一些，右侧图是根据马氏距离进行座标变换后的示意图，不难看出此时 <span style="color:#F07769;"><strong>红色</strong></span> 的点距离 <span style="color:#6C9BFF;"><strong>蓝色</strong></span> 的点更近一些。</p>

<h2 id="向量内积-inner-product-of-vectors">向量内积 (Inner Product of Vectors)</h2>

<p>在欧几里得几何中，两个笛卡尔坐标向量的点积常称为内积，向量内积是两个向量的长度与它们夹角余弦的积，定义为：</p>

<p><code>$$
x \cdot y = \sum_{i=1}^{n}{x_i y_i}
$$</code></p>

<p>从代数角度看，先对两个数字序列中的每组对应元素求积，再对所有积求和，结果即为点积。从几何角度看，点积则是两个向量的长度与它们夹角余弦的积。在欧几里得空间中，点积可以直观地定义为：</p>

<p><code>$$
x \cdot y = \left| x \right| \left| y \right| \cos \theta
$$</code></p>

<p><strong>余弦相似度 (Cosine Similarity)</strong> 可以利用两个向量夹角的 cos 值定义，即：</p>

<p><code>$$
s \left(x, y\right) = \cos \left(\theta\right) = \dfrac{x \cdot y}{\left| x \right| \left| y \right|} = \dfrac{\sum_{i=1}^{n}{x_i y_i}}{\sqrt{\sum_{i=1}^{n}{x_i^2}} \sqrt{\sum_{i=1}^{n}{y_i^2}}}
$$</code></p>

<p>余弦相似度的取值范围为：<code>$\left[-1, 1\right]$</code>，1 表示两者完全正相关，-1 表示两者完全负相关，0 表示两者之间独立。余弦相似度与向量的长度无关，只与向量的方向有关，但余弦相似度会受到向量平移的影响。</p>

<p><strong>皮尔逊相关系数 (Pearson Correlation)</strong> 解决了余弦相似度会收到向量平移影响的问题，其定义为：</p>

<p><code>$$
\rho \left(x, y\right) = \dfrac{\text{cov} \left(x, y\right)}{\sigma_x \sigma_y} = \dfrac{E \left[\left(x - \mu_x\right) \left(y - \mu_y\right)\right]}{\sigma_x \sigma_y}
$$</code></p>

<p>其中，<code>$\text{cov}$</code> 表示协方差，<code>$E$</code> 表示期望，<code>$\mu$</code> 表示均值，<code>$\sigma$</code> 表示标准差。对于样本的皮尔逊相关系数，可以通过如下方式计算：</p>

<p><code>$$
\begin{equation}
\begin{split}
r &amp;= \dfrac{\sum_{i=1}^{n}{\left(x_i - \bar{x}\right) \left(y_i - \bar{y}\right)}}{\sqrt{\sum_{i=1}^{n}{\left(x_i - \bar{x}\right)^2}} \sqrt{\sum_{i=1}^{n}{\left(y_i - \bar{y}\right)^2}}} \\
&amp;= \dfrac{1}{n-1} \sum_{i=1}^{n}{\left(\dfrac{x_i - \bar{x}}{\sigma_x}\right) \left(\dfrac{y_i - \bar{y}}{\sigma_y}\right)}
\end{split}
\end{equation}
$$</code></p>

<p>皮尔逊相关系数的取值范围为：<code>$\left[-1, 1\right]$</code>，值的含义与余弦相似度相同。皮尔逊相关系数有一个重要的数学特性是：变量位置和尺度的变化并不会引起相关系数的改变。下图给出了不同的 <code>$\left(x, y\right)$</code> 之间的皮尔逊相关系数。</p>

<p><img src="/images/cn/2019-01-01-similarity-and-distance-measurement/correlation-examples.png" alt="Correlation Examples" /></p>

<h2 id="集合距离-distance-of-sets">集合距离 (Distance of Sets)</h2>

<p>对于两个集合之间的相似性度量，主要有如下几种方法：</p>

<ul>
<li><strong>Jaccard 系数</strong></li>
</ul>

<p><code>$$
s = \dfrac{\left|X \cap Y\right|}{\left| X \cup Y \right|} = \dfrac{\left|X \cap Y\right|}{\left|X\right| + \left|Y\right| - \left|X \cap Y\right|}
$$</code></p>

<p>Jaccard 系数的取值范围为：<code>$\left[0, 1\right]$</code>，0 表示两个集合没有重合，1 表示两个集合完全重合。</p>

<ul>
<li><strong>Dice 系数</strong></li>
</ul>

<p><code>$$
s = \dfrac{2 \left| X \cap Y \right|}{\left|X\right| + \left|Y\right|}
$$</code></p>

<p>与 Jaccard 系数相同，Dice 系数的取值范围为：<code>$\left[0, 1\right]$</code>，两者之间可以相互转换 <code>$s_d = 2 s_j / \left(1 + s_j\right), s_j = s_d / \left(2 - s_d\right)$</code>。不同于 Jaccard 系数，Dice 系数的差异函数 <code>$d = 1 - s$</code> 并不是一个合适的距离度量，因为其并不满足距离函数的三角不等式。</p>

<ul>
<li><strong>Tversky 系数</strong></li>
</ul>

<p><code>$$
s = \dfrac{\left| X \cap Y \right|}{\left| X \cap Y \right| + \alpha \left| X \setminus Y \right| + \beta \left| Y \setminus X \right|}
$$</code></p>

<p>其中，<code>$X \setminus Y$</code> 表示集合的相对补集。Tversky 系数可以理解为 Jaccard 系数和 Dice 系数的一般化，当 <code>$\alpha = \beta = 1$</code> 时为 Jaccard 系数，当 <code>$\alpha = \beta = 0.5$</code> 时为 Dice 系数。</p>

<h2 id="字符串距离-distance-of-strings">字符串距离 (Distance of Strings)</h2>

<p>对于两个字符串之间的相似性度量，主要有如下几种方法：</p>

<ul>
<li><strong>Levenshtein 距离</strong></li>
</ul>

<p>Levenshtein 距离是 <strong>编辑距离 (Editor Distance)</strong> 的一种，指两个字串之间，由一个转成另一个所需的最少编辑操作次数。允许的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。例如将 <strong>kitten</strong> 转成 <strong>sitting</strong>，转换过程如下：</p>

<p><code>$$
\begin{equation*}
\begin{split}
\text{kitten} \to \text{sitten} \left(k \to s\right) \\
\text{sitten} \to \text{sittin} \left(e \to i\right) \\
\text{sittin} \to \text{sitting} \left(\  \to g\right)
\end{split}
\end{equation*}
$$</code></p>

<p>编辑距离的求解可以利用动态规划的思想优化计算的时间复杂度。</p>

<ul>
<li><strong>Jaro-Winkler 距离</strong></li>
</ul>

<p>对于给定的两个字符串 <code>$s_1$</code> 和 <code>$s_2$</code>，Jaro 相似度定义为：</p>

<p><code>$$
sim =
\begin{cases}
0 &amp; \text{if} \  m = 0 \\
\dfrac{1}{3} \left(\dfrac{m}{\left|s_1\right|} + \dfrac{m}{\left|s_2\right|} + \dfrac{m-t}{m}\right) &amp; \text{otherwise}
\end{cases}
$$</code></p>

<p>其中，<code>$\left|s_i\right|$</code> 为字符串 <code>$s_i$</code> 的长度，<code>$m$</code> 为匹配的字符的个数，<code>$t$</code> 换位数目的一半。如果字符串 <code>$s_1$</code> 和 <code>$s_2$</code> 相差不超过 <code>$\lfloor \dfrac{\max \left(\left|s_1\right|, \left|s_2\right|\right)}{2} \rfloor - 1$</code>，我们则认为两个字符串是匹配的。例如，对于字符串 <strong>CRATE</strong> 和 <strong>TRACE</strong>，仅 <strong>R, A, E</strong> 三个字符是匹配的，因此 <code>$m = 3$</code>，尽管 <strong>C, T</strong> 均出现在两个字符串中，但是他们的距离超过了 1 (即，<code>$\lfloor \dfrac{5}{2} \rfloor - 1$</code>)，因此 <code>$t = 0$</code>。</p>

<p>Jaro-Winkler 相似度给予了起始部分相同的字符串更高的分数，其定义为：</p>

<p><code>$$
sim_w = sim_j + l p \left(1 - sim_j\right)
$$</code></p>

<p>其中，<code>$sim_j$</code> 为字符串 <code>$s_1$</code> 和 <code>$s_2$</code> 的 Jaro 相似度，<code>$l$</code> 为共同前缀的长度 (规定不超过 <code>$4$</code>)，<code>$p$</code> 为调整系数 (规定不超过 <code>$0.25$</code>)，Winkler 将其设置为 <code>$p = 0.1$</code>。</p>

<ul>
<li><strong>汉明距离</strong></li>
</ul>

<p>汉明距离为两个<strong>等长字符串</strong>对应位置的不同字符的个数，也就是将一个字符串变换成另外一个字符串所需要<strong>替换</strong>的字符个数。例如：<strong>10<span style="color:#0000ff;">1</span>1<span style="color:#0000ff;">1</span>01</strong> 与 <strong>10<span style="color:#ff0000;">0</span>1<span style="color:#ff0000;">0</span>01</strong> 之间的汉明距离是 2，<strong>“<span style="color:#0000ff;">t</span>o<span style="color:#0000ff;">n</span>e<span style="color:#0000ff;">d</span>”</strong> 与 <strong>“<span style="color:#ff0000;">r</span>o<span style="color:#ff0000;">s</span>e<span style="color:#ff0000;">s</span>”</strong> 之间的汉明距离是 3。</p>

<h2 id="信息论距离-information-theory-distance">信息论距离 (Information Theory Distance)</h2>

<p>首先我们需要理解什么是 <strong>熵 (Entropy)</strong>？熵最早是用来表示物理学中一个热力系统无序的程度，后来依据香农的信息论，熵用来衡量一个随机变量的不确定性程度。对于一个随机变量 <code>$X$</code>，其概率分布为：</p>

<p><code>$$
P \left(X = x_i\right) = p_i, \quad i = 1, 2, ..., n
$$</code></p>

<p>则随机变量 <code>$X$</code> 的熵定义如下：</p>

<p><code>$$
H \left(X\right) = - \sum_{i=1}^{n} P \left(x_i\right) \log P \left(x_i\right) \label{eq:entropy}
$$</code></p>

<p>例如抛一枚硬币，假设硬币正面向上 <code>$X = 1$</code> 的概率为 <code>$p$</code>，硬币反面向上 <code>$X = 0$</code> 的概率为 <code>$1 - p$</code>。则对于抛一枚硬币那个面朝上这个随机变量 <code>$X$</code> 的熵为：</p>

<p><code>$$
H \left(X\right) = - p \log p - \left(1-p\right) \log \left(1-p\right)
$$</code></p>

<p>随概率 <code>$p$</code> 变化如下图所示：</p>

<p><img src="/images/cn/2019-01-01-similarity-and-distance-measurement/entropy-demo.png" alt="Entropy Demo" /></p>

<p>从图可以看出，当 <code>$p = 0.5$</code> 时熵最大，也就是说抛一枚硬币，当正反两面朝上的概率相同时，熵最大，系统最复杂。对于公式 <code>$\ref{eq:entropy}$</code>，当取以 2 为底的对数时，熵的单位为比特 (bit)，当取自然对数时，熵的单位为纳特 (nat)，当取以 10 为底的对数时，熵的单位为哈特 (hart)。</p>

<p>对于随机变量 <code>$\left(X, Y\right)$</code>，其联合概率分布为：</p>

<p><code>$$
P \left(X = x_i, Y = y_i\right) = p_{i, j}, \quad i = 1,2,...,n; \quad j = 1,2,...,m
$$</code></p>

<p><strong>条件熵 (Conditional Entropy)</strong> 表示在已知 <code>$X$</code> 的条件下 <code>$Y$</code> 的不确定性，定义为：</p>

<p><code>$$
\begin{equation}
\begin{split}
H \left(Y | X\right) &amp;= \sum_{i=i}^{n} P \left(x_i\right) H \left(Y | X = x_i\right) \\
&amp;= \sum_{i=1}^{n}{\sum_{j=1}^{m}{P \left(x_i, y_j\right) \log \dfrac{P \left(x_i\right)}{P \left(x_i, y_j\right)}}}
\end{split}
\end{equation}
$$</code></p>

<p><strong>联合熵 (Joint Entropy)</strong> 用于衡量多个随机变量的随机系统的信息量，定义为：</p>

<p><code>$$
H \left(X, Y\right) = \sum_{i=1}^{n}{\sum_{j=1}^{m}{P \left(x_i, y_j\right) \log P \left(x_i, y_j\right)}}
$$</code></p>

<ul>
<li><strong>互信息 (Mutual Information)</strong></li>
</ul>

<p>互信息用于衡量两个变量之间的关联程度，定义为：</p>

<p><code>$$
I \left(X; Y\right) = \sum_{i=1}^{n}{\sum_{j=1}^{m}{P \left(x_i, y_j\right) \log \dfrac{P \left(x_i, y_i\right)}{P \left(x_i\right) P \left(y_j\right)}}}
$$</code></p>

<p>直观上，互信息度量 <code>$X$</code> 和 <code>$Y$</code> 共享的信息，它度量知道这两个变量其中一个，对另一个不确定度减少的程度。</p>

<ul>
<li><strong>相对熵 (Relative Entropy)</strong></li>
</ul>

<p>相对熵又称之为 <strong>KL 散度 (Kullback-Leibler Divergence)</strong>，用于衡量两个分布之间的差异，定义为：</p>

<p><code>$$
D_{KL} \left(P \| Q\right) = \sum_{i}{P \left(i\right) \ln \dfrac{P \left(i\right)}{Q \left(i\right)}}
$$</code></p>

<p>KL 散度为非负数 <code>$D_{KL} \left(P \| Q\right) \geq 0$</code>，同时其不具有对称性 <code>$D_{KL} \left(P \| Q\right) \neq D_{KL} \left(Q \| P\right)$</code>，也不满足距离函数的三角不等式。</p>

<ul>
<li><strong>交叉熵 (Corss Entropy)</strong></li>
</ul>

<p>交叉熵定义为：</p>

<p><code>$$
\begin{equation}
\begin{split}
H \left(P, Q\right) &amp;= H \left(P\right) + D_{KL} \left(P \| Q\right) \\
&amp;= - \sum_{i}{P \left(i\right) \log Q \left(i\right)}
\end{split}
\end{equation}
$$</code></p>

<p>交叉熵常作为机器学习中的损失函数，用于衡量模型分布和训练数据分布之间的差异性。</p>

<ul>
<li><strong>JS 散度 (Jensen-Shannon Divergence)</strong></li>
</ul>

<p>JS 散度解决了 KL 散度不对称的问题，定义为：</p>

<p><code>$$
D_{JS} \left(P \| Q\right) = \dfrac{1}{2} D_{KL} \left(P \| \dfrac{P + Q}{2}\right) + \dfrac{1}{2} D_{KL} \left(Q \| \dfrac{P + Q}{2}\right)
$$</code></p>

<p>当取以 2 为底的对数时，JS 散度的取值范围为：<code>$\left[0, 1\right]$</code>。</p>

<ul>
<li><strong>推土机距离 (Earth Mover Distance, Wasserstein Distance)</strong></li>
</ul>

<p>推土机距离用于描述两个多维分布之间相似性，之所以称为推土机距离是因为我们将分布看做空间中的泥土，两个分布之间的距离则是通过泥土的搬运将一个分布改变到另一个分布所消耗的最小能量 (即运送距离和运送重量的乘积)。</p>

<p>对于给定的分布 <code>$P = \left\{\left(p_1, w_{p1}\right), \left(p_2, w_{p2}\right), \cdots, \left(p_m, w_{pm}\right)\right\}$</code> 和 <code>$Q = \left\{\left(q_1, w_{q1}\right), \left(q_2, w_{q2}\right), \cdots, \left(q_n, w_{qn}\right)\right\}$</code>，定义从 <code>$p_i$</code> 到 <code>$q_j$</code> 之间的距离为 <code>$d_{i, j}$</code>，所需运送的重量为 <code>$f_{i, j}$</code>。对于 <code>$f_{i, j}$</code> 有如下 4 个约束：</p>

<ol>
<li>运送需从 <code>$p_i$</code> 到 <code>$q_j$</code>，不能反向，即 <code>$f_{i, j} \geq 0, 1 \leq i \leq m, 1 \leq j \leq n$</code>。</li>
<li>从 <code>$p_i$</code> 运送出的总重量不超过原始的总重量 <code>$w_{pi}$</code>，即 <code>$\sum_{j=1}^{n}{f_{i, j}} \leq w_{pi}, 1 \leq i \leq m$</code>。</li>
<li>运送到 <code>$q_j$</code> 的总重量不超过其总容量 <code>$w_{qj}$</code>，即 <code>$\sum_{i=1}^{m}{f_{i, j}} \leq w_{qj}, 1 \leq j \leq n$</code>。</li>
<li><code>$\sum_{i=1}^{m}{\sum_{j=1}^{n}{f_{i, j}}} = \min \left\{\sum_{i=1}^{m}{w_{pi}}, \sum_{j=1}^{n}{w_{qj}}\right\}$</code>。</li>
</ol>

<p>在此约束下，通过最小化损失函数：</p>

<p><code>$$
\min \sum_{i=1}^{m}{\sum_{j=1}^{n}{d_{i, j} f_{i, j}}}
$$</code></p>

<p>得到最优解 <code>$f_{i, j}^*$</code>，则推土机距离定义为：</p>

<p><code>$$
D_{W} \left(P, Q\right) = \dfrac{\sum_{i=1}^{m}{\sum_{j=1}^{n}{d_{i, j} f_{i, j}^*}}}{\sum_{i=1}^{m}{\sum_{j=1}^{n}{f_{i, j}^*}}}
$$</code></p>

<h2 id="其他距离-other-distance">其他距离 (Other Distance)</h2>

<ul>
<li><strong>DTW (Dynamic Time Warping) 距离</strong></li>
</ul>

<p>DTW 距离用于衡量两个序列之间的相似性，序列的长度可能相等也可能不相等。对于两个给定的序列 <code>$X = \left(x_1, x_2, \cdots, x_m\right)$</code> 和 <code>$Y = \left(y_1, y_2, \cdots, y_n\right)$</code>，我们可以利用动态规划的方法求解 DTW 距离。首先我们构造一个 <code>$m \times n$</code> 的矩阵，矩阵中的元素 <code>$d_{i, j}$</code> 表示 <code>$x_i$</code> 和 <code>$y_j$</code> 之间的距离。我们需要找到一条通过该矩阵的路径 <code>$W = \left(w_1, w_2, \cdots, w_l\right)$</code>, <code>$\max\left(m, n\right) \leq l &lt; m + n + 1$</code>，假设 <code>$w_k$</code> 对应的矩阵元素为 <code>$\left(i, j\right)$</code>，对应的距离为 <code>$d_k$</code>，则 DTW 的优化目标为 <code>$\min \sum_{k=1}^{l}{d_k}$</code>。如下图右上角部分所示：</p>

<p><img src="/images/cn/2019-01-01-similarity-and-distance-measurement/dtw-threeway.png" alt="DTW Three-Way" /></p>

<p>对于路径 <code>$W$</code>，需要满足如下 3 个条件：</p>

<ol>
<li><strong>边界条件</strong>：<code>$w_1 = \left(1, 1\right), w_k = \left(m, n\right)$</code>，即路径须从左下角出发，在右上角终止。</li>
<li><strong>连续性</strong>：对于 <code>$w_{l-1} = \left(i', j'\right), w_l = \left(i, j\right)$</code>，需满足 <code>$i - i' \leq 1, j - j' \leq 1$</code>，即路径不能跨过任何一点进行匹配。</li>
<li><strong>单调性</strong>：对于 <code>$w_{l-1} = \left(i', j'\right), w_l = \left(i, j\right)$</code>，需满足 <code>$0 \leq i - i', 0 \leq j - j'$</code>，即路径上的点需单调递增，不能回退进行匹配。</li>
</ol>

<p>利用动态规划求解 DTW 的状态转移方程为：</p>

<p><code>$$
dtw_{i, j} =
\begin{cases}
0 &amp; \text{if} \  i = j = 0 \\
\infty &amp; \text{if} \  i = 0 \  \text{or} \  j = 0 \\
d_{i, j} + \min \left(dtw_{i-1, j}, dtw_{i-1, j-1}, dtw_{i, j-1}\right) &amp; \text{otherwise}
\end{cases}
$$</code></p>

<p><code>$dtw_{m, n}$</code> 则为最终的 DTW 距离。在 DTW 求解的过程中还可以使用不同的 Local Warping Step 和窗口类型，更多详细信息可看见 R 中 <a href="https://cran.r-project.org/web/packages/dtw/index.html" rel="noreferrer" target="_blank">dtw 包</a>。下图展示了利用 DTW 求解后不同点之间的对应关系：</p>

<p><img src="/images/cn/2019-01-01-similarity-and-distance-measurement/dtw-twoway.png" alt="DTW Two-Way" /></p>

<ul>
<li><strong>流形距离 (Distance of Manifold)</strong></li>
</ul>

<p>关于流形距离请参见之前的博客：<a href="/cn/2018/03/manifold-learning">流形学习 (Manifold Learning)</a>。</p>

<h2>🎉🎉🎉 Happe New Year! 🎉🎉🎉</h2>

        ]]>
      </description>
    </item>
    
    <item>
      <title>集成学习算法 (Ensemble Learning)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2018/12/ensemble-learning/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2018/12/ensemble-learning/</guid>
      <description>
        <![CDATA[
        

<p>传统机器学习算法 (例如：决策树，人工神经网络，支持向量机，朴素贝叶斯等) 的目标都是寻找一个最优分类器尽可能的将训练数据分开。集成学习 (Ensemble Learning) 算法的基本思想就是将多个分类器组合，从而实现一个预测效果更好的集成分类器。集成算法可以说从一方面验证了中国的一句老话：三个臭皮匠，赛过诸葛亮。</p>

<p>Thomas G. Dietterich <sup class="footnote-ref" id="fnref:dietterich2000ensemble"><a href="#fn:dietterich2000ensemble">1</a></sup> <sup class="footnote-ref" id="fnref:dietterich2002ensemble"><a href="#fn:dietterich2002ensemble">2</a></sup> 指出了集成算法在统计，计算和表示上的有效原因：</p>

<ul>
<li>统计上的原因</li>
</ul>

<p>一个学习算法可以理解为在一个假设空间 <code>$\mathcal{H}$</code> 中选找到一个最好的假设。但是，当训练样本的数据量小到不够用来精确的学习到目标假设时，学习算法可以找到很多满足训练样本的分类器。所以，学习算法选择任何一个分类器都会面临一定错误分类的风险，因此将多个假设集成起来可以降低选择错误分类器的风险。</p>

<ul>
<li>计算上的原因</li>
</ul>

<p>很多学习算法在进行最优化搜索时很有可能陷入局部最优的错误中，因此对于学习算法而言很难得到一个全局最优的假设。事实上人工神经网络和决策树已经被证实为是一 个NP 问题 <sup class="footnote-ref" id="fnref:hyafil1976constructing"><a href="#fn:hyafil1976constructing">3</a></sup> <sup class="footnote-ref" id="fnref:blum1992training"><a href="#fn:blum1992training">4</a></sup>。集成算法可以从多个起始点进行局部搜索，从而分散陷入局部最优的风险。</p>

<ul>
<li>表示上的原因</li>
</ul>

<p>在多数应用场景中，假设空间 <code>$\mathcal{H}$</code> 中的任意一个假设都无法表示 (或近似表示) 真正的分类函数 <code>$f$</code>。因此，对于不同的假设条件，通过加权的形式可以扩大假设空间，从而学习算法可以在一个无法表示或近似表示真正分类函数 <code>$f$</code> 的假设空间中找到一个逼近函数 <code>$f$</code> 的近似值。</p>

<p>集成算法大致可以分为：Bagging，Boosting 和 Stacking 等类型。</p>

<h2 id="bagging">Bagging</h2>

<p>Bagging (Boostrap Aggregating) 是由 Breiman 于 1996 年提出 <sup class="footnote-ref" id="fnref:breiman1996bagging"><a href="#fn:breiman1996bagging">5</a></sup>，基本思想如下：</p>

<ol>
<li>每次采用有放回的抽样从训练集中取出 <code>$n$</code> 个训练样本组成新的训练集。</li>
<li>利用新的训练集，训练得到 <code>$M$</code> 个子模型 <code>$\{h_1, h_2, ..., h_M\}$</code>。</li>
<li>对于分类问题，采用投票的方法，得票最多子模型的分类类别为最终的类别；对于回归问题，采用简单的平均方法得到预测值。</li>
</ol>

<p>Bagging 算法如下所示：</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{Bagging 算法}
\begin{algorithmic}
\REQUIRE \\
    学习算法 $L$ \\
    子模型个数 $M$ \\
    训练数据集 $T = \{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}$
\ENSURE \\
    Bagging 算法 $h_f\left(x\right)$
\FUNCTION{Bagging}{$L, M, T$}
\FOR{$m = 1$ \TO $M$}
    \STATE $T_m \gets $ boostrap sample from training set $T$
    \STATE $h_m \gets L\left(T_m\right)$
\ENDFOR
\STATE $h_f\left(x\right) \gets \text{sign} \left(\sum_{m=1}^{M} h_m\left(x\right)\right)$
\RETURN $h_f\left(x\right)$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>假设对于一个包含 <code>$M$</code> 个样本的数据集 <code>$T$</code>，利用自助采样，则一个样本始终不被采用的概率是 <code>$\left(1 - \frac{1}{M}\right)^M$</code>，取极限有：</p>

<p><code>$$
\lim_{x \to \infty} \left(1 - \dfrac{1}{M}\right)^M = \dfrac{1}{e} \approx 0.368
$$</code></p>

<p>即每个学习器仅用到了训练集中 <code>$63.2\%$</code> 的数据集，剩余的 <code>$36.8\%$</code> 的训练集样本可以用作验证集对于学习器的泛化能力进行包外估计 (out-of-bag estimate)。</p>

<h3 id="随机森林-random-forests">随机森林 (Random Forests)</h3>

<p>随机森林 (Random Forests) <sup class="footnote-ref" id="fnref:breiman2001random"><a href="#fn:breiman2001random">6</a></sup> 是一种利用决策树作为基学习器的 Bagging 集成学习算法。随机森林模型的构建过程如下：</p>

<ul>
<li>数据采样</li>
</ul>

<p>作为一种 Bagging 集成算法，随机森林同样采用有放回的采样，对于总体训练集 <code>$T$</code>，抽样一个子集 <code>$T_{sub}$</code> 作为训练样本集。除此之外，假设训练集的特征个数为 <code>$d$</code>，每次仅选择 <code>$k\left(k &lt; d\right)$</code> 个构建决策树。因此，随机森林除了能够做到样本扰动外，还添加了特征扰动，对于特征的选择个数，推荐值为 <code>$k = \log_2 d$</code> <sup class="footnote-ref" id="fnref:breiman2001random"><a href="#fn:breiman2001random">6</a></sup>。</p>

<ul>
<li>树的构建</li>
</ul>

<p>每次根据采样得到的数据和特征构建一棵决策树。在构建决策树的过程中，会让决策树生长完全而不进行剪枝。构建出的若干棵决策树则组成了最终的随机森林。</p>

<p>随机森林在众多分类算法中表现十分出众 <sup class="footnote-ref" id="fnref:fernandez2014we"><a href="#fn:fernandez2014we">7</a></sup>，其主要的优点包括：</p>

<ol>
<li>由于随机森林引入了样本扰动和特征扰动，从而很大程度上提高了模型的泛化能力，尽可能地避免了过拟合现象的出现。</li>
<li>随机森林可以处理高维数据，无需进行特征选择，在训练过程中可以得出不同特征对模型的重要性程度。</li>
<li>随机森林的每个基分类器采用决策树，方法简单且容易实现。同时每个基分类器之间没有相互依赖关系，整个算法易并行化。</li>
</ol>

<h2 id="boosting">Boosting</h2>

<p>Boosting 是一种提升算法，可以将弱的学习算法提升 (boost) 为强的学习算法。基本思路如下：</p>

<ol>
<li>利用初始训练样本集训练得到一个基学习器。</li>
<li>提高被基学习器误分的样本的权重，使得那些被错误分类的样本在下一轮训练中可以得到更大的关注，利用调整后的样本训练得到下一个基学习器。</li>
<li>重复上述步骤，直至得到 <code>$M$</code> 个学习器。</li>
<li>对于分类问题，采用有权重的投票方式；对于回归问题，采用加权平均得到预测值。</li>
</ol>

<h3 id="adaboost">Adaboost</h3>

<p>Adaboost <sup class="footnote-ref" id="fnref:freund1997decision"><a href="#fn:freund1997decision">8</a></sup> 是 Boosting 算法中有代表性的一个。原始的 Adaboost 算法用于解决二分类问题，因此对于一个训练集</p>

<p><code>$$
T = \{\left(x_1, y_1\right), \left(x_2, y_2\right), ..., \left(x_n, y_n\right)\}
$$</code></p>

<p>其中 <code>$x_i \in \mathcal{X} \subseteq \mathbb{R}^n, y_i \in \mathcal{Y} = \{-1, +1\}$</code>，首先初始化训练集的权重</p>

<p><code>$$
\begin{equation}
\begin{split}
D_1 =&amp; \left(w_{11}, w_{12}, ..., w_{1n}\right) \\
w_{1i} =&amp; \dfrac{1}{n}, i = 1, 2, ..., n
\end{split}
\end{equation}
$$</code></p>

<p>根据每一轮训练集的权重 <code>$D_m$</code>，对训练集数据进行抽样得到 <code>$T_m$</code>，再根据 <code>$T_m$</code> 训练得到每一轮的基学习器 <code>$h_m$</code>。通过计算可以得出基学习器 <code>$h_m$</code> 的误差为 <code>$\epsilon_m$</code>，根据基学习器的误差计算得出该基学习器在最终学习器中的权重系数</p>

<p><code>$$
\alpha_m = \dfrac{1}{2} \ln \dfrac{1 - \epsilon_m}{\epsilon_m}
$$</code></p>

<p>更新训练集的权重</p>

<p><code>$$
\begin{equation}
\begin{split}
D_{m+1} =&amp; \left(w_{m+1, 1}, w_{m+1, 2}, ..., w_{m+1, n}\right) \\
w_{m+1, i} =&amp; \dfrac{w_{m, i}}{Z_m} \exp \left(-\alpha_m y_i h_m\left(x_i\right)\right)
\end{split}
\end{equation}
$$</code></p>

<p>其中 <code>$Z_m$</code> 为规范化因子</p>

<p><code>$$
Z_m = \sum_{i = 1}^{n} w_{m, i} \exp \left(-\alpha_m y_i h_m \left(x_i\right)\right)
$$</code></p>

<p>从而保证 <code>$D_{m+1}$</code> 为一个概率分布。最终根据构建的 <code>$M$</code> 个基学习器得到最终的学习器：</p>

<p><code>$$
h_f\left(x\right) = \text{sign} \left(\sum_{m=1}^{M} \alpha_m h_m\left(x\right)\right)
$$</code></p>

<p>AdaBoost 算法过程如下所示：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{AdaBoost 算法}
\begin{algorithmic}
\REQUIRE \\
    学习算法 $L$ \\
    子模型个数 $M$ \\
    训练数据集 $T = \{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}$
\ENSURE \\
    AdaBoost 算法 $h_f\left(x\right)$
\FUNCTION{AdaBoost}{$L, M, T$}
\STATE $D_1\left(x\right) \gets 1 / n$
\FOR{$m = 1$ \TO $M$}
    \STATE $T_{sub} \gets $ sample from training set $T$ with weights
    \STATE $h_m \gets L\left(T_{sub}\right)$
    \STATE $\epsilon_m\gets Error\left(h_m\right)$
    \IF{$\epsilon_m > 0.5$}
        \BREAK
    \ENDIF
    \STATE $\alpha_m \gets \dfrac{1}{2} \ln \dfrac{1 - \epsilon_m}{\epsilon_m}$
    \STATE $D_{m+1} \gets \dfrac{D_m \exp \left(-\alpha_m y h_m\left(x\right)\right)}{Z_m}$
\ENDFOR
\STATE $h_f\left(x\right) \gets \text{sign} \left(\sum_{m=1}^{M} \alpha_m h_m\left(x\right)\right)$
\RETURN $h_f\left(x\right)$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<h3 id="gbdt-gbm-gbrt-mart">GBDT (GBM, GBRT, MART)</h3>

<p>GBDT (Gradient Boosting Decision Tree) 是另一种基于 Boosting 思想的集成算法，除此之外 GBDT 还有很多其他的叫法，例如：GBM (Gradient Boosting Machine)，GBRT (Gradient Boosting Regression Tree)，MART (Multiple Additive Regression Tree) 等等。GBDT 算法由 3 个主要概念构成：Gradient Boosting (GB)，Regression Decision Tree (DT 或 RT) 和 Shrinkage。</p>

<p>从 GBDT 的众多别名中可以看出，GBDT 中使用的决策树并非我们最常用的分类树，而是回归树。分类树主要用于处理响应变量为因子型的数据，例如天气 (可以为晴，阴或下雨等)。回归树主要用于处理响应变量为数值型的数据，例如商品的价格。当然回归树也可以用于二分类问题，对于回归树预测出的数值结果，通过设置一个阈值即可以将数值型的预测结果映射到二分类问题标签上，即 <code>$\mathcal{Y} = \{-1, +1\}$</code>。</p>

<p>对于 Gradient Boosting 而言，首先，Boosting 并不是 Adaboost 中 Boost 的概念，也不是 Random Forest 中的重抽样。在 Adaboost 中，Boost 是指在生成每个新的基学习器时，根据上一轮基学习器分类对错对训练集设置不同的权重，使得在上一轮中分类错误的样本在生成新的基学习器时更被重视。GBDT 中在应用 Boost 概念时，每一轮所使用的数据集没有经过重抽样，也没有更新样本的权重，而是每一轮选择了不用的回归目标，即上一轮计算得到的残差 (Residual)。其次，Gradient 是指在新一轮中在残差减少的梯度 (Gradient) 上建立新的基学习器。</p>

<p>下面我们通过一个年龄预测的 <a href="http://suanfazu.com/t/gbdt-die-dai-jue-ce-shu-ru-men-jiao-cheng/135" rel="noreferrer" target="_blank">示例</a> (较之原示例有修改) 简单介绍 GBDT 的工作流程。</p>

<p>假设存在 4 个人 <code>$P = \{p_1, p_2, p_3, p_4\}$</code>，他们的年龄分别为 <code>$14, 16, 24, 26$</code>。其中 <code>$p_1, p_2$</code> 分别是高一和高三学生，<code>$p_3, p_4$</code> 分别是应届毕业生和工作两年的员工。利用原始的决策树模型进行训练可以得到如下图所示的结果：</p>

<p><img src="/images/cn/2018-12-08-ensemble-learning/gbdt-decision-tree-1.png" alt="GBDT-Descision-Tree-1" /></p>

<p>利用 GBDT 训练模型，由于数据量少，在此我们限定每个基学习器中的叶子节点最多为 2 个，即树的深度最大为 1 层。训练得到的结果如下图所示：</p>

<p><img src="/images/cn/2018-12-08-ensemble-learning/gbdt-decision-tree-2.png" alt="GBDT-Descision-Tree-2" /></p>

<p>在训练第一棵树过程中，利用年龄作为预测值，根据计算可得由于 <code>$p_1, p_2$</code> 年龄相近，<code>$p_3, p_4$</code> 年龄相近被划分为两组。通过计算两组中真实年龄和预测的年龄的差值，可以得到第一棵树的残差 <code>$R = \{-1, 1, -1, 1\}$</code>。因此在训练第二棵树的过程中，利用第一棵树的残差作为标签值，最终所有人的年龄均正确被预测，即最终的残差均为 <code>$0$</code>。</p>

<p>则对于训练集中的 4 个人，利用训练得到的 GBDT 模型进行预测，结果如下：</p>

<ol>
<li><code>$p_1$</code> ：14 岁高一学生。购物较少，经常问学长问题，预测年龄 <code>$Age = 15 - 1 = 14$</code>。</li>
<li><code>$p_2$</code> ：16 岁高三学生。购物较少，经常回答学弟问题，预测年龄 <code>$Age = 15 + 1 = 16$</code>。</li>
<li><code>$p_3$</code> ：24 岁应届毕业生。购物较多，经常问别人问题，预测年龄 <code>$Age = 25 - 1 = 24$</code>。</li>
<li><code>$p_4$</code> ：26 岁 2 年工作经验员工。购物较多，经常回答别人问题，预测年龄 <code>$Age = 25 + 1 = 26$</code>。</li>
</ol>

<p>整个 GBDT 算法流程如下所示：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{GBDT 算法}
\begin{algorithmic}
\REQUIRE \\
    子模型个数 $M$ \\
    训练数据集 $T = \{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}$
\ENSURE \\
    GBDT 算法 $h_f\left(x\right)$
\FUNCTION{GBDT}{$M, T$}
\STATE $F_1\left(x\right) \gets \sum_{i = 1}^{N} y_i / N$
\FOR{$m = 1$ \TO $M$}
\STATE $r_m \gets y - F_m \left(x\right)$
\STATE $T_m \gets \left(x, r_m\right)$
\STATE $h_m \gets RegressionTree \left(T_m\right)$
\STATE $\alpha_m \gets \dfrac{\sum_{i = 1}^{N} r_{im} h_m \left(x_i\right)}{\sum_{i = 1}^{N} h_m \left(x_i\right)^2}$
\STATE $F_m \left(x\right) = F_{m-1} \left(x\right) + \alpha_m h_m \left(x\right)$
\ENDFOR
\STATE $h_f\left(x\right) =  F_M \left(x\right)$
\RETURN $h_f\left(x\right)$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>GBDT 中也应用到了 Shrinkage 的思想，其基本思想可以理解为每一轮利用残差学习得到的回归树仅学习到了一部分知识，因此我们无法完全信任一棵树的结果。Shrinkage 思想认为在新的一轮学习中，不能利用全部残差训练模型，而是仅利用其中一部分，即：</p>

<p><code>$$
r_m = y - s F_m \left(x\right), 0 \leq s \leq 1
$$</code></p>

<p>注意，这里的 Shrinkage 和学习算法中 Gradient 的步长是两个不一样的概念。Shrinkage 设置小一些可以避免发生过拟合现象；而 Gradient 中的步长如果设置太小则会陷入局部最优，如果设置过大又容易结果不收敛。</p>

<h3 id="xgboost">XGBoost</h3>

<p>XGBoost 是由 Chen 等人 <sup class="footnote-ref" id="fnref:chen2016xgboost"><a href="#fn:chen2016xgboost">9</a></sup> 提出的一种梯度提升树模型框架。XGBoost 的基本思想同 GBDT 一样，对于一个包含 <code>$n$</code> 个样本和 <code>$m$</code> 个特征的数据集 <code>$\mathcal{D} = \left\{\left(\mathbf{x}_i, y_i\right)\right\}$</code>，其中 <code>$\left|\mathcal{D}\right| = n, \mathbf{x}_i \in \mathbb{R}^m, y_i \in \mathbb{R}$</code>，一个集成树模型可以用 <code>$K$</code> 个加法函数预测输出：</p>

<p><code>$$
\hat{y}_i = \phi \left(\mathbf{x}_i\right) = \sum_{k=1}^{K}{f_k \left(\mathbf{x}_i\right)}, f_k \in \mathcal{F}
$$</code></p>

<p>其中，<code>$\mathcal{F} = \left\{f \left(\mathbf{x}\right) = w_{q \left(\mathbf{x}\right)}\right\} \left(q: \mathbb{R}^m \to T, w \in \mathbb{R}^T\right)$</code> 为回归树 (CART)，<code>$q$</code> 表示每棵树的结构，其将一个样本映射到最终的叶子节点，<code>$T$</code> 为叶子节点的数量，每个 <code>$f_w$</code> 单独的对应一棵结构为 <code>$q$</code> 和权重为 <code>$w$</code> 的树。不同于决策树，每棵回归树的每个叶子节点上包含了一个连续的分值，我们用 <code>$w_i$</code> 表示第 <code>$i$</code> 个叶子节点上的分值。</p>

<p>XGBoost 首先对损失函数进行了改进，添加了 L2 正则项，同时进行了二阶泰勒展开。损失函数表示为：</p>

<p><code>$$
\begin{equation}
\begin{split}
\mathcal{L} \left(\phi\right) = \sum_{i}{l \left(\hat{y}_i, y_i\right)} + \sum_{k}{\Omega \left(f_k\right)} \\
\text{where} \ \Omega \left(f\right) = \gamma T + \dfrac{1}{2} \lambda \left\| w \right\|^2
\end{split}
\end{equation}
$$</code></p>

<p>其中，<code>$l$</code> 为衡量预测值 <code>$\hat{y}_i$</code> 和真实值 <code>$y_i$</code> 之间差异的函数，<code>$\Omega$</code> 为惩罚项，<code>$\gamma$</code> 和 <code>$\lambda$</code> 为惩罚项系数。</p>

<p>我们用 <code>$\hat{y}_i^{\left(t\right)}$</code> 表示第 <code>$t$</code> 次迭代的第 <code>$i$</code> 个实例，我们需要增加 <code>$f_t$</code> 来最小化如下的损失函数：</p>

<p><code>$$
\mathcal{L}^{\left(t\right)} = \sum_{i=1}^{n}{l \left(y_i, \hat{y}_i^{\left(t-1\right)} + f_t \left(\mathbf{x}_i\right)\right)} + \Omega \left(f_t\right)
$$</code></p>

<p>对上式进行二阶泰勒展开有：</p>

<p><code>$$
\mathcal{L}^{\left(t\right)} \simeq \sum_{i=1}^{n}{\left[l \left(y_i, \hat{y}_i^{\left(t-1\right)}\right) + g_i f_t \left(\mathbf{x}_i\right) + \dfrac{1}{2} h_i f_t^2 \left(\mathbf{x}_i\right)\right]} + \Omega \left(f_t\right)
$$</code></p>

<p>其中，<code>$g_i = \partial_{\hat{y}^{\left(t-1\right)}} l \left(y_i, \hat{y}^{\left(t-1\right)}\right), h_i = \partial_{\hat{y}^{\left(t-1\right)}}^{2} l \left(y_i, \hat{y}^{\left(t-1\right)}\right)$</code> 分别为损失函数的一阶梯度和二阶梯度。去掉常数项，第 <code>$t$</code> 步的损失函数可以简化为：</p>

<p><code>$$
\tilde{\mathcal{L}}^{\left(t\right)} = \sum_{i=1}^{n}{\left[ g_i f_t \left(\mathbf{x}_i\right) + \dfrac{1}{2} h_i f_t^2 \left(\mathbf{x}_i\right)\right]} + \Omega \left(f_t\right)
$$</code></p>

<p>令 <code>$I_j = \left\{i \ | \ q \left(\mathbf{x}_i\right) = j\right\}$</code> 表示叶子节点 <code>$j$</code> 的实例集合，上式可重写为：</p>

<p><code>$$
\begin{equation}
\begin{split}
\tilde{\mathcal{L}}^{\left(t\right)} &amp;= \sum_{i=1}^{n}{\left[ g_i f_t \left(\mathbf{x}_i\right) + \dfrac{1}{2} h_i f_t^2 \left(\mathbf{x}_i\right)\right]} + \gamma T + \dfrac{1}{2} \lambda \sum_{j=1}^{T}{w_j^2} \\
&amp;= \sum_{j=1}^{T}{\left[\left(\sum_{i \in I_j}{g_i}\right) w_j + \dfrac{1}{2} \left(\sum_{i \in I_j}{h_i + \lambda}\right) w_j^2\right]} + \gamma T
\end{split}
\end{equation}
$$</code></p>

<p>对于一个固定的结构 <code>$q \left(\mathbf{x}\right)$</code>，可以通过下式计算叶子节点 <code>$j$</code> 的最优权重 <code>$w_j^*$</code>：</p>

<p><code>$$
w_j^* = - \dfrac{\sum_{i \in I_j}{g_i}}{\sum_{i \in I_j}{h_i} + \lambda}
$$</code></p>

<p>进而计算对应的最优值：</p>

<p><code>$$
\tilde{\mathcal{L}}^{\left(t\right)} \left(q\right) = - \dfrac{1}{2} \sum_{j=1}^{T}{\dfrac{\left(\sum_{i \in I_j}{g_i}\right)^2}{\sum_{i \in I_j}{h_i} + \lambda}} + \gamma T
$$</code></p>

<p>上式可以作为评价树的结构 <code>$q$</code> 的评分函数。通常情况下很难枚举所有可能的树结构，一个贪心的算法是从一个节点出发，逐层的选择最佳的分裂节点。令 <code>$I_L$</code> 和 <code>$I_R$</code> 分别表示分裂后左侧和右侧的节点集合，令 <code>$I = I_L \cup I_R$</code>，则分裂后损失的减少量为：</p>

<p><code>$$
\mathcal{L}_{\text{split}} = \dfrac{1}{2} \left[\dfrac{\left(\sum_{i \in I_L}{g_i}\right)^2}{\sum_{i \in I_L}{h_i} + \lambda} + \dfrac{\left(\sum_{i \in I_R}{g_i}\right)^2}{\sum_{i \in I_R}{h_i} + \lambda} - \dfrac{\left(\sum_{i \in I}{g_i}\right)^2}{\sum_{i \in I}{h_i} + \lambda}\right] - \gamma
$$</code></p>

<p>XGBoost 也采用了 Shrinkage 的思想减少每棵树的影响，为后续树模型留下更多的改进空间。同时 XGBoost 也采用了随机森林中的特征下采样 (列采样) 方法用于避免过拟合，同时 XGBoost 也支持样本下采样 (行采样)。XGBoost 在分裂点的查找上也进行了优化，使之能够处理无法将全部数据读入内存的情况，同时能够更好的应对一些由于数据缺失，大量零值和 One-Hot 编码导致的特征稀疏问题。除此之外，XGBoost 在系统实现，包括：并行化，Cache-Aware 加速和数据的核外计算 (Out-of-Core Computation) 等方面也进行了大量优化，相关具体实现请参见论文和 <a href="https://xgboost.readthedocs.io/en/latest/" rel="noreferrer" target="_blank">文档</a>。</p>

<h3 id="lightgbm">LightGBM</h3>

<p>LightGBM 是由微软研究院的 Ke 等人 <sup class="footnote-ref" id="fnref:ke2017lightgbm"><a href="#fn:ke2017lightgbm">10</a></sup> 提出了一种梯度提升树模型框架。之前的 GBDT 模型在查找最优分裂点时需要扫描所有的样本计算信息增益，因此其计算复杂度与样本的数量和特征的数量成正比，这使得在处理大数据量的问题时非常耗时。LightGBM 针对这个问题提出了两个算法：</p>

<ol>
<li>Gradient-based One-Side Sampling (GOSS)</li>
<li>Exclusive Feature Bundling (EFB)</li>
</ol>

<h4 id="gradient-based-one-side-sampling">Gradient-based One-Side Sampling</h4>

<p>在 AdaBoost 中，样本的权重很好的诠释了数据的重要性，但在 GBDT 中并没有这样的权重，因此无法直接应用 AdaBoost 的采样方法。幸运的是 GBDT 中每个样本的梯度可以为我们的数据采样提供有用的信息。当一个样本具有较小的梯度时，其训练的误差也较小，表明其已经训练好了。一个直观的想法就是丢弃这些具有较小梯度的样本，但是这样操作会影响整个数据的分布，从而对模型的精度造成损失。</p>

<p>GOSS 的做法是保留具有较大梯度的样本，并从具有较小梯度的样本中随机采样。同时为了补偿对数据分布的影响，在计算信息增益的时候，GOSS 针对梯度较小的样本引入了一个常数乘子。这样就保证了模型更多的关注未得到较好训练的数据，同时又不会对原始数据分布改变过多。整个算法流程如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{GOSS 算法}
\begin{algorithmic}
\INPUT \\
    训练数据 $I$ \\
    迭代次数 $d$ \\
    具有较大梯度数据的采样比例 $a$ \\
    具有较小梯度数据的采样比例 $b$ \\
    损失函数 $loss$ \\
    基学习器 $L$
\FUNCTION{GOSS}{$I, d, a, b, loss, L$}
\STATE $\text{models} \gets \varnothing$
\STATE $\text{fact} \gets \dfrac{1-a}{b}$
\STATE $\text{topN} \gets a \times \text{len} \left(I\right)$
\STATE $\text{randN} \gets b \times \text{len} \left(I\right)$
\FOR{$i = 1$ \TO $d$}
    \STATE $\text{preds} \gets \text{models.predict} \left(I\right)$
    \STATE $\text{g} \gets loss \left(I, \text{preds}\right)$
    \STATE $\text{w} \gets \left\{1, 1, \dotsc\right\}$
    \STATE $\text{sorted} \gets \text{GetSortedIndices} \left(\text{abs} \left(\text{g}\right)\right)$
    \STATE $\text{topSet} \gets \text{sorted[1:topN]}$
    \STATE $\text{randSet} \gets \text{RandomPick} \left(\text{sorted[topN:len}\left(I\right)\text{]}, \text{randN}\right)$
    \STATE $\text{usedSet} \gets \text{topSet} \cup \text{randSet}$
    \STATE $\text{w[randSet]} \gets \text{w[randSet]} \times \text{fact}$
    \STATE $\text{newModel} \gets L \left(I \text{[usedSet]}, - \text{g[usedSet]}, \text{w[usedSet]}\right)$
    \STATE $\text{models} \gets \text{models} \cup \text{newModel}$
\ENDFOR
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<h4 id="exclusive-feature-bundling">Exclusive Feature Bundling</h4>

<p>高维数据往往是稀疏的，特征空间的稀疏性为我们提供了可能的近似无损的特征降维实现。进一步而言，在稀疏的特征空间中，很多特征之间是互斥的，也就是说它们不同时取非零值。因此，我们就可以将这些互斥的特征绑定成一个特征。由于 <code>$\#bundle \ll \#feature$</code>，因此构建直方图的复杂度就可以从 <code>$O \left(\#data \times \#features\right)$</code> 减小至 <code>$O \left(\#data \times \#bundle\right)$</code>，从而在不损失精度的情况下加速模型的训练。这样我们就需要解决如下两个问题：</p>

<ol>
<li>确定对哪些特征进行绑定。</li>
<li>如果对这些特征进行绑定。</li>
</ol>

<p>对哪些特征进行绑定可以利用 <a href="https://en.wikipedia.org/wiki/Graph_coloring" rel="noreferrer" target="_blank">图着色问题</a> 进行解决。对于一个图 <code>$G = \left(V, E\right)$</code>，将 <code>$G$</code> 的 <a href="https://en.wikipedia.org/wiki/Incidence_matrix" rel="noreferrer" target="_blank">关联矩阵</a> 中的每一行看成特征，得到 <code>$|V|$</code> 个特征，从而可以得出图中颜色相同的节点即为互斥的特征。算法如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{Greedy Bundling}
\begin{algorithmic}
\INPUT \\
    特征 $F$ \\
    最大冲突数量 $K$
\OUTPUT \\
    需要绑定的特征 $bundles$
\FUNCTION{GreedyBundling}{$F, K$}
\STATE Construct graph $G$
\STATE $\text{searchOrder} \gets G.\text{sortByDegree}()$
\STATE $\text{bundles} \gets \varnothing$
\STATE $\text{bundlesConflict} \gets \varnothing$
\FOR{$i$ $\in$ searchOrder}
    \STATE $\text{needNew} \gets$ \TRUE
    \FOR{$j = 1$ \TO len(bundles)}
        \STATE $\text{cnt} \gets$ ConflictCnt(bundles[$j$],F[$i$])
        \IF{cnt $+$ bundlesConflict[$i$] $\leq K$}
            \STATE bundles[$j$].add($F[i]$)
            \STATE $\text{needNew} \gets$ \FALSE
            \BREAK
        \ENDIF
    \ENDFOR
    \IF{needNew}
        \STATE $bundles \gets bundles \cup F[i]$
    \ENDIF
\ENDFOR
\RETURN $bundles$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>上述算法的复杂度为 <code>$O \left(\#feature^2\right)$</code> ，并且仅在模型训练前运行一次。对于特征数不是很大的情况是可以接受的，但当特征数量很大时算法效率并不令人满意。进一步的优化是在不构造图的情况下进行高效的排序，即根据非零值的数量进行排序，更多的非零值意味着更高的冲突概率。</p>

<p>合并特征的关键在于确保原始特征的值能够从合并后的特征之中识别出来。由于基于直方图的算法保存的是原始特征的离散桶，而非连续的值，因此我们可以将互斥的特征置于不同的桶内。算法如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{Merge Exclusive Features}
\begin{algorithmic}
\REQUIRE \\
    数据数量 $numData$ \\
    一组互斥特征 $F$
\ENSURE \\
    新的分箱 $newBin$ \\
    分箱范围 $binRanges$
\FUNCTION{MergeExclusiveFeatures}{$numData, F$}
\STATE $\text{binRages} \gets \left\{0\right\}$
\STATE $\text{totalBin} \gets 0$
\FOR{$f$ $\in$ $F$}
    \STATE $\text{totalBin} \gets \text{totalBin} + \text{f.numBin}$
    \STATE $\text{binRanges} \gets \text{binRanges} \cup \text{totalBin}$
\ENDFOR
\STATE $\text{newBin} \gets \text{Bin} \left(numData\right)$
\FOR{$i = 1$ \TO $numData$}
    \STATE $\text{newBin}[i] \gets 0$
    \FOR{$j = 1$ \TO $\text{len} \left(F\right)$}
        \IF{$F[j].\text{bin}[i] \neq 0$}
            \STATE $\text{newBin}[i] \gets F[j].\text{bin}[i] + \text{binRanges}[j]$
        \ENDIF
    \ENDFOR
\ENDFOR
\RETURN $newBin, binRanges$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>EFB 算法可以将大量的互斥特征合并为少量的稠密特征，从而通过避免对零值特征的计算提高算法的运行效率。</p>

<h4 id="tree-growth">Tree Growth</h4>

<p>大多的决策树算法通过逐层 (Level-wise / Depth-wise) 的方法生成树，如下图所示：</p>

<p><img src="/images/cn/2018-12-08-ensemble-learning/tree-growth-level-wise.png" alt="Level-Wise-Tree-Growth" /></p>

<p>LightGBM 采用了另外一种 Leaf-wise (或称 Best-first) 的方式生成 <sup class="footnote-ref" id="fnref:shi2007best"><a href="#fn:shi2007best">11</a></sup>，如下图所示：</p>

<p><img src="/images/cn/2018-12-08-ensemble-learning/tree-growth-leaf-wise.png" alt="Leaf-Wise-Tree-Growth" /></p>

<p>该方法想选择具有最大 Delta Loss 值的叶子节点进行生长。在固定叶子节点数量的情况下，Leaf-wise 的生长方式比 Level-wise 的方式更容易获得较低的损失值。Leaf-wise 的生长方式在数据量较小时容易产生过拟合的现象，在 LightGBM 中可以通过限制树的最大深度减轻该问题。</p>

<p>更多有关 LightGBM 的优化请参见论文和 <a href="https://github.com/Microsoft/LightGBM/blob/master/docs/Features.rst" rel="noreferrer" target="_blank">文档</a>。</p>

<h3 id="catboost">CatBoost</h3>

<p>CatBoost 是由俄罗斯 Yandex 公司 <sup class="footnote-ref" id="fnref:dorogush2018catboost"><a href="#fn:dorogush2018catboost">12</a></sup> <sup class="footnote-ref" id="fnref:prokhorenkova2018catBoost"><a href="#fn:prokhorenkova2018catBoost">13</a></sup> 提出的一种梯度提升树模型框架。相比于之前的实现，CatBoost 的优化主要包括如下几点：</p>

<ol>
<li>提出了一种处理分类特征 (Categorical Features) 的算法。</li>
<li>提出了一种解决预测偏移 (Prediction Shift) 问题的算法。</li>
</ol>

<h4 id="分类特征">分类特征</h4>

<p>分类特征是由一些离散的值构成的集合，其无法直接应用在提升树模型中，一个常用的方法是利用 One-Hot 编码对分类特征进行预处理，将其转化成值特征。</p>

<p>另一种方法是根据样本的标签值计算分类特征的一些统计量 (Target Statistics, TS)。令 <code>$\mathcal{D} = \left\{\left(\mathbf{x}_k, y_k\right)\right\}_{k=1, \dotsc, n}$</code> 为一个数据集，其中 <code>$\mathbf{x}_k = \left(x_k^1, \dotsc, x_k^m\right)$</code> 为一个包含 <code>$m$</code> 个特征的向量 (包含值特征和分类特征)，<code>$y_k \in \mathbb{R}$</code> 为标签值。最简单的做法是将分类特征替换为全量训练数据上对应特征值相同的标签值的均值，即 <code>$\hat{x}_k^i \approx \mathbb{E} \left(y \ | \ x^i = x_k^i\right)$</code>。</p>

<ul>
<li>Greedy TS</li>
</ul>

<p>一个简单估计 <code>$\mathbb{E} \left(y \ | \ x^i = x_k^i\right)$</code> 的方法是对具有相同类型 <code>$x_k^i$</code> 的样本的标签值求均值。但这种估计对于低频的分类噪音较大，因此我们可以通过一个先验 <code>$P$</code> 来进行平滑：</p>

<p><code>$$
\hat{x}_k^i = \dfrac{\sum_{j=1}^{n}{\boldsymbol{1}_{\left\{x_j^i = x_k^i\right\}} \cdot y_j} + a P}{\sum_{j=1}^{n}{\boldsymbol{1}_{\left\{x_j^i = x_k^i\right\}}} + a}
$$</code></p>

<p>其中，<code>$a &gt; 0$</code> 为先验系数，<code>$\boldsymbol{1}$</code> 为指示函数，通常 <code>$P$</code> 取整个数据集标签值的均值。</p>

<p>上述贪婪 (Greedy) 的做法的问题在于存在目标泄露 (Target Leakage)，即特征 <code>$\hat{x}_k^i$</code> 是通过 <code>$\mathbf{x}_k$</code> 的目标 <code>$y_k$</code> 计算所得。这会导致条件偏移 (Conditional Shift) 的问题 <sup class="footnote-ref" id="fnref:zhang2013domain"><a href="#fn:zhang2013domain">14</a></sup>，即 <code>$\hat{x}^i \ | \ y$</code> 的分布在训练集和测试集上不同。因此在计算 TS 时需要满足如下特性：</p>

<div class="blockquote" style='border-left: 4px solid #369BE5;'><strong>特性 1.</strong> <code>$\mathbb{E} \left(\hat{x}^i \ | \ y = v\right) = \mathbb{E} \left(\hat{x}_k^i \ | \ y_k = v\right)$</code>，其中 <code>$\left(x_k, y_k\right)$</code> 为第 <code>$k$</code> 个训练样本。</div>

<p>一种修正方法是在计算 TS 时使用排除掉 <code>$\mathbf{x}_k$</code> 的一个子集，令 <code>$\mathcal{D}_k \subset \mathcal{D} \setminus \left\{\mathbf{x}_k\right\}$</code>，有：</p>

<p><code>$$
\hat{x}_k^i = \dfrac{\sum_{\mathbf{x}_j \in \mathcal{D}_k}{\boldsymbol{1}_{\left\{x_j^i = x_k^i\right\}} \cdot y_j} + a P}{\sum_{\mathbf{x}_j \in \mathcal{D}_k}{\boldsymbol{1}_{\left\{x_j^i = x_k^i\right\}}} + a}
$$</code></p>

<ul>
<li>Holdout TS</li>
</ul>

<p>另一种方法是将训练集划分为两部分 <code>$\mathcal{D} = \hat{\mathcal{D}}_0 \sqcup \hat{\mathcal{D}_1}$</code>，利用 <code>$\mathcal{D}_k = \hat{\mathcal{D}}_0$</code> 计算 TS，利用 <code>$\hat{\mathcal{D}_1}$</code> 进行训练。虽然满足了 <strong>特性 1</strong>，但是这会导致计算 TS 和用于训练的数据均显著减少，因此还需要满足另一个特性：</p>

<div class="blockquote" style='border-left: 4px solid #369BE5;'><strong>特性 2.</strong> 有效地利用所有的训练数据计算 TS 和训练模型。</div>

<ul>
<li>Leave-one-out TS</li>
</ul>

<p>对于训练样本 <code>$\mathbf{x}_k$</code> 令 <code>$\mathcal{D}_k = \mathcal{D} \setminus \mathbf{x}_k$</code>，对于测试集，令 <code>$\mathcal{D}_k = \mathcal{D}$</code>，但这并没有解决 Target Leakage 问题。</p>

<ul>
<li>Ordered TS</li>
</ul>

<p>Catboost 采用了一种更有效的策略：首先对于训练样本进行随机排列，得到排列下标 <code>$\sigma$</code>，之后对于每个训练样本仅利用“历史”样本来计算 TS，即：<code>$\mathcal{D}_k = \left\{\mathbf{x}_j: \sigma \left(j\right) &lt; \sigma \left(k\right)\right\}$</code>，对于每个测试样本 <code>$\mathcal{D}_k = \mathcal{D}$</code>。</p>

<h4 id="prediction-shift-ordered-boosting">Prediction Shift &amp; Ordered Boosting</h4>

<p>类似计算 TS，Prediction Shift 是由一种特殊的 Target Leakage 所导致的。对于第 <code>$t$</code> 次迭代，我们优化的目标为：</p>

<p><code>$$
h^t = \mathop{\arg\min}_{h \in H} \mathbb{E} \left(-g^t \left(\mathbf{x}, y\right) - h \left(\mathbf{x}\right)\right)^2  \label{eq:catboost-obj}
$$</code></p>

<p>其中，<code>$g^t \left(\mathbf{x}, y\right) := \dfrac{\partial L \left(y, s\right)}{\partial s} \bigg\vert_{s = F^{t-1} \left(\mathbf{x}\right)}$</code>。通常情况下会使用相同的数据集 <code>$\mathcal{D}$</code> 进行估计：</p>

<p><code>$$
h^t = \mathop{\arg\min}_{h \in H} \dfrac{1}{n} \sum_{k=1}^{n}{\left(-g^t \left(\mathbf{x}_k, y_k\right) - h \left(\mathbf{x}_k\right)\right)^2} \label{eq:catboost-obj-approx}
$$</code></p>

<p>整个偏移的链条如下：</p>

<ol>
<li>梯度的条件分布 <code>$g^t \left(\mathbf{x}_k, y_k\right) \ | \ \mathbf{x}_k$</code> 同测试样本对应的分布 <code>$g^t \left(\mathbf{x}, y\right) \ | \ \mathbf{x}$</code> 存在偏移。</li>
<li>由式 <code>$\ref{eq:catboost-obj}$</code> 定义的基学习器 <code>$h^t$</code> 同由式 <code>$\ref{eq:catboost-obj-approx}$</code> 定义的估计方法存在偏移。</li>
<li>最终影响训练模型 <code>$F^t$</code> 的泛化能力。</li>
</ol>

<p>每一步梯度的估计所使用的标签值同构建当前模型 <code>$F^{t-1}$</code> 使用的相同。但是，对于一个训练样本 <code>$\mathbf{x}_k$</code> 而言，条件分布 <code>$F^{t-1} \left(\mathbf{x}_k \ | \ \mathbf{x}_k\right)$</code> 相对一个测试样本 <code>$\mathbf{x}$</code> 对应的分布 <code>$F^{t-1} \left(\mathbf{x}\right) \ | \ \mathbf{x}$</code> 发生了偏移，我们称这为预测偏移 (Prediction Shift)。</p>

<p>CatBoost 提出了一种解决 Prediction Shift 的算法：Ordered Boosting。假设对于训练数据进行随机排序得到 <code>$\sigma$</code>，并有 <code>$n$</code> 个不同的模型 <code>$M_1, \dotsc, M_n$</code>，每个模型 <code>$M_i$</code> 仅利用随机排序后的前 <code>$i$</code> 个样本训练得到。算法如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{Ordered Boosting}
\begin{algorithmic}
\INPUT \\
    训练集 $\left\{\left(\mathbf{x}_k, y_k\right)\right\}_{k=1}^{n}$ \\
    树的个数 $I$
\OUTPUT \\
    模型 $M_n$
\FUNCTION{OrderedBoosting}{$numData, F$}
\STATE $\sigma \gets \text{random permutation of} \left[1, n\right]$
\STATE $M_i \gets 0$ for $i = 1, \dotsc, n$
\FOR{$t = 1$ \TO $I$}
    \FOR{$i = 1$ \TO $n$}
        \STATE $r_i \gets y_i - M_{\sigma \left(i\right) -1} \left(\mathbf{x}_i\right)$
    \ENDFOR
    \FOR{$i = 1$ \TO $n$}
        \STATE $\Delta M \gets \text{LearnModel} \left(\left(\mathbf{x}_j, r_j\right): \sigma \left(j\right) \leq i\right)$
        \STATE $M_i \gets M_i + \Delta M$
    \ENDFOR
\ENDFOR
\RETURN $M_n$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>在计算 TS 和进行 Ordered Boosting 时我们均使用了随机排列并得到 <code>$\sigma_{cat}$</code> 和 <code>$\sigma_{boost}$</code>。需要注意的是在将两部分合并为一个算法时，我们需要令 <code>$\sigma_{cat} = \sigma_{boost}$</code> 避免 Prediction Shift。这样可以保证目标 <code>$y_i$</code> 不用于训练模型 <code>$M_i$</code> (既不参与计算 TS，也不用于梯度估计)。</p>

<p>更多 CatBoost 的实现细节请参见论文和 <a href="https://tech.yandex.com/catboost/" rel="noreferrer" target="_blank">文档</a>。</p>

<h3 id="不同实现的比较">不同实现的比较</h3>

<p>针对 <a href="https://github.com/scikit-learn/scikit-learn" rel="noreferrer" target="_blank">scikit-learn</a>，<a href="https://github.com/dmlc/xgboost" rel="noreferrer" target="_blank">XGBoost</a>，<a href="https://github.com/Microsoft/LightGBM" rel="noreferrer" target="_blank">LightGBM</a> 和 <a href="https://github.com/catboost/catboost" rel="noreferrer" target="_blank">CatBoost</a> 4 种 GBDT 的具体实现，下表汇总了各自的相关特性：</p>

<table>
<thead>
<tr>
<th></th>
<th>scikit-learn</th>
<th>XGBoost</th>
<th>LightGBM</th>
<th>CatBoost</th>
</tr>
</thead>

<tbody>
<tr>
<td><strong>当前版本</strong></td>
<td>0.20.1</td>
<td>0.81</td>
<td>2.2.2</td>
<td>0.11.1</td>
</tr>

<tr>
<td><strong>实现语言</strong></td>
<td>C, C++, Python</td>
<td>C, C++</td>
<td>C, C++</td>
<td>C++</td>
</tr>

<tr>
<td><strong>API 语言</strong></td>
<td>Python</td>
<td>Python, R, Java, Scala, C++ and more</td>
<td>Python, R</td>
<td>Python, R</td>
</tr>

<tr>
<td><strong>模型导出</strong></td>
<td>JPMML <sup class="footnote-ref" id="fnref:JPMML-SkLearn"><a href="#fn:JPMML-SkLearn">15</a></sup></td>
<td>JPMML <sup class="footnote-ref" id="fnref:JPMML-XGBoost"><a href="#fn:JPMML-XGBoost">16</a></sup>, ONNX <sup class="footnote-ref" id="fnref:ONNX"><a href="#fn:ONNX">17</a></sup> <sup class="footnote-ref" id="fnref:WinMLTools"><a href="#fn:WinMLTools">18</a></sup></td>
<td>ONNX <sup class="footnote-ref" id="fnref:ONNX"><a href="#fn:ONNX">17</a></sup> <sup class="footnote-ref" id="fnref:ONNXMLTools"><a href="#fn:ONNXMLTools">19</a></sup></td>
<td>CoreML, Python, C++, JSON <sup class="footnote-ref" id="fnref:CatBoost-Save-Model"><a href="#fn:CatBoost-Save-Model">20</a></sup></td>
</tr>

<tr>
<td><strong>多线程</strong></td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>

<tr>
<td><strong>GPU</strong></td>
<td>No</td>
<td>Yes <sup class="footnote-ref" id="fnref:XGBoost-GPU"><a href="#fn:XGBoost-GPU">21</a></sup></td>
<td>Yes <sup class="footnote-ref" id="fnref:LightGBM-GPU"><a href="#fn:LightGBM-GPU">22</a></sup></td>
<td>Yes <sup class="footnote-ref" id="fnref:CatBoost-GPU"><a href="#fn:CatBoost-GPU">23</a></sup></td>
</tr>

<tr>
<td><strong>多 GPU</strong></td>
<td>No</td>
<td>Yes <sup class="footnote-ref" id="fnref:XGBoost-GPU"><a href="#fn:XGBoost-GPU">21</a></sup></td>
<td>No</td>
<td>Yes <sup class="footnote-ref" id="fnref:CatBoost-GPU"><a href="#fn:CatBoost-GPU">23</a></sup></td>
</tr>

<tr>
<td><strong>Boosting 类型</strong></td>
<td>Gradient Boosted Tree (<strong>GBDT</strong>)</td>
<td><strong>GBDT</strong> (booster: gbtree) <br/>Generalized Linear Model, <strong>GLM</strong> (booster: gbliner) <br/>Dropout Additive Regression Tree, <strong>DART</strong> (booster: dart)</td>
<td><strong>GBDT</strong> (boosting: gbdt) <br/><strong>Random Forest</strong> (boosting: rf) <br/><strong>DART</strong> (boosting: dart) <br/>Gradient-based One-Side Sampling, <strong>GOSS</strong> (bossting: goss)</td>
<td><strong>Ordered</strong> (boosting_type: Ordered) <br/><strong>Plain</strong> (bossting_type: Plain)</td>
</tr>

<tr>
<td><strong>Level-wise (Depth-wise) Split</strong></td>
<td>Yes</td>
<td>Yes <br/>(grow_policy: depthwise)</td>
<td>No</td>
<td>Yes</td>
</tr>

<tr>
<td><strong>Leaf-wise (Best-first) Split</strong></td>
<td>No</td>
<td>Yes <br/>(grow_policy: lossguide)</td>
<td>Yes</td>
<td>No</td>
</tr>

<tr>
<td><strong>Histogram-based Split</strong></td>
<td>No</td>
<td>Yes <br/>(tree_method: hist / gpu_hist)</td>
<td>Yes</td>
<td>Yes</td>
</tr>

<tr>
<td><strong>过拟合控制</strong></td>
<td>Yes <br>(max_depth, &hellip;)</td>
<td>Yes <br/>(max_depth, max_leaves, gamma, reg_alpha, reg_lamda, &hellip;)</td>
<td>Yes <br/>(max_depth, num_leaves, gamma, reg_alpha, reg_lamda, drop_rate, &hellip;)</td>
<td>Yes <br/>(max_depth, reg_lambda, &hellip;)</td>
</tr>

<tr>
<td><strong>分类特征</strong></td>
<td>No</td>
<td>No</td>
<td>Yes <br/>(categorical_feature)</td>
<td>Yes <br/>(cat_features)</td>
</tr>

<tr>
<td><strong>缺失值处理</strong></td>
<td>No</td>
<td>Yes</td>
<td>Yes <br/>(use_missing)</td>
<td>Yes</td>
</tr>

<tr>
<td><strong>不均衡数据</strong></td>
<td>No</td>
<td>Yes <br/>(scale_pos_weight, max_delta_step)</td>
<td>Yes <br/>(scale_pos_weight, poisson_max_delta_step)</td>
<td>Yes <br/>(scale_pos_weight)</td>
</tr>
</tbody>
</table>

<p>不同实现的性能分析和比较可参见如下文章，括号中内容为分析的实现库：</p>

<ul>
<li><a href="https://xgboost.ai/2016/12/14/GPU-accelerated-xgboost.html" rel="noreferrer" target="_blank">GPU Accelerated XGBoost</a> (XGBoost)</li>
<li><a href="https://xgboost.ai/2018/07/04/gpu-xgboost-update.html" rel="noreferrer" target="_blank">Updates to the XGBoost GPU algorithms</a> (XGBoost)</li>
<li><a href="https://lightgbm.readthedocs.io/en/latest/Experiments.html" rel="noreferrer" target="_blank">LightGBM Experiments</a> (XGBoost, LightGBM)，<a href="https://github.com/guolinke/boosting_tree_benchmarks" rel="noreferrer" target="_blank">代码</a></li>
<li><a href="https://lightgbm.readthedocs.io/en/latest/GPU-Performance.html" rel="noreferrer" target="_blank">GPU Tunning Guide and Performance Comparision</a> (LightGBM)</li>
<li><a href="https://blogs.technet.microsoft.com/machinelearning/2017/07/25/lessons-learned-benchmarking-fast-machine-learning-algorithms/" rel="noreferrer" target="_blank">Lessons Learned From Benchmarking Fast Machine Learning Algorithms</a> (XGBoost, LightGBM), <a href="https://github.com/Azure/fast_retraining" rel="noreferrer" target="_blank">代码</a></li>
<li><a href="https://github.com/catboost/benchmarks" rel="noreferrer" target="_blank">CatBoost Benchmarks</a> (XGBoost, LightGBM, CatBoost, H2O)</li>
<li><a href="https://arxiv.org/abs/1809.04559" rel="noreferrer" target="_blank">Benchmarking and Optimization of Gradient Boosted Decision Tree Algorithms</a> (XGBoost, LightGBM, CatBoost)</li>
<li><a href="https://sites.google.com/view/lauraepp/home" rel="noreferrer" target="_blank">Laurae++: xgboost / LightGBM</a> (XGBoost, LightGBM), <a href="https://github.com/Laurae2/gbt_benchmarks" rel="noreferrer" target="_blank">代码</a></li>
<li><a href="https://github.com/szilard/GBM-perf" rel="noreferrer" target="_blank">GBM Performance</a> (XGBoost, LightGBM, H2O), <a href="https://github.com/szilard/GBM-perf" rel="noreferrer" target="_blank">代码</a></li>
</ul>

<h2 id="stacking">Stacking</h2>

<p>Stacking 本身是一种集成学习方法，同时也是一种模型组合策略，我们首先介绍一些相对简单的模型组合策略：<strong>平均法</strong> 和 <strong>投票法</strong>。</p>

<p>对于 <strong>数值型的输出</strong> <code>$h_i \left(\mathbf{x}\right) \in \mathbb{R}$</code>，</p>

<ul>
<li>简单平均法 (Simple Averaging)</li>
</ul>

<p><code>$$
H \left(\mathbf{x}\right) = \dfrac{1}{M} \sum_{i=1}^{M}{h_i \left(\mathbf{x}\right)}
$$</code></p>

<ul>
<li>加权平均法 (Weighted Averaging)</li>
</ul>

<p><code>$$
H \left(\mathbf{x}\right) = \sum_{i=1}^{M}{w_i h_i \left(\mathbf{x}\right)}
$$</code></p>

<p>其中，<code>$w_i$</code> 为学习器 <code>$h_i$</code> 的权重，且 <code>$w_i \geq 0, \sum_{i=1}^{T}{w_i} = 1$</code>。</p>

<p>对于 <strong>分类型的任务</strong>，学习器 <code>$h_i$</code> 从类别集合 <code>$\left\{c_1, c_2, \dotsc, c_N\right\}$</code> 中预测一个标签。我们将 <code>$h_i$</code> 在样本 <code>$\mathbf{x}$</code> 上的预测输出表示为一个 <code>$N$</code> 维向量 <code>$\left(h_i^1 \left(\mathbf{x}\right); h_i^2 \left(\mathbf{x}\right); \dotsc, h_i^N \left(\mathbf{x}\right)\right)$</code>，其中 <code>$h_i^j \left(\mathbf{x}\right)$</code> 为 <code>$h_i$</code> 在类型标签 <code>$c_j$</code> 上的输出。</p>

<ul>
<li>绝对多数投票法 (Majority Voting)</li>
</ul>

<p><code>$$
H \left(\mathbf{x}\right) = \begin{cases}
c_j, &amp; \displaystyle\sum_{i=1}^{M}{h_i^j \left(\mathbf{x}\right) &gt; 0.5 \displaystyle\sum_{k=1}^{N}{\displaystyle\sum_{i=1}^{M}{h_i^k \left(\mathbf{x}\right)}}} \\
\text{refuse}, &amp; \text{other wise}
\end{cases}
$$</code></p>

<p>即如果一个类型的标记得票数过半，则预测为该类型，否则拒绝预测。</p>

<ul>
<li>相对多数投票法 (Plurality Voting)</li>
</ul>

<p><code>$$
H \left(\mathbf{x}\right) = c_{\arg\max_j \sum_{i=1}^{M}{h_i^j \left(\mathbf{x}\right)}}
$$</code></p>

<p>即预测为得票数最多的类型，如果同时有多个类型获得相同最高票数，则从中随机选取一个。</p>

<ul>
<li>加权投票法 （Weighted Voting)</li>
</ul>

<p><code>$$
H \left(\mathbf{x}\right) = c_{\arg\max_j \sum_{i=1}^{M}{w_i h_i^j \left(\mathbf{x}\right)}}
$$</code></p>

<p>其中，<code>$w_i$</code> 为学习器 <code>$h_i$</code> 的权重，且 <code>$w_i \geq 0, \sum_{i=1}^{M}{w_i} = 1$</code>。</p>

<p>绝对多数投票提供了“拒绝预测”，这为可靠性要求较高的学习任务提供了一个很好的机制，但如果学习任务要求必须有预测结果时则只能选择相对多数投票法和加权投票法。在实际任务中，不同类型的学习器可能产生不同类型的 <code>$h_i^j \left(\boldsymbol{x}\right)$</code> 值，常见的有：</p>

<ul>
<li>类标记，<code>$h_i^j \left(\mathbf{x}\right) \in \left\{0, 1\right\}$</code>，若 <code>$h_i$</code> 将样本 <code>$\mathbf{x}$</code> 预测为类型 <code>$c_j$</code> 则取值为 1，否则取值为 0。使用类型标记的投票称之为 <strong>“硬投票” (Hard Voting)</strong>。</li>
<li>类概率，<code>$h_i^j \left(\mathbf{x}\right) \in \left[0, 1\right]$</code>，相当于对后验概率 <code>$P \left(c_j \ | \ \mathbf{x}\right)$</code> 的一个估计。使用类型概率的投票称之为 <strong>“软投票” (Soft Voting)</strong>。</li>
</ul>

<p>Stacking <sup class="footnote-ref" id="fnref:wolpert1992stacked"><a href="#fn:wolpert1992stacked">24</a></sup> <sup class="footnote-ref" id="fnref:breiman1996stacked"><a href="#fn:breiman1996stacked">25</a></sup> 方法又称为 Stacked Generalization，是一种基于分层模型组合的集成算法。Stacking 算法的基本思想如下：</p>

<ol>
<li>利用初级学习算法对原始数据集进行学习，同时生成一个新的数据集。</li>
<li>根据从初级学习算法生成的新数据集，利用次级学习算法学习并得到最终的输出。</li>
</ol>

<p>对于初级学习器，可以是相同类型也可以是不同类型的。在新的数据集中，初级学习器的输出被用作次级学习器的输入特征，初始样本的标记仍被用作次级学习器学习样本的标记。Stacking 算法的流程如下图所示：</p>

<p><img src="/images/cn/2018-12-08-ensemble-learning/stacking.png" alt="Stacking" /></p>

<p>Stacking 算法过程如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{Stacking 算法}
\begin{algorithmic}
\REQUIRE \\
    初级学习算法 $L = \{L_1, L_2, ... L_M\}$ \\
    次级学习算法 $L'$ \\
    训练数据集 $T = \{(\mathbf{x}_1, y_1), (\mathbf{x}_2, y_2), ..., (\mathbf{x}_N, y_N)\}$
\ENSURE \\
    Stacking 算法 $h_f\left(x\right)$
\FUNCTION{Stacking}{$L, L', T$}
\FOR{$m$ = $1$ to $M$}
  \STATE $h_t \gets L_m \left(T\right)$
\ENDFOR
\STATE $T' \gets \varnothing$
\FOR{$i$ = $1$ to $N$}
  \FOR{$m$ = $1$ to $M$}
    \STATE $z_{im} \gets h_m(\mathbf{x}_i)$
  \ENDFOR
  \STATE $T' \gets T' \cup \left(\left(z_{i1}, z_{i2}, ..., z_{iM}\right), y_i\right)$
\ENDFOR
\STATE $h' \gets L' \left(T'\right)$
\STATE $h_f\left(\mathbf{x}\right) \gets h' \left(h_1\left(\mathbf{x}\right), h_2\left(\mathbf{x}\right), ..., h_M\left(\mathbf{x}\right)\right)$
\RETURN $h_f\left(\mathbf{x}\right)$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>次级学习器的训练集是有初级学习器产生的，如果直接利用初级学习器的训练集生成次级学习器的训练集，过拟合风险会比较大 <sup class="footnote-ref" id="fnref:zhouzhihua2016machine"><a href="#fn:zhouzhihua2016machine">26</a></sup>。因此，一般利用在训练初级学习器中未使用过的样本来生成次级学习器的训练样本。以 <code>$k$</code> 折交叉检验为例：初始的训练集 <code>$T$</code> 被随机划分为 <code>$k$</code> 个大小相近的集合 <code>$T_1, T_2, ..., T_k$</code>。令 <code>$T_j$</code> 和 <code>$\overline{T}_j = T \setminus T_j$</code> 表示第 <code>$j$</code> 折的测试集和训练集。则对于 <code>$M$</code> 个初级学习算法，学习器 <code>$h_m^{\left(j\right)}$</code> 是根据训练集 <code>$\overline{T}_j$</code> 生成的，对于测试集 <code>$T_j$</code> 中的每个样本 <code>$\mathbf{x}_i$</code>，得到 <code>$z_{im} = h_m^{\left(j\right)} \left(\mathbf{x}_i\right)$</code>。则根据 <code>$\mathbf{x}_i$</code> 所产生的次级学习器的训练样本为 <code>$\mathbf{z}_i = \left(\left(z_{i1}, z_{i2}, ..., z_{iM}\right), y_i\right)$</code>。最终利用 <code>$M$</code> 个初级学习器产生的训练集 <code>$T' = \{\left(\mathbf{z}_i, y_i\right)\}_{i=1}^N$</code> 训练次级学习器。</p>

<p>下图展示了一些基础分类器以及 Soft Voting 和 Stacking 两种融合策略的模型在 Iris 数据集分类任务上的决策区域。数据选取 Iris 数据集中的 Sepal Length 和 Petal Length 两个特征，Stacking 中的次级学习器选择 Logistic Regression，详细实现请参见 <a href="https://github.com/leovan/leovan.me/blob/master/scripts/cn/2018-12-08-ensemble-learning/clfs-decision-regions.py" rel="noreferrer" target="_blank">这里</a>。</p>

<p><img src="/images/cn/2018-12-08-ensemble-learning/clfs-decision-regions.png" alt="Classifiers-Decision-Regions" /></p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:dietterich2000ensemble">Dietterich, T. G. (2000, June). Ensemble methods in machine learning. In <em>International workshop on multiple classifier systems</em> (pp. 1-15).
 <a class="footnote-return" href="#fnref:dietterich2000ensemble">↩</a></li>
<li id="fn:dietterich2002ensemble">Dietterich, T. G. (2002). <em>Ensemble Learning, The Handbook of Brain Theory and Neural Networks</em>, MA Arbib.
 <a class="footnote-return" href="#fnref:dietterich2002ensemble">↩</a></li>
<li id="fn:hyafil1976constructing">Laurent, H., &amp; Rivest, R. L. (1976). Constructing optimal binary decision trees is NP-complete. <em>Information processing letters</em>, 5(1), 15-17.
 <a class="footnote-return" href="#fnref:hyafil1976constructing">↩</a></li>
<li id="fn:blum1992training">Blum, A., &amp; Rivest, R. L. (1989). Training a 3-node neural network is NP-complete. In <em>Advances in neural information processing systems</em> (pp. 494-501).
 <a class="footnote-return" href="#fnref:blum1992training">↩</a></li>
<li id="fn:breiman1996bagging">Breiman, L. (1996). Bagging predictors. <em>Machine learning, 24</em>(2), 123-140.
 <a class="footnote-return" href="#fnref:breiman1996bagging">↩</a></li>
<li id="fn:breiman2001random">Breiman, L. (2001). Random forests. <em>Machine learning, 45</em>(1), 5-32.
 <a class="footnote-return" href="#fnref:breiman2001random">↩</a></li>
<li id="fn:fernandez2014we">Fernández-Delgado, M., Cernadas, E., Barro, S., &amp; Amorim, D. (2014). Do we need hundreds of classifiers to solve real world classification problems?. <em>The Journal of Machine Learning Research, 15</em>(1), 3133-3181.
 <a class="footnote-return" href="#fnref:fernandez2014we">↩</a></li>
<li id="fn:freund1997decision">Freund, Y., &amp; Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. <em>Journal of computer and system sciences, 55</em>(1), 119-139.
 <a class="footnote-return" href="#fnref:freund1997decision">↩</a></li>
<li id="fn:chen2016xgboost">Chen, T., &amp; Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. In <em>Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (pp. 785–794).
 <a class="footnote-return" href="#fnref:chen2016xgboost">↩</a></li>
<li id="fn:ke2017lightgbm">Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., … Liu, T.-Y. (2017). LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, &amp; R. Garnett (Eds.), <em>Advances in Neural Information Processing Systems 30</em> (pp. 3146–3154).
 <a class="footnote-return" href="#fnref:ke2017lightgbm">↩</a></li>
<li id="fn:shi2007best">Shi, H. (2007). <em>Best-first Decision Tree Learning</em> (Thesis). The University of Waikato.
 <a class="footnote-return" href="#fnref:shi2007best">↩</a></li>
<li id="fn:dorogush2018catboost">Dorogush, A. V., Ershov, V., &amp; Gulin, A. (2018). CatBoost: gradient boosting with categorical features support. <em>arXiv preprint arXiv:1810.11363</em>
 <a class="footnote-return" href="#fnref:dorogush2018catboost">↩</a></li>
<li id="fn:prokhorenkova2018catBoost">Prokhorenkova, L., Gusev, G., Vorobev, A., Dorogush, A. V., &amp; Gulin, A. (2018). CatBoost: unbiased boosting with categorical features. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, &amp; R. Garnett (Eds.), <em>Advances in Neural Information Processing Systems 31</em> (pp. 6637–6647).
 <a class="footnote-return" href="#fnref:prokhorenkova2018catBoost">↩</a></li>
<li id="fn:zhang2013domain">Zhang, K., Schölkopf, B., Muandet, K., &amp; Wang, Z. (2013, February). Domain adaptation under target and conditional shift. In <em>International Conference on Machine Learning</em> (pp. 819-827).
 <a class="footnote-return" href="#fnref:zhang2013domain">↩</a></li>
<li id="fn:JPMML-SkLearn"><a href="https://github.com/jpmml/jpmml-sklearn" rel="noreferrer" target="_blank">https://github.com/jpmml/jpmml-sklearn</a>
 <a class="footnote-return" href="#fnref:JPMML-SkLearn">↩</a></li>
<li id="fn:JPMML-XGBoost"><a href="https://github.com/jpmml/jpmml-xgboost" rel="noreferrer" target="_blank">https://github.com/jpmml/jpmml-xgboost</a>
 <a class="footnote-return" href="#fnref:JPMML-XGBoost">↩</a></li>
<li id="fn:ONNX"><a href="https://github.com/onnx/onnx" rel="noreferrer" target="_blank">https://github.com/onnx/onnx</a>
 <a class="footnote-return" href="#fnref:ONNX">↩</a></li>
<li id="fn:WinMLTools"><a href="https://pypi.org/project/winmltools" rel="noreferrer" target="_blank">https://pypi.org/project/winmltools</a>
 <a class="footnote-return" href="#fnref:WinMLTools">↩</a></li>
<li id="fn:ONNXMLTools"><a href="https://github.com/onnx/onnxmltools" rel="noreferrer" target="_blank">https://github.com/onnx/onnxmltools</a>
 <a class="footnote-return" href="#fnref:ONNXMLTools">↩</a></li>
<li id="fn:CatBoost-Save-Model"><a href="https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_catboost_save_model-docpage" rel="noreferrer" target="_blank">https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_catboost_save_model-docpage</a>
 <a class="footnote-return" href="#fnref:CatBoost-Save-Model">↩</a></li>
<li id="fn:XGBoost-GPU"><a href="https://xgboost.readthedocs.io/en/latest/gpu/index.html" rel="noreferrer" target="_blank">https://xgboost.readthedocs.io/en/latest/gpu/index.html</a>
 <a class="footnote-return" href="#fnref:XGBoost-GPU">↩</a></li>
<li id="fn:LightGBM-GPU"><a href="https://lightgbm.readthedocs.io/en/latest/GPU-Tutorial.html" rel="noreferrer" target="_blank">https://lightgbm.readthedocs.io/en/latest/GPU-Tutorial.html</a>
 <a class="footnote-return" href="#fnref:LightGBM-GPU">↩</a></li>
<li id="fn:CatBoost-GPU"><a href="https://tech.yandex.com/catboost/doc/dg/features/training-on-gpu-docpage" rel="noreferrer" target="_blank">https://tech.yandex.com/catboost/doc/dg/features/training-on-gpu-docpage</a>
 <a class="footnote-return" href="#fnref:CatBoost-GPU">↩</a></li>
<li id="fn:wolpert1992stacked">Wolpert, D. H. (1992). Stacked generalization. <em>Neural networks, 5</em>(2), 241-259.
 <a class="footnote-return" href="#fnref:wolpert1992stacked">↩</a></li>
<li id="fn:breiman1996stacked">Breiman, L. (1996). Stacked regressions. <em>Machine learning, 24</em>(1), 49-64.
 <a class="footnote-return" href="#fnref:breiman1996stacked">↩</a></li>
<li id="fn:zhouzhihua2016machine">周志华. (2016). <em>机器学习</em>. 清华大学出版社.
 <a class="footnote-return" href="#fnref:zhouzhihua2016machine">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>利用 Flask 和 Google App Engine 部署模型服务</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2018/10/serving-models-with-flask-and-gae/</link>
      <pubDate>Fri, 19 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2018/10/serving-models-with-flask-and-gae/</guid>
      <description>
        <![CDATA[
        

<div class="blockquote" style='border-left: 4px solid #369BE5;'>本文的配套代码请参见 <a href="https://github.com/leovan/model-serving-demo" rel="noreferrer" target="_blank">这里</a>，建议配合代码阅读本文。</div>

<h2 id="模型部署和服务调用">模型部署和服务调用</h2>

<p>对于做算法的同学，大家或多或少的更关心模型的性能指标多些，对于一些工程性问题考虑的较少。模型的部署是这些工程性问题中重要的一个，它直接关系到模型在生产系统的使用。一些成熟的机器学习框架会提供自己的解决方案，例如 <a href="https://www.tensorflow.org" rel="noreferrer" target="_blank">Tensorflow</a> 提供的 <a href="https://www.tensorflow.org/serving/" rel="noreferrer" target="_blank">Serving</a> 服务等。但很多情况下我们构建的工程可能不只使用了一种框架，因此一个框架自身的部署工具可能就很难满足我们的需求了。</p>

<p>针对此类情况，本文介绍一个 <strong>简单</strong> 的 <strong>准生产</strong> 模型部署方案。简单是指除了模型相关代码之外的工程性代码量不大，这得益于将要使用的 <a href="http://flask.pocoo.org/" rel="noreferrer" target="_blank">Flask</a> 框架。准生产是指这种部署方案应对一般的生产环境问题不大，对于高并发的场景可以通过横向扩容并进行负载均衡解决，但对于单次调用时效性要求较高的场景则需要另寻其他解决方案。</p>

<p>本文方案的模型部署和服务调用框架如下图所示：</p>

<p><img src="/images/cn/2018-10-19-serving-models-with-flask-and-gae/model-serving.png" alt="Model-Serving" /></p>

<p>其主要特性如下：</p>

<ol>
<li>服务端采用 Python 的 Flask 框架构建，无需使用其他外部服务。Flask 框架的 <a href="https://zh.wikipedia.org/zh/微服务" rel="noreferrer" target="_blank">微服务</a> (Microframework) 特性使得服务端代码简洁高效。</li>
<li>利用 <a href="https://gunicorn.org/" rel="noreferrer" target="_blank">Gunicorn</a> 提供的高性能 Python WSGI HTTP UNIX Server，方便在服务端运行 Flask 应用。</li>
<li>客户端和服务端之间采用 <a href="https://zh.wikipedia.org/zh/表现层状态转换" rel="noreferrer" target="_blank">RESTful API</a> 调用方式，尽管在性能上可能不及其他一些方案 (例如：基于 RPC 的解决方案等)，但其较好地解决了跨语言交互的问题，不同语言之间交互仅需使用 HTTP 协议和 JSON 数据格式即可。</li>
</ol>

<h2 id="flask-服务和-ajax-调用">Flask 服务和 AJAX 调用</h2>

<h3 id="flask-服务封装">Flask 服务封装</h3>

<p>为了将模型代码和 Flask 服务进行整合，首先假设你已经对模型部分代码做了完美的封装 😎，整个工程先叫做 <code>model-serving-demo</code> 吧。整理一下代码的目录结构，给一个我中意的 Python 目录结构风格：</p>

<pre><code>model-serving-demo/                # 工程根目录
├── bin/                           # 可执行命令目录
|   ├─ start.sh                    # 启动脚本
|   ├─ stop.sh                     # 停止脚本
|   └─ ...
├── conf/                          # 配置文件目录
|   ├─ logging.conf                # 日志配置文件
|   ├─ xxx_model.conf              # XXX Model 配置文件
|   └─ ...
├── data/                          # 数据文件目录
├── docs/                          # 文档目录
├── model_serving/                 # 模块根目录
|   ├─ models/                     # 模型代码目录
|   |   ├─ __init__.py
|   |   ├─ xxx_model.py            # XXX Model 代码
|   |   └─ ...
|   ├─ resources/                  # Flask RESTful Resources 代码目录
|   |   ├─ __init__.py
|   |   ├─ xxx_model_resource.py   # XXX Model Flask RESTful Resources 代码
|   |   └─ ...
|   ├─ tests/                      # 测试代码根目录
|   |   ├─ models                  # 模型测试代码目录
|   |   |   ├─ __init__.py
|   |   |   ├─ test_xxx_model.py   # XXX Model 测试代码
|   |   |   └─ ...
|   |   ├─ __init__.py
|   |   └─ ...
|   ├─ tmp/                        # 临时目录
|   └─ ...
├── .gitignore                     # Git Ignore 文件
├── app.yaml                       # Google App Engine 配置文件
├── LICENSE                        # 授权协议
├── main.py                        # 主程序代码
├── README.md                      # 说明文件
└── requirements.txt               # 依赖包列表
</code></pre>

<p>我们利用一个极简的示例介绍整个模型部署，相关的库依赖 <code>requirements.txt</code> 如下：</p>

<pre><code>Flask==1.0.2
Flask-RESTful==0.3.6
Flask-Cors==3.0.6
jsonschema==2.6.0
docopt==0.6.2

# 本地部署时需保留，GAE 部署时请删除
# gunicorn==19.9.0
</code></pre>

<p>其中：</p>

<ol>
<li><a href="http://flask.pocoo.org/" rel="noreferrer" target="_blank">Flask</a> 用于构建 Flask 服务。</li>
<li><a href="https://flask-restful.readthedocs.io/" rel="noreferrer" target="_blank">Flask-RESTful</a> 用于构建 Flask RESTful API。</li>
<li><a href="https://flask-cors.readthedocs.io/" rel="noreferrer" target="_blank">Flask-Cors</a> 用于解决 AJAX 调用时的 <a href="https://zh.wikipedia.org/zh/跨來源資源共享" rel="noreferrer" target="_blank">跨域问题</a>。</li>
<li><a href="https://python-jsonschema.readthedocs.io/" rel="noreferrer" target="_blank">jsonschema</a> 用于对请求数据的 JSON 格式进行校验。</li>
<li><a href="http://docopt.org/" rel="noreferrer" target="_blank">docopt</a> 用于从代码文档自动生成命令行参数解析器。</li>
<li><a href="https://gunicorn.org/" rel="noreferrer" target="_blank">gunicorn</a> 用于提供的高性能 Python WSGI HTTP UNIX Server。</li>
</ol>

<p>XXX Model 的代码 <code>xxx_model.py</code> 如下：</p>

<pre><code class="language-python">from ..utils.log_utils import XXXModel_LOGGER


LOGGER = XXXModel_LOGGER


class XXXModel():
    def __init__(self):
        LOGGER.info('Initializing XXX Model ...')

        LOGGER.info('XXX Model Initialized.')

    def hello(self, name:str) -&gt; str:
        return 'Hello, {name}!'.format(name=name)
</code></pre>

<p>其中 <code>hello()</code> 为服务使用的方法，其接受一个类型为 <code>str</code> 的参数 <code>name</code>，并返回一个类型为 <code>str</code> 的结果。</p>

<p>XXX Model 的 Flask RESTful Resource 代码 <code>xxx_model_resource.py</code> 如下：</p>

<pre><code class="language-python">from flask_restful import Resource, request

from ..models.xxx_model import XXXModel
from ..utils.validation_utils import validate_json


xxx_model_instance = XXXModel()
xxx_model_schema = {
    'type': 'object',
    'properties': {
        'name': {'type': 'string'}
    },
    'required': ['name']
}


class XXXModelResource(Resource):
    @validate_json(xxx_model_schema)
    def post(self):
        json = request.json

        return {'result': xxx_model_instance.hello(json['name'])}
</code></pre>

<p>我们需要从 Flask RESTful 的 <code>Resource</code> 类继承一个新的类 <code>XXXModelResource</code> 用于处理 XXX Model 的服务请求。如上文介绍，我们在整个模型服务调用中使用 POST 请求方式和 JSON 数据格式，因此我们需要在类 <code>XXXModelResource</code> 中实现 <code>post()</code> 方法，同时对于传入数据的 JSON 格式进行校验。</p>

<p><code>post()</code> 方法用于处理整个模型的服务请求，<code>xxx_model_instance</code> 模型实例在类 <code>XXXModelResource</code> 外部进行实例化，避免每次处理请求时都进行初始化。<code>post()</code> 的返回结果无需处理成 JSON 格式的字符串，仅需返回词典数据即可，Flask RESTful 会自动对其进行转换。</p>

<p>为了方便对请求数据的 JSON 格式进行校验，我们将对 JSON 格式的校验封装成一个修饰器。使用时如上文代码中所示，在 <code>post()</code> 方法上方添加 <code>@validate_json(xxx_model_schema)</code> 即可，其中 <code>xxx_model_schema</code> 为一个符合 <a href="https://python-jsonschema.readthedocs.io/" rel="noreferrer" target="_blank">jsonschema</a> 要求的 JSON Schema。示例代码中要求传入的 JSON 数据 <strong>必须</strong> 包含一个名为 <code>name</code> 类型为 <code>string</code> 的字段。</p>

<p><code>validate_json</code> 修饰器的代码 <code>validation_utils.py</code> 如下：</p>

<pre><code class="language-python">from functools import wraps
from jsonschema import validate, ValidationError
from flask_restful import request


def validate_json(schema, force=False):
    def decorator(f):
        @wraps(f)
        def wrapper(*args, **kwargs):
            json_body = request.get_json(force=force)

            if json_body is None:
                return {'message': 'No JSON object'}, 400

            try:
                validate(json_body, schema)
            except ValidationError as e:
                return {'message': e.message}, 400

            return f(*args, **kwargs)
        return wrapper
    return decorator
</code></pre>

<p>首先我们需要验证请求包含一个 JSON 请求体，同时 JSON 请求体的内容需满足 <code>schema</code> 的要求。如果不满足这些条件，我们需要返回对应的错误信息 <code>message</code>，同时返回合理的 <a href="https://zh.wikipedia.org/zh/HTTP状态码" rel="noreferrer" target="_blank">HTTP 状态码</a> (例如：<code>400</code>) 用于表示无法处理错误的请求。对于正常的请求响应 (即 HTTP 状态码为 200 的情况)，状态码可以省略不写。</p>

<p>构建完 XXX Model 的 Flask RESTful Resource 后，我们就可以构建 Flask 的主服务了，主程序代码 <code>main.py</code> 如下：</p>

<pre><code class="language-python">&quot;&quot;&quot;
Model Serving Demo

Usage:
    main.py [--host &lt;host&gt;] [--port &lt;port&gt;] [--debug]
    main.py (-h | --help)
    main.py --version

Options:
    --host &lt;host&gt;                     绑定的 Host [default: 0.0.0.0]
    --port &lt;port&gt;                     绑定的 Port [default: 9999]
    --debug                           是否开启 Debug [default: False]
    -h --help                         显示帮助
    -v --version                      显示版本

&quot;&quot;&quot;

from docopt import docopt

from flask import Flask
from flask_cors import CORS
from flask_restful import Api

from model_serving.resources.xxx_model_resource import XXXModelResource


app = Flask(__name__)
CORS(app)

api = Api(app)
api.add_resource(XXXModelResource, '/v1/XXXModel')


if __name__ == '__main__':
    args = docopt(__doc__, version='Model Serving Demo v1.0.0')
    app.run(host=args['--host'], port=args['--port'], debug=args['--debug'])
</code></pre>

<p><code>docopt</code> 库用于从代码文档自动生成命令行参数解析器，具体使用方法请参见 <a href="http://docopt.org/" rel="noreferrer" target="_blank">官方文档</a>。整个 Flask 主服务的构建比较简单，流程如下：</p>

<ol>
<li>构建 Flask 主程序，<code>app = Flask(__name__)</code>。</li>
<li>解决 AJAX 调用的跨域问题， <code>CORS(app)</code>。为了方便起见，我们不加任何参数，允许任意来源的请求，详细的使用方式请参见 <a href="https://flask-cors.readthedocs.io/" rel="noreferrer" target="_blank">官方文档</a>。</li>
<li>构建 Flask RESTful API，<code>api = Api(app)</code>。</li>
<li>将构建好的 XXX Model 的 Flask RESTful Resource 添加到 API 中，<code>api.add_resource(XXXModelResource, '/v1/XXXModel')</code>。
其中第二个参数为请求的 URL，对于这个 URL 的建议将在后续小节中详细说明。</li>
</ol>

<p>Flask 主程序配置完毕后，我们通过 <code>app.run()</code> 在本地启动 Flask 服务，同时可以指定绑定的主机名，端口，以及是否开启调试模式等。通过 <code>python main.py</code> 启动 Flask 服务后，可以在命令行看到如下类似的日志：</p>

<pre><code>[2018/10/21 00:00:00] - [INFO] - [XXXModel] - Initializing XXX Model ...
[2018/10/21 00:00:00] - [INFO] - [XXXModel] - XXX Model Initialized.
 * Serving Flask app &quot;main&quot; (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: off
[2018/10/21 00:00:00] - [INFO] - [werkzeug] -  * Running on http://0.0.0.0:9999/ (Press CTRL+C to quit)
</code></pre>

<p>现在就可以测试调用服务了，我们用 <code>curl</code> 命令进行简单的测试，相关代码 <code>request-demo.sh</code> 如下：</p>

<pre><code class="language-bash">host=0.0.0.0
port=9999
url=http://zeqiang.fun/user_blogdown/v1/XXXModel
curl_url=http://${host}:${port}${url}

invalid_json='{}'
valid_json='{&quot;name&quot;: &quot;Leo&quot;}'

# No JSON object
curl --request POST --url ${curl_url} --verbose

# Invalid JSON object
curl --header 'Content-Type: application/json; charset=UTF-8' \
    --request POST --data ${invalid_json} --url ${curl_url} --verbose

# Valid JSON object
curl --header 'Content-Type: application/json; charset=UTF-8' \
    --request POST --data ${valid_json} --url ${curl_url} --verbose
</code></pre>

<p>三种不同的请求返回的 HTTP 状态码和结果如下：</p>

<pre><code>HTTP/1.0 400 BAD REQUEST
{&quot;message&quot;: &quot;No JSON object&quot;}

HTTP/1.0 400 BAD REQUEST
{&quot;message&quot;: &quot;'name' is a required property&quot;}

HTTP/1.0 200 OK
{&quot;result&quot;: &quot;Hello, Leo!&quot;}
</code></pre>

<p>上文中，我们通过 <code>python main.py</code> 利用内置的 Server 启动了 Flask 服务，启动后日志中打印出来一条警告信息，告诉使用者不要在生产环境中使用内置的 Server。在生产环境中我们可以利用高性能 Python WSGI HTTP UNIX Server <a href="https://gunicorn.org/" rel="noreferrer" target="_blank">gunicorn</a> 来启动 Flask 服务。</p>

<p>服务启动 (<code>start.sh</code>) 脚本代码如下：</p>

<pre><code class="language-bash">cd `dirname $0`
cd ..

base_dir=`pwd`
tmp_dir=${base_dir}/tmp
pid_file_path=${tmp_dir}/model-serving-demo.pid
log_file_path=${tmp_dir}/model-serving-demo.log

bind_host=0.0.0.0
bind_port=9999
workers=2

nohup gunicorn -b ${bind_host}:${bind_port} \
  -w ${workers} -p ${pid_file_path} \
  main:app &gt; ${log_file_path} 2&gt;&amp;1 &amp;
</code></pre>

<p>服务停止 (<code>stop.sh</code>) 脚本代码如下：</p>

<pre><code class="language-bash">cd `dirname $0`
cd ..

base_dir=`pwd`
tmp_dir=${base_dir}/tmp
pid_file_path=${tmp_dir}/model-serving-demo.pid

kill -TERM `echo ${pid_file_path}`
</code></pre>

<p>gunicorn 的详细参数配置和使用教程请参见 <a href="https://docs.gunicorn.org/en/stable/" rel="noreferrer" target="_blank">官方文档</a>。</p>

<h3 id="restful-api-设计">RESTful API 设计</h3>

<p>RESTful API 是一种符合 REST(Representational State Transfer，表现层状态转换) 原则的框架，该框架是由 Fielding 在其博士论文 <sup class="footnote-ref" id="fnref:fielding2000architectural"><a href="#fn:fielding2000architectural">1</a></sup> 中提出。相关的核心概念如下：</p>

<ol>
<li><strong>资源 (Resources)</strong>，即网络中的一个实体 (文本，图片，服务等)，使用一个 URL 进行表示。</li>
<li><strong>表现层 (Representation)</strong>，资源具体的呈现形式即为表现层，例如图片可以表示为 PNG 文件，音乐可以表示为 MP3 文件，还有本文使用的数据格式 JSON 等。HTTP 请求的头信息中用 Accept 和 Content-Type 字段对表现层进行描述。</li>
<li><strong>状态转换 (State Transfer)</strong>，互联网通信协议 HTTP 协议是一个无状态协议，所有的状态都保存在服务端。因此如果客户端想要操作服务器，必须通过某种手段让服务器端发生 <strong>状态转换</strong>。客户端利用 HTTP 协议中的动作对服务器进行操作，例如：GET，POST，PUT，DELETE 等。</li>
</ol>

<p>利用 RESTful API 构建模型服务时，需要注意如下几点：</p>

<ol>
<li>为模型服务设置专用域名，例如：<code>https://api.example.com</code>，并配以负载均衡。</li>
<li>将 API 的版本号写入 URL 中，例如：<code>https://api.example.com/v1</code>。</li>
<li>RESTful 框架中每个 URL 表示一种资源，因此可以将模型的名称作为 URL 的终点 (Endpoint)，例如：<code>https://api.example.com/v1/XXXModel</code>。</li>
<li>对于操作资源的 HTTP 方式有多种，综合考虑建议选用 POST 方式，同时建议使用 JSON 数据格式。</li>
<li>为请求响应设置合理的状态码，例如：200 OK 表示正常返回，400 INVALID REQUEST 表示无法处理客户端的错误请求等。</li>
<li>对于错误码为 4xx 的情况，建议在返回中添加键名为 <code>message</code> 的错误信息。</li>
</ol>

<h3 id="ajax-调用">AJAX 调用</h3>

<p>对于动态网页，我们可以很容易的在后端服务中发起 POST 请求调用模型服务，然后将结果在前端进行渲染。对于静态网页，我们可以利用 AJAX 进行相关操作。首先我们需要一个交互界面，如下为利用 <a href="https://material.io/design/" rel="noreferrer" target="_blank">Google Material Design</a> 风格的 <a href="https://github.com/material-components/material-components-web" rel="noreferrer" target="_blank">Material Design Components Web</a> 组件设计一个交互界面，实现细节请参见 <a href="https://github.com/leovan/model-serving-demo/tree/master/client/xxx-model-ajax-client.html" rel="noreferrer" target="_blank">示例代码</a>。</p>

<p>
  
<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/material-components-web@latest/dist/material-components-web.min.css">





















<style type="text/css">
.center {
  justify-content: center;
}

.text-field--fullwidth {
  width: 100%;
}

.loading {
  width: 32px;
  height: 32px;
  position: relative;
  margin: auto;
}

.loading-bounce-1, .loading-bounce-2 {
  width: 100%;
  height: 100%;
  border-radius: 50%;
  background-color: #333;
  opacity: 0.6;
  position: absolute;
  top: 0;
  left: 0;

  -webkit-animation: bounce 2.0s infinite ease-in-out;
  animation: bounce 2.0s infinite ease-in-out;
}

.loading-bounce-2 {
  -webkit-animation-delay: -1.0s;
  animation-delay: -1.0s;
}

@-webkit-keyframes bounce {
  0%, 100% { -webkit-transform: scale(0.0) }
  50% { -webkit-transform: scale(1.0) }
}

@keyframes bounce {
  0%, 100% {
    transform: scale(0.0);
    -webkit-transform: scale(0.0);
  } 50% {
    transform: scale(1.0);
    -webkit-transform: scale(1.0);
  }
}
</style>

<div class="mdc-card">
  <div class="mdc-card__actions center">
    <div class="mdc-typography--headline6"><span>XXX Model AJAX Client</span></div>
  </div>
  <div class="mdc-card__actions">
    <div class="mdc-text-field text-field--fullwidth" data-mdc-auto-init="MDCTextField">
      <input id="name" class="mdc-text-field__input" value="Leo">
      <div class="mdc-line-ripple"></div>
    </div>
  </div>
  <div class="mdc-card__actions center">
    <button id="submit" class="mdc-button mdc-button--outlined" data-mdc-auto-init="MDCRipple">Submit</button>
    <div class="loading" id="loading" style="display: none;">
      <div class="loading-bounce-1"></div>
      <div class="loading-bounce-2"></div>
    </div>
  </div>
  <div class="mdc-card__actions center">
    <div class="mdc-typography--body1">
      <p id="result">Result</p>
    </div>
  </div>
</div>

<script>
  $(document).ready(function() {
    $("#submit").click(function() {
      $("#submit").toggle();
      $("#loading").toggle();

      /*
      $.ajax({
        url: "http://0.0.0.0:9999/v1/XXXModel",
        method: "POST",
        contentType: "application/json; charset=UTF-8",
        data: JSON.stringify({"name": $("#name").val()}),
        timeout: 3000,

        success: function (data, textStatus, jqXHR) {
          $("#result").html(data.result);

          $("#loading").toggle();
          $("#submit").toggle();
        },
        error: function (jqXHR, textStatus, errorThrown) {
          $("#result").html(errorThrown);

          $("#loading").toggle();
          $("#submit").toggle();
        }
      });
      */

      setTimeout(function() {
        $("#result").html("Hello, " + $("#name").val() + "!");
        $("#submit").toggle();
        $("#loading").toggle();
      }, 1000);
    });
  });
</script>





</p>

<p>AJAX 服务请求代码的核心部分如下：</p>

<pre><code class="language-javascript">$(document).ready(function() {
    $(&quot;#submit&quot;).click(function() {
        $.ajax({
            url: &quot;http://0.0.0.0:9999/v1/XXXModel&quot;,
            method: &quot;POST&quot;,
            contentType: &quot;application/json; charset=UTF-8&quot;,
            data: JSON.stringify({&quot;name&quot;: $(&quot;#name&quot;).val()}),
            timeout: 3000,

            success: function (data, textStatus, jqXHR) {
                $(&quot;#result&quot;).html(data.result);
            },
            error: function (jqXHR, textStatus, errorThrown) {
                $(&quot;#result&quot;).html(errorThrown);
            }
        });
    });
});
</code></pre>

<p>代码使用了 <a href="https://jquery.com/" rel="noreferrer" target="_blank">jQuery</a> 的相关函数。<code>JSON.stringify({&quot;name&quot;: $(&quot;#name&quot;).val()})</code> 获取 ID 为 <code>name</code> 的元素的值，并将其转换成符合服务端要求的 JSON 格式。通过 AJAX 向远程发出请求后，如果请求成功则将返回数据 <code>data</code> 中对应的结果 <code>result</code> 填充到 ID 为 <code>result</code> 的元素中，否则填入返回的错误信息。</p>

<h2 id="google-app-engine-部署">Google App Engine 部署</h2>

<p>上文中已经介绍了如何在本地利用 Flask 部署模型服务和相关调用方法，但如果希望在自己的网站中调用时，则利用 SaaS 来部署符合会是一个不二之选。国内外多个厂商均提供了相应的 SaaS 产品，例如 <a href="https://cloud.google.com/appengine/" rel="noreferrer" target="_blank">Google</a>，<a href="https://aws.amazon.com/partners/saas-on-aws/" rel="noreferrer" target="_blank">Amazon</a>，<a href="https://azure.microsoft.com/en-us/solutions/saas/" rel="noreferrer" target="_blank">Microsoft</a> 等。Google App Engine (GAE) 提供了一个 <a href="https://cloud.google.com/free/docs/always-free-usage-limits" rel="noreferrer" target="_blank">始终免费</a> 方案，虽然部署阶段会受到 GFW 的影响，但调用阶段测试影响并不是很大 (不同地区和服务提供商会有差异)。综合考虑，本文选择 GAE 作为 SaaS 平台部署服务，各位看官请自备梯子。</p>

<h3 id="环境准备">环境准备</h3>

<p>首先，在 <a href="https://console.cloud.google.com/projectcreate" rel="noreferrer" target="_blank">Google Cloud Platform Console</a> 中建立一个新的 Project，假设项目名为 <code>YOUR_PROJECT_ID</code>。</p>

<p>其次，根据 <a href="https://cloud.google.com/sdk/docs/" rel="noreferrer" target="_blank">Google Cloud SDK 文档</a> 在本地安装相应版本的 Google Cloud SDK。MacOS 下建议通过 <code>brew cask install google-cloud-sdk</code> 方式安装，安装完毕后确认在命令行中可以运行 <code>gcloud</code> 命令。</p>

<pre><code class="language-bash">$ gcloud version
Google Cloud SDK 221.0.0
bq 2.0.35
core 2018.10.12
gsutil 4.34
</code></pre>

<h3 id="构建-gae-工程">构建 GAE 工程</h3>

<p>模型服务仅作为后端应用，因此本节不介绍前端页面开发的相关部分，有兴趣的同学请参见 <a href="https://cloud.google.com/appengine/docs/standard/python3/quickstart" rel="noreferrer" target="_blank">官方文档</a>。GAE 部署 Python Web 应用采用了 <a href="https://wsgi.readthedocs.io/en/latest/" rel="noreferrer" target="_blank">WSGI 标准</a>，我们构建的本地部署版本完全满足这个要求，因此仅需为项目在根目录添加一个 GAE 配置文件 <code>app.yaml</code> 即可，内容如下：</p>

<pre><code class="language-yaml">runtime: python37

handlers:
  - url: /.*
    script: main.app

skip_files:
  - .idea/
  - .vscode/
  - __pycache__/
  - .hypothesis/
  - .pytest_cache/
  - bin/
  - ^(.*/)?.*\.py[cod]$
  - ^(.*/)?.*\$py\.class$
  - ^(.*/)?.*\.log$
</code></pre>

<p>其中，<code>runtime</code> 指定了服务运行的环境，<code>handlers</code> 指定了不同的 URL 对应的处理程序，在此所有的 URL 均由 <code>main.py</code> 中的 <code>app</code> 进行处理，<code>skip_files</code> 用于过滤不需要上传的文件。更多关于 <code>app.yaml</code> 的设置信息，请参见 <a href="https://cloud.google.com/appengine/docs/standard/python3/config/appref" rel="noreferrer" target="_blank">官方文档</a>。</p>

<h3 id="部署-gae-工程">部署 GAE 工程</h3>

<p>在部署 GAE 工程之前我们可以利用本地的开发环境对其进行测试，测试无误后，即可运行如下命令将其部署到 GAE 上：</p>

<pre><code class="language-bash">gcloud app deploy --project [YOUR_PROJECT_ID]
</code></pre>

<p>然后根据命令行提示完成整个部署流程，部署完成的远程服务 URL 为 <code>https://YOUR_PROJECT_ID.appspot.com</code>，更多的测试和部署细节请参见 <a href="https://cloud.google.com/appengine/docs/standard/python3/testing-and-deploying-your-app" rel="noreferrer" target="_blank">官方文档</a>。</p>

<p>部署后的 GAE 服务使用了其自带的域名 <code>appspot.com</code>。如果你拥有自己的域名，可以根据官方文档 <a href="https://cloud.google.com/appengine/docs/standard/python3/mapping-custom-domains" rel="noreferrer" target="_blank">设置自己的域名</a> 并 <a href="https://cloud.google.com/appengine/docs/standard/python3/secURLng-custom-domains-with-ssl" rel="noreferrer" target="_blank">开启 SSL</a>。</p>

<div class="blockquote" style='border-left: 4px solid #369BE5;'>本文部分内容参考了 Genthial 的博客 <a href="https://guillaumegenthial.github.io/serving.html" rel="noreferrer" target="_blank">Serving a model with Flask</a> 和阮一峰的博客 <a href="https://www.ruanyifeng.com/blog/2011/09/restful.html" rel="noreferrer" target="_blank">理解RESTful架构</a> 和 <a href="https://www.ruanyifeng.com/blog/2014/05/restful_api.html" rel="noreferrer" target="_blank">RESTful API 设计指南</a>。</div>
<div class="footnotes">

<hr />

<ol>
<li id="fn:fielding2000architectural">Fielding, Roy T., and Richard N. Taylor. <em>Architectural styles and the design of network-based software architectures.</em> Vol. 7. Doctoral dissertation: University of California, Irvine, 2000.
 <a class="footnote-return" href="#fnref:fielding2000architectural">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>流形学习 (Manifold Learning)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2018/03/manifold-learning/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2018/03/manifold-learning/</guid>
      <description>
        <![CDATA[
        

<h1 id="降维">降维</h1>

<p>在之前的 <a href="/cn/2017/12/evd-svd-and-pca">博客</a> 中，我们曾经介绍过 PCA 方法及其降维的作用。在原始数据中各个特征之间存在着一定的信息冗余，随着特征的不断增加就容易出现“维数灾难”的问题，因此降维的目的就是在尽可能多的保留原始信息的同时减少数据的维度。一般情况下我们将降维方法分为：<strong>线性降维方法</strong>和<strong>非线性降维方法</strong>，线性降维方法的典型算法有：</p>

<ul>
<li>主成份分析 (PCA, Principal Component Analysis) <sup class="footnote-ref" id="fnref:jolliffe1986principal"><a href="#fn:jolliffe1986principal">1</a></sup></li>
<li>线性判别分写 (LDA, Linear Discriminant Analysis) <sup class="footnote-ref" id="fnref:balakrishnama1998linear"><a href="#fn:balakrishnama1998linear">2</a></sup></li>
<li>多尺度变换 (MDS, Multi-Dimensional Scaling) <sup class="footnote-ref" id="fnref:cox2000multidimensional"><a href="#fn:cox2000multidimensional">3</a></sup></li>
</ul>

<p>非线性降维方法中在此我们仅列举一些基于流行学习的算法：</p>

<ul>
<li>保距特征映射 (ISOMAP) <sup class="footnote-ref" id="fnref:tenenbaum2000global"><a href="#fn:tenenbaum2000global">4</a></sup></li>
<li>局部线性嵌入 (LLE, Locally Linear Embedding) <sup class="footnote-ref" id="fnref:roweis2000nonlinear"><a href="#fn:roweis2000nonlinear">5</a></sup></li>
<li>拉普拉斯特征映射 (LE, Laplacian Eigenmap) <sup class="footnote-ref" id="fnref:belkin2003laplacian"><a href="#fn:belkin2003laplacian">6</a></sup></li>
</ul>

<p>在现实数据中，很多情况数据是无法通过线性的方法进行降维表示的，因此就需要非线性的降维算法出马了。</p>

<h1 id="流形">流形</h1>

<p>在调研流形相关概念时，发现要想深一步的理解这些概念还是需要详细的了解微分几何相关的内容，鉴于本文的目的主要是介绍流形学习 (主要是降维角度) 的相关内容，因此我们对流形仅做一些粗略的介绍。</p>

<p>“<strong>流形</strong>”是英文单词 <strong>Manifold</strong> 的中文译名，它源于德文术语 Mannigfaltigkeit，最早出现在 Riemann 1851 年的博士论文中，用来表示某种属性所能取到的所有值 <sup class="footnote-ref" id="fnref:meijiaqiang"><a href="#fn:meijiaqiang">7</a></sup>。为了更好的理解流形，我们先引入几个概念：</p>

<p><strong>拓扑结构 (拓扑)</strong> 任意给定集合 <code>$X$</code> 上的一个<strong>拓扑结构 (拓扑)</strong> 是 <code>$X$</code> 的某些特定子集组成的集合 <code>$\tau \subset 2^X$</code>，其中那些特定子集称为 <code>$\tau$</code> 所声明的<strong>开集</strong>，同时满足如下性质：</p>

<ol>
<li>空集和全集是开集，即 <code>$\varnothing, X \in \tau$</code></li>
<li>任意多个开集的并集是开集</li>
<li>有限多个开集的交集是开集</li>
</ol>

<p><strong>拓扑空间</strong> 指定了拓扑结构的集合就称为一个<strong>拓扑空间</strong>。</p>

<p><img src="/images/cn/2018-03-16-manifold-learning/topological-space-sample.png" alt="" /></p>

<p>上图中给出了一些拓扑空间的示例，其中左侧 4 个为正确示例，右侧 2 个为错误示例。右上角的缺少了 {2} 和 {3} 的并集 {2, 3}，右下角的缺少了 {1, 2} 和 {2, 3} 的交集 {2}。</p>

<p><strong>同胚</strong> 两个拓扑空间 <code>$\left(X, \tau_X\right)$</code> 和 <code>$\left(Y, \tau_Y\right)$</code> 之间的函数 <code>$f: X \to Y$</code> 称为<strong>同胚</strong>，如果它具有下列性质：</p>

<ol>
<li><code>$f$</code> 是双射 (单射和满射)</li>
<li><code>$f$</code> 是连续的</li>
<li>反函数 <code>$f^{−1}$</code> 也是连续的 (<code>$f$</code> 是开映射)</li>
</ol>

<p>如果拓扑空间是一个几何物体，同胚就是把物体连续延展和弯曲，使其成为一个新的物体。因此，正方形和圆是同胚的，但球面和环面就不是。用一幅图形象的理解同胚，例如下图所示的<strong>咖啡杯</strong>和<strong>甜甜圈</strong> <sup class="footnote-ref" id="fnref:wikipedia-manifold"><a href="#fn:wikipedia-manifold">8</a></sup>：</p>

<p><img src="/images/cn/2018-03-16-manifold-learning/mug-and-torus-morph.gif" alt="" /></p>

<p>最后我们回过头来解释到底什么是<strong>流形</strong>？流形并不是一个“形状”，而是一个“空间” <sup class="footnote-ref" id="fnref:pluskid"><a href="#fn:pluskid">9</a></sup>。最容易定义的流形是<strong>拓扑流形</strong>，它局部看起来象一些“普通”的欧几里得空间 <code>$\mathbb{R}^n$</code>，一个拓扑流形是一个局部同胚于一个欧几里得空间的拓扑空间。根据 Whitney 嵌入理论 <sup class="footnote-ref" id="fnref:wikipedia-whitney"><a href="#fn:wikipedia-whitney">10</a></sup>，任何一个流形都可以嵌入到高维的欧氏空间中。例如，地球的表面可以理解为一个嵌入 3 维空间的 2 维流形，其局部同胚于 2 维的欧式空间，对于一个球体的表面，用极坐标的形式可以表示为</p>

<p><code>$$
\begin{equation}
\begin{split}
x &amp;= r \sin \theta \cos \phi \\
y &amp;= r \sin \theta \sin \phi \\
z &amp;= r \cos \theta
\end{split}
\end{equation}
$$</code></p>

<p>也就是说其 3 个维度实际上是由 2 个变量控制的。</p>

<h1 id="流形学习">流形学习</h1>

<p>假设 <code>$Y$</code> 为一个欧式空间 <code>$\mathbb{R}^d$</code> 的一个 <code>$d$</code> 维流形，<code>$f: Y \to \mathbb{R}^D$</code> 为一个光滑嵌入，对于 <code>$D &gt; d$</code>，流形学习的目的就是根据空间 <code>$\mathbb{R}^D$</code> 中的观测数据 <code>$\{x_i\}$</code> 重构 <code>$Y$</code> 和 <code>$f$</code> 的过程。隐含数据 <code>$\{y_i\}$</code> 由 <code>$Y$</code> 随机生成，通过光滑嵌入 <code>$f$</code> 生成观测数据，即 <code>$\{x_i = f\left(y_i\right)\}$</code>，所以我们可以将流形学习的问题看做是对于一个给定的观测数据一个生成模型的反向过程 <sup class="footnote-ref" id="fnref:silva2003global"><a href="#fn:silva2003global">11</a></sup>。</p>

<p>在介绍具体的流形学习算法前，我们先引入几个 3 维数据用于解释后续的具体算法</p>

<p><img src="/images/cn/2018-03-16-manifold-learning/manifold-examples.png" alt="" /></p>

<p>第一个为<strong>瑞士卷 (Swiss Roll)</strong>，其形状和我们日常生活中的瑞士卷相似；第二个为 <strong>S 形曲线 (S Curve)</strong>；第三个为一个被<strong>切断的球面 (Severed Sphere)</strong>。</p>

<h2 id="mds">MDS</h2>

<p>多尺度变换 (MDS, Multi-Dimensional Scaling) <sup class="footnote-ref" id="fnref:cox2000multidimensional"><a href="#fn:cox2000multidimensional">3</a></sup> 是一种通过保留样本在高维空间中的不相似性 (Dissimilarity) 降低数据维度的方法，在这里不相似性可以理解为样本之间的距离。因此，根据距离的度量方式不同可以将其分为度量型 (metric) MDS 和 非度量型 (non-metric) MDS。度量型 MDS 通过计算不同样本之间距离的度量值进行降维，而非度量型则仅考虑距离的排序信息，在此我们仅对度量型 MDS 做简单介绍。</p>

<p>MDS 的目标是保留样本在高维空间中的不相似性，假设 <code>$x \in \mathbb{R}^D, x' \in \mathbb{R}^d, D &gt; d$</code>，则 MDS 的目标函数可以写为</p>

<p><code>$$
\min \sum_{i, j} \lvert dist \left(x_i, x_j\right) - dist \left(x'_i, x'_j\right) \rvert
$$</code></p>

<p>则，度量型 MDS 的算法的步骤如下：</p>

<ol>
<li>计算样本的距离矩阵 <code>$\boldsymbol{D} = \left[d_{i, j}\right] = \left[dist \left(x_i, x_j\right)\right]$</code>。</li>
<li>构造矩阵 <code>$\boldsymbol{A} = \left[a_{i, j}\right] = \left[- \dfrac{1}{2} d_{i, j}^2\right]$</code>。</li>
<li>通过中心矫正的方法构造矩阵 <code>$\boldsymbol{B} = \boldsymbol{J} \boldsymbol{D} \boldsymbol{J}, \boldsymbol{J} = \boldsymbol{I} - \dfrac{1}{n} \boldsymbol{O}$</code>，其中 <code>$\boldsymbol{I}$</code> 为 <code>$n \times n$</code> 的单位阵，<code>$\boldsymbol{O}$</code> 为 <code>$n \times n$</code> 的值均为 <code>$1$</code> 的矩阵。</li>
<li>计算矩阵 <code>$\boldsymbol{B}$</code> 的特征向量 <code>$e_1, e_2, ..., e_m$</code> 及其对应的特征值 <code>$\lambda_1, \lambda_2, ..., \lambda_m$</code>。</li>
<li>确定维度 <code>$k$</code>，重构数据 <code>$\boldsymbol{X}' = \boldsymbol{E}_k \boldsymbol{\Lambda}_k^{1/2}$</code>，其中 <code>$\boldsymbol{\Lambda}_k$</code> 为前 <code>$k$</code> 个值最大的 <code>$k$</code> 个特征值构成的对角矩阵，<code>$\boldsymbol{E}_k$</code> 是对应的 <code>$k$</code> 个特征向量构成的矩阵。</li>
</ol>

<p>在《多元统计分析》<sup class="footnote-ref" id="fnref:hexiaoqun"><a href="#fn:hexiaoqun">12</a></sup>一书中证明了，<code>$\boldsymbol{X}$</code> 的 <code>$k$</code> 维主坐标正好是将 <code>$\boldsymbol{X}$</code> 中心化后 <code>$n$</code> 个样本的前 <code>$k$</code> 个主成份的值，由此可见 MDS 和 PCA 的作用是类似的。</p>

<p>我们利用中国省会的地理位置给出 MDS 的一个示例，首先我们获取中国省会共 34 个点的坐标，其次我们计算两两之间的距离，我们仅利用距离信息利用 MDS 还原出 2 维空间中的坐标，可视化结果如下所示</p>

<p><img src="/images/cn/2018-03-16-manifold-learning/cities-mds.svg" alt="" /></p>

<p>其中，黑色的点为省会的真实位置，蓝色的点为利用距离矩阵和 MDS 还原出来的位置，为了绘制还原出的位置我们对 MDS 的结果做出了适当的翻转和变换。从结果中不难看出，尽管每个点的坐标相比真实坐标都有一定的偏离，但是其很好的保持了相对距离，这也正是 MDS 算法的要求。</p>

<h2 id="isomap">ISOMAP</h2>

<p>对于一些非线性的流形，如果使用线性的降维方法得到的效果就不尽人意了，例如上文中提到的瑞士卷。在 ISOMAP 中，我们首先引入一个测地线的概念，在距离度量定义时，测地线可以定义为空间中两点的局域最短路径。形象的，在一个球面上，两点之间的测地线就是过这两个点的大圆的弧线</p>

<p><img src="/images/cn/2018-03-16-manifold-learning/spherical-triangle.svg" alt="" /></p>

<p>那么，对于非线性流形，ISOMAP 则是通过构建邻接图，利用图上的最短距离来近似测地线。在构造邻接图时，我们使用最近邻算法，对于一个点 <code>$x_i$</code> 连接距离其最近的 <code>$k$</code> 个点，两点之间的距离我们则一般使用传统的欧式距离。则任意两点之间的测地线距离则可以利用构建的邻接图上的最短路径进行估计，图上的最短路问题我们可以通过 Dijkstra 或 Floyd-Warshall 算法计算。得到样本的距离矩阵后，ISOMAP 算法则使用 MDS 方法计算得到低维空间的座标映射。</p>

<p><img src="/images/cn/2018-03-16-manifold-learning/swiss-roll-isomap.png" alt="" /></p>

<p>上图中，我们给出了利用 ISOMAP 对瑞士卷降至 2 维的一个格式化过程。第一幅图中，我们标注了 2 个蓝色的点，其中蓝色的直线为这 2 个点在三维空间中的欧式距离。第二幅图中，同样是相同的两个点，我们首先利用最近邻算法 (<code>$k = 10$</code>) 将瑞士卷所有的点连接为一个邻接图，其中红色的路径为这 2 个点在邻接图上的最短路。第三幅图是通过 ISOMAP 算法降维至 2 维的结果，其中蓝色的直线是这两个点在 2 维空间中的欧式距离，红色的路径是 3 维最短路在 2 维结果中的连线，可以看出两者是很相近的。</p>

<h2 id="lle">LLE</h2>

<p>局部线性嵌入 (LLE, Locally Linear Embedding) <sup class="footnote-ref" id="fnref:roweis2000nonlinear"><a href="#fn:roweis2000nonlinear">5</a></sup>，从这个名称上我们不难看出其不同与 ISOMAP 那种通过都建邻接图保留全局结构的，而是从局部结构出发对数据进行降维。在 LLE 方法中，主要有如下的基本假设：</p>

<ul>
<li>一个流形的局部可以近似于一个欧式空间</li>
<li>每个样本均可以利用其邻居进行线性重构</li>
</ul>

<p>基于上面的假设，LLE 算法的流程如下：</p>

<ol>
<li>对于点 <code>$X_i$</code>，计算距离其最近的 <code>$k$</code> 个点，<code>$X_j, j \in N_i$</code>。</li>
<li>计算权重 <code>$W_{ij}$</code> 是的能够通过点 <code>$X_i$</code> 的邻居节点最优的重构该点，即最小化
<code>$$
\epsilon \left(W\right) = \sum_i \left\lVert X_i - \sum_j W_{ij} X_j \right\rVert ^2
$$</code></li>
<li>通过权重 <code>$W_{ij}$</code> 计算 <code>$X$</code> 的低维最优重构 <code>$Y$</code>，即最小化
<code>$$
\phi \left(Y\right) = \sum_i \left\lVert Y_i - \sum_j W_{ij} Y_j \right\rVert ^2
$$</code></li>
</ol>

<p>具体上述问题的优化求解过程在此就不在详细描述。针对 LLE 算法，后续很多人从不同方面对其进行了改进：</p>

<ol>
<li>Hessian LLE <sup class="footnote-ref" id="fnref:donoho2003hessian"><a href="#fn:donoho2003hessian">13</a></sup> 在局部中不再考虑局部的线性关系，而是保持局部的 Hessian 矩阵的二次型的关系。</li>
<li>Modified LLE <sup class="footnote-ref" id="fnref:zhang2007mlle"><a href="#fn:zhang2007mlle">14</a></sup> 则是修改了寻找最临近的 <code>$k$</code> 个样本的方案，其在寻找 <code>$k$</code> 近邻时希望找到的近邻尽量分布在样本的各个方向，而不是集中在一侧。</li>
<li>LTSA (Local Tangent Space Alignment) <sup class="footnote-ref" id="fnref:zhang2004principal"><a href="#fn:zhang2004principal">15</a></sup> 则是除了保留了局部的几何性质，同时使用的一个从局部几何到整体性质过渡的 alignment 方法，因此可以理解为是一个局部和整体的组合。</li>
</ol>

<h2 id="le">LE</h2>

<p>LE (Laplacian Eigenmap) <sup class="footnote-ref" id="fnref:belkin2003laplacian"><a href="#fn:belkin2003laplacian">6</a></sup> 的基本思想是认为在高维空间中距离近的点映射到低维空间中后其位置也相距很近。LE 从这个思想出发，最终将问题转化为求解图拉普拉斯算子的广义特征值问题，具体的一些证明不在这里详细展开说明，具体请参见原文，下面仅给出 LE 算法的流程：</p>

<ol>
<li>构建邻接图。</li>
<li>构建邻接矩阵 <code>$W$</code>，构建邻接矩阵有两种方法：对于点 <code>$i$</code> 和点 <code>$j$</code> 相连，如果利用 Hear Kernel (参数 <code>$t \in \mathbb{R}$</code>)，则令 <code>$W_{ij} = \exp \left(\dfrac{- \left\lVert x_i - x_j \right\rVert ^ 2}{t}\right)$</code>；如果使用简介方案，则令 <code>$W_{ij} = 1$</code>，对于不相连的点，则令 <code>$W_{ij} = 0$</code>。</li>
<li>进行特征映射，通过上面构造的图 <code>$G$</code>，计算如下广义特征值和特征向量
<code>$$
L f = \lambda D f
$$</code>
其中 <code>$D$</code> 是一个对角矩阵，<code>$D_{ii} = \sum_{j} W_{ji}$</code>，<code>$L = D - W$</code> 即为拉普拉斯矩阵。对于上式的解 <code>$f_0, .., f_{k-1}$</code> 为根据特征值从小到大的排序，其中 <code>$0 = \lambda_0 \leq \lambda_1 \leq ... \leq \lambda_{k-1}$</code>，则降维至 <code>$d$</code> 维的后的特征即为 <code>$\left(f_1, f_2, ..., f_d\right)$</code>。</li>
</ol>

<h2 id="sne-和-t-sne">SNE 和 t-SNE</h2>

<h3 id="sne">SNE</h3>

<p>SNE (Stochastic Neighbor Embedding) <sup class="footnote-ref" id="fnref:hinton2003stochastic"><a href="#fn:hinton2003stochastic">16</a></sup> 是由 Hinton 等人提出的一种降维算法，其方法的基本假设如下：</p>

<ol>
<li>对象之间的相似度可以用概率进行表示，即：相似的对象有更高的概率被同时选择，不相似的对象有较低的概率被同时选择。</li>
<li>在高维空间中构建的这种概率分布应该尽可能的同低维空间中的概率分布相似。</li>
</ol>

<p>对于两个点 <code>$x_i, x_j$</code>，假设 <code>$x_i$</code> 以条件概率 <code>$p_{j∣i}$</code> 选择 <code>$x_j$</code> 作为它的邻近点，因此如果两者距离更近 (更相似)，则概率值越大，反之概率值越小，则我们定义 <code>$p_{j∣i}$</code> 如下：</p>

<p><code>$$
p_{j∣i} = \dfrac{\exp \left(\dfrac{- \left\lVert x_i - x_j \right\rVert ^ 2}{2 \sigma_i^2}\right)}{\sum_{k \neq i} \exp \left(\dfrac{- \left\lVert x_i - x_k \right\rVert ^ 2}{2 \sigma_i^2}\right)}
$$</code></p>

<p>其中，<code>$\sigma_i$</code> 为参数，同时我们设置 <code>$p_{i∣i} = 0$</code>，因为我们仅需衡量不同对象之间的相似度。</p>

<p>类似的，根据 SNE 的基本思想，当数据被映射到低维空间中后，其概率分布应同高维空间中的分布尽可能的相似，假设点 <code>$x_i, x_j$</code> 在低维空间中的映射点为 <code>$y_i, y_j$</code>，则在低维空间中的条件概率 <code>$q_{j∣i}$</code> 定义为：</p>

<p><code>$$
q_{j∣i} = \dfrac{\exp \left(- \left\lVert y_i - y_j \right\rVert ^ 2\right)}{\sum_{k \neq i} \exp \left(- \left\lVert y_i - y_k \right\rVert ^ 2\right)}
$$</code></p>

<p>同样，我们设置 <code>$q_{i∣i} = 0$</code>。从 SNE 的基本假设出发，我们的目的是使得数据在高维空间中的条件概率尽可能的和其在低维空间中的条件概率相同，因此对于全部点样本点而言，就是保证高维空间的概率分布 <code>$P_i$</code> 和低维空间的概率分布 <code>$Q_i$</code> 尽量形同。在这里我们利用 KL 散度衡量这两个概率分布的差异，则 SNE 的损失函数可以写为：</p>

<p><code>$$
C = \sum_{i} KL \left(P_i \Vert Q_i\right) = \sum_{i} \sum_{j} p_{j∣i} \log \dfrac{p_{j∣i}}{q_{j∣i}}
$$</code></p>

<p>因为 KL 散度具有不对称性可知，当在原始空间中两点距离较远而降维后的空间中距离较近 (即，<code>$q_{j|i} &lt; p_{j|i}$</code>) 时，会产生较大的 cost，相反则会产生较小的 cost。正是这种不对称性的损失函数导致了 SNE 算法更加关注局部结构，相比忽略了全局结构。</p>

<p>上文中，对于不同的点，<code>$\sigma_i$</code> 具有不同的值，SNE 算法利用困惑度 (Perplexity) 对其进行优化寻找一个最佳的 <code>$\sigma$</code>，对于一个随机变量 <code>$P_i$</code>，困惑度定义如下：</p>

<p><code>$$
Perp \left(P_i\right) = 2^{H \left(P_i\right)}
$$</code></p>

<p>其中，<code>$H \left(P_i\right) = \sum_{j} p_{j|i} \log_2 p_{j|i}$</code> 表示 <code>$P_i$</code> 的熵。困惑度可以解释为一个点附近的有效近邻点个数。SNE 对困惑度的调整比较有鲁棒性，通常选择 5-50 之间，给定之后，使用二分搜索的方式寻找合适的 <code>$\sigma$</code>。</p>

<p>SNE 的损失函数对 <code>$y_i$</code> 求梯度后，可得：</p>

<p><code>$$
\dfrac{\delta C}{\delta y_i} = 2 \sum_j \left(p_{j|i} - q_{j|i} + p_{i|j} - q_{i|j}\right) \left(y_i - y_j\right)
$$</code></p>

<h3 id="t-sne">t-SNE</h3>

<p>SNE 为我们提供了一种很好的降维方法，但是其本身也存在一定的问题，主要有如下两点：</p>

<ul>
<li><strong>不对称问题</strong>：损失函数中的 KL 散度具有不对称性，导致 SNE 更加关注局部结构，相比忽略了全局结构。</li>
<li><strong>拥挤问题</strong>：从高维空间映射到低维空间后，不同类别的簇容易挤在一起，无法较好地区分开。</li>
</ul>

<p>针对这两个问题，Maaten 等人又提出了 t-SNE 算法对其进行优化 <sup class="footnote-ref" id="fnref:maaten2008visualizing"><a href="#fn:maaten2008visualizing">17</a></sup>。</p>

<p>针对不对称问题，Maaten 采用的方法是用联合概率分布来替代条件概率分布。高维控件中的联合概率分布为 <code>$P$</code>，低维空间中的联合概率分布为 <code>$Q$</code>，则对于任意的 <code>$i, j$</code>，有 <code>$p_{ij} = p_{ji}, q_{ij} = q_{ji}$</code>，联合概率定义为：</p>

<p><code>$$
\begin{align}
p_{ij} &amp;= \dfrac{\exp \left(\dfrac{- \left\lVert x_i - x_j \right\rVert ^ 2}{2 \sigma^2}\right)}{\sum_{k \neq l} \exp \left(\dfrac{- \left\lVert x_k - x_l \right\rVert ^ 2}{2 \sigma^2}\right)} \\
q_{ij} &amp;= \dfrac{\exp \left(- \left\lVert y_i - y_j \right\rVert ^ 2\right)}{\sum_{k \neq l} \exp \left(- \left\lVert y_k - y_l \right\rVert ^ 2\right)}
\end{align}
$$</code></p>

<p>虽然这样保证了对称性，但是对于异常的情况，例如数据点 <code>$x_i$</code> 在距离群簇较远，则 <code>$\lVert x_i − x_j \rVert ^ 2$</code> 的值会很大，而 <code>$p_{ij}$</code> 会相应变得非常小，也就是说 <code>$x_i$</code> 的位置很远这件事情对损失函数影响很小 (惩罚过小)，那这个点在低维空间中将无法从其他点中区分出来。因此 Maaten 提出了对称的条件概率来重新定义上述联合概率 <code>$p_{ij}$</code> ，对于数量为 <code>$n$</code> 的数据点，新的概率公式是：</p>

<p><code>$$
p_{ij} = \dfrac{p_{j|i} + p_{i|j}}{2n}
$$</code></p>

<p>则损失函数更新为：</p>

<p><code>$$
C = \sum_{i} KL \left(P_i \Vert Q_i\right) = \sum_{i} \sum_{j} p_{ij} \log \dfrac{p_{ij}}{q_{ij}}
$$</code></p>

<p>梯度更新为：</p>

<p><code>$$
\dfrac{\delta C}{\delta y_i} = 4 \sum_j \left(p_{ij} - q_{ij}\right) \left(y_i - y_j\right)
$$</code></p>

<p>拥挤问题 (Crowding) 就是从高维空间映射到低维空间后，不同类别的簇容易挤在一起，不能很好的地区分开。t-SNE 则是利用了 t 分布重新定义 <code>$q_{ij}$</code>，t 分布具有长尾特性，相比于高斯分布，其在尾部趋向于 0 的速度更慢，对比如图所示：</p>

<p><img src="/images/cn/2018-03-16-manifold-learning/gassion-t-comparison.png" alt="" /></p>

<p>利用 t 分布重新定义的 <code>$q_{ij}$</code> 为：</p>

<p><code>$$
q_{ij} = \dfrac{\left(1 + \lVert y_i - y_j \rVert ^ 2\right) ^ {-1}}{\sum_{k \neq l} \left(1 + \lVert y_k - y_l \rVert ^ 2\right) ^ {-1}}
$$</code></p>

<p>梯度更新为：</p>

<p><code>$$
\dfrac{\delta C}{\delta y_i} = 4 \sum_j \left(p_{ij} - q_{ij}\right) \left(y_i - y_j\right) \left(1 + \lVert y_i - y_j \rVert ^ 2\right) ^ {-1}
$$</code></p>

<p>利用 t-SNE 对 MNIST 数据集进行降维可视化结果如下：</p>

<p><img src="/images/cn/2018-03-16-manifold-learning/mnist-t-sne.png" alt="" /></p>

<h2 id="方法比较">方法比较</h2>

<p>针对上述的若干算法，我们简单列举一下每个算法的优缺点</p>

<table>
<thead>
<tr>
<th>方法</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>

<tbody>
<tr>
<td>Isomap</td>
<td>1. 保持流形的全局几何结构 <br/> 2. 适用于学习内部平坦的低维流形</td>
<td>1. 对于数据量较大的情况，计算效率过低 <br/> 2. 不适于学习有较大内在曲率的流形</td>
</tr>

<tr>
<td>LLE</td>
<td>1. 可以学习任意维的局部线性的低维流形 <br/> 2. 归结为稀疏矩阵特征值计算，计算复杂度相对较小</td>
<td>1. 所学习的流形只能是不闭合的 <br/> 2. 要求样本在流形上是稠密采样的 <br/> 3.对样本中的噪声和邻域参数比较敏感</td>
</tr>

<tr>
<td>LE</td>
<td>1. 是局部非线性方法，与谱图理论有很紧密的联系 <br/> 2. 通过求解稀疏矩阵的特征值问题解析地求出整体最优解，效率非常高 <br/> 3. 使原空间中离得很近的点在低维空间也离得很近，可以用于聚类</td>
<td>1. 对算法参数和数据采样密度较敏感 <br/> 2. 不能有效保持流形的全局几何结构</td>
</tr>

<tr>
<td>SNE, t-SNE</td>
<td>1. 非线性降维效果相较上述方法较好</td>
<td>1. 大规模高维数据时，效率显著降低 <br/> 2. 参数对不同数据集较为敏感</td>
</tr>
</tbody>
</table>

<p>对于<strong>瑞士卷 (Swiss Roll)</strong>，<strong>S 形曲线 (S Curve)</strong> 和<strong>切断的球面 (Severed Sphere)</strong>，我们利用不同的流形算法对其进行降维，可视化的对比结果如下面 3 张图所示，图中同时标注了算法的运行时间，实现主要参照了 scikit-learn 关于流形学习算法的比较 <sup class="footnote-ref" id="fnref:sklearn-manifold"><a href="#fn:sklearn-manifold">18</a></sup>。</p>

<p><img src="/images/cn/2018-03-16-manifold-learning/s-curve.png" alt="" /></p>

<p><img src="/images/cn/2018-03-16-manifold-learning/swiss-roll.png" alt="" /></p>

<p><img src="/images/cn/2018-03-16-manifold-learning/severed-sphere.png" alt="" /></p>

<p>文中相关图片绘制实现详见<a href="https://github.com/leovan/leovan.me/tree/master/scripts/cn/2018-03-16-manifold-learning" rel="noreferrer" target="_blank">代码</a>，本文部分内容参考了<strong>流形学习专题介绍</strong> <sup class="footnote-ref" id="fnref:wangruiping"><a href="#fn:wangruiping">19</a></sup>， <strong>流形学习</strong> <sup class="footnote-ref" id="fnref:hexiaofei"><a href="#fn:hexiaofei">20</a></sup>，<strong>Chrispher</strong> <sup class="footnote-ref" id="fnref:chrispher"><a href="#fn:chrispher">21</a></sup> 的博客和 <strong>bingo</strong> <sup class="footnote-ref" id="fnref:bindog"><a href="#fn:bindog">22</a></sup> 的博客。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:jolliffe1986principal">Jolliffe, Ian T. &ldquo;Principal component analysis and factor analysis.&rdquo; <em>Principal component analysis.</em> Springer, New York, NY, 1986. 115-128.
 <a class="footnote-return" href="#fnref:jolliffe1986principal">↩</a></li>
<li id="fn:balakrishnama1998linear">Balakrishnama, Suresh, and Aravind Ganapathiraju. &ldquo;Linear discriminant analysis-a brief tutorial.&rdquo; <em>Institute for Signal and information Processing</em> 18 (1998): 1-8.
 <a class="footnote-return" href="#fnref:balakrishnama1998linear">↩</a></li>
<li id="fn:cox2000multidimensional">Cox, Trevor F., and Michael AA Cox. <em>Multidimensional scaling.</em> CRC press, 2000.
 <a class="footnote-return" href="#fnref:cox2000multidimensional">↩</a></li>
<li id="fn:tenenbaum2000global">Tenenbaum, Joshua B., Vin De Silva, and John C. Langford. &ldquo;A global geometric framework for nonlinear dimensionality reduction.&rdquo; <em>Science</em> 290.5500 (2000): 2319-2323.
 <a class="footnote-return" href="#fnref:tenenbaum2000global">↩</a></li>
<li id="fn:roweis2000nonlinear">Roweis, Sam T., and Lawrence K. Saul. &ldquo;Nonlinear dimensionality reduction by locally linear embedding.&rdquo; <em>Science</em> 290.5500 (2000): 2323-2326.
 <a class="footnote-return" href="#fnref:roweis2000nonlinear">↩</a></li>
<li id="fn:belkin2003laplacian">Belkin, Mikhail, and Partha Niyogi. &ldquo;Laplacian eigenmaps for dimensionality reduction and data representation.&rdquo; <em>Neural computation</em> 15.6 (2003): 1373-1396.
 <a class="footnote-return" href="#fnref:belkin2003laplacian">↩</a></li>
<li id="fn:meijiaqiang">梅加强. 流形与几何初步
 <a class="footnote-return" href="#fnref:meijiaqiang">↩</a></li>
<li id="fn:wikipedia-manifold"><a href="https://zh.wikipedia.org/zh-hans/流形" rel="noreferrer" target="_blank">https://zh.wikipedia.org/zh-hans/流形</a>
 <a class="footnote-return" href="#fnref:wikipedia-manifold">↩</a></li>
<li id="fn:pluskid">pluskid. <a href="http://blog.pluskid.org/?p=533" rel="noreferrer" target="_blank">浅谈流形学习</a>
 <a class="footnote-return" href="#fnref:pluskid">↩</a></li>
<li id="fn:wikipedia-whitney"><a href="https://en.wikipedia.org/wiki/Whitney_embedding_theorem" rel="noreferrer" target="_blank">https://en.wikipedia.org/wiki/Whitney_embedding_theorem</a>
 <a class="footnote-return" href="#fnref:wikipedia-whitney">↩</a></li>
<li id="fn:silva2003global">Silva, Vin D., and Joshua B. Tenenbaum. &ldquo;Global versus local methods in nonlinear dimensionality reduction.&rdquo; <em>Advances in neural information processing systems.</em> 2003.
 <a class="footnote-return" href="#fnref:silva2003global">↩</a></li>
<li id="fn:hexiaoqun">何晓群. 多元统计分析
 <a class="footnote-return" href="#fnref:hexiaoqun">↩</a></li>
<li id="fn:donoho2003hessian">Donoho, David L., and Carrie Grimes. &ldquo;Hessian eigenmaps: Locally linear embedding techniques for high-dimensional data.&rdquo; <em>Proceedings of the National Academy of Sciences</em> 100.10 (2003): 5591-5596.
 <a class="footnote-return" href="#fnref:donoho2003hessian">↩</a></li>
<li id="fn:zhang2007mlle">Zhang, Zhenyue, and Jing Wang. &ldquo;MLLE: Modified locally linear embedding using multiple weights.&rdquo; <em>Advances in neural information processing systems.</em> 2007.
 <a class="footnote-return" href="#fnref:zhang2007mlle">↩</a></li>
<li id="fn:zhang2004principal">Zhang, Zhenyue, and Hongyuan Zha. &ldquo;Principal manifolds and nonlinear dimensionality reduction via tangent space alignment.&rdquo; <em>SIAM journal on scientific computing</em> 26.1 (2004): 313-338.
 <a class="footnote-return" href="#fnref:zhang2004principal">↩</a></li>
<li id="fn:hinton2003stochastic">Hinton, Geoffrey E., and Sam T. Roweis. &ldquo;Stochastic neighbor embedding.&rdquo; <em>Advances in neural information processing systems.</em> 2003.
 <a class="footnote-return" href="#fnref:hinton2003stochastic">↩</a></li>
<li id="fn:maaten2008visualizing">Maaten, Laurens van der, and Geoffrey Hinton. &ldquo;Visualizing data using t-SNE.&rdquo; <em>Journal of machine learning research</em> 9.Nov (2008): 2579-2605.
 <a class="footnote-return" href="#fnref:maaten2008visualizing">↩</a></li>
<li id="fn:sklearn-manifold"><a href="http://scikit-learn.org/stable/auto_examples/manifold/plot_compare_methods.html" rel="noreferrer" target="_blank">http://scikit-learn.org/stable/auto_examples/manifold/plot_compare_methods.html</a>
 <a class="footnote-return" href="#fnref:sklearn-manifold">↩</a></li>
<li id="fn:wangruiping">王瑞平. 流形学习专题介绍
 <a class="footnote-return" href="#fnref:wangruiping">↩</a></li>
<li id="fn:hexiaofei">何晓飞. 流形学习
 <a class="footnote-return" href="#fnref:hexiaofei">↩</a></li>
<li id="fn:chrispher"><a href="http://www.datakit.cn/blog/2017/02/05/t_sne_full.html" rel="noreferrer" target="_blank">http://www.datakit.cn/blog/2017/02/05/t_sne_full.html</a>
 <a class="footnote-return" href="#fnref:chrispher">↩</a></li>
<li id="fn:bindog"><a href="http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/" rel="noreferrer" target="_blank">http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/</a>
 <a class="footnote-return" href="#fnref:bindog">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>深度学习优化算法 (Optimization Methods for Deeplearning)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2018/02/optimization-methods-for-deeplearning/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2018/02/optimization-methods-for-deeplearning/</guid>
      <description>
        <![CDATA[
        

<p>在构建神经网络模型的时候，除了网络结构设计以外，选取合适的优化算法也对网络起着至关重要的作用，本文将对神经网络中常用的优化算法进行简单的介绍和对比，本文部分参考了 Ruder 的关于梯度下降优化算法一文 <sup class="footnote-ref" id="fnref:ruder2016overview"><a href="#fn:ruder2016overview">1</a></sup>。首先，我们对下文中使用的符号进行同意说明：网络中的参数同一表示为 <code>$\theta$</code>，网络的假设函数为 <code>$h_{\boldsymbol{\theta}}\left(\boldsymbol{x}\right)$</code>，网络的损失函数为 <code>$J\left(\boldsymbol{\theta}\right)$</code>，学习率为 <code>$\alpha$</code>，假设训练数据中共包含 <code>$m$</code> 个样本，网络参数个数为 <code>$n$</code>。</p>

<h1 id="梯度下降">梯度下降</h1>

<p>在梯度下降算法中，常用的主要包含 3 种不同的形式，分别是批量梯度下降 (Batch Gradient Descent, BGD)，随机梯度下降 (Stochastic Gradient Descent, SGD) 和小批量梯度下降 (Mini-Batch Gradient Descent, MBGD)。一般情况下，我们在谈论梯度下降时，更多的是指小批量梯度下降。</p>

<h2 id="bgd">BGD</h2>

<p>BGD 为梯度下降算法中最基础的一个算法，其损失函数定义如下：</p>

<p><code>$$
J \left(\boldsymbol{\theta}\right) = \dfrac{1}{2m} \sum_{i=1}^{m}{\left(h_{\boldsymbol{\theta}}\left(x^{\left(i\right)}\right) - y^{\left(i\right)}\right)}
$$</code></p>

<p>针对任意参数 <code>$\theta_j$</code> 我们可以求得其梯度为：</p>

<p><code>$$
\nabla_{\theta_j} = \dfrac{\partial J\left(\boldsymbol{\theta}\right)}{\partial \theta_j} = - \dfrac{1}{m} \sum_{i=1}^{m}{\left(y^{\left(i\right)} - h_{\boldsymbol{\theta}} \left(x^{\left(i\right)}\right)\right) x_j^{\left(i\right)}}
$$</code></p>

<p>之后，对于任意参数 <code>$\theta_j$</code> 我们按照其<strong>负梯度</strong>方向进行更新：</p>

<p><code>$$
\theta_j = \theta_j + \alpha \left[\dfrac{1}{m} \sum_{i=1}^{m}{\left(y^{\left(i\right)} - h_{\boldsymbol{\theta}} \left(x^{\left(i\right)}\right)\right) x_j^{\left(i\right)}}\right]
$$</code></p>

<p>整个算法流程可以表示如下：</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{BGD 算法}
\begin{algorithmic}
\FOR{$epoch = 1, 2, ...$}
    \FOR{$j = 1, 2, ..., n$}
        \STATE $J \left(\boldsymbol{\theta}\right) = \dfrac{1}{2m} \sum_{i=1}^{m}{\left(h_{\boldsymbol{\theta}}\left(x^{\left(i\right)}\right) - y^{\left(i\right)}\right)}$
        \STATE $\theta_j = \theta_j - \alpha \dfrac{\partial J\left(\boldsymbol{\theta}\right)}{\partial \theta_j}$
    \ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>从上述算法流程中我们可以看到，BGD 算法每次计算梯度都使用了整个训练集，也就是说对于给定的一个初始点，其每一步的更新都是沿着全局梯度最大的负方向。但这同样是其问题，当 <code>$m$</code> 太大时，整个算法的计算开销就很高了。</p>

<h2 id="sgd">SGD</h2>

<p>SGD 相比于 BGD，其最主要的区别就在于计算梯度时不再利用整个数据集，而是针对单个样本计算梯度并更新权重，因此，其损失函数定义如下：</p>

<p><code>$$
J \left(\boldsymbol{\theta}\right) = \dfrac{1}{2} \left(h_{\boldsymbol{\theta}}\left(x^{\left(i\right)}\right) - y^{\left(i\right)}\right)
$$</code></p>

<p>整个算法流程可以表示如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{SGD 算法}
\begin{algorithmic}
\FOR{$epoch = 1, 2, ...$}
    \STATE Randomly shuffle dataset
    \FOR{$i = 1, 2, ..., m$}
        \FOR{$j = 1, 2, ..., n$}
            \STATE $J \left(\boldsymbol{\theta}\right) = \dfrac{1}{2} \left(h_{\boldsymbol{\theta}}\left(x^{\left(i\right)}\right) - y^{\left(i\right)}\right)$
            \STATE $\theta_j = \theta_j - \alpha \dfrac{\partial J\left(\boldsymbol{\theta}\right)}{\partial \theta_j}$
        \ENDFOR
    \ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>SGD 相比于 BGD 具有训练速度快的优势，但同时由于权重改变的方向并不是全局梯度最大的负方向，甚至相反，因此不能够保证每次损失函数都会减小。</p>

<h2 id="mbgd">MBGD</h2>

<p>针对 BGD 和 SGD 的问题，MBGD 则是一个折中的方案，在每次更新参数时，MBGD 会选取 <code>$b$</code> 个样本计算的梯度，设第 <code>$k$</code> 批中数据的下标的集合为 <code>$B_k$</code>，则其损失函数定义如下：</p>

<p><code>$$
\nabla_{\theta_j} = \dfrac{\partial J\left(\boldsymbol{\theta}\right)}{\partial \theta_j} = - \dfrac{1}{|B_k|} \sum_{i \in B_k}{\left(y^{\left(i\right)} - h_{\boldsymbol{\theta}} \left(x^{\left(i\right)}\right)\right) x_j^{\left(i\right)}}
$$</code></p>

<p>整个算法流程可以表示如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{MBGD 算法}
\begin{algorithmic}
\FOR{$epoch = 1, 2, ...$}
    \FOR{$k = 1, 2, ..., m / b$}
        \FOR{$j = 1, 2, ..., n$}
            \STATE $J \left(\boldsymbol{\theta}\right) = \dfrac{1}{|B_k|} \sum_{i \in B_k}{\left(y^{\left(i\right)} - h_{\boldsymbol{\theta}} \left(x^{\left(i\right)}\right)\right) x_j^{\left(i\right)}}$
            \STATE $\theta_j = \theta_j - \alpha \dfrac{\partial J\left(\boldsymbol{\theta}\right)}{\partial \theta_j}$
        \ENDFOR
    \ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<h1 id="momentum">Momentum</h1>

<p>当梯度沿着一个方向要明显比其他方向陡峭，我们可以形象的称之为峡谷形梯度，这种情况多位于局部最优点附近。在这种情况下，SGD 通常会摇摆着通过峡谷的斜坡，这就导致了其到达局部最优值的速度过慢。因此，针对这种情况，Momentum <sup class="footnote-ref" id="fnref:qian1999momentum"><a href="#fn:qian1999momentum">2</a></sup> 方法提供了一种解决方案。针对原始的 SGD 算法，参数每 <code>$t$</code> 步的变化量可以表示为</p>

<p><code>$$
\boldsymbol{v}_t = - \alpha \nabla_{\boldsymbol{\theta}} J \left(\boldsymbol{\theta}_t\right)
$$</code></p>

<p>Momentum 算法则在其变化量中添加了一个动量分量，即</p>

<p><code>$$
\begin{equation}
\begin{split}
\boldsymbol{v}_t &amp;= - \alpha \nabla_{\boldsymbol{\theta}} J \left(\boldsymbol{\theta}_t\right) + \gamma \boldsymbol{v}_{t-1} \\
\boldsymbol{\theta}_t &amp;= \boldsymbol{\theta}_{t-1} + \boldsymbol{v}_t
\end{split}
\end{equation}
$$</code></p>

<p>对于添加的动量项，当第 <code>$t$</code> 步和第 <code>$t-1$</code> 步的梯度方向<strong>相同</strong>时，<code>$\boldsymbol{\theta}$</code> 则以更快的速度更新；当第 <code>$t$</code> 步和第 <code>$t-1$</code> 步的梯度方向<strong>相反</strong>时，<code>$\boldsymbol{\theta}$</code> 则以较慢的速度更新。利用 SGD 和 Momentum 两种方法，在峡谷行的二维梯度上更新参数的示意图如下所示</p>

<p><img src="/images/cn/2018-02-24-optimization-methods-for-deeplearning/sgd-and-momentum.png" alt="" /></p>

<h1 id="nag">NAG</h1>

<p>NAG (Nesterov Accelerated Gradient) <sup class="footnote-ref" id="fnref:nesterov1983method"><a href="#fn:nesterov1983method">3</a></sup> 是一种 Momentum 算法的变种，其核心思想会利用“下一步的梯度”确定“这一步的梯度”，当然这里“下一步的梯度”并非真正的下一步的梯度，而是指仅根据动量项更新后位置的梯度。Sutskever <sup class="footnote-ref" id="fnref:sutskever2013training"><a href="#fn:sutskever2013training">4</a></sup> 给出了一种更新参数的方法：</p>

<p><code>$$
\begin{equation}
\begin{split}
\boldsymbol{v}_t &amp;= - \alpha \nabla_{\boldsymbol{\theta}} J \left(\boldsymbol{\theta}_t + \gamma \boldsymbol{v}_{t-1}\right) + \gamma \boldsymbol{v}_{t-1} \\
\boldsymbol{\theta}_t &amp;= \boldsymbol{\theta}_{t-1} + \boldsymbol{v}_t
\end{split}
\end{equation}
$$</code></p>

<p>针对 Momentum 和 NAG 两种不同的方法，其更新权重的差异如下图所示：</p>

<p><img src="/images/cn/2018-02-24-optimization-methods-for-deeplearning/momentum-and-nag.png" alt="" /></p>

<h1 id="adagrad">AdaGrad</h1>

<p>AdaGrad <sup class="footnote-ref" id="fnref:duchi2011adaptive"><a href="#fn:duchi2011adaptive">5</a></sup> 是一种具有自适应学习率的的方法，其对于低频特征的参数选择更大的更新量，对于高频特征的参数选择更小的更新量。因此，AdaGrad算法更加适用于处理稀疏数据。Pennington 等则利用该方法训练 GloVe <sup class="footnote-ref" id="fnref:pennington2014glove"><a href="#fn:pennington2014glove">6</a></sup> 词向量，因为对于出现次数较少的词应当获得更大的参数更新。</p>

<p>因为每个参数的学习速率不再一样，则在 <code>$t$</code> 时刻第 <code>$i$</code> 个参数的变化为</p>

<p><code>$$
\theta_{t, i} = \theta_{t-1, i} - \alpha \nabla_{\theta} J \left(\theta_{t-1, i}\right)
$$</code></p>

<p>根据 AdaGrad 方法的更新方式，我们对学习率做出如下变化</p>

<p><code>$$
\theta_{t, i} = \theta_{t-1, i} - \dfrac{\alpha}{\sqrt{G_{t, i}} + \epsilon} \nabla_{\theta} J \left(\theta_{t-1, i}\right)
$$</code></p>

<p>其中，<code>$G_t$</code> 表示截止到 <code>$t$</code> 时刻梯度的平方和；<code>$\epsilon$</code> 为平滑项，防止除数为零，一般设置为 <code>$10^{-8}$</code>。AdaGrad 最大的优势就在于其能够自动调节每个参数的学习率。</p>

<h1 id="adadelta">Adadelta</h1>

<p>上文中 AdaGrad 算法存在一个缺点，即其用于调节学习率的分母中包含的是一个梯度的平方累加项，随着训练的不断进行，这个值将会越来越大，也就是说学习率将会越来越小，最终导致模型不会再学习到任何知识。Adadelta <sup class="footnote-ref" id="fnref:zeiler2012adadelta"><a href="#fn:zeiler2012adadelta">7</a></sup> 方法针对 AdaGrad 的这个问题，做出了进一步改进，其不再计算历史所以梯度的平方和，而是使用一个固定长度 <code>$w$</code> 的滑动窗口内的梯度。</p>

<p>因为存储 <code>$w$</code> 的梯度平方并不高效，Adadelta 采用了一种递归的方式进行计算，定义 <code>$t$</code> 时刻梯度平方的均值为</p>

<p><code>$$
E \left[g^2\right]_t = \rho E \left[g^2\right]_{t-1} + \left(1 - \rho\right) g^2_{t}
$$</code></p>

<p>其中，<code>$g_t$</code> 表示 <code>$t$</code> 时刻的梯度；<code>$\rho$</code> 为一个衰减项，类似于 Momentum 中的衰减项。在更新参数过程中我们需要其平方根，即</p>

<p><code>$$
\text{RMS} \left[g\right]_t = \sqrt{E \left[g^2\right]_t + \epsilon}
$$</code></p>

<p>则参数的更新量为</p>

<p><code>$$
\Delta \theta_t = - \dfrac{\alpha}{\text{RMS} \left[g\right]_t} g_t
$$</code></p>

<p>除此之外，作者还考虑到上述更新中更新量和参数的假设单位不一致的情况，在上述更新公式中添加了一个关于参数的衰减项</p>

<p><code>$$
\text{RMS} \left[\Delta \theta\right]_t = \sqrt{E \left[\Delta \theta^2\right]_t + \epsilon}
$$</code></p>

<p>其中</p>

<p><code>$$
E \left[\Delta \theta^2\right]_t = \rho E \left[\Delta \theta^2\right]_{t-1} + \left(1 - \rho\right) \Delta \theta_t^2
$$</code></p>

<p>在原始的论文中，作者直接用 <code>$\text{RMS} \left[\Delta \theta^2\right]_t$</code> 替换了学习率，即</p>

<p><code>$$
\Delta \theta_t = - \dfrac{\text{RMS} \left[\Delta \theta\right]_{t-1}}{\text{RMS} \left[g\right]_t} g_t
$$</code></p>

<p>而在 <code>Keras</code> 源码中，则保留了固定的学习率，即</p>

<p><code>$$
\Delta \theta_t = - \alpha \dfrac{\text{RMS} \left[\Delta \theta\right]_{t-1}}{\text{RMS} \left[g\right]_t} g_t
$$</code></p>

<h1 id="rmsprop">RMSprop</h1>

<p>RMSprop <sup class="footnote-ref" id="fnref:hinton2012rmsprop"><a href="#fn:hinton2012rmsprop">8</a></sup> 是由 Hinton 提出的一种针对 AdaGrad 的改进算法。参数的更新量为</p>

<p><code>$$
\Delta \theta_t = - \dfrac{\alpha}{\text{RMS} \left[g\right]_t} g_t
$$</code></p>

<h1 id="adam">Adam</h1>

<p>Adam (Adaptive Moment Estimation) <sup class="footnote-ref" id="fnref:kingma2014adam"><a href="#fn:kingma2014adam">9</a></sup> 是另一种类型的自适应学习率方法，类似 Adadelta，Adam 对于每个参数都计算各自的学习率。Adam 方法中包含一个一阶梯度衰减项 <code>$m_t$</code> 和一个二阶梯度衰减项 <code>$v_t$</code></p>

<p><code>$$
\begin{equation}
\begin{split}
m_t &amp;= \beta_1 m_{t-1} + \left(1 - \beta_1\right) g_t \\
v_t &amp;= \beta_2 v_{t-1} + \left(1 - \beta_2\right) g_t^2
\end{split}
\end{equation}
$$</code></p>

<p>算法中，<code>$m_t$</code> 和 <code>$v_t$</code> 初始化为零向量，作者发现两者会更加偏向 <code>$0$</code>，尤其是在训练的初始阶段和衰减率很小的时候 (即 <code>$\beta_1$</code> 和 <code>$\beta_2$</code> 趋近于1的时候)。因此，对其偏差做如下校正</p>

<p><code>$$
\begin{equation}
\begin{split}
\hat{m}_t &amp;= \dfrac{m_t}{1 - \beta_1^t} \\
\hat{v}_t &amp;= \dfrac{v_t}{1 - \beta_2^t}
\end{split}
\end{equation}
$$</code></p>

<p>最终得到 Adam 算法的参数更新量如下</p>

<p><code>$$
\Delta \theta = - \dfrac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t
$$</code></p>

<h1 id="adamax">Adamax</h1>

<p>在 Adam 中参数的更新方法利用了 <code>$L_2$</code> 正则形式的历史梯度 (<code>$v_{t-1}$</code>) 和当前梯度 (<code>$|g_t|^2$</code>)，因此，更一般的，我们可以使用 <code>$L_p$</code> 正则形式，即</p>

<p><code>$$
\begin{equation}
\begin{split}
v_t &amp;= \beta_2^p v_{t-1} + \left(1 - \beta_2^p\right) |g_t|^p \\
&amp;= \left(1 - \beta_2^p\right) \sum_{i=1}^{t} \beta_2^{p\left(t-i\right)} \cdot |g_t|^p
\end{split}
\end{equation}
$$</code></p>

<p>这样的变换对于值较大的 <code>$p$</code> 而言是很不稳定的，但对于极端的情况，当 <code>$p$</code> 趋近于无穷的时候，则变为了一个简单并且稳定的算法。则在 <code>$t$</code> 时刻对应的我们需要计算 <code>$v_t^{1/p}$</code>，令 <code>$u_t = \lim_{p \to \infty} \left(v_t\right)^{1/p}$</code>，则有</p>

<p><code>$$
\begin{equation}
\begin{split}
u_t &amp;= \lim_{p \to \infty} \left(\left(1 - \beta_2^p\right) \sum_{i=1}^{t} \beta_2^{p\left(t-i\right)} \cdot |g_t|^p\right)^{1/p} \\
&amp;= \lim_{p \to \infty} \left(1 - \beta_2^p\right)^{1/p} \left(\sum_{i=1}^{t} \beta_2^{p\left(t-i\right)} \cdot |g_t|^p\right)^{1/p} \\
&amp;= \lim_{p \to \infty} \left(\sum_{i=1}^{t} \beta_2^{p\left(t-i\right)} \cdot |g_t|^p\right)^{1/p} \\
&amp;= \max \left(\beta_2^{t-1} |g_1|, \beta_2^{t-2} |g_2|, ..., \beta_{t-1} |g_t|\right)
\end{split}
\end{equation}
$$</code></p>

<p>写成递归的形式，则有</p>

<p><code>$$
u_t = \max \left(\beta_2 \cdot u_{t-1}, |g_t|\right)
$$</code></p>

<p>则 Adamax 算法的参数更新量为</p>

<p><code>$$
\Delta \theta = - \dfrac{\alpha}{u_t} \hat{m}_t
$$</code></p>

<h1 id="nadam">Nadam</h1>

<p>Adam 算法可以看做是对 RMSprop 和 Momentum 的结合：历史平方梯度的衰减项 <code>$v_t$</code> (RMSprop) 和 历史梯度的衰减项 <code>$m_t$</code> (Momentum)。Nadam (Nesterov-accelerated Adaptive Moment Estimation) <sup class="footnote-ref" id="fnref:dozat2016incorporating"><a href="#fn:dozat2016incorporating">10</a></sup> 则是将 Adam 同 NAG 进行了进一步结合。我们利用 Adam 中的符号重新回顾一下 NAG 算法</p>

<p><code>$$
\begin{equation}
\begin{split}
g_t &amp;= \nabla_{\theta} J \left(\theta_t - \gamma m_{t-1}\right) \\
m_t &amp;= \gamma m_{t-1} + \alpha g_t \\
\theta_t &amp;= \theta_{t-1} - m_t
\end{split}
\end{equation}
$$</code></p>

<p>NAG 算法的核心思想会利用“下一步的梯度”确定“这一步的梯度”，在 Nadam 算法中，作者在考虑“下一步的梯度”时对 NAG 进行了改动，修改为</p>

<p><code>$$
\begin{equation}
\begin{split}
g_t &amp;= \nabla_{\theta} J \left(\theta_t\right) \\
m_t &amp;= \gamma m_{t-1} + \alpha g_t \\
\theta_t &amp;= \theta_{t-1} - \left(\gamma m_t + \alpha g_t\right)
\end{split}
\end{equation}
$$</code></p>

<p>对于 Adam，根据</p>

<p><code>$$
\hat{m}_t = \dfrac{\beta_1 m_{t-1}}{1 - \beta_1^t} + \dfrac{\left(1 - \beta_1\right) g_t}{1 - \beta_1^t}
$$</code></p>

<p>则有</p>

<p><code>$$
\begin{equation}
\begin{split}
\Delta \theta &amp;= - \dfrac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t \\
&amp;= - \dfrac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \left(\dfrac{\beta_1 m_{t-1}}{1 - \beta_1^t} + \dfrac{\left(1 - \beta_1\right) g_t}{1 - \beta_1^t}\right)
\end{split}
\end{equation}
$$</code></p>

<p>上式中，仅 <code>$\dfrac{\beta_1 m_{t-1}}{1 - \beta_1^t}$</code> 和动量项相关，因此我们类似上文中对 NAG 的改动，通过简单的替换加入 Nesterov 动量项，最终得到 Nadam 方法的参数的更新量</p>

<p><code>$$
\Delta \theta = - \dfrac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \left(\dfrac{\beta_1 m_{t-1}}{1 - \beta_1^{t+1}} + \dfrac{\left(1 - \beta_1\right) g_t}{1 - \beta_1^t}\right)
$$</code></p>

<h1 id="amsgrad">AMSGrad</h1>

<p>对于前面提到的 Adadelta，RMSprop，Adam 和 Nadam 方法，他们均采用了平方梯度的指数平滑平均值迭代产生新的梯度，但根据观察，在一些情况下这些算法并不能收敛到最优解。Reddi 等提出了一种新的 Adam 变体算法 AMSGrad <sup class="footnote-ref" id="fnref:reddi2018convergence"><a href="#fn:reddi2018convergence">11</a></sup>，在文中作者解释了为什么 RMSprop 和 Adam 算法无法收敛到一个最优解的问题。通过分析表明，为了保证得到一个收敛的最优解需要保留过去梯度的“长期记忆”，因此在 AMSGrad 算法中使用了历史平方梯度的最大值而非滑动平均进行更新参数，即</p>

<p><code>$$
\begin{equation}
\begin{split}
m_t &amp;= \beta_1 m_{t-1} + \left(1 - \beta_1\right) g_t \\
v_t &amp;= \beta_2 v_{t-1} + \left(1 - \beta_2\right) g_t^2 \\
\hat{v}_t &amp;= \max \left(\hat{v}_{t-1}, v_t\right) \\
\Delta \theta &amp;= - \dfrac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} m_t
\end{split}
\end{equation}
$$</code></p>

<p>作者在一些小数据集和 CIFAR-10 数据集上得到了相比于 Adam 更好的效果，但与此同时一些其他的 <a href="https://fdlm.github.io/post/amsgrad/" rel="noreferrer" target="_blank">实验</a> 却得到了相比与 Adam 类似或更差的结果，因此对于 AMSGrad 算法的效果还有待进一步确定。</p>

<h1 id="算法可视化">算法可视化</h1>

<p>正所谓一图胜千言，<a href="https://imgur.com/a/Hqolp" rel="noreferrer" target="_blank">Alec Radford</a> 提供了 2 张图形象了描述了不同优化算法之间的区别</p>

<p><img src="/images/cn/2018-02-24-optimization-methods-for-deeplearning/contours-evaluation-optimizers.gif" style="float: left; width: 50%;" />
<img src="/images/cn/2018-02-24-optimization-methods-for-deeplearning/saddle-point-evaluation-optimizers.gif" style="clear: right; width: 50%;" /></p>

<p>左图为 <a href="https://en.wikipedia.org/wiki/Test_functions_for_optimization" rel="noreferrer" target="_blank">Beale Function</a> 在二维平面上的等高线，从图中可以看出 AdaGrad，Adadelta 和 RMSprop 算法很快的找到正确的方向并迅速的收敛到最优解；Momentum 和 NAG 则在初期出现了偏离，但偏离之后调整了方向并收敛到最优解；而 SGD 尽管方向正确，但收敛速度过慢。</p>

<p>右图为包含鞍点的一个三维图像，图像函数为 <code>$z = x^2 - y^2$</code>，从图中可以看出 AdaGrad，Adadelta 和 RMSprop 算法能够相对很快的逃离鞍点，而 Momentum，NAG 和 SGD 则相对比较困难逃离鞍点。</p>

<p>很不幸没能找到 Alec Radford 绘图的原始代码，不过 Louis Tiao 在 <a href="http://louistiao.me/notes/visualizing-and-animating-optimization-algorithms-with-matplotlib/" rel="noreferrer" target="_blank">博客</a> 中给出了绘制类似动图的方法。因此，本文参考该博客和 <code>Keras</code> 源码中对不同优化算法的实现重新绘制了 2 张类似图像，详细过程参见 <a href="https://github.com/leovan/leovan.me/tree/master/scripts/cn/2018-02-24-optimization-methods-for-deeplearning" rel="noreferrer" target="_blank">源代码</a>，动图如下所示：</p>

<p><img src="/images/cn/2018-02-24-optimization-methods-for-deeplearning/beales-2d-anim.gif" style="float: left; clear: both; width: 50%;" />
<img src="/images/cn/2018-02-24-optimization-methods-for-deeplearning/saddle-3d-anim.gif" style="clear: both; width: 50%;" /></p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:ruder2016overview">Ruder, Sebastian. &ldquo;An overview of gradient descent optimization algorithms.&rdquo; <em>arXiv preprint arXiv:1609.04747</em> (2016).
 <a class="footnote-return" href="#fnref:ruder2016overview">↩</a></li>
<li id="fn:qian1999momentum">Qian, Ning. &ldquo;On the momentum term in gradient descent learning algorithms.&rdquo; <em>Neural networks</em> 12.1 (1999): 145-151.
 <a class="footnote-return" href="#fnref:qian1999momentum">↩</a></li>
<li id="fn:nesterov1983method">Nesterov, Yurii. &ldquo;A method for unconstrained convex minimization problem with the rate of convergence O (1/k^2).&rdquo; <em>Doklady AN USSR.</em> Vol. 269. 1983.
 <a class="footnote-return" href="#fnref:nesterov1983method">↩</a></li>
<li id="fn:sutskever2013training">Sutskever, Ilya. &ldquo;Training recurrent neural networks.&rdquo; University of Toronto, Toronto, Ont., Canada (2013).
 <a class="footnote-return" href="#fnref:sutskever2013training">↩</a></li>
<li id="fn:duchi2011adaptive">Duchi, John, Elad Hazan, and Yoram Singer. &ldquo;Adaptive subgradient methods for online learning and stochastic optimization.&rdquo; <em>Journal of Machine Learning Research</em> 12.Jul (2011): 2121-2159.
 <a class="footnote-return" href="#fnref:duchi2011adaptive">↩</a></li>
<li id="fn:pennington2014glove">Pennington, Jeffrey, Richard Socher, and Christopher Manning. &ldquo;Glove: Global vectors for word representation.&rdquo; <em>Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP).</em> 2014.
 <a class="footnote-return" href="#fnref:pennington2014glove">↩</a></li>
<li id="fn:zeiler2012adadelta">Zeiler, Matthew D. &ldquo;ADADELTA: an adaptive learning rate method.&rdquo; <em>arXiv preprint arXiv:1212.5701</em> (2012).
 <a class="footnote-return" href="#fnref:zeiler2012adadelta">↩</a></li>
<li id="fn:hinton2012rmsprop">Hinton, G., Nitish Srivastava, and Kevin Swersky. &ldquo;Rmsprop: Divide the gradient by a running average of its recent magnitude.&rdquo; <em>Neural networks for machine learning, Coursera lecture 6e</em> (2012).
 <a class="footnote-return" href="#fnref:hinton2012rmsprop">↩</a></li>
<li id="fn:kingma2014adam">Kingma, Diederik P., and Jimmy Ba. &ldquo;Adam: A method for stochastic optimization.&rdquo; <em>arXiv preprint arXiv:1412.6980</em> (2014).
 <a class="footnote-return" href="#fnref:kingma2014adam">↩</a></li>
<li id="fn:dozat2016incorporating">Dozat, Timothy. &ldquo;Incorporating nesterov momentum into adam.&rdquo; (2016).
 <a class="footnote-return" href="#fnref:dozat2016incorporating">↩</a></li>
<li id="fn:reddi2018convergence">Reddi, Sashank J., Satyen Kale, and Sanjiv Kumar. &ldquo;On the convergence of adam and beyond.&rdquo; International Conference on Learning Representations. 2018.
 <a class="footnote-return" href="#fnref:reddi2018convergence">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>生成对抗网络简介 (GAN Introduction)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2018/02/gan-introduction/</link>
      <pubDate>Sat, 03 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2018/02/gan-introduction/</guid>
      <description>
        <![CDATA[
        

<h1 id="generative-adversarial-networks-gan">Generative Adversarial Networks (GAN)</h1>

<p><strong>生成对抗网络</strong> (<strong>Generative Adversarial Network, GAN</strong>) 是由 Goodfellow <sup class="footnote-ref" id="fnref:goodfellow2014generative"><a href="#fn:goodfellow2014generative">1</a></sup> 于 2014 年提出的一种对抗网络。这个网络框架包含两个部分，一个生成模型 (generative model) 和一个判别模型 (discriminative model)。其中，生成模型可以理解为一个伪造者，试图通过构造假的数据骗过判别模型的甄别；判别模型可以理解为一个警察，尽可能甄别数据是来自于真实样本还是伪造者构造的假数据。两个模型都通过不断的学习提高自己的能力，即生成模型希望生成更真的假数据骗过判别模型，而判别模型希望能学习如何更准确的识别生成模型的假数据。</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/zhoubotong.png" alt="" /></p>

<h2 id="网络框架">网络框架</h2>

<p>GAN 由两部分构成，一个<strong>生成器</strong> (<strong>Generator</strong>) 和一个<strong>判别器</strong> (<strong>Discriminator</strong>)。对于生成器，我们需要学习关于数据 <code>$\boldsymbol{x}$</code> 的一个分布 <code>$p_g$</code>，首先定义一个输入数据的先验分布 <code>$p_{\boldsymbol{z}} \left(\boldsymbol{z}\right)$</code>，其次定义一个映射 <code>$G \left(\boldsymbol{z}; \theta_g\right): \boldsymbol{z} \to \boldsymbol{x}$</code>。对于判别器，我们则需要定义一个映射 <code>$D \left(\boldsymbol{x}; \theta_d\right)$</code> 用于表示数据 <code>$\boldsymbol{x}$</code> 是来自于真实数据，还是来自于 <code>$p_g$</code>。GAN 的网络框架如下图所示 <sup class="footnote-ref" id="fnref:goodfellow2016nips"><a href="#fn:goodfellow2016nips">2</a></sup>：</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/gan-framework.svg" alt="" /></p>

<h2 id="模型训练">模型训练</h2>

<p>Goodfellow 在文献中给出了一个重要的公式用于求解最优的生成器</p>

<p><code>$$
\min_{G} \max_{D} V\left(D, G\right) = \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log D\left(\boldsymbol{x}\right)\right]} + \mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}\left(\boldsymbol{z}\right)}{\left[\log \left(1 - D\left(G\left(\boldsymbol{z}\right)\right)\right)\right]}
$$</code></p>

<p>上式中，在给定的 <code>$G$</code> 的情况下，<code>$\max_{D} V\left(G, D\right)$</code>衡量的是 <code>$p_{data}$</code> 和 <code>$p_g$</code> 之间的“区别”，因此我们最终的优化目标就是找到最优的 <code>$G^*$</code> 使得 <code>$p_{data}$</code> 和 <code>$p_g$</code> 之间的“区别”最小。</p>

<p>首先，在给定 <code>$G$</code> 的时候，我们可以通过最大化 <code>$V \left(G, D\right)$</code> 得到最优 <code>$D^*$</code></p>

<p><code>$$
\begin{equation}
\begin{split}
V \left(G, D\right) &amp;= \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log D\left(\boldsymbol{x}\right)\right]} + \mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}\left(\boldsymbol{z}\right)}{\left[\log \left(1 - D\left(G\left(\boldsymbol{z}\right)\right)\right)\right]} \\
&amp;= \int_{\boldsymbol{x}}{p_{data}\left(\boldsymbol{x}\right) \log D\left(\boldsymbol{x}\right) dx} + \int_{\boldsymbol{z}}{p_{\boldsymbol{z}} \left(\boldsymbol{z}\right) \log \left(1 - D\left(g\left(\boldsymbol{z}\right)\right)\right) dz} \\
&amp;= \int_{\boldsymbol{x}}{p_{data}\left(\boldsymbol{x}\right) \log D\left(\boldsymbol{x}\right) + p_g\left(\boldsymbol{x}\right) \log \left(1 - D\left(\boldsymbol{x}\right)\right) dx}
\end{split}
\end{equation}
$$</code></p>

<p>对于给定的任意 <code>$a, b \in \mathbb{R}^2 \setminus \{0, 0\}$</code>，<code>$a \log\left(x\right) + b \log\left(1 - x\right)$</code>在 <code>$x = \dfrac{a}{a+b}$</code> 处取得最大值，<code>$D$</code> 的最优值为</p>

<p><code>$$
D_{G}^{*} = \dfrac{p_{data} \left(\boldsymbol{x}\right)}{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}
$$</code></p>

<p>因此，<code>$\max_{D} V \left(G, D\right)$</code> 可重写为</p>

<p><code>$$
\begin{equation}
\begin{split}
&amp;C\left(G\right) \\
=&amp; \max_{D} V \left(G, D\right) = V \left(G, D^*\right) \\
=&amp; \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log D_{G}^{*}\left(\boldsymbol{x}\right)\right]} + \mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}\left(\boldsymbol{z}\right)}{\left[\log \left(1 - D_{G}^{*}\left(G\left(\boldsymbol{z}\right)\right)\right)\right]} \\
=&amp; \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log D_{G}^{*}\left(\boldsymbol{x}\right)\right]} + \mathbb{E}_{\boldsymbol{x} \sim p_g\left(\boldsymbol{x}\right)}{\left[\log \left(1 - D_{G}^{*}\left(\boldsymbol{x}\right)\right)\right]} \\
=&amp; \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log \dfrac{p_{data} \left(\boldsymbol{x}\right)}{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)} \right]} + \mathbb{E}_{\boldsymbol{x} \sim p_g\left(\boldsymbol{x}\right)}{\left[\log  \dfrac{p_g \left(\boldsymbol{x}\right)}{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}\right]} \\
=&amp; \int_{x}{p_{data} \left(\boldsymbol{x}\right) \log \dfrac{\dfrac{1}{2} p_{data} \left(\boldsymbol{x}\right)}{\dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}} dx} + \int_{x}{p_g \left(\boldsymbol{x}\right) \log  \dfrac{\dfrac{1}{2} p_g \left(\boldsymbol{x}\right)}{\dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}} dx} \\
=&amp; \int_{x}{p_{data} \left(\boldsymbol{x}\right) \log \dfrac{p_{data} \left(\boldsymbol{x}\right)}{\dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}} dx} + \int_{x}{p_g \left(\boldsymbol{x}\right) \log  \dfrac{p_g \left(\boldsymbol{x}\right)}{\dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}} dx} + 2 \log \dfrac{1}{2} \\
=&amp; KL \left(p_{data} \left(\boldsymbol{x}\right) \Vert \dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}\right) + KL \left(p_g \left(\boldsymbol{x}\right) \Vert \dfrac{p_{data} \left(\boldsymbol{x}\right) + p_g \left(\boldsymbol{x}\right)}{2}\right) - 2 \log 2 \\
=&amp; 2 JS \left(p_{data} \left(\boldsymbol{x}\right) \Vert p_g \left(\boldsymbol{x}\right) \right) - 2 \log 2
\end{split}
\end{equation}
$$</code></p>

<p>其中 <code>$KL$</code> 表示 KL 散度 <sup class="footnote-ref" id="fnref:kl-divergence"><a href="#fn:kl-divergence">3</a></sup>，<code>$JS$</code> 表示 JS 散度 <sup class="footnote-ref" id="fnref:jsd-divergence"><a href="#fn:jsd-divergence">4</a></sup>，因此在全局最优情况下 <code>$p_g = p_{data}$</code>。</p>

<p>整个 GAN 的训练过程如下所示：</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{Minibatch SGD for GAN 算法}
\begin{algorithmic}
\REQUIRE $iter, k, m$
\ENSURE $\theta_d, \theta_g$
\FOR{$i = 1, 2, ..., iter$}
    \FOR{$j = 1, 2, ..., k$}
        \STATE Sample minibatch of $m$ noise samples $\{z^{\left(1\right)}, ..., z^{\left(m\right)}\}$ from $p_g \left(\boldsymbol{z}\right)$
        \STATE Sample minibatch of $m$ examples $\{x^{\left(1\right)}, ..., x^{\left(m\right)}\}$ from $p_{data} \left(\boldsymbol{z}\right)$
        \STATE $\theta_d \gets \theta_d \textcolor{red}{+} \nabla_{\theta_d} \dfrac{1}{m} \sum_{i=1}^{m}{\left[\log D \left(x^{\left(i\right)}\right) + \log \left(1 - D \left(G \left(z^{\left(i\right)}\right)\right)\right)\right]}$
    \ENDFOR
    \STATE Sample minibatch of $m$ noise samples $\{z^{\left(1\right)}, ..., z^{\left(m\right)}\}$ from $p_g \left(\boldsymbol{z}\right)$
    \STATE $\theta_g \gets \theta_g \textcolor{red}{-} \nabla_{\theta_g} \dfrac{1}{m} \sum_{i=1}^{m}{\log \left(1 - D \left(G \left(z^{\left(i\right)}\right)\right)\right)}$
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>在实际的训练过程中，我们通常不会直接训练 <code>$G$</code> <strong>最小化</strong> <code>$\log \left(1 - D \left(G \left(\boldsymbol{z}\right)\right)\right)$</code>，因为其在学习过程中的早起处于饱和状态，因此我们通常会通过<strong>最大化</strong> <code>$\log \left(D \left(G \left(z\right)\right)\right)$</code>。</p>

<h2 id="存在的问题">存在的问题</h2>

<p>针对 GAN，包括 Goodfellow 自己在内也提出了其中包含的很多问题 <sup class="footnote-ref" id="fnref:goodfellow2016nips"><a href="#fn:goodfellow2016nips">2</a></sup>，因此后人也提出了大量的改进，衍生出了大量的 GAN 变种。本章节仅对原始的 GAN 中存在的问题进行简略介绍，相关的改进请参见后续的具体改进算法。</p>

<h3 id="js-散度问题">JS 散度问题</h3>

<p>我们在训练判别器的时候，其目标是最大化 JS 散度，但 JS 散度真的能够很好的帮助我们训练判别器吗？ Wasserstein GAN 一文 <sup class="footnote-ref" id="fnref:arjovsky2017wasserstein"><a href="#fn:arjovsky2017wasserstein">5</a></sup>给出了不同生成器情况下 JS 散度的变化情况。</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/different-generator-jsd.png" alt="" /></p>

<p>上图中，左边为一个基于 MLP 的生成器，右边为一个 DCGAN <sup class="footnote-ref" id="fnref:radford2015unsupervised"><a href="#fn:radford2015unsupervised">6</a></sup> 生成器，两者均有一个 DCGAN 的判别器。根据上文我们可以知道判别器的目标是最大化</p>

<p><code>$$
\begin{equation}
\begin{split}
L \left(D, \theta_g\right) &amp;= \mathbb{E}_{\boldsymbol{x} \sim p_{data}{\left(\boldsymbol{x}\right)}}{\left[\log D_{G}^{*}\left(\boldsymbol{x}\right)\right]} + \mathbb{E}_{\boldsymbol{x} \sim p_g\left(\boldsymbol{x}\right)}{\left[\log \left(1 - D_{G}^{*}\left(\boldsymbol{x}\right)\right)\right]} \\
&amp;= 2 JS \left(p_{data} \left(\boldsymbol{x}\right) \Vert p_g \left(\boldsymbol{x}\right) \right) - 2 \log 2
\end{split}
\end{equation}
$$</code></p>

<p>上图中 Y 轴绘制的为 <code>$\dfrac{1}{2} L \left(D, \theta_g\right) + \log 2$</code>，因为 <code>$-2 \log 2 \leq L \left(D, \theta_g\right) \leq 0$</code>，因此我们可得 <code>$0 \leq \dfrac{1}{2} L \left(D, \theta_g\right) + \log 2 \leq \log 2$</code>。从图中我们可以看出，针对两种不同的情况，其值均很快的逼近最大值 <code>$\log 2 \approx 0.69$</code>，当接近最大值的时候，判别器将具有接近于零的损失，此时我们可以发现，尽管 JS 散度很快趋于饱和，但 DCGAN 生成器的效果却仍在不断的变好，因此，使用 JS 散度作为判别其的目标就显得不是很合适。</p>

<h3 id="多样性问题-mode-collapse">多样性问题 Mode Collapse</h3>

<p>Mode Collapse 问题是指生成器更多的是生成了大量相同模式的数据，导致的结果就是生成的数据缺乏多样性，如下图所示 <sup class="footnote-ref" id="fnref:mlds-gan-basic-idea"><a href="#fn:mlds-gan-basic-idea">7</a></sup>:</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/mode-collapse-demo.png" alt="" /></p>

<p>不难看出，其中红色方框圈出来的图像十分相似，这样的问题我们就称之为 Mode Collapse。Goolfellow 曾经从不同的 KL 散度的角度解释引起 Mode Collapse 的问题，但最后发现其并非由散度的不同所导致。对于 KL 散度，其并非是对称的，即 <code>$D_{KL} \left(p_{data} \Vert p_{model}\right)$</code> 与 <code>$D_{KL} \left(p_{model} \Vert p_{data}\right)$</code> 是不同的。在最大化似然估计的时候使用的是前者，而在最小化 JS 散度的时候使用的更类似于后者。如下图所示</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/difference-of-kl-distributation.svg" alt="" /></p>

<p>假设我们的模型 <code>$q$</code> 并没有足够能能力去拟合真实数据分布 <code>$p$</code>，假设真实数据由两个二维的高斯分布构成，而模型需要使用一个一维的高斯分布去拟合。在左图中，模型更倾向于覆盖两个高斯分布，也就是说其更倾向与在有真实数据的地方得到更大的概率。在右图中，模型更倾向于覆盖其中一个高斯分布，也就是说其更倾向于在没有真实数据的地方取得更小的概率。这样，如果我们用 JS 散度训练模型的时候就容易出现模式缺失的问题，但尽管我们利用前者去优化模型，但结果中仍然出现了 Mode Collapse 的问题，这也就说明并非 JS 散度问题导致的 Mode Collapse。</p>

<p>针对 Mode Collapse 的问题，出现了大量不同角度的优化</p>

<ul>
<li>基于正则化的优化 <sup class="footnote-ref" id="fnref:che2016mode"><a href="#fn:che2016mode">8</a></sup></li>
<li>基于 Minibatch 的优化 <sup class="footnote-ref" id="fnref:salimans2016improved"><a href="#fn:salimans2016improved">9</a></sup></li>
<li>基于 Unrolled Optimization 的优化 <sup class="footnote-ref" id="fnref:metz2016unrolled"><a href="#fn:metz2016unrolled">10</a></sup></li>
<li>基于集成算法的优化 <sup class="footnote-ref" id="fnref:tolstikhin2017adagan"><a href="#fn:tolstikhin2017adagan">11</a></sup></li>
</ul>

<h2 id="mnist-示例">MNIST 示例</h2>

<p>我们利用 MNIST 数据集测试原始的 GAN 模型的效果，代码主要参考了 <a href="https://github.com/eriklindernoren/Keras-GAN" rel="noreferrer" target="_blank"><code>Keras-GAN</code></a>，最终实现代码详见 <a href="https://github.com/leovan/leovan.me/tree/master/scripts/cn/2018-02-03-gan-introduction/image_gan_keras.py" rel="noreferrer" target="_blank"><code>image_gan_keras.py</code></a>，我们简单对其核心部分进行说明。</p>

<ul>
<li><p>生成器</p>

<pre><code class="language-python">def build_generator(self):
  model = Sequential()
  
  model.add(Dense(int(self._hidden_dim / 4),
                      input_shape=self._noise_shape))
  model.add(LeakyReLU(alpha=0.2))
  model.add(BatchNormalization(momentum=0.8))
  model.add(Dense(int(self._hidden_dim / 2)))
  model.add(LeakyReLU(alpha=0.2))
  model.add(BatchNormalization(momentum=0.8))
  model.add(Dense(self._hidden_dim))
  model.add(LeakyReLU(alpha=0.2))
  model.add(BatchNormalization(momentum=0.8))
  model.add(Dense(np.prod(self._input_shape), activation='tanh'))
  model.add(Reshape(self._input_shape))
  
  print('Generator Summary: ')
  model.summary()
  
  noise = Input(shape=self._noise_shape)
  image = model(noise)
      
  return Model(noise, image)
</code></pre></li>
</ul>

<p>在生成器中，我们使用了一个包含3个隐含层的全链接网络，其中 <code>self._hidden_dim</code> 是我们定义的隐含节点最多一层的节点数；<code>self._noise_shape</code> 为用于生成器的噪音数据的形状；<code>self._input_shape</code> 为输入数据形状，即图片数据的形状，中间层次采用的激活函数为 <code>LeakyReLU</code>，最后一层采用的激活函数为 <code>tanh</code>。</p>

<ul>
<li><p>判别器</p>

<pre><code class="language-python">def build_discriminator(self):
  model = Sequential()
  
  model.add(Flatten(input_shape=self._input_shape))
  model.add(Dense(int(self._hidden_dim / 2)))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(int(self._hidden_dim / 4)))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(1, activation='sigmoid'))
  
  print('Discriminator Summary: ')
  model.summary()
  
  image = Input(shape=self._input_shape)
  label = model(image)
      
  return Model(image, label)
</code></pre></li>
</ul>

<p>在判别器中，我们使用了一个包含2个隐含层的全链接网络，中间层次采用的激活函数为 <code>LeakyReLU</code>，最后一层采用的激活函数为 <code>sigmoid</code>。</p>

<ul>
<li><p>对抗网络</p>

<pre><code class="language-python">class ImageBasicGAN():
  def __init__(self, width, height, channels,
               a_optimizer=Adam(1e-4, beta_1=0.5),
               g_optimizer=Adam(1e-4, beta_1=0.5),
               d_optimizer=Adam(1e-4, beta_1=0.5),
               noise_dim=100, hidden_dim=1024):
      '''
  
      Args:
          width: 图像宽度
          height: 图像高度
          channels: 图像颜色通道数
          a_optimizer: 对抗网络优化器
          g_optimizer: 生成器优化器
          d_optimizer: 判别器优化器
          noise_dim: 噪音数据维度
          hidden_dim: 隐含层最大维度
      '''
          
      # 省略一大坨代码
  
      # 构建和编译判别器
      self._discriminator = self.build_discriminator()
      self._discriminator.compile(loss='binary_crossentropy',
                                  optimizer=d_optimizer,
                                  metrics=['accuracy'])
  
      # 构建和编译生成器
      self._generator = self.build_generator()
      self._generator.compile(loss='binary_crossentropy',
                              optimizer=g_optimizer)
  
      # 生成器利用噪声数据作为输入
      noise = Input(shape=self._noise_shape)
      generated_image = self._generator(noise)
  
      # 当训练整个对抗网络时，仅训练生成器
      self._discriminator.trainable = False
  
      # 判别器将生成的图像作为输入
      label = self._discriminator(generated_image)
  
      # 构建和编译整个对抗网络
      self._adversarial = Model(noise, label)
      self._adversarial.compile(loss='binary_crossentropy',
                                optimizer=a_optimizer)
</code></pre></li>
</ul>

<p>在构造整个对抗网络的时候，需要注意我们训练完判别器后，通过训练整个对抗网络进而训练生成器的时候是固定住训练好的判别器的，因此在训练整个对抗网络的时候我们应该将判别器置为无需训练的状态。</p>

<ul>
<li><p>训练过程</p>

<pre><code class="language-python">def train(self, x_train, output_dir, iters,
        batch_size=32, k=1, save_interval=200):
  ''' 训练模型
  
  Args:
      x_train: 训练数据
      output_dir: 相关输出路径
      iters: 迭代次数
      batch_size: 批大小
      k: K
      save_interval: 结果保存间隔
  '''
      
  # 省略一大坨代码
  
  for iter in range(iters):
      # 训练判别器
      for _ in range(k):
          train_indices = np.random.randint(0, x_train.shape[0],
                                            batch_size)
          train_images = x_train[train_indices]
  
          noises = np.random.normal(0, 1, (batch_size, self._noise_dim))
          generated_images = self._generator.predict(noises)
  
          self._discriminator.train_on_batch(train_images,
                                             np.ones((batch_size, 1)))
          self._discriminator.train_on_batch(generated_images,
                                             np.zeros((batch_size, 1)))
              
      # 训练生成器
      noises = np.random.normal(0, 1, (batch_size, self._noise_dim))
      labels = np.ones(batch_size)
  
      self._adversarial.train_on_batch(noises, labels)
  
  # 再省略一大坨代码
</code></pre></li>
</ul>

<p>在训练整个对抗网络的时候，我们对于一个给定的生成器，我们将生成器生成的数据作为负样本，将从真实数据中采样的数据作为正样本训练判别器。Goodfellow 在描述 GAN 训练的过程中，对于给定的生成器，训练判别器 <code>$k$</code> 次，不过通常取 <code>$k = 1$</code>。训练好判别器后，再随机生成噪音数据用于训练生成器，周而复始直至达到最大迭代次数。</p>

<p>在整个训练过程中，我们分别记录了判别器和生成器的损失的变化，以及判别器的准确率的变化，如下图所示：</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/mnist-gan-keras-train-history.png" alt="" /></p>

<p>从上图中我们可以看出，在训练开始阶段，判别器能够相对容易的识别出哪些数据是来自于真实数据的采样，哪些数据是来自于生成器的伪造数据。随着训练的不断进行，判别器的准确率逐渐下降，并稳定在 60% 左右，也就是说生成器伪造的数据越来越像真实的数据，判别器越来越难进行甄别。</p>

<p>下图中我们展示了利用 MNIST 数据集，进行 30000 次的迭代，每 1000 次截取 100 张生成器利用相同噪音数据伪造的图像，最后合成的一张生成图片的变化动图。</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/mnist-gan-generated-images.gif" alt="" /></p>

<h1 id="deep-convolutional-gan">Deep Convolutional GAN</h1>

<p>DCGAN (Deep Convolutional GAN) 是由 Radford <sup class="footnote-ref" id="fnref:radford2015unsupervised"><a href="#fn:radford2015unsupervised">6</a></sup> 等人提出的一种对原始 GAN 的变种，其基本的思想就是将原始 GAN 中的全链接层用卷积神经网络代替。在文中，Radford 等人给出构建一个稳定的 DCGAN 的建议，如下：</p>

<ul>
<li>在网络中不使用 pooling 层，而是使用多步长的卷积层 (判别器) 和多步长的反卷积层 (生成器)。</li>
<li>在生成器和判别器中均使用批标准化。</li>
<li>对于深层的框架，去掉全链接层。</li>
<li>在生成器中使用 ReLU 激活函数，最后一层使用 Tanh 激活函数。</li>
<li>在判别器中使用 LeakyReLU 激活函数。</li>
</ul>

<p>我们利用 MNIST 数据集测试 DCGAN 模型的效果，最终实现代码详见 <a href="https://github.com/leovan/leovan.me/tree/master/scripts/cn/2018-02-03-gan-introduction/image_dcgan_keras.py" rel="noreferrer" target="_blank"><code>image_dcgan_keras.py</code></a>。训练过程中判别器和生成器的损失的变化，以及判别器的准确率的变化，如下图所示：</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/mnist-dcgan-keras-train-history.png" alt="" /></p>

<p>下图中我们展示了利用 MNIST 数据集，进行 30000 次的迭代，每 1000 次截取 100 张生成器利用相同噪音数据伪造的图像，最后合成的一张生成图片的变化动图。</p>

<p><img src="/images/cn/2018-02-03-gan-introduction/mnist-dcgan-generated-images.gif" alt="" /></p>

<p>从生成的结果中可以看出，DCGAN 生成的图片的质量还是优于原始的 GAN 的，在原始的 GAN 中我们能够明显的看出其中仍旧包含大量的噪音点，而在 DCGAN 中这种情况几乎不存在了。</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:goodfellow2014generative">Goodfellow, Ian, et al. &ldquo;Generative adversarial nets.&rdquo; <em>Advances in neural information processing systems</em>. 2014.
 <a class="footnote-return" href="#fnref:goodfellow2014generative">↩</a></li>
<li id="fn:goodfellow2016nips">Goodfellow, Ian. &ldquo;NIPS 2016 tutorial: Generative adversarial networks.&rdquo; <em>arXiv preprint arXiv:1701.00160</em> (2016).
 <a class="footnote-return" href="#fnref:goodfellow2016nips">↩</a></li>
<li id="fn:kl-divergence"><a href="https://en.wikipedia.org/wiki/Kullback–Leibler_divergence" rel="noreferrer" target="_blank">https://en.wikipedia.org/wiki/Kullback–Leibler_divergence</a>
 <a class="footnote-return" href="#fnref:kl-divergence">↩</a></li>
<li id="fn:jsd-divergence"><a href="https://en.wikipedia.org/wiki/Jensen–Shannon_divergence" rel="noreferrer" target="_blank">https://en.wikipedia.org/wiki/Jensen–Shannon_divergence</a>
 <a class="footnote-return" href="#fnref:jsd-divergence">↩</a></li>
<li id="fn:arjovsky2017wasserstein">Arjovsky, Martin, Soumith Chintala, and Léon Bottou. &ldquo;Wasserstein gan.&rdquo; <em>arXiv preprint arXiv:1701.07875</em> (2017).
 <a class="footnote-return" href="#fnref:arjovsky2017wasserstein">↩</a></li>
<li id="fn:radford2015unsupervised">Radford, Alec, Luke Metz, and Soumith Chintala. &ldquo;Unsupervised representation learning with deep convolutional generative adversarial networks.&rdquo; <em>arXiv preprint arXiv:1511.06434</em> (2015).
 <a class="footnote-return" href="#fnref:radford2015unsupervised">↩</a></li>
<li id="fn:mlds-gan-basic-idea"><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2017/Lecture/GAN%20(v11).pdf" rel="noreferrer" target="_blank">http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2017/Lecture/GAN%20(v11).pdf</a>
 <a class="footnote-return" href="#fnref:mlds-gan-basic-idea">↩</a></li>
<li id="fn:che2016mode">Che, Tong, et al. &ldquo;Mode regularized generative adversarial networks.&rdquo; <em>arXiv preprint arXiv:1612.02136</em> (2016).
 <a class="footnote-return" href="#fnref:che2016mode">↩</a></li>
<li id="fn:salimans2016improved">Salimans, Tim, et al. &ldquo;Improved techniques for training gans.&rdquo; <em>Advances in Neural Information Processing Systems.</em> 2016.
 <a class="footnote-return" href="#fnref:salimans2016improved">↩</a></li>
<li id="fn:metz2016unrolled">Metz, Luke, et al. &ldquo;Unrolled generative adversarial networks.&rdquo; <em>arXiv preprint arXiv:1611.02163</em> (2016).
 <a class="footnote-return" href="#fnref:metz2016unrolled">↩</a></li>
<li id="fn:tolstikhin2017adagan">Tolstikhin, Ilya O., et al. &ldquo;Adagan: Boosting generative models.&rdquo; <em>Advances in Neural Information Processing Systems.</em> 2017.
 <a class="footnote-return" href="#fnref:tolstikhin2017adagan">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>Ising 模型，Hopfield 网络和受限的玻尔兹曼机 (Ising, Hopfield and RBM)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2018/01/ising-hopfield-and-rbm/</link>
      <pubDate>Wed, 17 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2018/01/ising-hopfield-and-rbm/</guid>
      <description>
        <![CDATA[
        

<p><code>$\renewcommand{\sign}{\operatorname{sign}}$</code></p>

<h2 id="ising-模型">Ising 模型</h2>

<p><a href="https://zh.wikipedia.org/zh/易辛模型" rel="noreferrer" target="_blank">Ising 模型</a>最早是由物理学家威廉·冷次在 1920 年发明的，他把该模型当成是一个给他学生恩斯特·易辛的问题。易辛在他一篇 1924 年的论文 <sup class="footnote-ref" id="fnref:ising1924contribution"><a href="#fn:ising1924contribution">1</a></sup> 中求得了一维易辛模型的解析解，并且证明它不会产生相变。 二维方晶格易辛模型相对于一维的难出许多，因此其解析的描述在一段时间之后才在 1943 年由拉斯·昂萨格给出 <sup class="footnote-ref" id="fnref:onsager1944a"><a href="#fn:onsager1944a">2</a></sup>。</p>

<p>Ising 模型假设铁磁物质是由一堆规则排列的小磁针构成，每个磁针只有上下两个方向。相邻的小磁针之间通过能量约束发生相互作用，同时受到环境热噪声的干扰而发生磁性的随机转变。涨落的大小由关键的温度参数决定，温度越高，随机涨落干扰越强，小磁针越容易发生无序而剧烈地状态转变，从而让上下两个方向的磁性相互抵消，整个系统消失磁性，如果温度很低，则小磁针相对宁静，系统处于能量约束高的状态，大量的小磁针方向一致，铁磁系统展现出磁性。而当系统处于临界温度 <code>$T_C$</code> 时，Ising 模型表现出一系列幂律行为和自相似现象 <sup class="footnote-ref" id="fnref:ising-model"><a href="#fn:ising-model">3</a></sup>。</p>

<p>由于 Ising 模型的高度抽象，可以很容易地将它应用到其他领域之中。例如，将每个小磁针比喻为某个村落中的村民，而将小磁针上下的两种状态比喻成个体所具备的两种政治观点，相邻小磁针之间的相互作用比喻成村民之间观点的影响，环境的温度比喻成每个村民对自己意见不坚持的程度，这样 Ising 模型就可以建模该村落中不同政治见解的动态演化。在社会科学中，人们已经将 Ising 模型应用于股票市场、种族隔离、政治选择等不同的问题。另一方面，如果将小磁针比喻成神经元细胞，向上向下的状态比喻成神经元的激活与抑制，小磁针的相互作用比喻成神经元之间的信号传导，那么，Ising 模型的变种还可以用来建模神经网络系统，从而搭建可适应环境、不断学习的机器，例如 Hopfield 网络或 Boltzmann 机。</p>

<p>考虑一个二维的情况</p>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/ising-model.svg" alt="" /></p>

<p>如图所示，每个节点都有两种状态 <code>$s_i \in \{+1, -1\}$</code>，则我们可以定义这个系统的能量为</p>

<p><code>$$
E = -H \sum_{i=1}^{N}{s_i} - J \sum_{&lt;i, j&gt;}{s_i s_j}
$$</code></p>

<p>其中 <code>$H$</code> 为外界磁场的强度，<code>$J$</code> 为能量耦合常数，<code>$\sum_{&lt;i, j&gt;}$</code>表示对于相邻的两个节点的函数值求和。因此，可以得出</p>

<ol>
<li>当每个节点的方向同外部磁场一致时，系统能量越小；反之系统能量越大。</li>
<li>对于 <code>$J &gt; 0$</code>，当相邻的节点方向相同时，系统能量越小；反之系统能量越大。</li>
</ol>

<p>对于整个系统的演变，除了系统的总能量以外，还受到节点所处环境的热噪声影响。我们利用温度 <code>$T$</code> 表示环境对节点的影响，当 <code>$T$</code> 越高时，节点状态发生变化的可能性越大。此时，则有两种力量作用在每个节点上</p>

<ol>
<li>节点邻居和外部磁场的影响，这种影响使得当前节点尽可能的同其邻居和外部磁场保持一致，即尽可能是系统的总能量达到最小。</li>
<li>环境的影响，这种影响使得每个节点的状态以一定的概率发生随机变化。</li>
</ol>

<p>不难想像，当 <code>$T = 0$</code> 时，节点状态完全受其邻居和外部磁场影响，当 <code>$J = 0, H = 0$</code> 时，节点处于完全的随机状态。</p>

<p>对于 Ising 模型，我们利用蒙特卡罗方法进行模拟。初始化系统状态为 <code>$s_i^{\left(0\right)}$</code>，对于任意时刻 <code>$t$</code>，对其状态 <code>$s_i^{\left(t\right)}$</code>进行一个改变，将其中一个节点变为相反的状态，得到新的状态 <code>$s'_i$</code></p>

<p><code>$$
s_i^{\left(t+1\right)} =
\begin{cases}
    s'_i &amp; \text{with probablity of } \mu \\
    s_i^{\left(t\right)} &amp; \text{with probablity of } 1-\mu
\end{cases}
$$</code></p>

<p>其中 <code>$\mu = \min\left\lbrace\dfrac{e^{E\left(s_i^{\left(t\right)}\right) - E\left(s'_i\right)}}{kT}, 1\right\rbrace$</code> 表示接受转移的概率；<code>$k \approx 1.38 \times 10^{23}$</code> 为玻尔兹曼常数。我们利用蒙特卡罗方法对其进行模拟 <code>$T = 4J/k$</code>的情况，我们分别保留第 <code>$0, 1, 5, 50, 500, 5000$</code> 步的模拟结果</p>

<pre><code class="language-r"># 每一轮状态转移
each_round &lt;- function(current_matrix, ising_config) {
    n_row &lt;- nrow(current_matrix)
    n_col &lt;- ncol(current_matrix)
    
    for (i in 1:n_row) {
        for (j in 1:n_col) {
            current_row &lt;- sample(1:n_row, 1)
            current_col &lt;- sample(1:n_col, 1)
            s &lt;- current_matrix[current_row, current_col]
            e &lt;- -(current_matrix[(current_row-1-1)%%n_row+1, current_col] +
                current_matrix[current_row, (current_col-1-1)%%n_col+1] +
                current_matrix[(current_row+1)%%n_row, current_col] +
                current_matrix[current_row, (current_col+1)%%n_col]) *
                s * ising_config$j
            mu &lt;- min(exp((e + e) / (ising_config$k * ising_config$t)), 1)
            mu_random &lt;- runif(1)
            
            if (mu_random &lt; mu) {
                s &lt;- -1 * s
            }
            
            current_matrix[current_row, current_col] &lt;- s
        }
    }
    
    current_matrix
}

# Ising 模拟
ising_simulation &lt;- function(N, iter, ising_config, saved_steps) {
    set.seed(112358)
    current_matrix &lt;- matrix(sample(0:1, N^2, replace = T), N, N)*2-1
    saved_matrix &lt;- list()
    
    if (0 %in% saved_steps) {
        saved_matrix &lt;- c(saved_matrix, list(current_matrix))
    }
    
    for (i in 1:iter) {
        if (i %in% saved_steps) {
            saved_matrix &lt;- c(saved_matrix, list(current_matrix))
        }
        
        current_matrix &lt;- each_round(current_matrix, ising_config)
        
        if (i %% 1000 == 0) {
            cat(paste0(&quot;Steps: &quot;, i, '\n'))
        }
    }
    
    saved_matrix
}

# T = 4J/K，方便模拟取 j = 1, k = 1, t = 4
ising_config &lt;- list(j = 1, k = 1, t = 4)
diff_steps_matrix &lt;- ising_simulation(100, 5000, ising_config,
                                      c(0, 1, 5, 50, 500, 5000))
</code></pre>

<p>模拟结果可视化效果如图所示</p>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/ising-different-steps.png" alt="" /></p>

<p>对于二维的 Ising 模型，存在一个相变点，在相变点上的温度 <code>$T_c$</code> 满足</p>

<p><code>$$
\sinh\left(\dfrac{2J_1}{kT_c}\right) \sinh\left(\dfrac{2J_2}{kT_c}\right) = 1
$$</code></p>

<p>若 <code>$J_1 = J_2$</code>，则</p>

<p><code>$$
T_c = \dfrac{2J}{k \ln\left(1 + \sqrt{2}\right)} \approx 2.27 \dfrac{J}{k}
$$</code></p>

<p>称之为临界温度。当温度小于临界值的时候，Ising 模型中大多数节点状态相同，系统处于较为秩序的状态。当温度大于临界值的时候，大多数节点的状态较为混乱，系统处于随机的状态。而当温度接近临界的时候，系统的运行介于随机与秩序之间，也就是进入了混沌的边缘地带，这种状态称为临界状态。</p>

<p>我们模拟不同温度下，系统在运行 <code>$50$</code> 步时的状态</p>

<pre><code class="language-r">ising_config_t &lt;- c(1, 2, 2.27, 2.5, 3, 6)
diff_t_matrix &lt;- lapply(ising_config_t, function(t) {
    ising_config &lt;- list(j = 1, k = 1, t = t)
    ising_simulation(100, 50, ising_config, c(50))
})
</code></pre>

<p>模拟结果可视化效果如图所示</p>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/ising-different-t.png" alt="" /></p>

<h2 id="hopfield-神经网络">Hopfield 神经网络</h2>

<p>Hopfield 神经网络 <sup class="footnote-ref" id="fnref:hopfield1987neural"><a href="#fn:hopfield1987neural">4</a></sup> 是一种基于能量的反馈人工神经网络。Hopfield 神经网络分为离散型 (Discrete Hopfield Neural Network, DHNN) 和 连续性 (Continues Hopfield Neural Network, CHNN)。</p>

<h3 id="离散型-hopfield-神经网络">离散型 Hopfield 神经网络</h3>

<h4 id="网络结构">网络结构</h4>

<p>对于离散型 Hopfield 神经网络，其网络结果如下</p>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/hopfield-network.png" alt="" /></p>

<p>对于具有 <code>$n$</code> 个神经元的网络，我们设 <code>$t$</code> 时刻的网络状态为 <code>$\boldsymbol{X}^{\left(t\right)} = \left(x_1^{\left(t\right)}, x_2^{\left(t\right)}, ..., x_n^{\left(t\right)}\right)^T$</code>，对于 <code>$t+1$</code> 时刻网络的状态</p>

<p><code>$$
x_i^{\left(t+1\right)} = f \left(net_i\right)
$$</code></p>

<p>其中，DHNN 中 <code>$f$</code> 多为符号函数，即</p>

<p><code>$$
x_i = \sign \left(net_i\right) = \begin{cases}
1, net_i \geq 0 \\
-1, net_i &lt; 0
\end{cases}
$$</code></p>

<p><code>$net_i$</code> 为一个节点的输入，为</p>

<p><code>$$
net_i = \sum_{j=1}^{n}{\left(w_{ij}x_j - T_i\right)}
$$</code></p>

<p>其中 <code>$T_i$</code> 为每个神经元的阈值，对于 DHNN，一般有 <code>$w_{ii} = 0, w_{ij} = w_{ji}$</code>，当反馈网络稳定后，稳定后的状态即为网络的输出。网络的更新主要有两种状态，<strong>异步方式</strong>和<strong>同步方式</strong>。</p>

<p>对于异步方式的更新方法，每一次仅改变一个神经元 <code>$j$</code> 的状态，即</p>

<p><code>$$
x_i^{\left(t+1\right)} = \begin{cases}
\sign\left(net_i^{\left(t\right)}\right), i = j \\
x_i^{\left(t\right)}, i \neq j
\end{cases}
$$</code></p>

<p>对于同步方式的更新方法，每一次需改变所有神经元的状态，即</p>

<p><code>$$
x_i^{\left(t+1\right)} = \sign\left(net_i^{\left(t\right)}\right)
$$</code></p>

<h4 id="网络稳定性">网络稳定性</h4>

<p>我们可以将反馈网络看做一个非线性动力学系统，因此这个系统最后可能会收敛到一个稳态，或在有限状态之间振荡，亦或是状态为无穷多个即混沌现象。对于 DHNN 因为其网络状态是有限的，因此不会出现混沌的现象。若一个反馈网络达到一个稳态状态 <code>$\boldsymbol{X}$</code> 时，即 <code>$\boldsymbol{X}^{\left(t+1\right)} = \boldsymbol{X}^{\left(t\right)}$</code> ，则称这个状态为一个吸引子。在 Hopfield 网络结构和权重确定的情况下，其具有 <code>$M$</code> 个吸引子，因此我们可以认为这个网络具有存储 <code>$M$</code> 个记忆的能力。</p>

<p>设 <code>$\boldsymbol{X}$</code> 为网络的一个吸引子，权重矩阵 <code>$\boldsymbol{W}$</code> 是一个对称阵，则定义 <code>$t$</code> 时刻网络的能量函数为</p>

<p><code>$$
E\left(t\right) = -\dfrac{1}{2} \boldsymbol{X}^{\left(t\right)T} \boldsymbol{W} \boldsymbol{X}^{\left(t\right)} + \boldsymbol{X}^{\left(t\right)T} \boldsymbol{T}
$$</code></p>

<p>则定义网络能量的变化量</p>

<p><code>$$
\Delta E\left(t\right) = E\left(t+1\right) - E\left(t\right)
$$</code></p>

<p>则以<strong>异步更新</strong>方式，不难推导得出</p>

<p><code>$$
\begin{equation}
\begin{split}
\Delta E\left(t\right) = -\Delta x_i^{\left(t\right)} \left(\sum_{j=1}^{n}{\left(w_{ij}x_j - T_j\right)}\right) - \dfrac{1}{2} \Delta x_i^{\left(t\right)2} w_{ii}
\end{split}
\end{equation}
$$</code></p>

<p>由于网络中的神经元不存在自反馈，即 <code>$w_{ii} = 0$</code>，则上式可以化简为</p>

<p><code>$$
\Delta E\left(t\right) = -\Delta x_i^{\left(t\right)} net_i^{\left(t\right)}
$$</code></p>

<p>因此，对于如上的能量变化，可分为 3 中情况：</p>

<ol>
<li>当 <code>$x_i^{\left(t\right)} = -1, x_i^{\left(t+1\right)} = 1$</code> 时，<code>$\Delta x_i^{\left(t\right)} = 2, net_i^{\left(t\right)} \geq 0$</code>，则可得 <code>$\Delta E \left(t\right) \leq 0$</code>。</li>
<li>当 <code>$x_i^{\left(t\right)} = 1, x_i^{\left(t+1\right)} = -1$</code> 时，<code>$\Delta x_i^{\left(t\right)} = -2, net_i^{\left(t\right)} &lt; 0$</code>，则可得 <code>$\Delta E \left(t\right) &lt; 0$</code>。</li>
<li>当 <code>$x_i^{\left(t\right)} = x_i^{\left(t+1\right)}$</code> 时，<code>$\Delta x_i^{\left(t\right)} = 0$</code>，则可得 <code>$\Delta E \left(t\right) = 0$</code>。</li>
</ol>

<p>则对于任何情况，<code>$\Delta E \left(t\right) \leq 0$</code>，也就是说在网络不断变化的过程中，网络的总能量是一直下降或保持不变的，因此网络的能量最终会收敛到一个常数。</p>

<p>设 <code>$\boldsymbol{X}'$</code> 为吸引子，对于异步更新方式，若<strong>存在</strong>一个变换顺序，使得网络可以从状态 <code>$\boldsymbol{X}$</code> 转移到 <code>$\boldsymbol{X}'$</code>，则称 <code>$\boldsymbol{X}$</code> 弱吸引到 <code>$\boldsymbol{X}'$</code>，这些 <code>$\boldsymbol{X}$</code> 的集合称之为 <code>$\boldsymbol{X}$</code> 的弱吸引域；若对于<strong>任意</strong>变换顺序，都能够使得网络可以从状态 <code>$\boldsymbol{X}$</code> 转移到 <code>$\boldsymbol{X}'$</code>，则称 <code>$\boldsymbol{X}$</code> 强吸引到 <code>$\boldsymbol{X}'$</code>，对于这些 <code>$\boldsymbol{X}$</code> 称之为 <code>$\boldsymbol{X}$</code> 的强吸引域。</p>

<p>对于 Hopfield 网络的权重，我们利用 Hebbian 规则进行设计。Hebbian 规则认为如果两个神经元同步激发，则它们之间的权重增加；如果单独激发，则权重减少。则对于给定的 <code>$p$</code> 个模式样本 <code>$\boldsymbol{X}^k, k = 1, 2, ..., p$</code>，其中 <code>$x \in \{-1, 1\}^n$</code> 且样本之间两两正交，则权重计算公式为</p>

<p><code>$$
w_{ij} = \dfrac{1}{n} \sum_{k=1}^{p}{x_i^k x_j^k}
$$</code></p>

<p>则对于给定的样本 <code>$\boldsymbol{X}$</code> 确定为网络的吸引子，但对于有些非给定的样本也可能是网络的吸引子，这些吸引子称之为伪吸引子。以上权重的计算是基于两两正交的样本得到的，但真实情况下很难保证样本两两正交，对于非正交的模式，网络的存储能力则会大大下降。根据 Abu-Mostafa<sup class="footnote-ref" id="fnref:abu1985information"><a href="#fn:abu1985information">5</a></sup> 的研究表明，当模式的数量 <code>$p$</code> 大于 <code>$0.15 n$</code> 时，网络的推断就很可能出错，也就是结果会收敛到伪吸引子上。</p>

<h4 id="示例">示例</h4>

<p>我们通过一个手写数字识别的例子介绍一些 Hopfield 网络的功能，我们存在如下 10 个数字的图片，每张为像素 16*16 的二值化图片，其中背景色为白色，前景色为黑色 (每个图片的名称为 <code>num.png</code>，图片位于 <code>/images/cn/2018-01-17-ising-hopfield-and-rbm</code> 目录)。</p>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/digits.png" alt="" /></p>

<p>首先我们载入每张图片的数据</p>

<pre><code class="language-r">library(EBImage)

# 载入数据
digits &lt;- lapply(0:9, function(num) {
    readImage(paste0(num, '.png'))
})

# 转换图像为 16*16 的一维向量
# 将 (0, 1) 转换为 (-1, 1)
digits_patterns &lt;- lapply(digits, function(digit) {
    pixels &lt;- c(digit)
    pixels * 2 - 1
})
</code></pre>

<p>接下来利用这 10 个模式训练一个 Hopfield 网络</p>

<pre><code class="language-r">#' 训练 Hopfield 网络
#' 
#' @param n 网络节点个数
#' @param pattern_list 模式列表
#' @return 训练好的 Hopfield 网络
train_hopfield &lt;- function(n, pattern_list) {
    weights &lt;- matrix(rep(0, n*n), n, n)
    n_patterns &lt;- length(pattern_list)
    
    for (i in 1:n_patterns) {
        weights &lt;- weights + pattern_list[[i]] %o% pattern_list[[i]]
    }
    diag(weights) &lt;- 0
    weights &lt;- weights / n_patterns
    
    list(weights = weights, n = n)
}

# 训练 Hopfield 网络
digits_hopfield_network &lt;- train_hopfield(16*16, digits_patterns)
</code></pre>

<p>为了测试 Hopfiled 网络的记忆能力，我们利用 10 个模式生成一些测试数据，我们分别去掉图像的右边或下边的 5 个像素，生成新的 20 张测试图片</p>

<pre><code class="language-r"># 构造测试数据
digits_test_remove_right &lt;- lapply(0:9, function(num) {
    digit_test &lt;- digits[[num+1]]
    digit_test[12:16, ] &lt;- 1
    digit_test
})
digits_test_remove_bottom &lt;- lapply(0:9, function(num) {
    digit_test &lt;- digits[[num+1]]
    digit_test[, 12:16] &lt;- 1
    digit_test
})
digits_test &lt;- c(digits_test_remove_right, digits_test_remove_bottom)

# 转换图像为 16*16 的一维向量
# 将 (0, 1) 转换为 (-1, 1)
digits_test_patterns &lt;- lapply(digits_test, function(digit) {
    pixels &lt;- c(digit)
    pixels * 2 - 1
})
</code></pre>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/digits-test.png" alt="" /></p>

<p>我们利用训练好的 Hopfield 网络运行测试数据，我们迭代 300 次并保存最后的网络输出</p>

<pre><code class="language-r">#' 运行 Hopfiled 网络
#' @param hopfield_network 训练好的 Hopfield 网络
#' @param pattern 输入的模式
#' @param max_iter 最大迭代次数
#' @param save_history 是否保存状态变化历史
#' @return 最终的模式 (以及历史模式)
run_hopfield &lt;- function(hopfield_network, pattern,
                         max_iter = 100, save_history = T) {
    last_pattern &lt;- pattern
    history_patterns &lt;- list()
    
    for (iter in 1:max_iter) {
        current_pattern &lt;- last_pattern
        
        i &lt;- round(runif(1, 1, hopfield_network$n))
        net_i &lt;- hopfield_network$weights[i, ] %*% current_pattern
        current_pattern[i] &lt;- ifelse(net_i &lt; 0, -1, 1)
        
        if (save_history) {
            history_patterns[[iter]] &lt;- last_pattern
        }
        
        last_pattern &lt;- current_pattern
    }
    
    list(history_patterns = history_patterns,
         final_pattern = last_pattern)
}

# 运行 Hopfield 网络，获取测试数据结果
digits_test_results_patterns &lt;- lapply(digits_test_patterns,
                                       function(pattern) {
    run_hopfield(digits_hopfield_network, pattern, max_iter = 300)
})

# 转换测试数据结果为图片
digits_test_results &lt;- lapply(digits_test_results_patterns,
                              function(result) {
    each_dim &lt;- sqrt(digits_hopfield_network$n)
    Image((result$final_pattern + 1) / 2,
          dim = c(each_dim, each_dim),
          colormode = 'Grayscale')
})
</code></pre>

<p>网络变换过程中，图像的变换如图所示</p>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/digits-test-results.gif" alt="" /></p>

<p>最终网络的输出如图所示</p>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/digits-test-results.png" alt="" /></p>

<p>从结果中可以看出，部分测试图片还是得到了比较好的恢复，但如上文所说，由于我们给定的模式之间并不是两两正交的，因此，网络的推断就很可能出错 (例如：数字 5 恢复的结果更像 9 多一些)，甚至结果会收敛到伪吸引子上。</p>

<h3 id="连续型-hopfield-神经网络">连续型 Hopfield 神经网络</h3>

<h4 id="网络结构-1">网络结构</h4>

<p>连续型 Hopfield 网络相比于离散型 Hopfield 网络的主要差别在于：</p>

<ol>
<li>网络中所有的神经元随时间 <code>$t$</code> 同时更新，网络状态随时间连续变化。</li>
<li>神经元的状态转移函数为一个 S 型函数，例如
<code>$$
v_i = f\left(u_i\right) = \dfrac{1}{1 + e^{\dfrac{-2 u_i}{\gamma}}} = \dfrac{1}{2} \left(1 + \tanh \dfrac{u_i}{\gamma}\right)
$$</code>
其中，<code>$v_i$</code> 表示一个神经元的输出，<code>$u_i$</code> 表示一个神经元的输入。</li>
</ol>

<p>对于理想情况，网络的能量函数可以写为<sup class="footnote-ref" id="fnref:han-nn"><a href="#fn:han-nn">6</a></sup></p>

<p><code>$$
E = -\dfrac{1}{2} \sum_{i=1}^{n}{\sum_{j=1}^{n}{w_{ij} v_i v_j}} - \sum_{i=1}^{n} v_i I_i
$$</code></p>

<p>可以得出，随着网络的演变，网络的总能量是降低的，随着网络中节点的不断变化，网络最终收敛到一个稳定的状态。</p>

<h4 id="tsp-问题求解">TSP 问题求解</h4>

<p>旅行推销员问题 (Travelling salesman problem, TSP) 是指给定一系列城市和每对城市之间的距离，求解访问每一座城市一次并回到起始城市的最短路径 <sup class="footnote-ref" id="fnref:tsp"><a href="#fn:tsp">7</a></sup>。TSP 问题是一个 NP-hard 问题 <sup class="footnote-ref" id="fnref:np-hard"><a href="#fn:np-hard">8</a></sup>。</p>

<p>对于 TSP 问题，我们给定一个城市指之间的距离矩阵</p>

<p><code>$$
D = \left\lgroup
\begin{array}{cccc}
d_{11} &amp; d_{12} &amp; \cdots &amp; d_{1n} \\
d_{21} &amp; d_{22} &amp; \cdots &amp; d_{2n} \\
\vdots &amp; \vdots &amp;        &amp; \vdots \\
d_{n1} &amp; d_{n2} &amp; \cdots &amp; d_{nn}
\end{array}
\right\rgroup
$$</code></p>

<p>其中 <code>$d_{ij} = d_{ji}, i \neq j$</code> 表示城市 <code>$i$</code> 和城市 <code>$j$</code> 之间的距离，<code>$d_{ij} = 0, i = j$</code>。TSP 问题的优化目标是找到一条路径访问每一座城市一次并回到起始城市，我们利用一个矩阵表示访问城市的路径</p>

<p><code>$$
V = \left\lgroup
\begin{array}{cccc}
v_{11} &amp; v_{12} &amp; \cdots &amp; v_{1n} \\
v_{21} &amp; v_{22} &amp; \cdots &amp; v_{2n} \\
\vdots &amp; \vdots &amp;        &amp; \vdots \\
v_{n1} &amp; v_{n2} &amp; \cdots &amp; v_{nn}
\end{array}
\right\rgroup
$$</code></p>

<p>其中 <code>$v_{xi} = 1$</code> 表示第 <code>$i$</code> 次访问城市 <code>$x$</code>，因此对于矩阵 <code>$V$</code>，其每一行每一列仅有一个元素值为 <code>$1$</code>，其他元素值均为 <code>$0$</code>。</p>

<p>对于 TSP 问题，我们可以得到如下约束条件</p>

<ul>
<li>城市约束</li>
</ul>

<p>因为每个城市只能访问一次，因此对于第 <code>$x$</code> 行仅能有一个元素是 <code>$1$</code>，其他均为 <code>$0$</code>，即任意两个相邻元素的乘积为 <code>$0$</code></p>

<p><code>$$
\sum_{i=1}^{n-1}{\sum_{j=i+1}^{n}{v_{xi}v_{xj}}} = 0
$$</code></p>

<p>则对于城市约束，我们得到该约束对应的能量分量为</p>

<p><code>$$
E_1 = \dfrac{1}{2} A \sum_{x=1}^{n}{\sum_{i=1}^{n-1}{\sum_{j=i+1}^{n}{v_{xi}v_{xj}}}}
$$</code></p>

<ul>
<li>时间约束</li>
</ul>

<p>因为每一时刻仅能够访问一个城市，因此对于第 <code>$i$</code> 行仅能有一个元素是 <code>$1$</code>，其他均为 <code>$0$</code>，即任意两个相邻元素的乘积为 <code>$0$</code></p>

<p><code>$$
\sum_{x=1}^{n-1}{\sum_{y=x+1}^{n}{v_{xi}v_{yi}}} = 0
$$</code></p>

<p>则对于时间约束，我们得到该约束对应的能量分量为</p>

<p><code>$$
E_2 = \dfrac{1}{2} B \sum_{i=1}^{n}{\sum_{x=1}^{n-1}{\sum_{y=x+1}^{n}{v_{xi}v_{yi}}}}
$$</code></p>

<ul>
<li>有效性约束</li>
</ul>

<p>当矩阵 <code>$V$</code> 中所有的元素均为 <code>$0$</code> 的时候，可得 <code>$E_1 = 0, E_2 = 0$</code>，但显然这并不是一个有效的路径，因此我们需要保证矩阵 <code>$V$</code> 中元素值为 <code>$1$</code> 的个数为 <code>$n$</code>，即</p>

<p><code>$$
\sum_{x=1}^{n}{\sum_{i=1}^{n}{v_{xi}}} = n
$$</code></p>

<p>则对于有效性约束，我们得到该约束对应的能量分量为</p>

<p><code>$$
E_3 = \dfrac{1}{2} C \left(\sum_{x=1}^{n}{\sum_{i=1}^{n}{v_{xi}}} - n\right)^2
$$</code></p>

<ul>
<li>路径长度约束</li>
</ul>

<p>如上三个约束仅能够保证我们的路径是有效的，但并不一定是最优的。根绝 TSP 问题的优化目标，我们需要引入一个反映路径长度的能量分量，并保证该能量分量随着路径长度的减小而减小。访问两个城市 <code>$x, y$</code> 有两种形式，<code>$x \to y$</code> 或 <code>$y \to x$</code>，如果城市 <code>$x$</code> 和城市 <code>$y$</code> 在旅行中顺序相邻，则 <code>$v_{xi}v_{y,i+1} = 1, v_{xi}v_{y,i-1} = 0$</code>，反之亦然。则反映路径长度的能量分量可以定义为</p>

<p><code>$$
E_4 = \dfrac{1}{2} D \sum_{x=1}^{n}{\sum_{y=1}^{n}{\sum_{i=1}^{n}{d_{xy}\left(v_{xi}v_{y,i+1} + v_{xi}v_{y,i-1}\right)}}}
$$</code></p>

<p>综上所述，TSP 问题的能量函数定义为</p>

<p><code>$$
E = E_1 + E_2 + E_3 + E_4
$$</code></p>

<p>其中，<code>$A, B, C, D &gt; 0$</code> 分别为每个能量分量的权重。针对这样的能量函数，我们可得对应神经元 <code>$x_i$</code> 和 <code>$y_i$</code> 之间的权重为</p>

<p><code>$$
\begin{equation}
\begin{split}
w_{x_i, y_i} = &amp;-2A \delta_{xy} \left(1-\delta_{xy}\right) - 2B \delta_{ij} \left(1-\delta_{xy}\right) \\
&amp;- 2C -2D d_{xy} \left(\delta_{j, i+1} + \delta_{i, j+1}\right)
\end{split}
\end{equation}
$$</code></p>

<p>其中</p>

<p><code>$$
\delta_{xy} = \begin{cases}
1, x = y \\
0, x \neq y
\end{cases}
, 
\delta_{ij} = \begin{cases}
1, i = j \\
0, i \neq j
\end{cases}
$$</code></p>

<p>因此可以得到网络关于时间的导数</p>

<p><code>$$
\begin{equation}
\begin{split}
\dfrac{d u_{xi}}{d t} = &amp;-2A \sum_{j \neq i}^{n}{v_{xj}} - 2B \sum_{y \neq x}^{n}{v_{yi}} - 2C \left(\sum_{x=1}^{n}{\sum_{j=1}^{n}{v_{xj}}} - n\right) \\
&amp;- 2D \sum_{y \neq x}^{n}{d_{xy}\left(v_{y, i+1} + v_{y, i-1}\right)} - \dfrac{u_{xi}}{\tau}
\end{split}
\end{equation}
$$</code></p>

<p>据此，我们以一个 10 个城市的数据为例，利用 CHNN 求解 TSP 问题，其中 10 个城市的座标为</p>

<table>
<thead>
<tr>
<th align="center">城市</th>
<th align="center">横座标</th>
<th align="center">纵座标</th>
</tr>
</thead>

<tbody>
<tr>
<td align="center">A</td>
<td align="center">0.4000</td>
<td align="center">0.4439</td>
</tr>

<tr>
<td align="center">B</td>
<td align="center">0.2439</td>
<td align="center">0.1463</td>
</tr>

<tr>
<td align="center">C</td>
<td align="center">0.1707</td>
<td align="center">0.2293</td>
</tr>

<tr>
<td align="center">D</td>
<td align="center">0.2293</td>
<td align="center">0.7610</td>
</tr>

<tr>
<td align="center">E</td>
<td align="center">0.5171</td>
<td align="center">0.9414</td>
</tr>

<tr>
<td align="center">F</td>
<td align="center">0.8732</td>
<td align="center">0.6536</td>
</tr>

<tr>
<td align="center">G</td>
<td align="center">0.6878</td>
<td align="center">0.5219</td>
</tr>

<tr>
<td align="center">H</td>
<td align="center">0.8488</td>
<td align="center">0.3609</td>
</tr>

<tr>
<td align="center">I</td>
<td align="center">0.6683</td>
<td align="center">0.2536</td>
</tr>

<tr>
<td align="center">J</td>
<td align="center">0.6195</td>
<td align="center">0.2634</td>
</tr>
</tbody>
</table>

<p>已知的最优路线为 <code>$A \to D \to E \to F \to G \to H \to I \to J \to B \to C \to A$</code>，最优路线的路径长度为 <code>$2.6907$</code>。我们使用如下参数求解 TSP 问题，初始化 <code>$u_{init} = -\dfrac{\gamma}{2} \ln\left(n - 1\right)$</code>，<code>$\gamma = 0.02$</code>，学习率 <code>$\alpha = 0.0001$</code>，神经元激活阈值 <code>$\theta = 0.7$</code>，<code>$\tau = 1$</code>，能量分量权重参数 <code>$A = 500, B = 500, C = 1000, D = 500$</code>，单次迭代最大次数为 1000，共模拟 100 次。</p>

<pre><code class="language-r"># 城市座标
cities &lt;- data.frame(
    l = LETTERS[1:10],
    x = c(0.4000, 0.2439, 0.1707, 0.2293, 0.5171,
          0.8732, 0.6878, 0.8488, 0.6683, 0.6195),
    y = c(0.4439, 0.1463, 0.2293, 0.7610, 0.9414,
          0.6536, 0.5219, 0.3609, 0.2536, 0.2634)
)

# 通过城市座标构建距离矩阵
distance_matrix &lt;- function(points) {
    n &lt;- nrow(points)
    d &lt;- matrix(rep(0, n^2), n, n)
    
    for (i in 1:n) {
        for (j in i:n) {
            distance &lt;- sqrt((points[i, ]$x - points[j, ]$x)^2 +
                                 (points[i, ]$y - points[j, ]$y)^2)
            d[i, j] &lt;- distance
            d[j, i] &lt;- distance
        }
    }
    
    d
}

# 结果约束校验
check_path_valid &lt;- function(v, n) {
    # 城市约束
    c1 &lt;- 0
    for (x in 1:n) {
        for (i in 1:(n-1)) {
            for (j in (i+1):n) {
                c1 &lt;- c1 + v[x, i] * v[x, j]
            }
        }
    }
    
    # 时间约束
    c2 &lt;- 0
    for (i in 1:n) {
        for (x in 1:(n-1)) {
            for (y in (x+1):n) {
                c2 &lt;- c2 + v[x, i] * v[y, i]
            }
        }
    }
    
    # 有效性约束
    c3 &lt;- sum(v)
    
    ifelse(c1 == 0 &amp; c2 == 0 &amp; c3 == n, T, F)
}

# 根据结果矩阵获取路径
v_to_path &lt;- function(v, n) {
    p &lt;- c()
    
    for (i in 1:n) {
        for (x in 1:n) {
            if (v[x, i] == 1) {
                p &lt;- c(p, x)
                break
            }
        }
    }
    
    p
}

# 计算结果矩阵的路径长度
path_distance &lt;- function(v, n, d) {
    p &lt;- v_to_path(v, n)
    p &lt;- c(p, p[1])
    distance &lt;- 0 
    for (i in 1:(length(p)-1)) {
        distance &lt;- distance + d[p[i], p[i+1]]
    }
    
    distance
}

# 构建 Hopfield 网络
tsp_chnn &lt;- function(d, n, gamma = 0.02, alpha = 0.0001,
                     theta = 0.7, tau = 1,
                     A = 500, B = 500, C = 1000, D = 500,
                     max_iter = 1000) {
    v &lt;- matrix(runif(n^2), n, n)
    u &lt;- matrix(rep(1, n^2), n, n) * (-gamma * log(n-1) / 2)
    du &lt;- matrix(rep(0, n^2), n, n)
    
    for (iter in 1:max_iter) {
        for (x in 1:n) {
            for (i in 1:n) {
                # E1
                e1 &lt;- 0
                for (j in 1:n) {
                    if (j != i) {
                        e1 &lt;- e1 + v[x, j]
                    }
                }
                e1 &lt;- -A * e1
                
                # E2
                e2 &lt;- 0
                for (y in 1:n) {
                    if (y != x) {
                        e2 &lt;- e2 + v[y, i]
                    }
                }
                e2 &lt;- -B * e2
                
                # E3
                e3 &lt;- -C * (sum(v) - n)
                
                # E4
                e4 &lt;- 0
                for (y in 1:n) {
                    if (y != x) {
                        e4 &lt;- e4 + d[x, y] *
                            (v[y, (i+1-1)%%n+1] + v[y, (i-1-1)%%n+1])
                    }
                }
                e4 &lt;- -D * e4
                
                du[x, i] &lt;- e1 + e2 + e3 + e4 - u[x, i] / tau
            }
        }
        
        u &lt;- u + alpha * du
        v &lt;- (1 + tanh(u / gamma)) / 2
        v &lt;- ifelse(v &gt;= theta, 1, 0)
    }
    
    v
}

# 利用 Hopfiled 网络求解 TSP 问题
set.seed(112358)

n &lt;- 10
d &lt;- distance_matrix(cities)

# 模拟 100 次并获取最终结果
tsp_solutions &lt;- lapply(1:100, function(round) {
    v &lt;- tsp_chnn(d, n)
    valid &lt;- check_path_valid(v, n)
    distance &lt;- ifelse(valid, path_distance(v, n, d), NA)
    
    list(round = round, valid = valid,
         distance = distance, v = v)
})

# 获取最优结果
best_tsp_solution &lt;- NA
for (tsp_solution in tsp_solutions) {
    if (tsp_solution$valid) {
        if (!is.na(best_tsp_solution)) {
            if (tsp_solution$distance &lt; best_tsp_solution$distance) {
                best_tsp_solution &lt;- tsp_solution
            }
        } else {
            best_tsp_solution &lt;- tsp_solution
        }
    }
}

# 可视化最优结果
best_tsp_solution_path &lt;- v_to_path(best_tsp_solution$v, n)
ordered_cities &lt;- cities[best_tsp_solution_path, ] %&gt;%
    mutate(ord = seq(1:10))

best_tsp_solution_path_p &lt;- ggplot(ordered_cities) +
    geom_polygon(aes(x, y), color = 'black', fill = NA) +
    geom_point(aes(x, y)) +
    geom_text(aes(x, y, label = l), vjust = -1) +
    geom_text(aes(x, y, label = ord), vjust = 2) +
    coord_fixed() + ylim(c(0, 1)) + xlim(c(0, 1)) +
    theme(axis.title = element_blank())
print(best_tsp_solution_path_p)
</code></pre>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/tsp-best-solution-path.png" alt="" /></p>

<h2 id="受限的玻尔兹曼机-rbm">受限的玻尔兹曼机 (RBM)</h2>

<h3 id="网络结构及其概率表示">网络结构及其概率表示</h3>

<p><strong>受限的玻尔兹曼机</strong> (Restricted Boltzmann Machine, RBM) 或<strong>簧风琴</strong> (harmonium) 是由 Smolensky 与 1986年在<strong>玻尔兹曼机</strong> (Boltzmann Machine, BM) 基础上提出的一种随机神经网络 (Stochastic Neural Networks) <sup class="footnote-ref" id="fnref:smolensky1986information"><a href="#fn:smolensky1986information">9</a></sup>。受限的玻尔兹曼机对于原始的玻尔兹曼机做了相应的限制，在其网络结构中包含<strong>可见节点</strong>和<strong>隐藏节点</strong>，并且<strong>可见节点</strong>和<strong>隐藏节点</strong>内部不允许存在连接，更加形象的可以将其理解为一个二分图。</p>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/rbm-network.svg" alt="" /></p>

<p>对于二值版本的 RBM 而言，其中可见层 <code>$\mathbf{v} = \left(v_1, v_2, ..., v_{n_v}\right)^T$</code> 由 <code>$n_v$</code> 个二值随机变量构成；隐藏层 <code>$\mathbf{h} = \left(h_1, h_2, ..., h_{n_h}\right)^T$</code> 由 <code>$n_h$</code> 个二值随机变量构成。</p>

<p>RBM 同样作为一个基于能量的模型，其能量函数定义为：</p>

<p><code>$$
E \left(\boldsymbol{v}, \boldsymbol{h}\right) = -\sum_{i=1}^{n_v}{b_i v_i} -\sum_{j=1}^{n_h}{c_j h_j} - \sum_{i=1}^{n_v}{\sum_{j=1}^{n_h}{v_i w_{i,j} h_i}}
$$</code></p>

<p>将其表示成矩阵向量的形式，可记为：</p>

<p><code>$$
E \left(\boldsymbol{v}, \boldsymbol{h}\right) = -\boldsymbol{b}^T \boldsymbol{v} - \boldsymbol{c}^T \boldsymbol{h} - \boldsymbol{v}^T \boldsymbol{W} \boldsymbol{h}
$$</code></p>

<p>其中 <code>$\boldsymbol{b} \in \mathbb{R}^{n_v}$</code> 为可见层的偏置向量；<code>$\boldsymbol{c} \in \mathbb{R}^{n_h}$</code> 为隐含层的偏置向量；<code>$\boldsymbol{W} \in \mathbb{R}^{n_v \times n_h}$</code> 为可见层和隐含层之间的权重矩阵。根据能量函数，可得其联合概率分布为：</p>

<p><code>$$
P \left(\mathbf{v} = \boldsymbol{v}, \mathbf{h} = \boldsymbol{h}\right) = \dfrac{1}{Z} e^{-E \left(\boldsymbol{v}, \boldsymbol{h}\right)}
$$</code></p>

<p>其中 <code>$Z$</code> 为归一化常数，成为配分函数：</p>

<p><code>$$
Z = \sum_{\boldsymbol{v}}{\sum_{\boldsymbol{h}}{e^{-E \left(\boldsymbol{v}, \boldsymbol{h}\right)}}}
$$</code></p>

<p>对于 RBM 我们更加关注的的为边缘分布，即：</p>

<p><code>$$
P \left(\boldsymbol{v}\right) = \sum_{h}{P\left(\boldsymbol{v}, \boldsymbol{h}\right)} = \dfrac{1}{Z} \sum_{h}{e^{-E\left(\boldsymbol{v}, \boldsymbol{h}\right)}}
$$</code></p>

<p>因为概率中包含归一化常数，我们需要计算 <code>$Z$</code>，从其定义可得，当穷举左右可能性的化，我们需要计算 <code>$2^{n_v + n_h}$</code> 个项，其计算复杂度很大。尽管 <code>$P\left(\boldsymbol{v}\right)$</code> 计算比较困难，但是其条件概率 <code>$P\left(\mathbf{h} | \mathbf{v}\right)$</code> 和 <code>$P\left(\mathbf{v} | \mathbf{h}\right)$</code> 计算和采样相对容易。为了便于推导，我们定义如下记号：</p>

<p><code>$$
\boldsymbol{h}_{-k} = \left(h_1, h_2, ..., h_{k-1}, h_{k+1}, ..., h_{n_h}\right)^T
$$</code></p>

<p>则 <code>$P\left(h_k = 1 | \boldsymbol{v}\right)$</code> 定义如下：</p>

<p><code>$$
\begin{equation}
\begin{split}
&amp;P\left(h_k = 1 | \boldsymbol{v}\right) \\
= &amp;P\left(h_k = 1 | h_{-k}, \boldsymbol{v}\right) \\
= &amp;\dfrac{P\left(h_k = 1, h_{-k}, \boldsymbol{v}\right)}{P\left(h_{-k}, \boldsymbol{v}\right)} \\
= &amp;\dfrac{P\left(h_k = 1, h_{-k}, \boldsymbol{v}\right)}{P\left(h_k = 1 | h_{-k}, \boldsymbol{v}\right) + P\left(h_k = 0 | h_{-k}, \boldsymbol{v}\right)} \\
= &amp;\dfrac{\dfrac{1}{Z} e^{-E\left(h_k = 1, h_{-k}, \boldsymbol{v}\right)}}{\dfrac{1}{Z} e^{-E\left(h_k = 1, h_{-k}, \boldsymbol{v}\right)} + \dfrac{1}{Z} e^{-E\left(h_k = 0, h_{-k}, \boldsymbol{v}\right)}} \\
= &amp;\dfrac{e^{-E\left(h_k = 1, h_{-k}, \boldsymbol{v}\right)}}{e^{-E\left(h_k = 1, h_{-k}, \boldsymbol{v}\right)} + e^{-E\left(h_k = 0, h_{-k}, \boldsymbol{v}\right)}} \\
= &amp;\dfrac{1}{1 + e^{E\left(h_k = 1, h_{-k}, \boldsymbol{v}\right) - E\left(h_k = 0, h_{-k}, \boldsymbol{v}\right)}} \\
\end{split}
\end{equation}
$$</code></p>

<p>其中：</p>

<p><code>$$
\begin{equation}
\begin{split}
&amp;E\left(h_k = 1, h_{-k}, \boldsymbol{v}\right) \\
= &amp;E\left(h_k = 1, \boldsymbol{v}\right) \\
= &amp;-\sum_{i=1}^{n_v}{b_i v_i} - \sum_{j=1, j \neq k}^{n_h}{c_j h_j} - \sum_{i=1}^{n_v}{\sum_{j=1, j \neq k}^{n_h}{v_i W_{i, j} h_i}} - c_k - \sum_{i=1}^{n_v}{v_i W_{i, k}} \\
&amp;E\left(h_k = 0, h_{-k}, \boldsymbol{v}\right) \\
= &amp;E\left(h_k = 0, \boldsymbol{v}\right) \\
= &amp;-\sum_{i=1}^{n_v}{b_i v_i} - \sum_{j=1, j \neq k}^{n_h}{c_j h_j} - \sum_{i=1}^{n_v}{\sum_{j=1, j \neq k}^{n_h}{v_i W_{i, j} h_i}}
\end{split}
\end{equation}
$$</code></p>

<p>因此，<code>$P\left(h_k = 1 | \boldsymbol{v}\right)$</code> 可以化简为：</p>

<p><code>$$
\begin{equation}
\begin{split}
&amp;P\left(h_k = 1 | \boldsymbol{v}\right) \\
= &amp;\dfrac{1}{1 + e^{-\left(c_k + \sum_{i=1}^{n_v}{v_i W_{i, k}}\right)}} \\
= &amp;\sigma\left(c_k + \sum_{i=1}^{n_v}{v_i W_{i, k}}\right) \\
= &amp;\sigma\left(c_k + \boldsymbol{v}^T \boldsymbol{W}_{:, k}\right)
\end{split}
\end{equation}
$$</code></p>

<p>其中，<code>$\sigma$</code> 为 sigmoid 函数。因此，我们可以将条件分布表示为连乘的形式：</p>

<p><code>$$
\begin{equation}
\begin{split}
P\left(\boldsymbol{h} | \boldsymbol{v}\right) &amp;= \prod_{j=1}^{n_h}{P\left(h_j | \boldsymbol{v}\right)} \\
&amp;= \prod_{j=1}^{n_h}{\sigma\left(\left(2h - 1\right) \odot \left(\boldsymbol{c} + \boldsymbol{W}^T \boldsymbol{v}\right)\right)_j}
\end{split}
\end{equation}
$$</code></p>

<p>同理可得：</p>

<p><code>$$
\begin{equation}
\begin{split}
P\left(\boldsymbol{v} | \boldsymbol{h}\right) &amp;= \prod_{i=1}^{n_v}{P\left(v_i | \boldsymbol{h}\right)} \\
&amp;= \prod_{i=1}^{n_v}{\sigma\left(\left(2v - 1\right) \odot \left(\boldsymbol{b} + \boldsymbol{W} \boldsymbol{h}\right)\right)_i}
\end{split}
\end{equation}
$$</code></p>

<h3 id="模型训练-itplus-rbm">模型训练 <sup class="footnote-ref" id="fnref:itplus-rbm"><a href="#fn:itplus-rbm">10</a></sup></h3>

<p>对于 RBM 模型的训练，假设训练样本集合为 <code>$S = \left\lbrace{\boldsymbol{v^1}, \boldsymbol{v^2}, ..., \boldsymbol{v^{n_s}}}\right\rbrace$</code>，其中 <code>$\boldsymbol{v^i} = \left(v_{1}^{i}, v_{2}^{i}, ..., v_{n_v}^{i}\right), i = 1, 2, ..., n_s$</code>。则训练 RBM 的目标可以定义为最大化如下似然：</p>

<p><code>$$
\mathcal{L}_{\theta, S} = \prod_{i=1}^{n_s}{P\left(\boldsymbol{v}^i\right)}
$$</code></p>

<p>其中 <code>$\theta$</code> 为待优化的参数，为了方便计算，等价目标为最大化其对数似然：</p>

<p><code>$$
\ln\mathcal{L}_{\theta, S} = \ln\prod_{i=1}^{n_s}{P\left(\boldsymbol{v}^i\right)} = \sum_{i=1}^{n_s}{\ln P\left(\boldsymbol{v}^i\right)}
$$</code></p>

<p>我们将其对数似然简写为 <code>$\ln\mathcal{L}_S$</code> ，通过梯度上升方法，我们可以得到参数的更新公式：</p>

<p><code>$$
\theta = \theta + \eta \dfrac{\partial \ln\mathcal{L}_S}{\partial \theta}
$$</code></p>

<p>对于单个样本 <code>$\boldsymbol{\color{red}{v'}}$</code> ，有：</p>

<p><code>$$
\begin{equation}
\begin{split}
\dfrac{\partial \ln\mathcal{L}_S}{\partial \theta} &amp;= \dfrac{\partial \ln P\left(\boldsymbol{\color{red}{v'}}\right)}{\partial \theta} = \dfrac{\partial \ln \left(\dfrac{1}{Z} \sum_{\boldsymbol{h}}{e^{-E\left(\boldsymbol{\color{red}{v'}, h}\right)}}\right)}{\partial \theta} \\
&amp;= \dfrac{\partial \left(\ln \sum_{\boldsymbol{h}}{e^{-E\left(\boldsymbol{\color{red}{v'}, h}\right)}} - \ln Z\right)}{\partial \theta} = \dfrac{\partial \left(\ln \sum_{\boldsymbol{h}}{e^{-E\left(\boldsymbol{\color{red}{v'}, h}\right)}} - \ln \sum_{\boldsymbol{v, h}}{e^{-E\left(\boldsymbol{v, h}\right)}}\right)}{\partial \theta} \\
&amp;= \dfrac{\partial}{\partial \theta} \left(\ln \sum_{\boldsymbol{h}}{e^{-E\left(\boldsymbol{\color{red}{v'}, h}\right)}}\right) - \dfrac{\partial}{\partial \theta} \left(\ln \sum_{\boldsymbol{v, h}}{e^{-E\left(\boldsymbol{v, h}\right)}}\right) \\
&amp;= -\dfrac{1}{\sum_{\boldsymbol{h}}{e^{-E\left(\boldsymbol{\color{red}{v'}, h}\right)}}} \sum_{\boldsymbol{h}}{e^{-E\left(\boldsymbol{\color{red}{v'}, h}\right)} \dfrac{\partial E\left(\boldsymbol{\color{red}{v'}, h}\right)}{\partial \theta}} + \dfrac{1}{\sum_{\boldsymbol{v, h}}{e^{-E\left(\boldsymbol{v, h}\right)}}} \sum_{\boldsymbol{v, h}}{e^{-E\left(\boldsymbol{v, h}\right)} \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial \theta}} \\
&amp;= -\sum_{\boldsymbol{h}}{\dfrac{e^{-E\left(\boldsymbol{\color{red}{v'}, h}\right)}}{\sum_{\boldsymbol{h}}{e^{-E\left(\boldsymbol{\color{red}{v'}, h}\right)}}} \dfrac{\partial E\left(\boldsymbol{\color{red}{v'}, h}\right)}{\partial \theta}} + \sum_{\boldsymbol{v, h}}{\dfrac{e^{-E\left(\boldsymbol{v, h}\right)}}{\sum_{\boldsymbol{v, h}}{e^{-E\left(\boldsymbol{v, h}\right)}}} \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial \theta}} \\
&amp;= -\sum_{\boldsymbol{h}}{\dfrac{\dfrac{e^{-E\left(\boldsymbol{\color{red}{v'}, h}\right)}}{Z}}{\dfrac{\sum_{\boldsymbol{h}}{e^{-E\left(\boldsymbol{\color{red}{v'}, h}\right)}}}{Z}} \dfrac{\partial E\left(\boldsymbol{\color{red}{v'}, h}\right)}{\partial \theta}} + \sum_{\boldsymbol{v, h}}{\dfrac{e^{-E\left(\boldsymbol{v, h}\right)}}{\sum_{\boldsymbol{v, h}}{e^{-E\left(\boldsymbol{v, h}\right)}}} \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial \theta}} \\
&amp;= -\sum_{\boldsymbol{h}}{\dfrac{P\left(\boldsymbol{\color{red}{v'}, h}\right)}{P\left(\boldsymbol{\color{red}{v'}}\right)} \dfrac{\partial E\left(\boldsymbol{\color{red}{v'}, h}\right)}{\partial \theta}} + \sum_{\boldsymbol{v, h}}{\dfrac{e^{-E\left(\boldsymbol{v, h}\right)}}{\sum_{\boldsymbol{v, h}}{e^{-E\left(\boldsymbol{v, h}\right)}}} \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial \theta}} \\
&amp;= -\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h | \color{red}{v'}}\right) \dfrac{\partial E\left(\boldsymbol{\color{red}{v'}, h}\right)}{\partial \theta}} + \sum_{\boldsymbol{v, h}}{P\left(\boldsymbol{h | v}\right) \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial \theta}}
\end{split}
\end{equation}
$$</code></p>

<p>其中：</p>

<p><code>$$
\begin{equation}
\begin{split}
\sum_{\boldsymbol{v, h}}{P\left(\boldsymbol{h | v}\right) \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial \theta}} &amp;= \sum_{\boldsymbol{v}}{\sum_{\boldsymbol{h}}{P\left(\boldsymbol{v}\right) P\left(\boldsymbol{h | v}\right) \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial \theta}}} \\
&amp;= \sum_{\boldsymbol{v}}{P\left(\boldsymbol{v}\right) \sum_{\boldsymbol{h}}{P \left(\boldsymbol{h | v}\right) \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial \theta}}}
\end{split}
\end{equation}
$$</code></p>

<p>则对于参数 <code>$w_{i, j}$</code> 可得：</p>

<p><code>$$
\begin{equation}
\begin{split}
&amp;\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h|v}\right) \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial w_{i, j}}} \\
= &amp;-\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h|v}\right) h_i v_j} \\
= &amp;-\sum_{\boldsymbol{h}}{\prod_{k=1}^{n_h}{P\left(h_k | \boldsymbol{v}\right) h_i v_j}} \\
= &amp;-\sum_{\boldsymbol{h}}{P\left(h_i | \boldsymbol{v}\right) P\left(h_{-i} | \boldsymbol{v}\right) h_i v_j} \\
= &amp;-\sum_{\boldsymbol{h_i}}{\sum_{h_{-i}}{P\left(h_i | \boldsymbol{v}\right) P\left(\boldsymbol{h_{-i}} | \boldsymbol{v}\right) h_i v_j}} \\
= &amp;-\sum_{\boldsymbol{h_i}}{P\left(h_i | \boldsymbol{v}\right) h_i v_j} \sum_{\boldsymbol{h_{-i}}}{P\left(h_{-i} | \boldsymbol{v}\right)} \\
= &amp;-\sum_{\boldsymbol{h_i}}{P\left(h_i | \boldsymbol{v}\right) h_i v_j} \\
= &amp;-\left(P\left(h_i = 0 | \boldsymbol{v}\right) \cdot 0 \cdot v_j + P\left(h_i = 1 | \boldsymbol{v}\right) \cdot 1 \cdot v_j\right) \\
= &amp;-P\left(h_i = 1 | \boldsymbol{v}\right) v_j
\end{split}
\end{equation}
$$</code></p>

<p>则对于参数 <code>$b_i$</code> 可得：</p>

<p><code>$$
\begin{equation}
\begin{split}
&amp;\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h|v}\right) \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial b_i}} \\
= &amp;-\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h|v}\right) v_i} \\
= &amp;-v_i \sum_{\boldsymbol{h}}{P\left(\boldsymbol{h|v}\right)} \\
= &amp;-v_i
\end{split}
\end{equation}
$$</code></p>

<p>则对于参数 <code>$c_j$</code> 可得：</p>

<p><code>$$
\begin{equation}
\begin{split}
&amp;\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h|v}\right) \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial c_j}} \\
= &amp;-\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h|v}\right) h_j} \\
= &amp;-\sum_{\boldsymbol{h}}{\prod_{k=1}^{n_h}{P\left(h_k | \boldsymbol{v}\right) h_j}} \\
= &amp;-\sum_{\boldsymbol{h}}{P\left(h_j | \boldsymbol{v}\right) P\left(h_{-j} | \boldsymbol{v}\right) h_j} \\
= &amp;-\sum_{h_j}{\sum_{h_{-j}}{P\left(h_i | \boldsymbol{v}\right) P\left(h_{-j} | \boldsymbol{v}\right) h_j}} \\
= &amp;-\sum_{h_j}{P\left(h_i | \boldsymbol{v}\right) h_j} \sum_{h_{-j}}{P\left(h_{-j} | \boldsymbol{v}\right)} \\
= &amp;-\sum_{h_j}{P\left(h_i | \boldsymbol{v}\right) h_j} \\
= &amp;-\left(P\left(h_j = 0 | \boldsymbol{v}\right) \cdot 0 + P\left(h_j = 1 | \boldsymbol{v}\right) \cdot 1\right) \\
= &amp;-P\left(h_j = 1 | \boldsymbol{v}\right)
\end{split}
\end{equation}
$$</code></p>

<p>综上所述，可得：</p>

<p><code>$$
\begin{equation}
\begin{split}
\dfrac{\partial \ln P\left(\color{red}{\boldsymbol{v'}}\right)}{\partial w_{i, j}} &amp;= -\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h | \color{red}{v'}}\right) \dfrac{\partial E\left(\boldsymbol{\color{red}{v'}, h}\right)}{\partial w_{i, j}}} + \sum_{\boldsymbol{v, h}}{P\left(\boldsymbol{h | v}\right) \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial w_{i, j}}} \\
&amp;= P\left(h_i = 1 | \boldsymbol{\color{red}{v'}}\right) \color{red}{v'_j} - \sum_{\boldsymbol{v}}{P\left(\boldsymbol{v}\right) P\left(h_i = 1 | \boldsymbol{v}\right) v_j}\\
\dfrac{\partial \ln P\left(\color{red}{\boldsymbol{v'}}\right)}{\partial b_i} &amp;= -\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h | \color{red}{v'}}\right) \dfrac{\partial E\left(\boldsymbol{\color{red}{v'}, h}\right)}{\partial b_i}} + \sum_{\boldsymbol{v, h}}{P\left(\boldsymbol{h | v}\right) \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial b_i}} \\
&amp;= \color{red}{v'_i} - \sum_{\boldsymbol{v}}{P\left(\boldsymbol{v}\right) v_i} \\
\dfrac{\partial \ln P\left(\color{red}{\boldsymbol{v'}}\right)}{\partial c_j} &amp;= -\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h | \color{red}{v'}}\right) \dfrac{\partial E\left(\boldsymbol{\color{red}{v'}, h}\right)}{\partial c_j}} + \sum_{\boldsymbol{v, h}}{P\left(\boldsymbol{h | v}\right) \dfrac{\partial E\left(\boldsymbol{v, h}\right)}{\partial c_j}} \\
&amp;= P\left(h_j = 1 | \boldsymbol{\color{red}{v'}}\right) - \sum_{\boldsymbol{v}}{P\left(\boldsymbol{v}\right) P\left(h_j = 1 | \boldsymbol{v}\right)} \\
\end{split}
\end{equation}
$$</code></p>

<p>对于多个样本 <code>$S = \left\lbrace{\boldsymbol{v^1}, \boldsymbol{v^2}, ..., \boldsymbol{v^{n_s}}}\right\rbrace$</code>，有：</p>

<p><code>$$
\begin{equation}
\begin{split}
\dfrac{\partial \ln \mathcal{L}_S}{\partial w_{i, j}} &amp;= \sum_{m=1}^{n_S}{\left[P\left(h_i = 1 | \boldsymbol{v^m}\right) v_j^m - \sum_{\boldsymbol{v}}{P\left(\boldsymbol{v}\right) P\left(h_i = 1 | \boldsymbol{v} v_j\right)}\right]} \\
\dfrac{\partial \ln \mathcal{L}_S}{\partial b_i} &amp;= \sum_{m=1}^{n_S}{\left[v_i^m - \sum_{\boldsymbol{v}}{P\left(\boldsymbol{v}\right) v_i}\right]} \\
\dfrac{\partial \ln \mathcal{L}_S}{\partial c_j} &amp;= \sum_{m=1}^{n_S}{\left[P\left(h_j = 1 | \boldsymbol{v^m}\right) - \sum_{\boldsymbol{v}}{P\left(\boldsymbol{v}\right) P\left(h_j = 1 | \boldsymbol{v}\right)}\right]}
\end{split}
\end{equation}
$$</code></p>

<p>针对如上方法，我们需要计算 <code>$\sum_{\boldsymbol{v}}$</code> 相关项，如上文所述，其计算复杂度为 <code>$O\left(2^{n_v + n_h}\right)$</code>，因为其条件概率计算比较容易，因此我们可以用 Gibbs 采样的方法进行估计，但由于 Gibbs 采样方法存在 burn-in period，因此需要足够次数的状态转移后才能够收敛到目标分布，因此这就增大了利用这种方法训练 RBM 模型的时间。</p>

<p>针对这个问题，Hinton 于 2002 年提出了对比散度 (Contrastive Divergence, CD) 算法 <sup class="footnote-ref" id="fnref:hinton2002training"><a href="#fn:hinton2002training">11</a></sup>，基本思想为将训练样本作为采样的初始值，因为目标就是让 RBM 去拟合这些样本的分布，因此这样则可以通过更少的状态转移就收敛到平稳分布。<code>$k$</code> 步 CD 算法大致步骤为：</p>

<ol>
<li>对 <code>$\forall \boldsymbol{v} \in \boldsymbol{S}$</code>，初始化 <code>$\boldsymbol{v}^{\left(0\right)} = \boldsymbol{v}$</code>。</li>
<li>执行 <code>$k$</code> 步 Gibbs 采样，对于第 <code>$t$</code> 步，分别利用 <code>$P\left(\boldsymbol{h} | \boldsymbol{v}^{\left(t-1\right)}\right)$</code> 和 <code>$P\left(\boldsymbol{v} | \boldsymbol{h}^{\left(t-1\right)}\right)$</code> 采样出 <code>$\boldsymbol{h}^{\left(t-1\right)}$</code> 和 <code>$\boldsymbol{v}^{\left(t\right)}$</code>。</li>
<li>利用采样得到的 <code>$\boldsymbol{v}^{\left(k\right)}$</code> <strong>近似估计</strong> <code>$\sum_{\boldsymbol{v}}$</code> 相关项：
<code>$$
\begin{equation}
\begin{split}
\dfrac{\partial \ln P\left(\boldsymbol{v}\right)}{\partial w_{i, j}} &amp;\approx P\left(h_i=1|\boldsymbol{v}^{\left(0\right)}\right) v_j^{\left(0\right)} - P\left(h_i=1|\boldsymbol{v}^{\left(k\right)}\right) v_j^{\left(k\right)} \\
\dfrac{\partial \ln P\left(\boldsymbol{v}\right)}{\partial b_i} &amp;\approx v_i^{\left(0\right)} - v_i^{\left(k\right)} \\
\dfrac{\partial \ln P\left(\boldsymbol{v}\right)}{\partial c_j} &amp;\approx P\left(h_j=1|\boldsymbol{v}^{\left(0\right)}\right) - P\left(h_j=1|\boldsymbol{v}^{\left(k\right)}\right)
\end{split}
\end{equation}
$$</code></li>
</ol>

<p><strong>近似估计</strong>可以看做是利用</p>

<p><code>$$
CDK\left(\theta, \boldsymbol{v}\right) = -\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h} | \boldsymbol{v}^{\left(0\right)}\right) \dfrac{\partial E\left(\boldsymbol{v}^{\left(0\right)}, h\right)}{\partial \theta}} + \sum_{\boldsymbol{h}}{P\left(\boldsymbol{h} | \boldsymbol{v}^{\left(k\right)}\right) \dfrac{\partial E\left(\boldsymbol{v}^{\left(k\right)}, \boldsymbol{h}\right)}{\partial \theta}}
$$</code></p>

<p>近似</p>

<p><code>$$
\dfrac{\partial \ln P\left(\boldsymbol{v}\right)}{\partial \theta} = -\sum_{\boldsymbol{h}}{P\left(\boldsymbol{h} | \boldsymbol{v}^{\left(0\right)}\right) \dfrac{\partial E\left(\boldsymbol{v}^{\left(0\right)}, h\right)}{\partial \theta}} + \sum_{\boldsymbol{v, h}}{P\left(\boldsymbol{v, h}\right) \dfrac{\partial E\left(\boldsymbol{v}, \boldsymbol{h}\right)}{\partial \theta}}
$$</code></p>

<p>的过程。</p>

<p>基于对比散度的 RBM 训练算法可以描述为：</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{CDK 算法}
\begin{algorithmic}
\REQUIRE $k, \boldsymbol{S}, \text{RBM}\left(\boldsymbol{W, b, c}\right)$
\ENSURE $\Delta \boldsymbol{W}, \Delta \boldsymbol{b}, \Delta \boldsymbol{c}$
\PROCEDURE{CDK}{$k, \boldsymbol{S}, \text{RBM}\left(\boldsymbol{W, b, c}\right)$}
    \STATE $\Delta \boldsymbol{W} \gets 0, \Delta \boldsymbol{b} \gets 0, \Delta \boldsymbol{c} \gets 0$
    \FORALL{$\boldsymbol{v \in S}$}
        \STATE $\boldsymbol{v}^{\left(0\right)} \gets \boldsymbol{v}$
        \FOR{$t = 0, 1, ..., k-1$}
            \STATE $\boldsymbol{h}^{\left(t\right)} \gets \text{sample_h_given_v} \left(\boldsymbol{v}^{\left(t\right)}, \text{RBM}\left(W, b, c\right)\right)$
            \STATE $\boldsymbol{v}^{\left(t+1\right)} \gets \text{sample_v_given_h} \left(\boldsymbol{h}^{\left(t\right)}, \text{RBM}\left(W, b, c\right)\right)$
        \ENDFOR
        \FOR{$i = 1, 2, ..., n_h; j = 1, 2, ..., n_v$}
            \STATE $\Delta w_{i, j} \gets \Delta w_{i, j} + \left[P\left(h_i=1|\boldsymbol{v}^{\left(0\right)}\right) v_j^{\left(0\right)} - P\left(h_i=1|\boldsymbol{v}^{\left(k\right)}\right) v_j^{\left(k\right)}\right]$
            \STATE $\Delta b_i \gets \Delta b_i = \left[v_i^{\left(0\right)} - v_i^{\left(k\right)}\right]$
            \STATE $\Delta c_j \gets \Delta c_j = \left[P\left(h_j=1|\boldsymbol{v}^{\left(0\right)}\right) - P\left(h_j=1|\boldsymbol{v}^{\left(k\right)}\right)\right]$
        \ENDFOR
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>其中，<code>sample_h_given_v</code> 和 <code>sample_v_given_h</code> 分别表示在已知可见层时采样隐含层和在已知隐含层时采样可见层。对于 <code>sample_h_given_v</code> 其算法流程如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{sample\_h\_given\_v 算法}
\begin{algorithmic}
\FOR{$j = 1, 2, ..., n_h$}
    \STATE sample $r_j \sim Uniform[0, 1]$
    \IF{$r_j < P\left(h_j = 1 | \boldsymbol{v}\right)$}
        \STATE $h_j \gets 1$
    \ELSE
        \STATE $h_j \gets 0$
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>类似的，对于 <code>sample_v_given_h</code> 其算法流程如下：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{sample\_v\_given\_h 算法}
\begin{algorithmic}
\FOR{$j = 1, 2, ..., n_h$}
    \STATE sample $r_j \sim Uniform[0, 1]$
    \IF{$r_i < P\left(v_i = 1 | \boldsymbol{h}\right)$}
        \STATE $v_i \gets 1$
    \ELSE
        \STATE $v_i \gets 0$
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>至此，我们可以得到 RBM 模型训练的整个流程：</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{RBM 训练算法}
\begin{algorithmic}
\FOR{$iter = 1, 2, ..., \text{max\_iter}$}
    \STATE $\Delta \boldsymbol{W}, \Delta \boldsymbol{b}, \Delta \boldsymbol{c} \gets \text{CDK} \left(k, \boldsymbol{S}, \text{RBM}\left(\boldsymbol{W, b, c}\right)\right)$
    \STATE $\boldsymbol{W} \gets \boldsymbol{W} + \eta \left(\dfrac{1}{n_s} \Delta \boldsymbol{W}\right)$
    \STATE $\boldsymbol{b} \gets \boldsymbol{b} + \eta \left(\dfrac{1}{n_s} \Delta \boldsymbol{b}\right)$
    \STATE $\boldsymbol{c} \gets \boldsymbol{c} + \eta \left(\dfrac{1}{n_s} \Delta \boldsymbol{c}\right)$
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>其中，<code>$k$</code> 为 CDK 算法参数，<code>$\text{max_iter}$</code> 为最大迭代次数，<code>$\boldsymbol{S}$</code> 为训练样本，<code>$n_s = |\boldsymbol{S}|$</code>，<code>$\eta$</code> 为学习率。</p>

<p>对于模型的评估，最简单的是利用 RBM 模型的似然或对数似然，但由于涉及到归一化因子 <code>$Z$</code> 的计算，其复杂度太高。更常用的方式是利用<strong>重构误差</strong> (reconstruction error)，即输入数据和利用 RBM 模型计算得到隐含节点再重构回可见节点之间的误差。</p>

<h3 id="mnist-示例">MNIST 示例</h3>

<p>我们利用经典的 MNIST 数据作为示例，我们利用基于 tensorflow 的扩展包 tfrbm <sup class="footnote-ref" id="fnref:tfrbm"><a href="#fn:tfrbm">12</a></sup>。tfrbm 实现了 Bernoulli-Bernoulli RBM 和 Gaussian-Bernoulli RBM 两种不同的 RBM，两者的比较详见 <sup class="footnote-ref" id="fnref:hinton2010practical"><a href="#fn:hinton2010practical">13</a></sup> <sup class="footnote-ref" id="fnref:yamashita2014bernoulli"><a href="#fn:yamashita2014bernoulli">14</a></sup>。</p>

<pre><code class="language-python">import numpy as np
from matplotlib import pyplot as plt, gridspec
from tfrbm import BBRBM, GBRBM
from tensorflow.examples.tutorials.mnist import input_data

# 读入训练数据和测试数据
mnist = input_data.read_data_sets('MNIST', one_hot=True)
mnist_train_images = mnist.train.images
mnist_test_images = mnist.test.images
mnist_test_labels = mnist.test.labels
</code></pre>

<p>MNIST 数据集中，训练集共包含 55000 个样本，每个样本的维度为 784，我们构建 Bernoulli-Bernoulli RBM，设置隐含节点个数为 64，学习率为 0.01，epoches 为 30，batch size 为 10。</p>

<pre><code class="language-python">bbrbm = BBRBM(n_visible=784,
              n_hidden=64,
              learning_rate=0.01,
              use_tqdm=True)

bbrbm_errs = bbrbm.fit(mnist_train_images, n_epoches=30, batch_size=10)

# Epoch: 0: 100%|##########| 5500/5500 [00:11&lt;00:00, 480.39it/s]
# Train error: 0.1267
# 
# ......
# 
# Epoch: 29: 100%|##########| 5500/5500 [00:11&lt;00:00, 482.15it/s]
# Train error: 0.0347
</code></pre>

<p>训练误差变化如下</p>

<pre><code class="language-python">plt.style.use('ggplot')
plt.plot(bbrbm_errs)
</code></pre>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/bbrbm-mnist-errs.png" alt="" /></p>

<p>我们从 MNIST 的测试集中针对每个数字选取 10 个样本，共 100 个样本作为测试数据，利用训练好的 RBM 模型重构这 100 个样本</p>

<pre><code class="language-python">mnist_test_images_samples = np.zeros([10 * 10, 784])
mnist_test_images_samples_rec = np.zeros([10 * 10, 784])
mnist_test_images_samples_plt = np.zeros([10 * 10 * 2, 784])

digits_current_counts = np.zeros(10, dtype=np.int32)
digits_total_counts = np.ones(10, dtype=np.int32) * 10

for idx in range(mnist_test_images.shape[0]):
    image = mnist_test_images[idx, ]
    label = mnist_test_labels[idx, ]

    for digit in range(10):
        digit_label = np.zeros(10)
        digit_label[digit] = 1

        if (label == digit_label).all() and
               digits_current_counts[digit] &lt; 10:
            nrow = digits_current_counts[digit]
            sample_idx = nrow * 10 + digit
            mnist_test_images_samples[sample_idx, ] = image
            mnist_test_images_samples_rec[sample_idx, ] = \
                bbrbm.reconstruct(image.reshape([1, -1]))
            mnist_test_images_samples_plt[sample_idx * 2, ] = \
                mnist_test_images_samples[sample_idx, ]
            mnist_test_images_samples_plt[sample_idx * 2 + 1, ] = \
                mnist_test_images_samples_rec[sample_idx, ]
            digits_current_counts[digit] += 1

    if (digits_current_counts == digits_total_counts).all():
        break
</code></pre>

<p>对比测试输入数据和重构结果，奇数列为输入数据，偶数列为重构数据</p>

<pre><code class="language-python">def plot_mnist(mnist_images, nrows, ncols, cmap='gray'):
    fig = plt.figure(figsize=(ncols, nrows))
    gs = gridspec.GridSpec(nrows, ncols)
    gs.update(wspace=0.025, hspace=0.025)

    for nrow in range(nrows):
        for ncol in range(ncols):
            ax = plt.subplot(gs[nrow, ncol])
            idx = nrow * ncols + ncol
            minist_image = mnist_images[idx, ].reshape([28, 28])
            ax.imshow(minist_image, cmap=cmap)
            ax.axis('off')

    return fig
    
plot_mnist(mnist_test_images_samples_plt, 10, 20)
</code></pre>

<p><img src="/images/cn/2018-01-17-ising-hopfield-and-rbm/bbrbm-mnist.png" alt="" /></p>

<p>测试集上的重构误差为</p>

<pre><code class="language-python">gbrbm.get_err(mnist_test_images_samples)

# 0.035245348
</code></pre>
<div class="footnotes">

<hr />

<ol>
<li id="fn:ising1924contribution">Ernest Ising, Beitrag zur Theorie des Ferround Paramagnetismus (1924) Contribution to the Theory of Ferromagnetism (English translation of &ldquo;Beitrag zur Theorie des Ferromagnetismus&rdquo;, 1925) Goethe as a Physicist (1950)
 <a class="footnote-return" href="#fnref:ising1924contribution">↩</a></li>
<li id="fn:onsager1944a">Onsager, L. &ldquo;A two-dimensional model with an order–disorder transition (crystal statistics I).&rdquo; <em>Phys. Rev</em> 65 (1944): 117-49.
 <a class="footnote-return" href="#fnref:onsager1944a">↩</a></li>
<li id="fn:ising-model"><a href="http://wiki.swarma.net/index.php?title=ISING模型" rel="noreferrer" target="_blank">http://wiki.swarma.net/index.php?title=ISING模型</a>
 <a class="footnote-return" href="#fnref:ising-model">↩</a></li>
<li id="fn:hopfield1987neural">Hopfield, John J. &ldquo;Neural networks and physical systems with emergent collective computational abilities.&rdquo; <em>Spin Glass Theory and Beyond: An Introduction to the Replica Method and Its Applications.</em> 1987. 411-415.
 <a class="footnote-return" href="#fnref:hopfield1987neural">↩</a></li>
<li id="fn:abu1985information">Abu-Mostafa, Y. A. S. E. R., and J. St Jacques. &ldquo;Information capacity of the Hopfield model.&rdquo; <em>IEEE Transactions on Information Theory</em> 31.4 (1985): 461-464.
 <a class="footnote-return" href="#fnref:abu1985information">↩</a></li>
<li id="fn:han-nn">韩力群. 人工神经网络理论、设计及应用
 <a class="footnote-return" href="#fnref:han-nn">↩</a></li>
<li id="fn:tsp"><a href="https://zh.wikipedia.org/zh-hans/旅行推销员问题" rel="noreferrer" target="_blank">https://zh.wikipedia.org/zh-hans/旅行推销员问题</a>
 <a class="footnote-return" href="#fnref:tsp">↩</a></li>
<li id="fn:np-hard"><a href="https://zh.wikipedia.org/zh-hans/NP困难" rel="noreferrer" target="_blank">https://zh.wikipedia.org/zh-hans/NP困难</a>
 <a class="footnote-return" href="#fnref:np-hard">↩</a></li>
<li id="fn:smolensky1986information">Smolensky, Paul. <em>Information processing in dynamical systems: Foundations of harmony theory.</em> No. CU-CS-321-86. COLORADO UNIV AT BOULDER DEPT OF COMPUTER SCIENCE, 1986.
 <a class="footnote-return" href="#fnref:smolensky1986information">↩</a></li>
<li id="fn:itplus-rbm"><a href="http://blog.csdn.net/itplus/article/details/19168937" rel="noreferrer" target="_blank">http://blog.csdn.net/itplus/article/details/19168937</a>
 <a class="footnote-return" href="#fnref:itplus-rbm">↩</a></li>
<li id="fn:hinton2002training">Hinton, Geoffrey E. &ldquo;Training products of experts by minimizing contrastive divergence.&rdquo; <em>Neural computation</em> 14.8 (2002): 1771-1800.
 <a class="footnote-return" href="#fnref:hinton2002training">↩</a></li>
<li id="fn:tfrbm"><a href="https://github.com/meownoid/tensorfow-rbm" rel="noreferrer" target="_blank">https://github.com/meownoid/tensorfow-rbm</a>
 <a class="footnote-return" href="#fnref:tfrbm">↩</a></li>
<li id="fn:hinton2010practical">Hinton, Geoffrey. &ldquo;A practical guide to training restricted Boltzmann machines.&rdquo; <em>Momentum</em> 9.1 (2010): 926.
 <a class="footnote-return" href="#fnref:hinton2010practical">↩</a></li>
<li id="fn:yamashita2014bernoulli">Yamashita, Takayoshi, et al. &ldquo;To be Bernoulli or to be Gaussian, for a Restricted Boltzmann Machine.&rdquo; <em>Pattern Recognition (ICPR), 2014 22nd International Conference on. IEEE</em>, 2014.
 <a class="footnote-return" href="#fnref:yamashita2014bernoulli">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>马尔科夫链蒙特卡洛方法和吉布斯采样 (MCMC and Gibbs Sampling)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2017/12/mcmc-and-gibbs-sampling/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2017/12/mcmc-and-gibbs-sampling/</guid>
      <description>
        <![CDATA[
        

<h2 id="蒙特卡罗方法-monte-carlo-mc">蒙特卡罗方法 (Monte Carlo, MC)</h2>

<p>蒙特卡罗方法 (Monte Carlo) 也称为统计模拟方法，是于 20 世纪 40 年代由冯·诺伊曼，斯塔尼斯拉夫·乌拉姆和尼古拉斯·梅特罗波利斯在洛斯阿拉莫斯国家实验室为核武器计划工作时 (曼哈顿计划) 发明。因为乌拉姆的叔叔经常在摩纳哥的蒙特卡罗赌场输钱，该方法被定名为蒙特卡罗方法。蒙特卡罗方法是以概率为基础的方法，与之对应的是确定性算法。</p>

<p>蒙特卡罗方法最早可以追述到 18 世纪的<a href="https://zh.wikipedia.org/zh-hans/布丰投针问题" rel="noreferrer" target="_blank">布丰投针问题</a>，该方法通过一个平行且等距木纹铺成的地板，随意抛一支长度比木纹之间距离小的针，求针和其中一条木纹相交的概率的方法得出了一个求 <code>$\pi$</code> 的蒙特卡罗方法。我们通过另一种方式使用蒙特卡罗方法计算圆周率 <code>$\pi$</code>，对于一个边长为 <code>$2r$</code> 的正方形，其内切圆的半径即为 <code>$r$</code>，因此圆形的面积 <code>$A_c$</code> 与正方形的面积 <code>$A_s$</code> 的比值为</p>

<p><code>$$
\dfrac{A_c}{A_s} = \dfrac{\pi r^2}{\left(2r\right)^2} = \dfrac{\pi}{4}
$$</code></p>

<p><img src="/images/cn/2017-12-17-mcmc-and-gibbs-sampling/mc-pi.png" alt="" /></p>

<p>如果我们在矩形内随机的生成均匀分布的点，则在圆内的点的个数的占比即为 <code>$\dfrac{\pi}{4}$</code>，因此通过模拟即可求出 <code>$\pi$</code> 的近似值</p>

<pre><code class="language-r">library(tidyverse)

# 圆的中心点和半径
r &lt;- 2
center_x &lt;- r
center_y &lt;- r

# 距离公式
distance &lt;- function(point_x, point_y, center_x, center_y) {
    sqrt((point_x - center_x)^2 + (point_y - center_y)^2)
}

# 点生成器
points_generator &lt;- function(size) {
    set.seed(112358)
    points_x &lt;- runif(size, min = 0, max = 2*r)
    points_y &lt;- runif(size, min = 0, max = 2*r)
    
    tibble(
        x = points_x,
        y = points_y,
        in_cycle = ifelse(
            distance(points_x, points_y, center_x, center_y) &gt; r, 0, 1)
    )
}

# 点的个数
sizes &lt;- c(1000, 10000, 100000, 1000000, 10000000)

# 估计的 PI 值
estimated_pi &lt;- sapply(sizes, function(size) {
    points &lt;- points_generator(size)
    sum(points$in_cycle) * 4 / size
})
print(estimated_pi)
# [1] 3.184000 3.146400 3.137880 3.143140 3.141889
</code></pre>

<p>模拟 <code>$1000$</code> 个随机点的结果如图所示</p>

<p><img src="/images/cn/2017-12-17-mcmc-and-gibbs-sampling/mc-pi-simulation.png" alt="" /></p>

<p>对于简单的分布 <code>$p\left(x\right)$</code>，我们可以相对容易的生成其样本，但对于复杂的分布或高维的分布，样本的生成就比较困难了<sup class="footnote-ref" id="fnref:rickjin2013lda"><a href="#fn:rickjin2013lda">1</a></sup>，例如：</p>

<ol>
<li><code>$p\left(x\right) = \dfrac{\tilde{p}\left(x\right)}{\int\tilde{p}\left(x\right) dx}$</code>，其中 <code>$\tilde{p}\left(x\right)$</code> 是可以计算的，而分母中的积分是无法显式计算的。</li>
<li><code>$p\left(x, y\right)$</code> 是一个二维分布函数，函数本身计算很困难，但其条件分布 <code>$p\left(x | y\right)$</code> 和 <code>$p\left(y | x\right)$</code> 计算相对简单。对于高维情况 <code>$p\left(\boldsymbol{x}\right)$</code>，这种情况则更加明显。</li>
</ol>

<p>这时候则需要更加复杂的模拟方法来生成样本了。</p>

<h2 id="马尔科夫链-markov-chain-mc">马尔科夫链 (Markov Chain, MC)</h2>

<p>马尔可夫过程 (Markov Process) 是因俄国数学家安德雷·安德耶维齐·马尔可夫 (Андрей Андреевич Марков) 而得名一个随机过程，在该随机过程中，给定当前状态和过去所有状态的条件下，其下一个状态的条件概率分布仅依赖于当前状态，通常具备离散状态的马尔科夫过程称之为马尔科夫链 (Markov Chain)。因此，马尔科夫链可以理解为一个有限状态机，给定了当前状态为 <code>$s_i$</code> 时，下一时刻状态为 <code>$s_j$</code> 的概率，不同状态之间变换的概率称之为转移概率。下图描述了 3 个状态 <code>$S_a, S_b, S_c$</code> 之间转换状态的马尔科夫链。</p>

<p><img src="/images/cn/2017-12-17-mcmc-and-gibbs-sampling/markov-chain-demo.png" alt="" /></p>

<p>对于马尔科夫链，我们设 <code>$X_t$</code> 表示 <code>$t$</code> 时刻随机变量 <code>$X$</code> 的取值，则马尔科夫链可以表示为</p>

<p><code>$$
P\left(X_{t+1} = s_j | X_0 = s_{i0}, X_1 = s_{i1}, ..., X_t = s_i\right) = P\left(X_{t+1} | X_t = s_i\right)
$$</code></p>

<p>其中，<code>$s_{i0}, s_{i1}, ..., s_i, s_j$</code> 为随机变量 <code>$X$</code> 可能的状态。则定义从一个状态 <code>$s_i$</code> 到另一个状态 <code>$s_j$</code> 的转移概率为</p>

<p><code>$$
P\left(i \to j\right) = P_{ij} = P\left(X_{t+1} | X_t = s_i\right)
$$</code></p>

<p>设 <code>$\pi_{k}^{\left(t\right)}$</code> 表示随机变量 <code>$X$</code> 在 <code>$t$</code> 时刻取值为 <code>$s_k$</code> 的概率，则 <code>$X$</code> 在 <code>$t+1$</code> 时刻取值为 <code>$s_i$</code> 的概率为</p>

<p><code>$$
\begin{equation}
\begin{split}
    \pi_{i}^{\left(t+1\right)} &amp;= P\left(X_{t+1} = s_i\right) \\
    &amp;= \sum_{k}{P\left(X_{t+1} = s_i | X_t = s_k\right) \cdot P\left(X_t = s_k\right)} \\
    &amp;= \sum_{k}{P_{ki} \cdot \pi_{k}^{\left(t\right)}}
\end{split}
\end{equation}
$$</code></p>

<p>我们通过一个例子来理解一下马尔科夫链，我们使用 LDA 数学八卦<sup class="footnote-ref" id="fnref:rickjin2013lda"><a href="#fn:rickjin2013lda">1</a></sup>一文中的例子，对于人口，我们将其经济状况分为 3 类：下层，中层和上层，其父代到子代收入阶层的转移情况如表所示</p>

<table>
<thead>
<tr>
<th align="center">父代阶层\子代阶层</th>
<th align="center">下层</th>
<th align="center">中层</th>
<th align="center">下层</th>
</tr>
</thead>

<tbody>
<tr>
<td align="center">下层</td>
<td align="center">0.65</td>
<td align="center">0.28</td>
<td align="center">0.07</td>
</tr>

<tr>
<td align="center">中层</td>
<td align="center">0.15</td>
<td align="center">0.67</td>
<td align="center">0.18</td>
</tr>

<tr>
<td align="center">上层</td>
<td align="center">0.12</td>
<td align="center">0.36</td>
<td align="center">0.52</td>
</tr>
</tbody>
</table>

<p>我们利用矩阵的形式表示转移概率</p>

<p><code>$$
P =
\left\lgroup
\begin{array}{cccc}
    P_{11} &amp; P_{12} &amp; \cdots &amp; P_{1n} \\
    P_{21} &amp; P_{22} &amp; \cdots &amp; P_{2n} \\
    \vdots &amp; \vdots &amp;        &amp; \vdots \\
    P_{n1} &amp; P_{n2} &amp; \cdots &amp; P_{nn}
    \end{array}
\right\rgroup
$$</code></p>

<p>则</p>

<p><code>$$
\pi^{\left(t+1\right)} = \pi^{\left(t\right)} P
$$</code></p>

<p>假设初始概率分布为 <code>$\pi_0 = \left(0.21, 0.68, 0.11\right)$</code>，则计算前 <code>$n$</code> 代人的阶层分布情况如下</p>

<pre><code class="language-r"># 转移矩阵
p &lt;- matrix(c(0.65, 0.28, 0.07,
              0.15, 0.67, 0.18,
              0.12, 0.36, 0.52),
            3, 3, byrow = T)
# 初始概率
pi &lt;- matrix(c(0.21, 0.68, 0.11), 1, 3, byrow = T)

# 迭代变化
for (i in 1:10) {
    pi_current &lt;- pi[i, ]
    pi_next &lt;- pi_current %*% p
    pi &lt;- rbind(pi, pi_next)
}

colnames(pi) &lt;- c('下层', '中层', '上层')
rownames(pi) &lt;- 0:10
print(pi)
#         下层      中层      上层
# 0  0.2100000 0.6800000 0.1100000
# 1  0.2517000 0.5540000 0.1943000
# 2  0.2700210 0.5116040 0.2183750
# 3  0.2784592 0.4969956 0.2245452
# 4  0.2824933 0.4917919 0.2257148
# 5  0.2844752 0.4898560 0.2256688
# 6  0.2854675 0.4890974 0.2254351
# 7  0.2859707 0.4887828 0.2252465
# 8  0.2862280 0.4886450 0.2251270
# 9  0.2863602 0.4885817 0.2250581
# 10 0.2864283 0.4885515 0.2250201
</code></pre>

<p>可以看出，从第 7 代人开始，分布就基本稳定下来了，如果将初值概率换成 <code>$\pi_0 = \left(0.75, 0.15, 0.1\right)$</code>，结果会是如何呢？</p>

<pre><code class="language-r">pi &lt;- matrix(c(0.75, 0.15, 0.1), 1, 3, byrow = T)

for (i in 1:10) {
    pi_current &lt;- pi[i, ]
    pi_next &lt;- pi_current %*% p
    pi &lt;- rbind(pi, pi_next)
}

colnames(pi) &lt;- c('下层', '中层', '上层')
rownames(pi) &lt;- 0:10
print(pi)
#         下层      中层      上层
# 0  0.7500000 0.1500000 0.1000000
# 1  0.5220000 0.3465000 0.1315000
# 2  0.4070550 0.4256550 0.1672900
# 3  0.3485088 0.4593887 0.1921025
# 4  0.3184913 0.4745298 0.2069789
# 5  0.3030363 0.4816249 0.2153388
# 6  0.2950580 0.4850608 0.2198812
# 7  0.2909326 0.4867642 0.2223032
# 8  0.2887972 0.4876223 0.2235805
# 9  0.2876912 0.4880591 0.2242497
# 10 0.2871181 0.4882830 0.2245989
</code></pre>

<p>可以看出从第 9 代人开始，分布又变得稳定了，这也就是说分布收敛情况是不随初始概率分布 <code>$\pi_0$</code> 的变化而改变的。则对于具有如下特征的马尔科夫链</p>

<ol>
<li>非周期性，可以简单理解为如果一个状态有自环，或者与一个非周期的状态互通，则是非周期的。</li>
<li>不可约性，即任意两个状态都是互通的。</li>
</ol>

<p>则这样的马尔科夫链，无论 <code>$\pi_0$</code> 取值如何，最终随机变量的分布都会收敛于 <code>$\pi^*$</code>，即</p>

<p><code>$$
\pi^* = \lim_{t \to \infty}{\pi^{\left(0\right)} \boldsymbol{P}^t}
$$</code></p>

<p><code>$\pi^*$</code> 称之为这个马尔科夫链的平稳分布。</p>

<h2 id="马尔科夫链蒙特卡洛方法-mcmc">马尔科夫链蒙特卡洛方法 (MCMC)</h2>

<p>构造一个转移矩阵为 <code>$P$</code> 的马尔科夫链，如果其能收敛到平稳分布 <code>$p\left(x\right)$</code>，则可以从任意一个状态 <code>$x_0$</code> 出发，得到一个状态转移序列 <code>$x_0, x_1, ..., x_n, x_{n+1}, ...$</code>，如果马尔科夫链在第 <code>$n$</code> 部收敛，我们就可以得到服从分布 <code>$p\left(x\right)$</code> 的样本 <code>$x_n, x_{n+1}, ...$</code>。因此，利用马尔科夫链的平稳性生成数据的样本的关键就在于如何构造一个状态转移矩阵 <code>$P$</code>，使得其平稳分布为 <code>$p\left(x\right)$</code>。</p>

<p>如果对于任意的 <code>$i, j$</code>，马尔科夫链的转移矩阵 <code>$P$</code> 和分布 <code>$\pi\left(x\right)$</code> 满足</p>

<p><code>$$
\pi\left(i\right) P_{ij} = \pi\left(j\right) P_{ji}
$$</code></p>

<p>则称 <code>$\pi\left(x\right)$</code> 为马尔科夫链的平稳分布，这称为<strong>细致平稳条件</strong>。对于一个马尔科夫链，通常情况下</p>

<p><code>$$
p\left(i\right) q\left(i, j\right) \neq p\left(j\right) q\left(j, i\right)
$$</code></p>

<p>其中 <code>$p\left(i, j\right)$</code> 表示状态从 <code>$i$</code> 转移到 <code>$j$</code> 的概率。因此，为了构造满足细致平稳条件，我们引入一个<strong>接受概率</strong> <code>$\alpha\left(i, j\right)$</code>，使得</p>

<p><code>$$
p\left(i\right) q\left(i, j\right) \alpha\left(i, j\right) = p\left(j\right) q\left(j, i\right) \alpha\left(j, i\right)
$$</code></p>

<p>最简单的，我们取</p>

<p><code>$$
\alpha\left(i, j\right) = p\left(j\right) q\left(j, i\right), \alpha\left(j, i\right) = p\left(i\right) q\left(i, j\right)
$$</code></p>

<p>即可保证细致平稳性。通过引入接受概率，我们将原始的马尔科夫链改造为具有新的转移矩阵的马尔科夫链。在原始马尔科夫链上以概率 <code>$q\left(i, j\right)$</code> 从状态 <code>$i$</code> 转移到状态 <code>$j$</code> 时，我们以概率 <code>$\alpha\left(i, j\right)$</code> 接受这个转移，因此在新的马尔科夫链上的转移概率为 <code>$q\left(i, j\right) \alpha\left(i, j\right)$</code>。在新的马尔科夫链转移的过程中，如果接受概率 <code>$\alpha\left(i, j\right)$</code> 过小，则可能导致存在大量的拒绝转移，马尔科夫链则很难收敛到平稳分布 <code>$p\left(x\right)$</code>，因此我们对 <code>$\alpha\left(i, j\right), \alpha\left(j, i\right)$</code> 进行同比例放大，将其中较大的数放大至 <code>$1$</code>，则可以增加接受跳转的概率，从而更快的收敛到平稳分布。因此，我们可以取</p>

<p><code>$$
\alpha\left(i, j\right) = \min \left\lbrace\dfrac{p\left(j\right) q\left(j, i\right)}{p\left(i\right) q\left(i, j\right)}, 1\right\rbrace
$$</code></p>

<p>这样我们就得到了 Metropolis-Hastings 算法</p>



<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">


<div><pre class="pseudocode">
\begin{algorithm}
\caption{Metropolis-Hastings 算法}
\begin{algorithmic}
\STATE $X_0 \gets x_0$
\FOR{$t = 0, 1, 2, ...$}
    \STATE $X_t = x_t$
    \STATE sample $y \sim q\left(x | x_t\right)$
    \STATE sample $u \sim Uniform[0, 1]$
    \IF{$u < \alpha\left(x_t, y\right) = \min\left\lbrace\dfrac{p\left(j\right) q\left(j, i\right)}{p\left(i\right) q\left(i, j\right)}, 1\right\rbrace$}
        \STATE $X_{t+1} \gets y$
    \ELSE
        \STATE $X_{t+1} \gets x_t$
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<h2 id="吉布斯采样-gibbs-sampling">吉布斯采样 (Gibbs Sampling)</h2>

<p>对于 Metropolis-Hastings 算法，由于存在接受跳转概率 <code>$\alpha &lt; 1$</code>，因此为了提高算法效率，我们尝试构建一个转移矩阵，使得 <code>$\alpha = 1$</code>。以二维情形为例，对于概率分布 <code>$p\left(x, y\right)$</code>，考虑两个点 <code>$A\left(x_1, y_1\right)$</code> 和 <code>$B\left(x_1, y_2\right)$</code></p>

<p><code>$$
\begin{equation}
\begin{split}
p\left(x_1, y_1\right) p\left(y_2 | x_1\right) &amp;= p\left(x_1\right) p\left(y_1 | x_1\right) p\left(y_2 | x_1\right) \\
p\left(x_1, y_2\right) p\left(y_1 | x_1\right) &amp;= p\left(x_1\right) p\left(y_2 | x_1\right) p\left(y_1 | x_1\right)
\end{split}
\end{equation}
$$</code></p>

<p>可得</p>

<p><code>$$
\begin{equation}
\begin{split}
p\left(x_1, y_1\right) p\left(y_2 | x_1\right) &amp;= p\left(x_1, y_2\right) p\left(y_1 | x_1\right) \\
p\left(A\right) p\left(y_2 | x_1\right) &amp;= p\left(B\right) p\left(y_1 | x_1\right)
\end{split}
\end{equation}
$$</code></p>

<p>可以得出在 <code>$x = x_1$</code> 上任意两点之间进行转移均满足细致平稳条件，同理可得在 <code>$y = y_1$</code>上也满足。因此，对于二维情况，我们构建满足如下调价的概率转移矩阵 <code>$Q$</code></p>

<p><code>$$
\begin{equation}
\begin{split}
&amp;Q\left(A \to B\right) = p\left(y_B | x_1\right), \text{for} \ x_A = x_B = x_1 \\
&amp;Q\left(A \to C\right) = p\left(x_C | y_1\right), \text{for} \ y_A = y_C = y_1 \\
&amp;Q\left(A \to D\right) = 0, \text{others}
\end{split}
\end{equation}
$$</code></p>

<p>则对于平面上任意两点 <code>$X, Y$</code> 满足细致平稳条件</p>

<p><code>$$
p\left(X\right) Q\left(X \to Y\right) = p\left(Y\right) Q\left(Y \to X\right)
$$</code></p>

<p>对于如上过程，我们不难推广到多维情况，将 <code>$x_1$</code> 变为多维情形 <code>$\boldsymbol{x_1}$</code>，容易验证细致平稳条件依旧成立。</p>

<p><code>$$
p\left(\boldsymbol{x_1}, y_1\right) p\left(y_2 | \boldsymbol{x_1}\right) = p\left(\boldsymbol{x_1}, y_2\right) p\left(y_1 | \boldsymbol{x_1}\right)
$$</code></p>

<p>对于 <code>$n$</code> 维的情况，通过不断的转移得到样本 <code>$\left(x_1^{\left(1\right)}, x_2^{\left(1\right)}, ..., x_n^{\left(1\right)}\right)$</code>, <code>$\left(x_1^{\left(2\right)}, x_2^{\left(2\right)}, ..., x_n^{\left(2\right)}\right)$</code>, &hellip;，当马尔科夫链收敛后，后续得到的样本即为 <code>$p\left(x_1, x_2, ..., x_n\right)$</code> 的样本，收敛之前的这一阶段我们称之为 <strong>burn-in period</strong>。在进行转移的时候，坐标轴轮换的采样方法并不是必须的，可以在坐标轴轮换中引入随机性。至此，我们就得到了吉布斯采样算法</p>



<div><pre class="pseudocode">
\begin{algorithm}
\caption{Gibbs Sampling 算法}
\begin{algorithmic}
\STATE initialize $x^{\left(0\right)}, \text{for} \ i = 1, 2, ..., n$
\FOR{$t = 0, 1, 2, ...$}
    \STATE $x_1^{\left(t+1\right)} \sim p\left(x_1 | x_2^{\left(t\right)}, x_3^{\left(t\right)}, ..., x_n^{\left(t\right)}\right)$
    \STATE $x_2^{\left(t+1\right)} \sim p\left(x_2 | x_1^{\left(t\right)}, x_3^{\left(t\right)}, ..., x_n^{\left(t\right)}\right)$
    \STATE $...$
    \STATE $x_n^{\left(t+1\right)} \sim p\left(x_n | x_1^{\left(t\right)}, x_2^{\left(t\right)}, ..., x_{n-1}^{\left(t\right)}\right)$
\ENDFOR
\end{algorithmic}
\end{algorithm}
</pre></div>


<p>我们以二元高斯分布为例，演示如何用 Gibbs Sampling 方法进行采样，二元高斯分布定义为</p>

<p><code>$$
\left(X, Y\right) \sim \mathcal{N}\left(\boldsymbol{\mu}, \boldsymbol{\Sigma}\right)
$$</code></p>

<p>其中</p>

<p><code>$$
\boldsymbol{\mu} = \left\lgroup \begin{array}{c} \mu_X \\ \mu_Y \end{array} \right\rgroup, \boldsymbol{\Sigma} = \left\lgroup \begin{array}{cc} \sigma_X^2 &amp; \rho \sigma_X \sigma_Y \\ \rho \sigma_X \sigma_Y &amp; \sigma_Y^2 \end{array} \right\rgroup
$$</code></p>

<p>因此可得</p>

<p><code>$$
\begin{equation}
\begin{split}
\mu_{x|y} &amp;= \mu_x + \sigma_x \rho_x\left(\dfrac{y - \mu_y}{\sigma_y}\right), \sigma_{x|y}^2 = \sigma_x^2 \left(1 - \rho^2\right) \\
\mu_{y|x} &amp;= \mu_y + \sigma_y \rho_y\left(\dfrac{y - \mu_x}{\sigma_x}\right), \sigma_{y|x}^2 = \sigma_y^2 \left(1 - \rho^2\right)
\end{split}
\end{equation}
$$</code></p>

<p>则</p>

<p><code>$$
\begin{equation}
\begin{split}
X|Y &amp;= \mu_{x|y} + \sigma_{x|y} \mathcal{N}\left(0, 1\right) \\
Y|X &amp;= \mu_{y|x} + \sigma_{y|x} \mathcal{N}\left(0, 1\right)
\end{split}
\end{equation}
$$</code></p>

<p>对于 <code>$\mu_x = 0, \mu_y = 0, \sigma_x = 10, \sigma_y = 1, \rho = 0.8$</code>，采样过程如下</p>

<pre><code class="language-r">mu_x &lt;- 0
mu_y &lt;- 0
sigma_x &lt;- 10
sigma_y &lt;- 1
rho &lt;- 0.8

iter &lt;- 1000
samples &lt;- matrix(c(mu_x, mu_y), 1, 2, byrow = T)

set.seed(112358)
for (i in 1:iter) {
    sample_x &lt;- mu_x +
        sigma_x * rho * (samples[i, 2] - mu_y) / sigma_y +
        sigma_x * sqrt(1 - rho^2) * rnorm(1)
    sample_y &lt;- mu_y +
        sigma_y * rho * (sample_x - mu_x) / sigma_x +
        sigma_y * sqrt(1 - rho^2) * rnorm(1)
    samples &lt;- rbind(samples, c(sample_x, sample_y))
}
</code></pre>

<p>可视化结果如下</p>

<p><img src="/images/cn/2017-12-17-mcmc-and-gibbs-sampling/gibbs-sampling-bivariate-guassian-distribution.gif" alt="" /></p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:rickjin2013lda">LDA 数学八卦，靳志辉，2013
 <a class="footnote-return" href="#fnref:rickjin2013lda">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
    <item>
      <title>特征值分解，奇异值分解和主成份分析 (EVD, SVD and PCA)</title>
      <link>http://zeqiang.fun/user_blogdown/cn/2017/12/evd-svd-and-pca/</link>
      <pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>http://zeqiang.fun/user_blogdown/cn/2017/12/evd-svd-and-pca/</guid>
      <description>
        <![CDATA[
        

<p><code>$\renewcommand{\diag}{\operatorname{diag}}\renewcommand{\cov}{\operatorname{cov}}$</code></p>

<h2 id="准备知识">准备知识</h2>

<h3 id="向量与基">向量与基</h3>

<p>首先，定义 <code>$\boldsymbol{\alpha}$</code> 为列向量，则维度相同的两个向量 <code>$\boldsymbol{\alpha}, \boldsymbol{\beta}$</code> 的内积可以表示为：</p>

<p><code>$$\boldsymbol{\alpha} \cdot \boldsymbol{\beta} = \boldsymbol{\alpha}^T \boldsymbol{\beta} = \sum_{i=1}^{n}{\alpha_i b_i}$$</code></p>

<p>后续为了便于理解，我们以二维向量为例，则 <code>$\boldsymbol{\alpha} = \left(x_1, y_1\right)^T, \boldsymbol{\beta} = \left(x_2, y_2\right)^T$</code>，在直角座标系中可以两个向量表示如下：</p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/vector-inner-product-and-projection.png" alt="" /></p>

<p>我们从 <code>$A$</code> 点向向量 <code>$\boldsymbol{\beta}$</code> 的方向做一条垂线，交于点 <code>$C$</code>，则称 <code>$OC$</code> 为 <code>$OA$</code> 在 <code>$OB$</code> 方向上的投影。设向量 <code>$\boldsymbol{\alpha}$</code> 和向量 <code>$\boldsymbol{\beta}$</code> 的夹角为 <code>$\theta$</code>，则：</p>

<p><code>$$\cos \left(\theta\right) = \dfrac{\boldsymbol{\alpha} \cdot \boldsymbol{\beta}}{\lvert\boldsymbol{\alpha}\rvert \lvert\boldsymbol{\beta}\rvert}$$</code></p>

<p>其中，<code>$\lvert\boldsymbol{\alpha}\rvert = \sqrt{x_1^2 + y_1^2}$</code>，则 <code>$OC$</code> 的长度为 <code>$\lvert\boldsymbol{\alpha}\rvert \cos\left(\theta\right)$</code>。</p>

<p>在 <code>$n$</code> 维的线性空间 <code>$V$</code> 中，<code>$n$</code> 个线性无关的向量 <code>$\boldsymbol{\epsilon_1, \epsilon_2, ..., \epsilon_n}$</code> 称为 <code>$V$</code> 的一组<strong>基</strong>。则对于 <code>$V$</code> 中的任一向量 <code>$\boldsymbol{\alpha}$</code> 可以由这组基线性表示出来：</p>

<p><code>$$\boldsymbol{\alpha} = x_1 \boldsymbol{\epsilon_1} + x_2 \boldsymbol{\epsilon_2} + ... + x_n \boldsymbol{\epsilon_n}$$</code></p>

<p>则对于向量 <code>$\boldsymbol{\alpha} = \left(3, 2\right)^T$</code>，可以表示为：</p>

<p><code>$$\boldsymbol{\alpha} = 2 \left(1, 0\right)^T + 3 \left(0, 1\right)^T$$</code></p>

<p>其中 <code>$\left(1, 0\right)^T$</code> 和 <code>$\left(0, 1\right)^T$</code> 为二维空间中的一组基。</p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/vector-bases.png" alt="" /></p>

<p>因此，当我们确定好一组基之后，我们仅需利用向量在基上的投影值即可表示对应的向量。一般情况下，我们会选择由坐标轴方向上的单位向量构成的基作为默认的基来表示向量，但我们仍可选择其他的基。例如，我们选择 <code>$\left(-\dfrac{1}{\sqrt{2}}, \dfrac{1}{\sqrt{2}}\right)$</code> 和 <code>$\left(\dfrac{1}{\sqrt{2}}, \dfrac{1}{\sqrt{2}}\right)$</code> 作为一组基，则向量在这组基上的坐标为 <code>$\left(-\dfrac{1}{\sqrt{2}}, \dfrac{5}{\sqrt{2}}\right)$</code>，示例如下：</p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/vector-change-of-bases.png" alt="" /></p>

<h3 id="线性变换">线性变换</h3>

<p>以二维空间为例，定义一个如下矩阵</p>

<p><code>$$
A = \left\lgroup
    \begin{array}{cc}
        a_{11} &amp; a_{12} \\
        a_{21} &amp; a_{22}
    \end{array}
\right\rgroup
$$</code></p>

<p>则对于二维空间中一个向量 <code>$\boldsymbol{\alpha} = \left(x, y\right)^T$</code> ，通过同上述矩阵进行乘法运算，可得</p>

<p><code>$$
\boldsymbol{\alpha'} = A \boldsymbol{\alpha} =
\left\lgroup
    \begin{array}{cc}
        a_{11} &amp; a_{12} \\
        a_{21} &amp; a_{22}
    \end{array}
\right\rgroup
\left\lgroup
    \begin{array}{c}
        x \\
        y
    \end{array}
\right\rgroup = 
\left\lgroup
    \begin{array}{c}
        x' \\
        y'
    \end{array}
\right\rgroup
$$</code></p>

<p>(1) 通过变换将任意一个点 <code>$x$</code> 变成它关于 <code>$x$</code> 轴对称的点 <code>$x'$</code></p>

<p><code>$$
x' =
\left\lgroup
    \begin{array}{cc}
        1 &amp; 0 \\
        0 &amp; -1
    \end{array}
\right\rgroup
\left\lgroup
    \begin{array}{c}
        x \\
        y
    \end{array}
\right\rgroup = 
\left\lgroup
    \begin{array}{c}
        x \\
        -y
    \end{array}
\right\rgroup
$$</code></p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/vector-linear-transformation-1.png" alt="" /></p>

<p>(2) 通过变换将任意一个点 <code>$x$</code> 变成它关于 <code>$y = x$</code> 对称的点 <code>$x'$</code></p>

<p><code>$$
x' =
\left\lgroup
    \begin{array}{cc}
        0 &amp; 1 \\
        1 &amp; 0
    \end{array}
\right\rgroup
\left\lgroup
    \begin{array}{c}
        x \\
        y
    \end{array}
\right\rgroup = 
\left\lgroup
    \begin{array}{c}
        y \\
        x
    \end{array}
\right\rgroup
$$</code></p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/vector-linear-transformation-2.png" alt="" /></p>

<p>(3) 变换将任意一个点 <code>$x$</code> 变成在它与原点连线上，与原点距离伸缩为 <code>$|\lambda|$</code> 倍的点 <code>$x'$</code></p>

<p><code>$$
x' =
\left\lgroup
    \begin{array}{cc}
        \lambda &amp; 0 \\
        0 &amp; \lambda
    \end{array}
\right\rgroup
\left\lgroup
    \begin{array}{c}
        x \\
        y
    \end{array}
\right\rgroup = 
\left\lgroup
    \begin{array}{c}
        \lambda x \\
        \lambda y
    \end{array}
\right\rgroup
$$</code></p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/vector-linear-transformation-3.png" alt="" /></p>

<p>(4) 通过变换将任意一个点 <code>$x$</code> 绕原点旋转了角度 <code>$\theta$</code> 的点 <code>$x'$</code></p>

<p><code>$$
\begin{equation}
\begin{split}
x'&amp; =
\left\lgroup
    \begin{array}{cc}
        \cos \theta &amp; -\sin \theta \\
        \sin \theta &amp; \cos \theta
    \end{array}
\right\rgroup
\left\lgroup
    \begin{array}{c}
        x \\
        y
    \end{array}
\right\rgroup \\
&amp; = 
\left\lgroup
    \begin{array}{cc}
        \cos \theta &amp; -\sin \theta \\
        \sin \theta &amp; \cos \theta
    \end{array}
\right\rgroup
\left\lgroup
    \begin{array}{c}
        r \cos \phi \\
        r \sin \phi
    \end{array}
\right\rgroup \\
&amp; = 
\left\lgroup
    \begin{array}{c}
        r \cos \left(\phi + \theta\right) \\
        r \sin \left(\phi + \theta\right)
    \end{array}
\right\rgroup
\end{split}
\end{equation}
$$</code></p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/vector-linear-transformation-4.png" alt="" /></p>

<p>(5) 变换将任意一个点 <code>$x$</code> 变成它在 <code>$x$</code> 轴上 的投影点 <code>$x'$</code></p>

<p><code>$$
x' =
\left\lgroup
    \begin{array}{cc}
        1 &amp; 0 \\
        0 &amp; 0
    \end{array}
\right\rgroup
\left\lgroup
    \begin{array}{c}
        x \\
        y
    \end{array}
\right\rgroup = 
\left\lgroup
    \begin{array}{c}
        x \\
        0
    \end{array}
\right\rgroup
$$</code></p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/vector-linear-transformation-5.png" alt="" /></p>

<h2 id="特征值分解">特征值分解</h2>

<p>设 <code>$A$</code> 是线性空间 <code>$V$</code> 上的一个线性变换，对于一个非零向量 <code>$\boldsymbol{\alpha} = \left(x_1, x_2, ..., x_n\right)^T$</code> 使得</p>

<p><code>$$A \boldsymbol{\alpha} = \lambda \boldsymbol{\alpha}$$</code></p>

<p>则 <code>$\lambda$</code> 称为 <code>$A$</code> 的一个<strong>特征值</strong>，<code>$\boldsymbol{\alpha}$</code> 称为 <code>$A$</code> 的一个<strong>特征向量</strong>。通过</p>

<p><code>$$
\begin{equation}
\begin{split}
A \boldsymbol{\alpha} &amp;= \lambda \boldsymbol{\alpha} \\
A \boldsymbol{\alpha} - \lambda \boldsymbol{\alpha} &amp;= 0 \\
\left(A - \lambda E\right) \boldsymbol{\alpha} &amp;= 0 \\
A - \lambda E &amp;= 0
\end{split}
\end{equation}
$$</code></p>

<p>其中 <code>$E = \diag \left(1, 1, ..., 1\right)$</code> 为单位对角阵，即可求解其特征值，进而求解特征向量。若 <code>$A$</code> 是一个可逆矩阵，则上式可以改写为：</p>

<p><code>$$
A = Q \sum Q^{-1}
$$</code></p>

<p>这样，一个方阵 <code>$A$</code> 就被一组特征值和特征向量表示了。例如，对于如下矩阵进行特征值分解</p>

<p><code>$$
A = \left\lgroup
\begin{array}{cccc}
    3 &amp; -2 &amp; -0.9 &amp; 0 \\
    -2 &amp; 4 &amp; 1 &amp; 0 \\
    0 &amp; 0 &amp; -1 &amp; 0 \\
    -0.5 &amp; -0.5 &amp; 0.1 &amp; 1
\end{array}
\right\rgroup
$$</code></p>

<pre><code class="language-r">A &lt;- matrix(c(3, -2, -0.9, 0,
              -2, 4, 1, 0,
              0, 0, -1, 0,
              -0.5, -0.5, 0.1, 1),
            4, 4, byrow = T)
A_eig &lt;- eigen(A)
print(A_eig)

# eigen() decomposition
# $values
# [1]  5.561553  1.438447  1.000000 -1.000000
# 
# $vectors
#             [,1]       [,2] [,3]        [,4]
# [1,] -0.61530186  0.4176225    0  0.15282144
# [2,]  0.78806410  0.3260698    0 -0.13448286
# [3,]  0.00000000  0.0000000    0  0.97805719
# [4,] -0.01893678 -0.8480979    1 -0.04431822
</code></pre>

<p>则利用特征值和特征向量，可以还原原矩阵</p>

<pre><code class="language-r">A_re &lt;- A_eig$vectors %*%
    diag(A_eig$values) %*%
    solve(A_eig$vectors)
print(A_re)

#      [,1] [,2] [,3] [,4]
# [1,]  3.0 -2.0 -0.9    0
# [2,] -2.0  4.0  1.0    0
# [3,]  0.0  0.0 -1.0    0
# [4,] -0.5 -0.5  0.1    1
</code></pre>

<h2 id="奇异值分解">奇异值分解</h2>

<p>特征值分解针对的是方阵，对于一个 <code>$m*n$</code> 的矩阵是无法进行特征值分解的，这时我们就需要使用奇异值分解来解决这个问题。对于 <code>$m*n$</code> 的矩阵 <code>$A$</code>，可得 <code>$A A^T$</code> 是一个 <code>$m*m$</code> 的方阵，则针对 <code>$A A^T$</code>，通过 <code>$\left(A A^T\right) \boldsymbol{\alpha} = \lambda \boldsymbol{\alpha}$</code>，即可求解这个方阵的特征值和特征向量。针对矩阵 <code>$A$</code>，奇异值分解是将原矩阵分解为三个部分</p>

<p><code>$$
A_{m*n} = U_{m*r} \sum\nolimits_{r*r} V_{r*n}^T
$$</code></p>

<p>其中 <code>$U$</code> 称之为左奇异向量，即为 <code>$A A^T$</code> 单位化后的特征向量；<code>$V$</code> 称之为右奇异向量，即为 <code>$A^T A$</code> 单位化后的特征向量；<code>$\sum$</code>矩阵对角线上的值称之为奇异值，即为 <code>$A A^T$</code> 或 <code>$A^T A$</code> 特征值的平方根。</p>

<p>我们利用经典的 lena 图片展示一下 SVD 的作用，lena图片为一张 <code>$512*512$</code> 像素的彩色图片</p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/lena-std.png" alt="" /></p>

<p>我们对原始图片进行灰度处理后，进行特征值分解，下图中从左到右，从上到下分别是原始的灰度图像，利用 20 个左奇异向量和 20 个右奇异向量重构图像，利用 50 个左奇异向量和 100 个右奇异向量重构图像，利用 200 个左奇异向量和 200 个右奇异向量重构图像。</p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/lena-reconstruction.png" alt="" /></p>

<p>从图中可以看出，我们仅用了 200 个左奇异向量和 200 个右奇异向量重构图像与原始灰度图像已经基本看不出任何区别。因此，我们利用 SVD 可以通过仅保留较大的奇异值实现数据的压缩。</p>

<h2 id="主成份分析">主成份分析</h2>

<p>主成份分析<sup class="footnote-ref" id="fnref:wold1987principal"><a href="#fn:wold1987principal">1</a></sup>可以通俗的理解为一种降维方法。其目标可以理解为将一个 <code>$m$</code> 维的数据转换称一个 <code>$k$</code> 维的数据，其中 <code>$k &lt; m$</code>。对于具有 <code>$n$</code> 个样本的数据集，设 <code>$\boldsymbol{x_i}$</code> 表示 <code>$m$</code> 维的列向量，则</p>

<p><code>$$
X_{m*n} = \left(\boldsymbol{x_1}, \boldsymbol{x_2}, ..., \boldsymbol{x_n}\right)
$$</code></p>

<p>对每一个维度进行零均值化，即减去这一维度的均值</p>

<p><code>$$
X'_{m*n} = X - \boldsymbol{u}\boldsymbol{h}
$$</code></p>

<p>其中，<code>$\boldsymbol{u}$</code> 是一个 <code>$m$</code> 维的行向量，<code>$\boldsymbol{u}[m] = \dfrac{1}{n} \sum_{i=1}^{n} X[m, i]$</code>；<code>$h$</code> 是一个值全为 <code>$1$</code> 的 <code>$n$</code> 维行向量。</p>

<p>对于两个随机变量，我们可以利用协方差简单表示这两个变量之间的相关性</p>

<p><code>$$
\cov \left(x, y\right) = E \left(\left(x - \mu_x\right) \left(x - \mu_x\right)\right)
$$</code></p>

<p>对于已经零均值化后的矩阵 <code>$X'$</code>，计算得出如下矩阵</p>

<p><code>$$
C = \dfrac{1}{n} X' X'^T = \left\lgroup
\begin{array}{cccc}
   \dfrac{1}{n} \sum_{i=1}^{n} x_{1i}^2 &amp; \dfrac{1}{n} \sum_{i=1}^{n} x_{1i} x_{2i} &amp; \cdots &amp; \dfrac{1}{n} \sum_{}^{} x_{1i} x_{ni} \\
   \dfrac{1}{n} \sum_{i=1}^{n} x_{2i} x_{1i} &amp; \dfrac{1}{n} \sum_{i=1}^{n} x_{2i}^2 &amp; \cdots &amp; \dfrac{1}{n} \sum_{}^{} x_{2i} x_{ni} \\
   \vdots &amp; \vdots &amp; &amp; \vdots \\
   \dfrac{1}{n} \sum_{i=1}^{n} x_{mi} x_{1i} &amp; \dfrac{1}{n} \sum_{i=1}^{n} x_{mi} x_{2i} &amp; \cdots &amp; \dfrac{1}{n} \sum_{}^{} x_{mi}^2 \\
\end{array}
\right\rgroup
$$</code></p>

<p>因为矩阵 <code>$X'$</code> 已经经过了零均值化处理，因此矩阵 <code>$C$</code> 中对角线上的元素为维度 <code>$m$</code> 的方差，其他元素则为两个维度之间的协方差。</p>

<p>从 PCA 的目标来看，我们则可以通过求解矩阵 <code>$C$</code> 的特征值和特征向量，将其特征值按照从大到小的顺序按行重排其对应的特征向量，则取前 <code>$k$</code> 个，则实现了数据从 <code>$m$</code> 维降至 <code>$k$</code> 维。</p>

<p>例如，我们将二维数据</p>

<p><code>$$
\left\lgroup
\begin{array}
  -1 &amp; -1 &amp; 0 &amp; 0 &amp; 2 \\
  -2 &amp; 0 &amp; 0 &amp; 1 &amp; 1
\end{array}
\right\rgroup
$$</code></p>

<p>降至一维</p>

<pre><code class="language-r">x &lt;- matrix(c(-1, -1, 0, 0, 2,
              -2, 0, 0, 1, 1),
            5, 2, byrow = F)
x_pca &lt;- prcomp(x)

print(pca)
# Standard deviations (1, .., p=2):
# [1] 1.5811388 0.7071068
# 
# Rotation (n x k) = (2 x 2):
#            PC1        PC2
# [1,] 0.7071068  0.7071068
# [2,] 0.7071068 -0.7071068

summary(pca)
# Importance of components:
#                           PC1    PC2
# Standard deviation     1.5811 0.7071
# Proportion of Variance 0.8333 0.1667
# Cumulative Proportion  0.8333 1.0000

x_ &lt;- predict(x_pca, x)
print(x_)
#             PC1        PC2
# [1,] -2.1213203  0.7071068
# [2,] -0.7071068 -0.7071068
# [3,]  0.0000000  0.0000000
# [4,]  0.7071068 -0.7071068
# [5,]  2.1213203  0.7071068
</code></pre>

<p>降维的投影结果如图所示</p>

<p><img src="/images/cn/2017-12-11-evd-svd-and-pca/pca-projection.png" alt="" /></p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:wold1987principal">Wold, Svante, Kim Esbensen, and Paul Geladi. &ldquo;Principal component analysis.&rdquo; <em>Chemometrics and intelligent laboratory systems</em> 2.1-3 (1987): 37-52.
 <a class="footnote-return" href="#fnref:wold1987principal">↩</a></li>
</ol>
</div>

        ]]>
      </description>
    </item>
    
  </channel>
</rss>
